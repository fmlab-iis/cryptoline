(* server@szu: -v -jobs 8 -no_carry_constraint -slicing -isafety invntt_fast.cl
Parsing Cryptoline file:                [OK]            0.322784 seconds
Checking well-formedness:               [OK]            0.057714 seconds
Transforming to SSA form:               [OK]            0.037407 seconds
Rewriting assignments:                  [OK]            0.037362 seconds
Verifying program safety:               [OK]            237.465760 seconds
Verifying range assertions:             [OK]            0.133421 seconds
Verifying range specification:          [OK]            129.077460 seconds
Rewriting value-preserved casting:      [OK]            0.000915 seconds
Verifying algebraic assertions:         [OK]            194.742007 seconds
Verifying algebraic specification:      [OK]            40800.145253 seconds
Verification result:                    [OK]            41362.048457 seconds
*) 



proc main (
  sint16 x,
  sint16 f000, sint16 f001, sint16 f002, sint16 f003,
  sint16 f004, sint16 f005, sint16 f006, sint16 f007,
  sint16 f008, sint16 f009, sint16 f010, sint16 f011,
  sint16 f012, sint16 f013, sint16 f014, sint16 f015,
  sint16 f016, sint16 f017, sint16 f018, sint16 f019,
  sint16 f020, sint16 f021, sint16 f022, sint16 f023,
  sint16 f024, sint16 f025, sint16 f026, sint16 f027,
  sint16 f028, sint16 f029, sint16 f030, sint16 f031,
  sint16 f032, sint16 f033, sint16 f034, sint16 f035,
  sint16 f036, sint16 f037, sint16 f038, sint16 f039,
  sint16 f040, sint16 f041, sint16 f042, sint16 f043,
  sint16 f044, sint16 f045, sint16 f046, sint16 f047,
  sint16 f048, sint16 f049, sint16 f050, sint16 f051,
  sint16 f052, sint16 f053, sint16 f054, sint16 f055,
  sint16 f056, sint16 f057, sint16 f058, sint16 f059,
  sint16 f060, sint16 f061, sint16 f062, sint16 f063,
  sint16 f064, sint16 f065, sint16 f066, sint16 f067,
  sint16 f068, sint16 f069, sint16 f070, sint16 f071,
  sint16 f072, sint16 f073, sint16 f074, sint16 f075,
  sint16 f076, sint16 f077, sint16 f078, sint16 f079,
  sint16 f080, sint16 f081, sint16 f082, sint16 f083,
  sint16 f084, sint16 f085, sint16 f086, sint16 f087,
  sint16 f088, sint16 f089, sint16 f090, sint16 f091,
  sint16 f092, sint16 f093, sint16 f094, sint16 f095,
  sint16 f096, sint16 f097, sint16 f098, sint16 f099,
  sint16 f100, sint16 f101, sint16 f102, sint16 f103,
  sint16 f104, sint16 f105, sint16 f106, sint16 f107,
  sint16 f108, sint16 f109, sint16 f110, sint16 f111,
  sint16 f112, sint16 f113, sint16 f114, sint16 f115,
  sint16 f116, sint16 f117, sint16 f118, sint16 f119,
  sint16 f120, sint16 f121, sint16 f122, sint16 f123,
  sint16 f124, sint16 f125, sint16 f126, sint16 f127,
  sint16 f128, sint16 f129, sint16 f130, sint16 f131,
  sint16 f132, sint16 f133, sint16 f134, sint16 f135,
  sint16 f136, sint16 f137, sint16 f138, sint16 f139,
  sint16 f140, sint16 f141, sint16 f142, sint16 f143,
  sint16 f144, sint16 f145, sint16 f146, sint16 f147,
  sint16 f148, sint16 f149, sint16 f150, sint16 f151,
  sint16 f152, sint16 f153, sint16 f154, sint16 f155,
  sint16 f156, sint16 f157, sint16 f158, sint16 f159,
  sint16 f160, sint16 f161, sint16 f162, sint16 f163,
  sint16 f164, sint16 f165, sint16 f166, sint16 f167,
  sint16 f168, sint16 f169, sint16 f170, sint16 f171,
  sint16 f172, sint16 f173, sint16 f174, sint16 f175,
  sint16 f176, sint16 f177, sint16 f178, sint16 f179,
  sint16 f180, sint16 f181, sint16 f182, sint16 f183,
  sint16 f184, sint16 f185, sint16 f186, sint16 f187,
  sint16 f188, sint16 f189, sint16 f190, sint16 f191,
  sint16 f192, sint16 f193, sint16 f194, sint16 f195,
  sint16 f196, sint16 f197, sint16 f198, sint16 f199,
  sint16 f200, sint16 f201, sint16 f202, sint16 f203,
  sint16 f204, sint16 f205, sint16 f206, sint16 f207,
  sint16 f208, sint16 f209, sint16 f210, sint16 f211,
  sint16 f212, sint16 f213, sint16 f214, sint16 f215,
  sint16 f216, sint16 f217, sint16 f218, sint16 f219,
  sint16 f220, sint16 f221, sint16 f222, sint16 f223,
  sint16 f224, sint16 f225, sint16 f226, sint16 f227,
  sint16 f228, sint16 f229, sint16 f230, sint16 f231,
  sint16 f232, sint16 f233, sint16 f234, sint16 f235,
  sint16 f236, sint16 f237, sint16 f238, sint16 f239,
  sint16 f240, sint16 f241, sint16 f242, sint16 f243,
  sint16 f244, sint16 f245, sint16 f246, sint16 f247,
  sint16 f248, sint16 f249, sint16 f250, sint16 f251,
  sint16 f252, sint16 f253, sint16 f254, sint16 f255
) =

{
  true
  &&
  (* range *)
  and [
    (-3329)@16 <=s f000, f000 <s 3329@16,
    (-3329)@16 <=s f001, f001 <s 3329@16,
    (-3329)@16 <=s f002, f002 <s 3329@16,
    (-3329)@16 <=s f003, f003 <s 3329@16,
    (-3329)@16 <=s f004, f004 <s 3329@16,
    (-3329)@16 <=s f005, f005 <s 3329@16,
    (-3329)@16 <=s f006, f006 <s 3329@16,
    (-3329)@16 <=s f007, f007 <s 3329@16,
    (-3329)@16 <=s f008, f008 <s 3329@16,
    (-3329)@16 <=s f009, f009 <s 3329@16,
    (-3329)@16 <=s f010, f010 <s 3329@16,
    (-3329)@16 <=s f011, f011 <s 3329@16,
    (-3329)@16 <=s f012, f012 <s 3329@16,
    (-3329)@16 <=s f013, f013 <s 3329@16,
    (-3329)@16 <=s f014, f014 <s 3329@16,
    (-3329)@16 <=s f015, f015 <s 3329@16,
    (-3329)@16 <=s f016, f016 <s 3329@16,
    (-3329)@16 <=s f017, f017 <s 3329@16,
    (-3329)@16 <=s f018, f018 <s 3329@16,
    (-3329)@16 <=s f019, f019 <s 3329@16,
    (-3329)@16 <=s f020, f020 <s 3329@16,
    (-3329)@16 <=s f021, f021 <s 3329@16,
    (-3329)@16 <=s f022, f022 <s 3329@16,
    (-3329)@16 <=s f023, f023 <s 3329@16,
    (-3329)@16 <=s f024, f024 <s 3329@16,
    (-3329)@16 <=s f025, f025 <s 3329@16,
    (-3329)@16 <=s f026, f026 <s 3329@16,
    (-3329)@16 <=s f027, f027 <s 3329@16,
    (-3329)@16 <=s f028, f028 <s 3329@16,
    (-3329)@16 <=s f029, f029 <s 3329@16,
    (-3329)@16 <=s f030, f030 <s 3329@16,
    (-3329)@16 <=s f031, f031 <s 3329@16,
    (-3329)@16 <=s f032, f032 <s 3329@16,
    (-3329)@16 <=s f033, f033 <s 3329@16,
    (-3329)@16 <=s f034, f034 <s 3329@16,
    (-3329)@16 <=s f035, f035 <s 3329@16,
    (-3329)@16 <=s f036, f036 <s 3329@16,
    (-3329)@16 <=s f037, f037 <s 3329@16,
    (-3329)@16 <=s f038, f038 <s 3329@16,
    (-3329)@16 <=s f039, f039 <s 3329@16,
    (-3329)@16 <=s f040, f040 <s 3329@16,
    (-3329)@16 <=s f041, f041 <s 3329@16,
    (-3329)@16 <=s f042, f042 <s 3329@16,
    (-3329)@16 <=s f043, f043 <s 3329@16,
    (-3329)@16 <=s f044, f044 <s 3329@16,
    (-3329)@16 <=s f045, f045 <s 3329@16,
    (-3329)@16 <=s f046, f046 <s 3329@16,
    (-3329)@16 <=s f047, f047 <s 3329@16,
    (-3329)@16 <=s f048, f048 <s 3329@16,
    (-3329)@16 <=s f049, f049 <s 3329@16,
    (-3329)@16 <=s f050, f050 <s 3329@16,
    (-3329)@16 <=s f051, f051 <s 3329@16,
    (-3329)@16 <=s f052, f052 <s 3329@16,
    (-3329)@16 <=s f053, f053 <s 3329@16,
    (-3329)@16 <=s f054, f054 <s 3329@16,
    (-3329)@16 <=s f055, f055 <s 3329@16,
    (-3329)@16 <=s f056, f056 <s 3329@16,
    (-3329)@16 <=s f057, f057 <s 3329@16,
    (-3329)@16 <=s f058, f058 <s 3329@16,
    (-3329)@16 <=s f059, f059 <s 3329@16,
    (-3329)@16 <=s f060, f060 <s 3329@16,
    (-3329)@16 <=s f061, f061 <s 3329@16,
    (-3329)@16 <=s f062, f062 <s 3329@16,
    (-3329)@16 <=s f063, f063 <s 3329@16,
    (-3329)@16 <=s f064, f064 <s 3329@16,
    (-3329)@16 <=s f065, f065 <s 3329@16,
    (-3329)@16 <=s f066, f066 <s 3329@16,
    (-3329)@16 <=s f067, f067 <s 3329@16,
    (-3329)@16 <=s f068, f068 <s 3329@16,
    (-3329)@16 <=s f069, f069 <s 3329@16,
    (-3329)@16 <=s f070, f070 <s 3329@16,
    (-3329)@16 <=s f071, f071 <s 3329@16,
    (-3329)@16 <=s f072, f072 <s 3329@16,
    (-3329)@16 <=s f073, f073 <s 3329@16,
    (-3329)@16 <=s f074, f074 <s 3329@16,
    (-3329)@16 <=s f075, f075 <s 3329@16,
    (-3329)@16 <=s f076, f076 <s 3329@16,
    (-3329)@16 <=s f077, f077 <s 3329@16,
    (-3329)@16 <=s f078, f078 <s 3329@16,
    (-3329)@16 <=s f079, f079 <s 3329@16,
    (-3329)@16 <=s f080, f080 <s 3329@16,
    (-3329)@16 <=s f081, f081 <s 3329@16,
    (-3329)@16 <=s f082, f082 <s 3329@16,
    (-3329)@16 <=s f083, f083 <s 3329@16,
    (-3329)@16 <=s f084, f084 <s 3329@16,
    (-3329)@16 <=s f085, f085 <s 3329@16,
    (-3329)@16 <=s f086, f086 <s 3329@16,
    (-3329)@16 <=s f087, f087 <s 3329@16,
    (-3329)@16 <=s f088, f088 <s 3329@16,
    (-3329)@16 <=s f089, f089 <s 3329@16,
    (-3329)@16 <=s f090, f090 <s 3329@16,
    (-3329)@16 <=s f091, f091 <s 3329@16,
    (-3329)@16 <=s f092, f092 <s 3329@16,
    (-3329)@16 <=s f093, f093 <s 3329@16,
    (-3329)@16 <=s f094, f094 <s 3329@16,
    (-3329)@16 <=s f095, f095 <s 3329@16,
    (-3329)@16 <=s f096, f096 <s 3329@16,
    (-3329)@16 <=s f097, f097 <s 3329@16,
    (-3329)@16 <=s f098, f098 <s 3329@16,
    (-3329)@16 <=s f099, f099 <s 3329@16,
    (-3329)@16 <=s f100, f100 <s 3329@16,
    (-3329)@16 <=s f101, f101 <s 3329@16,
    (-3329)@16 <=s f102, f102 <s 3329@16,
    (-3329)@16 <=s f103, f103 <s 3329@16,
    (-3329)@16 <=s f104, f104 <s 3329@16,
    (-3329)@16 <=s f105, f105 <s 3329@16,
    (-3329)@16 <=s f106, f106 <s 3329@16,
    (-3329)@16 <=s f107, f107 <s 3329@16,
    (-3329)@16 <=s f108, f108 <s 3329@16,
    (-3329)@16 <=s f109, f109 <s 3329@16,
    (-3329)@16 <=s f110, f110 <s 3329@16,
    (-3329)@16 <=s f111, f111 <s 3329@16,
    (-3329)@16 <=s f112, f112 <s 3329@16,
    (-3329)@16 <=s f113, f113 <s 3329@16,
    (-3329)@16 <=s f114, f114 <s 3329@16,
    (-3329)@16 <=s f115, f115 <s 3329@16,
    (-3329)@16 <=s f116, f116 <s 3329@16,
    (-3329)@16 <=s f117, f117 <s 3329@16,
    (-3329)@16 <=s f118, f118 <s 3329@16,
    (-3329)@16 <=s f119, f119 <s 3329@16,
    (-3329)@16 <=s f120, f120 <s 3329@16,
    (-3329)@16 <=s f121, f121 <s 3329@16,
    (-3329)@16 <=s f122, f122 <s 3329@16,
    (-3329)@16 <=s f123, f123 <s 3329@16,
    (-3329)@16 <=s f124, f124 <s 3329@16,
    (-3329)@16 <=s f125, f125 <s 3329@16,
    (-3329)@16 <=s f126, f126 <s 3329@16,
    (-3329)@16 <=s f127, f127 <s 3329@16,
    (-3329)@16 <=s f128, f128 <s 3329@16,
    (-3329)@16 <=s f129, f129 <s 3329@16,
    (-3329)@16 <=s f130, f130 <s 3329@16,
    (-3329)@16 <=s f131, f131 <s 3329@16,
    (-3329)@16 <=s f132, f132 <s 3329@16,
    (-3329)@16 <=s f133, f133 <s 3329@16,
    (-3329)@16 <=s f134, f134 <s 3329@16,
    (-3329)@16 <=s f135, f135 <s 3329@16,
    (-3329)@16 <=s f136, f136 <s 3329@16,
    (-3329)@16 <=s f137, f137 <s 3329@16,
    (-3329)@16 <=s f138, f138 <s 3329@16,
    (-3329)@16 <=s f139, f139 <s 3329@16,
    (-3329)@16 <=s f140, f140 <s 3329@16,
    (-3329)@16 <=s f141, f141 <s 3329@16,
    (-3329)@16 <=s f142, f142 <s 3329@16,
    (-3329)@16 <=s f143, f143 <s 3329@16,
    (-3329)@16 <=s f144, f144 <s 3329@16,
    (-3329)@16 <=s f145, f145 <s 3329@16,
    (-3329)@16 <=s f146, f146 <s 3329@16,
    (-3329)@16 <=s f147, f147 <s 3329@16,
    (-3329)@16 <=s f148, f148 <s 3329@16,
    (-3329)@16 <=s f149, f149 <s 3329@16,
    (-3329)@16 <=s f150, f150 <s 3329@16,
    (-3329)@16 <=s f151, f151 <s 3329@16,
    (-3329)@16 <=s f152, f152 <s 3329@16,
    (-3329)@16 <=s f153, f153 <s 3329@16,
    (-3329)@16 <=s f154, f154 <s 3329@16,
    (-3329)@16 <=s f155, f155 <s 3329@16,
    (-3329)@16 <=s f156, f156 <s 3329@16,
    (-3329)@16 <=s f157, f157 <s 3329@16,
    (-3329)@16 <=s f158, f158 <s 3329@16,
    (-3329)@16 <=s f159, f159 <s 3329@16,
    (-3329)@16 <=s f160, f160 <s 3329@16,
    (-3329)@16 <=s f161, f161 <s 3329@16,
    (-3329)@16 <=s f162, f162 <s 3329@16,
    (-3329)@16 <=s f163, f163 <s 3329@16,
    (-3329)@16 <=s f164, f164 <s 3329@16,
    (-3329)@16 <=s f165, f165 <s 3329@16,
    (-3329)@16 <=s f166, f166 <s 3329@16,
    (-3329)@16 <=s f167, f167 <s 3329@16,
    (-3329)@16 <=s f168, f168 <s 3329@16,
    (-3329)@16 <=s f169, f169 <s 3329@16,
    (-3329)@16 <=s f170, f170 <s 3329@16,
    (-3329)@16 <=s f171, f171 <s 3329@16,
    (-3329)@16 <=s f172, f172 <s 3329@16,
    (-3329)@16 <=s f173, f173 <s 3329@16,
    (-3329)@16 <=s f174, f174 <s 3329@16,
    (-3329)@16 <=s f175, f175 <s 3329@16,
    (-3329)@16 <=s f176, f176 <s 3329@16,
    (-3329)@16 <=s f177, f177 <s 3329@16,
    (-3329)@16 <=s f178, f178 <s 3329@16,
    (-3329)@16 <=s f179, f179 <s 3329@16,
    (-3329)@16 <=s f180, f180 <s 3329@16,
    (-3329)@16 <=s f181, f181 <s 3329@16,
    (-3329)@16 <=s f182, f182 <s 3329@16,
    (-3329)@16 <=s f183, f183 <s 3329@16,
    (-3329)@16 <=s f184, f184 <s 3329@16,
    (-3329)@16 <=s f185, f185 <s 3329@16,
    (-3329)@16 <=s f186, f186 <s 3329@16,
    (-3329)@16 <=s f187, f187 <s 3329@16,
    (-3329)@16 <=s f188, f188 <s 3329@16,
    (-3329)@16 <=s f189, f189 <s 3329@16,
    (-3329)@16 <=s f190, f190 <s 3329@16,
    (-3329)@16 <=s f191, f191 <s 3329@16,
    (-3329)@16 <=s f192, f192 <s 3329@16,
    (-3329)@16 <=s f193, f193 <s 3329@16,
    (-3329)@16 <=s f194, f194 <s 3329@16,
    (-3329)@16 <=s f195, f195 <s 3329@16,
    (-3329)@16 <=s f196, f196 <s 3329@16,
    (-3329)@16 <=s f197, f197 <s 3329@16,
    (-3329)@16 <=s f198, f198 <s 3329@16,
    (-3329)@16 <=s f199, f199 <s 3329@16,
    (-3329)@16 <=s f200, f200 <s 3329@16,
    (-3329)@16 <=s f201, f201 <s 3329@16,
    (-3329)@16 <=s f202, f202 <s 3329@16,
    (-3329)@16 <=s f203, f203 <s 3329@16,
    (-3329)@16 <=s f204, f204 <s 3329@16,
    (-3329)@16 <=s f205, f205 <s 3329@16,
    (-3329)@16 <=s f206, f206 <s 3329@16,
    (-3329)@16 <=s f207, f207 <s 3329@16,
    (-3329)@16 <=s f208, f208 <s 3329@16,
    (-3329)@16 <=s f209, f209 <s 3329@16,
    (-3329)@16 <=s f210, f210 <s 3329@16,
    (-3329)@16 <=s f211, f211 <s 3329@16,
    (-3329)@16 <=s f212, f212 <s 3329@16,
    (-3329)@16 <=s f213, f213 <s 3329@16,
    (-3329)@16 <=s f214, f214 <s 3329@16,
    (-3329)@16 <=s f215, f215 <s 3329@16,
    (-3329)@16 <=s f216, f216 <s 3329@16,
    (-3329)@16 <=s f217, f217 <s 3329@16,
    (-3329)@16 <=s f218, f218 <s 3329@16,
    (-3329)@16 <=s f219, f219 <s 3329@16,
    (-3329)@16 <=s f220, f220 <s 3329@16,
    (-3329)@16 <=s f221, f221 <s 3329@16,
    (-3329)@16 <=s f222, f222 <s 3329@16,
    (-3329)@16 <=s f223, f223 <s 3329@16,
    (-3329)@16 <=s f224, f224 <s 3329@16,
    (-3329)@16 <=s f225, f225 <s 3329@16,
    (-3329)@16 <=s f226, f226 <s 3329@16,
    (-3329)@16 <=s f227, f227 <s 3329@16,
    (-3329)@16 <=s f228, f228 <s 3329@16,
    (-3329)@16 <=s f229, f229 <s 3329@16,
    (-3329)@16 <=s f230, f230 <s 3329@16,
    (-3329)@16 <=s f231, f231 <s 3329@16,
    (-3329)@16 <=s f232, f232 <s 3329@16,
    (-3329)@16 <=s f233, f233 <s 3329@16,
    (-3329)@16 <=s f234, f234 <s 3329@16,
    (-3329)@16 <=s f235, f235 <s 3329@16,
    (-3329)@16 <=s f236, f236 <s 3329@16,
    (-3329)@16 <=s f237, f237 <s 3329@16,
    (-3329)@16 <=s f238, f238 <s 3329@16,
    (-3329)@16 <=s f239, f239 <s 3329@16,
    (-3329)@16 <=s f240, f240 <s 3329@16,
    (-3329)@16 <=s f241, f241 <s 3329@16,
    (-3329)@16 <=s f242, f242 <s 3329@16,
    (-3329)@16 <=s f243, f243 <s 3329@16,
    (-3329)@16 <=s f244, f244 <s 3329@16,
    (-3329)@16 <=s f245, f245 <s 3329@16,
    (-3329)@16 <=s f246, f246 <s 3329@16,
    (-3329)@16 <=s f247, f247 <s 3329@16,
    (-3329)@16 <=s f248, f248 <s 3329@16,
    (-3329)@16 <=s f249, f249 <s 3329@16,
    (-3329)@16 <=s f250, f250 <s 3329@16,
    (-3329)@16 <=s f251, f251 <s 3329@16,
    (-3329)@16 <=s f252, f252 <s 3329@16,
    (-3329)@16 <=s f253, f253 <s 3329@16,
    (-3329)@16 <=s f254, f254 <s 3329@16,
    (-3329)@16 <=s f255, f255 <s 3329@16
  ]
}

(* === params === *)

mov q 3329@sint16;

(* === inits === *)

(* src *)
mov L0x2001a530 f000;  mov L0x2001a532 f001;
mov L0x2001a534 f002;  mov L0x2001a536 f003;
mov L0x2001a538 f004;  mov L0x2001a53a f005;
mov L0x2001a53c f006;  mov L0x2001a53e f007;
mov L0x2001a540 f008;  mov L0x2001a542 f009;
mov L0x2001a544 f010;  mov L0x2001a546 f011;
mov L0x2001a548 f012;  mov L0x2001a54a f013;
mov L0x2001a54c f014;  mov L0x2001a54e f015;
mov L0x2001a550 f016;  mov L0x2001a552 f017;
mov L0x2001a554 f018;  mov L0x2001a556 f019;
mov L0x2001a558 f020;  mov L0x2001a55a f021;
mov L0x2001a55c f022;  mov L0x2001a55e f023;
mov L0x2001a560 f024;  mov L0x2001a562 f025;
mov L0x2001a564 f026;  mov L0x2001a566 f027;
mov L0x2001a568 f028;  mov L0x2001a56a f029;
mov L0x2001a56c f030;  mov L0x2001a56e f031;
mov L0x2001a570 f032;  mov L0x2001a572 f033;
mov L0x2001a574 f034;  mov L0x2001a576 f035;
mov L0x2001a578 f036;  mov L0x2001a57a f037;
mov L0x2001a57c f038;  mov L0x2001a57e f039;
mov L0x2001a580 f040;  mov L0x2001a582 f041;
mov L0x2001a584 f042;  mov L0x2001a586 f043;
mov L0x2001a588 f044;  mov L0x2001a58a f045;
mov L0x2001a58c f046;  mov L0x2001a58e f047;
mov L0x2001a590 f048;  mov L0x2001a592 f049;
mov L0x2001a594 f050;  mov L0x2001a596 f051;
mov L0x2001a598 f052;  mov L0x2001a59a f053;
mov L0x2001a59c f054;  mov L0x2001a59e f055;
mov L0x2001a5a0 f056;  mov L0x2001a5a2 f057;
mov L0x2001a5a4 f058;  mov L0x2001a5a6 f059;
mov L0x2001a5a8 f060;  mov L0x2001a5aa f061;
mov L0x2001a5ac f062;  mov L0x2001a5ae f063;
mov L0x2001a5b0 f064;  mov L0x2001a5b2 f065;
mov L0x2001a5b4 f066;  mov L0x2001a5b6 f067;
mov L0x2001a5b8 f068;  mov L0x2001a5ba f069;
mov L0x2001a5bc f070;  mov L0x2001a5be f071;
mov L0x2001a5c0 f072;  mov L0x2001a5c2 f073;
mov L0x2001a5c4 f074;  mov L0x2001a5c6 f075;
mov L0x2001a5c8 f076;  mov L0x2001a5ca f077;
mov L0x2001a5cc f078;  mov L0x2001a5ce f079;
mov L0x2001a5d0 f080;  mov L0x2001a5d2 f081;
mov L0x2001a5d4 f082;  mov L0x2001a5d6 f083;
mov L0x2001a5d8 f084;  mov L0x2001a5da f085;
mov L0x2001a5dc f086;  mov L0x2001a5de f087;
mov L0x2001a5e0 f088;  mov L0x2001a5e2 f089;
mov L0x2001a5e4 f090;  mov L0x2001a5e6 f091;
mov L0x2001a5e8 f092;  mov L0x2001a5ea f093;
mov L0x2001a5ec f094;  mov L0x2001a5ee f095;
mov L0x2001a5f0 f096;  mov L0x2001a5f2 f097;
mov L0x2001a5f4 f098;  mov L0x2001a5f6 f099;
mov L0x2001a5f8 f100;  mov L0x2001a5fa f101;
mov L0x2001a5fc f102;  mov L0x2001a5fe f103;
mov L0x2001a600 f104;  mov L0x2001a602 f105;
mov L0x2001a604 f106;  mov L0x2001a606 f107;
mov L0x2001a608 f108;  mov L0x2001a60a f109;
mov L0x2001a60c f110;  mov L0x2001a60e f111;
mov L0x2001a610 f112;  mov L0x2001a612 f113;
mov L0x2001a614 f114;  mov L0x2001a616 f115;
mov L0x2001a618 f116;  mov L0x2001a61a f117;
mov L0x2001a61c f118;  mov L0x2001a61e f119;
mov L0x2001a620 f120;  mov L0x2001a622 f121;
mov L0x2001a624 f122;  mov L0x2001a626 f123;
mov L0x2001a628 f124;  mov L0x2001a62a f125;
mov L0x2001a62c f126;  mov L0x2001a62e f127;
mov L0x2001a630 f128;  mov L0x2001a632 f129;
mov L0x2001a634 f130;  mov L0x2001a636 f131;
mov L0x2001a638 f132;  mov L0x2001a63a f133;
mov L0x2001a63c f134;  mov L0x2001a63e f135;
mov L0x2001a640 f136;  mov L0x2001a642 f137;
mov L0x2001a644 f138;  mov L0x2001a646 f139;
mov L0x2001a648 f140;  mov L0x2001a64a f141;
mov L0x2001a64c f142;  mov L0x2001a64e f143;
mov L0x2001a650 f144;  mov L0x2001a652 f145;
mov L0x2001a654 f146;  mov L0x2001a656 f147;
mov L0x2001a658 f148;  mov L0x2001a65a f149;
mov L0x2001a65c f150;  mov L0x2001a65e f151;
mov L0x2001a660 f152;  mov L0x2001a662 f153;
mov L0x2001a664 f154;  mov L0x2001a666 f155;
mov L0x2001a668 f156;  mov L0x2001a66a f157;
mov L0x2001a66c f158;  mov L0x2001a66e f159;
mov L0x2001a670 f160;  mov L0x2001a672 f161;
mov L0x2001a674 f162;  mov L0x2001a676 f163;
mov L0x2001a678 f164;  mov L0x2001a67a f165;
mov L0x2001a67c f166;  mov L0x2001a67e f167;
mov L0x2001a680 f168;  mov L0x2001a682 f169;
mov L0x2001a684 f170;  mov L0x2001a686 f171;
mov L0x2001a688 f172;  mov L0x2001a68a f173;
mov L0x2001a68c f174;  mov L0x2001a68e f175;
mov L0x2001a690 f176;  mov L0x2001a692 f177;
mov L0x2001a694 f178;  mov L0x2001a696 f179;
mov L0x2001a698 f180;  mov L0x2001a69a f181;
mov L0x2001a69c f182;  mov L0x2001a69e f183;
mov L0x2001a6a0 f184;  mov L0x2001a6a2 f185;
mov L0x2001a6a4 f186;  mov L0x2001a6a6 f187;
mov L0x2001a6a8 f188;  mov L0x2001a6aa f189;
mov L0x2001a6ac f190;  mov L0x2001a6ae f191;
mov L0x2001a6b0 f192;  mov L0x2001a6b2 f193;
mov L0x2001a6b4 f194;  mov L0x2001a6b6 f195;
mov L0x2001a6b8 f196;  mov L0x2001a6ba f197;
mov L0x2001a6bc f198;  mov L0x2001a6be f199;
mov L0x2001a6c0 f200;  mov L0x2001a6c2 f201;
mov L0x2001a6c4 f202;  mov L0x2001a6c6 f203;
mov L0x2001a6c8 f204;  mov L0x2001a6ca f205;
mov L0x2001a6cc f206;  mov L0x2001a6ce f207;
mov L0x2001a6d0 f208;  mov L0x2001a6d2 f209;
mov L0x2001a6d4 f210;  mov L0x2001a6d6 f211;
mov L0x2001a6d8 f212;  mov L0x2001a6da f213;
mov L0x2001a6dc f214;  mov L0x2001a6de f215;
mov L0x2001a6e0 f216;  mov L0x2001a6e2 f217;
mov L0x2001a6e4 f218;  mov L0x2001a6e6 f219;
mov L0x2001a6e8 f220;  mov L0x2001a6ea f221;
mov L0x2001a6ec f222;  mov L0x2001a6ee f223;
mov L0x2001a6f0 f224;  mov L0x2001a6f2 f225;
mov L0x2001a6f4 f226;  mov L0x2001a6f6 f227;
mov L0x2001a6f8 f228;  mov L0x2001a6fa f229;
mov L0x2001a6fc f230;  mov L0x2001a6fe f231;
mov L0x2001a700 f232;  mov L0x2001a702 f233;
mov L0x2001a704 f234;  mov L0x2001a706 f235;
mov L0x2001a708 f236;  mov L0x2001a70a f237;
mov L0x2001a70c f238;  mov L0x2001a70e f239;
mov L0x2001a710 f240;  mov L0x2001a712 f241;
mov L0x2001a714 f242;  mov L0x2001a716 f243;
mov L0x2001a718 f244;  mov L0x2001a71a f245;
mov L0x2001a71c f246;  mov L0x2001a71e f247;
mov L0x2001a720 f248;  mov L0x2001a722 f249;
mov L0x2001a724 f250;  mov L0x2001a726 f251;
mov L0x2001a728 f252;  mov L0x2001a72a f253;
mov L0x2001a72c f254;  mov L0x2001a72e f255;

(* inv_roots *)
mov L0x800e5d4 1701@sint16;  mov L0x800e5d6 1807@sint16;
mov L0x800e5d8 1460@sint16;  mov L0x800e5da 2371@sint16;
mov L0x800e5dc 2338@sint16;  mov L0x800e5de 2333@sint16;
mov L0x800e5e0  308@sint16;  mov L0x800e5e2  108@sint16;
mov L0x800e5e4 2851@sint16;  mov L0x800e5e6  870@sint16;
mov L0x800e5e8  854@sint16;  mov L0x800e5ea 1510@sint16;
mov L0x800e5ec 2535@sint16;  mov L0x800e5ee 1278@sint16;
mov L0x800e5f0 1530@sint16;  mov L0x800e5f2 1185@sint16;
mov L0x800e5f4 1659@sint16;  mov L0x800e5f6 1187@sint16;
mov L0x800e5f8 3109@sint16;  mov L0x800e5fa  874@sint16;
mov L0x800e5fc 1335@sint16;  mov L0x800e5fe 2111@sint16;
mov L0x800e600  136@sint16;  mov L0x800e602 1215@sint16;
mov L0x800e604 2945@sint16;  mov L0x800e606 1465@sint16;
mov L0x800e608 1285@sint16;  mov L0x800e60a 2007@sint16;
mov L0x800e60c 2719@sint16;  mov L0x800e60e 2726@sint16;
mov L0x800e610 2232@sint16;  mov L0x800e612 2512@sint16;
mov L0x800e614   75@sint16;  mov L0x800e616  156@sint16;
mov L0x800e618 3000@sint16;  mov L0x800e61a 2911@sint16;
mov L0x800e61c 2980@sint16;  mov L0x800e61e  872@sint16;
mov L0x800e620 2685@sint16;  mov L0x800e622 1590@sint16;
mov L0x800e624 2210@sint16;  mov L0x800e626  602@sint16;
mov L0x800e628 1846@sint16;  mov L0x800e62a  777@sint16;
mov L0x800e62c  147@sint16;  mov L0x800e62e 2170@sint16;
mov L0x800e630 2551@sint16;  mov L0x800e632  246@sint16;
mov L0x800e634 1676@sint16;  mov L0x800e636 1755@sint16;
mov L0x800e638  460@sint16;  mov L0x800e63a  291@sint16;
mov L0x800e63c  235@sint16;  mov L0x800e63e 3152@sint16;
mov L0x800e640 2742@sint16;  mov L0x800e642 2907@sint16;
mov L0x800e644 3224@sint16;  mov L0x800e646 1779@sint16;
mov L0x800e648 2458@sint16;  mov L0x800e64a 1251@sint16;
mov L0x800e64c 2486@sint16;  mov L0x800e64e 2774@sint16;
mov L0x800e650 2899@sint16;  mov L0x800e652 1103@sint16;
mov L0x800e654 1275@sint16;  mov L0x800e656 2652@sint16;
mov L0x800e658 1065@sint16;  mov L0x800e65a 2881@sint16;
mov L0x800e65c 1571@sint16;  mov L0x800e65e  205@sint16;
mov L0x800e660 1861@sint16;  mov L0x800e662  725@sint16;
mov L0x800e664 1508@sint16;  mov L0x800e666 2368@sint16;
mov L0x800e668  398@sint16;  mov L0x800e66a 2918@sint16;
mov L0x800e66c 1542@sint16;  mov L0x800e66e 1474@sint16;
mov L0x800e670  951@sint16;  mov L0x800e672  247@sint16;
mov L0x800e674 1421@sint16;  mov L0x800e676 3222@sint16;
mov L0x800e678 2721@sint16;  mov L0x800e67a 2597@sint16;
mov L0x800e67c 1202@sint16;  mov L0x800e67e 2499@sint16;
mov L0x800e680  271@sint16;  mov L0x800e682   90@sint16;
mov L0x800e684  853@sint16;  mov L0x800e686 2312@sint16;
mov L0x800e688  681@sint16;  mov L0x800e68a 2367@sint16;
mov L0x800e68c 1860@sint16;  mov L0x800e68e 3203@sint16;
mov L0x800e690 1162@sint16;  mov L0x800e692 1618@sint16;
mov L0x800e694  130@sint16;  mov L0x800e696 1602@sint16;
mov L0x800e698 3147@sint16;  mov L0x800e69a  666@sint16;
mov L0x800e69c  320@sint16;  mov L0x800e69e    8@sint16;
mov L0x800e6a0 2813@sint16;  mov L0x800e6a2 1871@sint16;
mov L0x800e6a4  829@sint16;  mov L0x800e6a6 1752@sint16;
mov L0x800e6a8 1544@sint16;  mov L0x800e6aa  282@sint16;
mov L0x800e6ac 1838@sint16;  mov L0x800e6ae 1293@sint16;
mov L0x800e6b0 2946@sint16;  mov L0x800e6b2 3065@sint16;
mov L0x800e6b4 2707@sint16;  mov L0x800e6b6 2314@sint16;
mov L0x800e6b8  552@sint16;  mov L0x800e6ba 2677@sint16;
mov L0x800e6bc 2106@sint16;  mov L0x800e6be 1325@sint16;
mov L0x800e6c0 2756@sint16;  mov L0x800e6c2  171@sint16;
mov L0x800e6c4 3127@sint16;  mov L0x800e6c6 3042@sint16;
mov L0x800e6c8 1907@sint16;  mov L0x800e6ca 1836@sint16;
mov L0x800e6cc 1517@sint16;  mov L0x800e6ce  359@sint16;
mov L0x800e6d0 1932@sint16;  mov L0x800e6d2 1441@sint16;

(* regs *)
nondet r0@uint32;

(* inp_polys *)
ghost inp_poly_0@bit :
  inp_poly_0 * inp_poly_0 = 
    L0x2001a530 * (x**0) + L0x2001a532 * (x**1)
  && true;

ghost inp_poly_1@bit :
  inp_poly_1 * inp_poly_1 = 
    L0x2001a534 * (x**0) + L0x2001a536 * (x**1)
  && true;

ghost inp_poly_2@bit :
  inp_poly_2 * inp_poly_2 = 
    L0x2001a538 * (x**0) + L0x2001a53a * (x**1)
  && true;

ghost inp_poly_3@bit :
  inp_poly_3 * inp_poly_3 = 
    L0x2001a53c * (x**0) + L0x2001a53e * (x**1)
  && true;

ghost inp_poly_4@bit :
  inp_poly_4 * inp_poly_4 = 
    L0x2001a540 * (x**0) + L0x2001a542 * (x**1)
  && true;

ghost inp_poly_5@bit :
  inp_poly_5 * inp_poly_5 = 
    L0x2001a544 * (x**0) + L0x2001a546 * (x**1)
  && true;

ghost inp_poly_6@bit :
  inp_poly_6 * inp_poly_6 = 
    L0x2001a548 * (x**0) + L0x2001a54a * (x**1)
  && true;

ghost inp_poly_7@bit :
  inp_poly_7 * inp_poly_7 = 
    L0x2001a54c * (x**0) + L0x2001a54e * (x**1)
  && true;

ghost inp_poly_8@bit :
  inp_poly_8 * inp_poly_8 = 
    L0x2001a550 * (x**0) + L0x2001a552 * (x**1)
  && true;

ghost inp_poly_9@bit :
  inp_poly_9 * inp_poly_9 = 
    L0x2001a554 * (x**0) + L0x2001a556 * (x**1)
  && true;

ghost inp_poly_10@bit :
  inp_poly_10 * inp_poly_10 = 
    L0x2001a558 * (x**0) + L0x2001a55a * (x**1)
  && true;

ghost inp_poly_11@bit :
  inp_poly_11 * inp_poly_11 = 
    L0x2001a55c * (x**0) + L0x2001a55e * (x**1)
  && true;

ghost inp_poly_12@bit :
  inp_poly_12 * inp_poly_12 = 
    L0x2001a560 * (x**0) + L0x2001a562 * (x**1)
  && true;

ghost inp_poly_13@bit :
  inp_poly_13 * inp_poly_13 = 
    L0x2001a564 * (x**0) + L0x2001a566 * (x**1)
  && true;

ghost inp_poly_14@bit :
  inp_poly_14 * inp_poly_14 = 
    L0x2001a568 * (x**0) + L0x2001a56a * (x**1)
  && true;

ghost inp_poly_15@bit :
  inp_poly_15 * inp_poly_15 = 
    L0x2001a56c * (x**0) + L0x2001a56e * (x**1)
  && true;

ghost inp_poly_16@bit :
  inp_poly_16 * inp_poly_16 = 
    L0x2001a570 * (x**0) + L0x2001a572 * (x**1)
  && true;

ghost inp_poly_17@bit :
  inp_poly_17 * inp_poly_17 = 
    L0x2001a574 * (x**0) + L0x2001a576 * (x**1)
  && true;

ghost inp_poly_18@bit :
  inp_poly_18 * inp_poly_18 = 
    L0x2001a578 * (x**0) + L0x2001a57a * (x**1)
  && true;

ghost inp_poly_19@bit :
  inp_poly_19 * inp_poly_19 = 
    L0x2001a57c * (x**0) + L0x2001a57e * (x**1)
  && true;

ghost inp_poly_20@bit :
  inp_poly_20 * inp_poly_20 = 
    L0x2001a580 * (x**0) + L0x2001a582 * (x**1)
  && true;

ghost inp_poly_21@bit :
  inp_poly_21 * inp_poly_21 = 
    L0x2001a584 * (x**0) + L0x2001a586 * (x**1)
  && true;

ghost inp_poly_22@bit :
  inp_poly_22 * inp_poly_22 = 
    L0x2001a588 * (x**0) + L0x2001a58a * (x**1)
  && true;

ghost inp_poly_23@bit :
  inp_poly_23 * inp_poly_23 = 
    L0x2001a58c * (x**0) + L0x2001a58e * (x**1)
  && true;

ghost inp_poly_24@bit :
  inp_poly_24 * inp_poly_24 = 
    L0x2001a590 * (x**0) + L0x2001a592 * (x**1)
  && true;

ghost inp_poly_25@bit :
  inp_poly_25 * inp_poly_25 = 
    L0x2001a594 * (x**0) + L0x2001a596 * (x**1)
  && true;

ghost inp_poly_26@bit :
  inp_poly_26 * inp_poly_26 = 
    L0x2001a598 * (x**0) + L0x2001a59a * (x**1)
  && true;

ghost inp_poly_27@bit :
  inp_poly_27 * inp_poly_27 = 
    L0x2001a59c * (x**0) + L0x2001a59e * (x**1)
  && true;

ghost inp_poly_28@bit :
  inp_poly_28 * inp_poly_28 = 
    L0x2001a5a0 * (x**0) + L0x2001a5a2 * (x**1)
  && true;

ghost inp_poly_29@bit :
  inp_poly_29 * inp_poly_29 = 
    L0x2001a5a4 * (x**0) + L0x2001a5a6 * (x**1)
  && true;

ghost inp_poly_30@bit :
  inp_poly_30 * inp_poly_30 = 
    L0x2001a5a8 * (x**0) + L0x2001a5aa * (x**1)
  && true;

ghost inp_poly_31@bit :
  inp_poly_31 * inp_poly_31 = 
    L0x2001a5ac * (x**0) + L0x2001a5ae * (x**1)
  && true;

ghost inp_poly_32@bit :
  inp_poly_32 * inp_poly_32 = 
    L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1)
  && true;

ghost inp_poly_33@bit :
  inp_poly_33 * inp_poly_33 = 
    L0x2001a5b4 * (x**0) + L0x2001a5b6 * (x**1)
  && true;

ghost inp_poly_34@bit :
  inp_poly_34 * inp_poly_34 = 
    L0x2001a5b8 * (x**0) + L0x2001a5ba * (x**1)
  && true;

ghost inp_poly_35@bit :
  inp_poly_35 * inp_poly_35 = 
    L0x2001a5bc * (x**0) + L0x2001a5be * (x**1)
  && true;

ghost inp_poly_36@bit :
  inp_poly_36 * inp_poly_36 = 
    L0x2001a5c0 * (x**0) + L0x2001a5c2 * (x**1)
  && true;

ghost inp_poly_37@bit :
  inp_poly_37 * inp_poly_37 = 
    L0x2001a5c4 * (x**0) + L0x2001a5c6 * (x**1)
  && true;

ghost inp_poly_38@bit :
  inp_poly_38 * inp_poly_38 = 
    L0x2001a5c8 * (x**0) + L0x2001a5ca * (x**1)
  && true;

ghost inp_poly_39@bit :
  inp_poly_39 * inp_poly_39 = 
    L0x2001a5cc * (x**0) + L0x2001a5ce * (x**1)
  && true;

ghost inp_poly_40@bit :
  inp_poly_40 * inp_poly_40 = 
    L0x2001a5d0 * (x**0) + L0x2001a5d2 * (x**1)
  && true;

ghost inp_poly_41@bit :
  inp_poly_41 * inp_poly_41 = 
    L0x2001a5d4 * (x**0) + L0x2001a5d6 * (x**1)
  && true;

ghost inp_poly_42@bit :
  inp_poly_42 * inp_poly_42 = 
    L0x2001a5d8 * (x**0) + L0x2001a5da * (x**1)
  && true;

ghost inp_poly_43@bit :
  inp_poly_43 * inp_poly_43 = 
    L0x2001a5dc * (x**0) + L0x2001a5de * (x**1)
  && true;

ghost inp_poly_44@bit :
  inp_poly_44 * inp_poly_44 = 
    L0x2001a5e0 * (x**0) + L0x2001a5e2 * (x**1)
  && true;

ghost inp_poly_45@bit :
  inp_poly_45 * inp_poly_45 = 
    L0x2001a5e4 * (x**0) + L0x2001a5e6 * (x**1)
  && true;

ghost inp_poly_46@bit :
  inp_poly_46 * inp_poly_46 = 
    L0x2001a5e8 * (x**0) + L0x2001a5ea * (x**1)
  && true;

ghost inp_poly_47@bit :
  inp_poly_47 * inp_poly_47 = 
    L0x2001a5ec * (x**0) + L0x2001a5ee * (x**1)
  && true;

ghost inp_poly_48@bit :
  inp_poly_48 * inp_poly_48 = 
    L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1)
  && true;

ghost inp_poly_49@bit :
  inp_poly_49 * inp_poly_49 = 
    L0x2001a5f4 * (x**0) + L0x2001a5f6 * (x**1)
  && true;

ghost inp_poly_50@bit :
  inp_poly_50 * inp_poly_50 = 
    L0x2001a5f8 * (x**0) + L0x2001a5fa * (x**1)
  && true;

ghost inp_poly_51@bit :
  inp_poly_51 * inp_poly_51 = 
    L0x2001a5fc * (x**0) + L0x2001a5fe * (x**1)
  && true;

ghost inp_poly_52@bit :
  inp_poly_52 * inp_poly_52 = 
    L0x2001a600 * (x**0) + L0x2001a602 * (x**1)
  && true;

ghost inp_poly_53@bit :
  inp_poly_53 * inp_poly_53 = 
    L0x2001a604 * (x**0) + L0x2001a606 * (x**1)
  && true;

ghost inp_poly_54@bit :
  inp_poly_54 * inp_poly_54 = 
    L0x2001a608 * (x**0) + L0x2001a60a * (x**1)
  && true;

ghost inp_poly_55@bit :
  inp_poly_55 * inp_poly_55 = 
    L0x2001a60c * (x**0) + L0x2001a60e * (x**1)
  && true;

ghost inp_poly_56@bit :
  inp_poly_56 * inp_poly_56 = 
    L0x2001a610 * (x**0) + L0x2001a612 * (x**1)
  && true;

ghost inp_poly_57@bit :
  inp_poly_57 * inp_poly_57 = 
    L0x2001a614 * (x**0) + L0x2001a616 * (x**1)
  && true;

ghost inp_poly_58@bit :
  inp_poly_58 * inp_poly_58 = 
    L0x2001a618 * (x**0) + L0x2001a61a * (x**1)
  && true;

ghost inp_poly_59@bit :
  inp_poly_59 * inp_poly_59 = 
    L0x2001a61c * (x**0) + L0x2001a61e * (x**1)
  && true;

ghost inp_poly_60@bit :
  inp_poly_60 * inp_poly_60 = 
    L0x2001a620 * (x**0) + L0x2001a622 * (x**1)
  && true;

ghost inp_poly_61@bit :
  inp_poly_61 * inp_poly_61 = 
    L0x2001a624 * (x**0) + L0x2001a626 * (x**1)
  && true;

ghost inp_poly_62@bit :
  inp_poly_62 * inp_poly_62 = 
    L0x2001a628 * (x**0) + L0x2001a62a * (x**1)
  && true;

ghost inp_poly_63@bit :
  inp_poly_63 * inp_poly_63 = 
    L0x2001a62c * (x**0) + L0x2001a62e * (x**1)
  && true;

ghost inp_poly_64@bit :
  inp_poly_64 * inp_poly_64 = 
    L0x2001a630 * (x**0) + L0x2001a632 * (x**1)
  && true;

ghost inp_poly_65@bit :
  inp_poly_65 * inp_poly_65 = 
    L0x2001a634 * (x**0) + L0x2001a636 * (x**1)
  && true;

ghost inp_poly_66@bit :
  inp_poly_66 * inp_poly_66 = 
    L0x2001a638 * (x**0) + L0x2001a63a * (x**1)
  && true;

ghost inp_poly_67@bit :
  inp_poly_67 * inp_poly_67 = 
    L0x2001a63c * (x**0) + L0x2001a63e * (x**1)
  && true;

ghost inp_poly_68@bit :
  inp_poly_68 * inp_poly_68 = 
    L0x2001a640 * (x**0) + L0x2001a642 * (x**1)
  && true;

ghost inp_poly_69@bit :
  inp_poly_69 * inp_poly_69 = 
    L0x2001a644 * (x**0) + L0x2001a646 * (x**1)
  && true;

ghost inp_poly_70@bit :
  inp_poly_70 * inp_poly_70 = 
    L0x2001a648 * (x**0) + L0x2001a64a * (x**1)
  && true;

ghost inp_poly_71@bit :
  inp_poly_71 * inp_poly_71 = 
    L0x2001a64c * (x**0) + L0x2001a64e * (x**1)
  && true;

ghost inp_poly_72@bit :
  inp_poly_72 * inp_poly_72 = 
    L0x2001a650 * (x**0) + L0x2001a652 * (x**1)
  && true;

ghost inp_poly_73@bit :
  inp_poly_73 * inp_poly_73 = 
    L0x2001a654 * (x**0) + L0x2001a656 * (x**1)
  && true;

ghost inp_poly_74@bit :
  inp_poly_74 * inp_poly_74 = 
    L0x2001a658 * (x**0) + L0x2001a65a * (x**1)
  && true;

ghost inp_poly_75@bit :
  inp_poly_75 * inp_poly_75 = 
    L0x2001a65c * (x**0) + L0x2001a65e * (x**1)
  && true;

ghost inp_poly_76@bit :
  inp_poly_76 * inp_poly_76 = 
    L0x2001a660 * (x**0) + L0x2001a662 * (x**1)
  && true;

ghost inp_poly_77@bit :
  inp_poly_77 * inp_poly_77 = 
    L0x2001a664 * (x**0) + L0x2001a666 * (x**1)
  && true;

ghost inp_poly_78@bit :
  inp_poly_78 * inp_poly_78 = 
    L0x2001a668 * (x**0) + L0x2001a66a * (x**1)
  && true;

ghost inp_poly_79@bit :
  inp_poly_79 * inp_poly_79 = 
    L0x2001a66c * (x**0) + L0x2001a66e * (x**1)
  && true;

ghost inp_poly_80@bit :
  inp_poly_80 * inp_poly_80 = 
    L0x2001a670 * (x**0) + L0x2001a672 * (x**1)
  && true;

ghost inp_poly_81@bit :
  inp_poly_81 * inp_poly_81 = 
    L0x2001a674 * (x**0) + L0x2001a676 * (x**1)
  && true;

ghost inp_poly_82@bit :
  inp_poly_82 * inp_poly_82 = 
    L0x2001a678 * (x**0) + L0x2001a67a * (x**1)
  && true;

ghost inp_poly_83@bit :
  inp_poly_83 * inp_poly_83 = 
    L0x2001a67c * (x**0) + L0x2001a67e * (x**1)
  && true;

ghost inp_poly_84@bit :
  inp_poly_84 * inp_poly_84 = 
    L0x2001a680 * (x**0) + L0x2001a682 * (x**1)
  && true;

ghost inp_poly_85@bit :
  inp_poly_85 * inp_poly_85 = 
    L0x2001a684 * (x**0) + L0x2001a686 * (x**1)
  && true;

ghost inp_poly_86@bit :
  inp_poly_86 * inp_poly_86 = 
    L0x2001a688 * (x**0) + L0x2001a68a * (x**1)
  && true;

ghost inp_poly_87@bit :
  inp_poly_87 * inp_poly_87 = 
    L0x2001a68c * (x**0) + L0x2001a68e * (x**1)
  && true;

ghost inp_poly_88@bit :
  inp_poly_88 * inp_poly_88 = 
    L0x2001a690 * (x**0) + L0x2001a692 * (x**1)
  && true;

ghost inp_poly_89@bit :
  inp_poly_89 * inp_poly_89 = 
    L0x2001a694 * (x**0) + L0x2001a696 * (x**1)
  && true;

ghost inp_poly_90@bit :
  inp_poly_90 * inp_poly_90 = 
    L0x2001a698 * (x**0) + L0x2001a69a * (x**1)
  && true;

ghost inp_poly_91@bit :
  inp_poly_91 * inp_poly_91 = 
    L0x2001a69c * (x**0) + L0x2001a69e * (x**1)
  && true;

ghost inp_poly_92@bit :
  inp_poly_92 * inp_poly_92 = 
    L0x2001a6a0 * (x**0) + L0x2001a6a2 * (x**1)
  && true;

ghost inp_poly_93@bit :
  inp_poly_93 * inp_poly_93 = 
    L0x2001a6a4 * (x**0) + L0x2001a6a6 * (x**1)
  && true;

ghost inp_poly_94@bit :
  inp_poly_94 * inp_poly_94 = 
    L0x2001a6a8 * (x**0) + L0x2001a6aa * (x**1)
  && true;

ghost inp_poly_95@bit :
  inp_poly_95 * inp_poly_95 = 
    L0x2001a6ac * (x**0) + L0x2001a6ae * (x**1)
  && true;

ghost inp_poly_96@bit :
  inp_poly_96 * inp_poly_96 = 
    L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1)
  && true;

ghost inp_poly_97@bit :
  inp_poly_97 * inp_poly_97 = 
    L0x2001a6b4 * (x**0) + L0x2001a6b6 * (x**1)
  && true;

ghost inp_poly_98@bit :
  inp_poly_98 * inp_poly_98 = 
    L0x2001a6b8 * (x**0) + L0x2001a6ba * (x**1)
  && true;

ghost inp_poly_99@bit :
  inp_poly_99 * inp_poly_99 = 
    L0x2001a6bc * (x**0) + L0x2001a6be * (x**1)
  && true;

ghost inp_poly_100@bit :
  inp_poly_100 * inp_poly_100 = 
    L0x2001a6c0 * (x**0) + L0x2001a6c2 * (x**1)
  && true;

ghost inp_poly_101@bit :
  inp_poly_101 * inp_poly_101 = 
    L0x2001a6c4 * (x**0) + L0x2001a6c6 * (x**1)
  && true;

ghost inp_poly_102@bit :
  inp_poly_102 * inp_poly_102 = 
    L0x2001a6c8 * (x**0) + L0x2001a6ca * (x**1)
  && true;

ghost inp_poly_103@bit :
  inp_poly_103 * inp_poly_103 = 
    L0x2001a6cc * (x**0) + L0x2001a6ce * (x**1)
  && true;

ghost inp_poly_104@bit :
  inp_poly_104 * inp_poly_104 = 
    L0x2001a6d0 * (x**0) + L0x2001a6d2 * (x**1)
  && true;

ghost inp_poly_105@bit :
  inp_poly_105 * inp_poly_105 = 
    L0x2001a6d4 * (x**0) + L0x2001a6d6 * (x**1)
  && true;

ghost inp_poly_106@bit :
  inp_poly_106 * inp_poly_106 = 
    L0x2001a6d8 * (x**0) + L0x2001a6da * (x**1)
  && true;

ghost inp_poly_107@bit :
  inp_poly_107 * inp_poly_107 = 
    L0x2001a6dc * (x**0) + L0x2001a6de * (x**1)
  && true;

ghost inp_poly_108@bit :
  inp_poly_108 * inp_poly_108 = 
    L0x2001a6e0 * (x**0) + L0x2001a6e2 * (x**1)
  && true;

ghost inp_poly_109@bit :
  inp_poly_109 * inp_poly_109 = 
    L0x2001a6e4 * (x**0) + L0x2001a6e6 * (x**1)
  && true;

ghost inp_poly_110@bit :
  inp_poly_110 * inp_poly_110 = 
    L0x2001a6e8 * (x**0) + L0x2001a6ea * (x**1)
  && true;

ghost inp_poly_111@bit :
  inp_poly_111 * inp_poly_111 = 
    L0x2001a6ec * (x**0) + L0x2001a6ee * (x**1)
  && true;

ghost inp_poly_112@bit :
  inp_poly_112 * inp_poly_112 = 
    L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1)
  && true;

ghost inp_poly_113@bit :
  inp_poly_113 * inp_poly_113 = 
    L0x2001a6f4 * (x**0) + L0x2001a6f6 * (x**1)
  && true;

ghost inp_poly_114@bit :
  inp_poly_114 * inp_poly_114 = 
    L0x2001a6f8 * (x**0) + L0x2001a6fa * (x**1)
  && true;

ghost inp_poly_115@bit :
  inp_poly_115 * inp_poly_115 = 
    L0x2001a6fc * (x**0) + L0x2001a6fe * (x**1)
  && true;

ghost inp_poly_116@bit :
  inp_poly_116 * inp_poly_116 = 
    L0x2001a700 * (x**0) + L0x2001a702 * (x**1)
  && true;

ghost inp_poly_117@bit :
  inp_poly_117 * inp_poly_117 = 
    L0x2001a704 * (x**0) + L0x2001a706 * (x**1)
  && true;

ghost inp_poly_118@bit :
  inp_poly_118 * inp_poly_118 = 
    L0x2001a708 * (x**0) + L0x2001a70a * (x**1)
  && true;

ghost inp_poly_119@bit :
  inp_poly_119 * inp_poly_119 = 
    L0x2001a70c * (x**0) + L0x2001a70e * (x**1)
  && true;

ghost inp_poly_120@bit :
  inp_poly_120 * inp_poly_120 = 
    L0x2001a710 * (x**0) + L0x2001a712 * (x**1)
  && true;

ghost inp_poly_121@bit :
  inp_poly_121 * inp_poly_121 = 
    L0x2001a714 * (x**0) + L0x2001a716 * (x**1)
  && true;

ghost inp_poly_122@bit :
  inp_poly_122 * inp_poly_122 = 
    L0x2001a718 * (x**0) + L0x2001a71a * (x**1)
  && true;

ghost inp_poly_123@bit :
  inp_poly_123 * inp_poly_123 = 
    L0x2001a71c * (x**0) + L0x2001a71e * (x**1)
  && true;

ghost inp_poly_124@bit :
  inp_poly_124 * inp_poly_124 = 
    L0x2001a720 * (x**0) + L0x2001a722 * (x**1)
  && true;

ghost inp_poly_125@bit :
  inp_poly_125 * inp_poly_125 = 
    L0x2001a724 * (x**0) + L0x2001a726 * (x**1)
  && true;

ghost inp_poly_126@bit :
  inp_poly_126 * inp_poly_126 = 
    L0x2001a728 * (x**0) + L0x2001a72a * (x**1)
  && true;

ghost inp_poly_127@bit :
  inp_poly_127 * inp_poly_127 = 
    L0x2001a72c * (x**0) + L0x2001a72e * (x**1)
  && true;


(* #! -> SP = 0x2001a4c0 *)
#! 0x2001a4c0 = 0x2001a4c0;
(* movw	r11, #3329	; 0xd01                         #! PC = 0x8005164 *)
mov r11_b 3329@sint16;
mov r11_t 0@sint16;
(* movt	r11, #3327	; 0xcff                         #! PC = 0x8005168 *)
mov r11_t 3327@sint16;
(* movw	r12, #16                                   #! PC = 0x800516c *)
mov r12_b 16@sint16;
mov r12_t 0@sint16;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a530; Value = 0x0274f3e8; PC = 0x8005174 *)
mov r2_b L0x2001a530;
mov r2_t L0x2001a532;
mov r3_b L0x2001a534;
mov r3_t L0x2001a536;
mov r4_b L0x2001a538;
mov r4_t L0x2001a53a;
mov r5_b L0x2001a53c;
mov r5_t L0x2001a53e;
mov r6_b L0x2001a540;
mov r6_t L0x2001a542;
mov r7_b L0x2001a544;
mov r7_t L0x2001a546;
mov r8_b L0x2001a548;
mov r8_t L0x2001a54a;
mov r9_b L0x2001a54c;
mov r9_t L0x2001a54e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5d4; Value = 0x070f06a5; PC = 0x8005178 *)
mov r10_b L0x800e5d4;
mov r10_t L0x800e5d6;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5d8; Value = 0x094305b4; PC = 0x80051c4 *)
mov r10_b L0x800e5d8;
mov r10_t L0x800e5da;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a530; PC = 0x8005284 *)
mov L0x2001a530 r2_b;
mov L0x2001a532 r2_t;
mov L0x2001a534 r3_b;
mov L0x2001a536 r3_t;
mov L0x2001a538 r4_b;
mov L0x2001a53a r4_t;
mov L0x2001a53c r5_b;
mov L0x2001a53e r5_t;
mov L0x2001a540 r6_b;
mov L0x2001a542 r6_t;
mov L0x2001a544 r7_b;
mov L0x2001a546 r7_t;
mov L0x2001a548 r8_b;
mov L0x2001a54a r8_t;
mov L0x2001a54c r9_b;
mov L0x2001a54e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000010; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a550; Value = 0xffb80666; PC = 0x8005174 *)
mov r2_b L0x2001a550;
mov r2_t L0x2001a552;
mov r3_b L0x2001a554;
mov r3_t L0x2001a556;
mov r4_b L0x2001a558;
mov r4_t L0x2001a55a;
mov r5_b L0x2001a55c;
mov r5_t L0x2001a55e;
mov r6_b L0x2001a560;
mov r6_t L0x2001a562;
mov r7_b L0x2001a564;
mov r7_t L0x2001a566;
mov r8_b L0x2001a568;
mov r8_t L0x2001a56a;
mov r9_b L0x2001a56c;
mov r9_t L0x2001a56e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5dc; Value = 0x091d0922; PC = 0x8005178 *)
mov r10_b L0x800e5dc;
mov r10_t L0x800e5de;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5e0; Value = 0x006c0134; PC = 0x80051c4 *)
mov r10_b L0x800e5e0;
mov r10_t L0x800e5e2;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a550; PC = 0x8005284 *)
mov L0x2001a550 r2_b;
mov L0x2001a552 r2_t;
mov L0x2001a554 r3_b;
mov L0x2001a556 r3_t;
mov L0x2001a558 r4_b;
mov L0x2001a55a r4_t;
mov L0x2001a55c r5_b;
mov L0x2001a55e r5_t;
mov L0x2001a560 r6_b;
mov L0x2001a562 r6_t;
mov L0x2001a564 r7_b;
mov L0x2001a566 r7_t;
mov L0x2001a568 r8_b;
mov L0x2001a56a r8_t;
mov L0x2001a56c r9_b;
mov L0x2001a56e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000f; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a570; Value = 0x0ea6f941; PC = 0x8005174 *)
mov r2_b L0x2001a570;
mov r2_t L0x2001a572;
mov r3_b L0x2001a574;
mov r3_t L0x2001a576;
mov r4_b L0x2001a578;
mov r4_t L0x2001a57a;
mov r5_b L0x2001a57c;
mov r5_t L0x2001a57e;
mov r6_b L0x2001a580;
mov r6_t L0x2001a582;
mov r7_b L0x2001a584;
mov r7_t L0x2001a586;
mov r8_b L0x2001a588;
mov r8_t L0x2001a58a;
mov r9_b L0x2001a58c;
mov r9_t L0x2001a58e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5e4; Value = 0x03660b23; PC = 0x8005178 *)
mov r10_b L0x800e5e4;
mov r10_t L0x800e5e6;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5e8; Value = 0x05e60356; PC = 0x80051c4 *)
mov r10_b L0x800e5e8;
mov r10_t L0x800e5ea;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a570; PC = 0x8005284 *)
mov L0x2001a570 r2_b;
mov L0x2001a572 r2_t;
mov L0x2001a574 r3_b;
mov L0x2001a576 r3_t;
mov L0x2001a578 r4_b;
mov L0x2001a57a r4_t;
mov L0x2001a57c r5_b;
mov L0x2001a57e r5_t;
mov L0x2001a580 r6_b;
mov L0x2001a582 r6_t;
mov L0x2001a584 r7_b;
mov L0x2001a586 r7_t;
mov L0x2001a588 r8_b;
mov L0x2001a58a r8_t;
mov L0x2001a58c r9_b;
mov L0x2001a58e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000e; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a590; Value = 0xfe84066e; PC = 0x8005174 *)
mov r2_b L0x2001a590;
mov r2_t L0x2001a592;
mov r3_b L0x2001a594;
mov r3_t L0x2001a596;
mov r4_b L0x2001a598;
mov r4_t L0x2001a59a;
mov r5_b L0x2001a59c;
mov r5_t L0x2001a59e;
mov r6_b L0x2001a5a0;
mov r6_t L0x2001a5a2;
mov r7_b L0x2001a5a4;
mov r7_t L0x2001a5a6;
mov r8_b L0x2001a5a8;
mov r8_t L0x2001a5aa;
mov r9_b L0x2001a5ac;
mov r9_t L0x2001a5ae;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5ec; Value = 0x04fe09e7; PC = 0x8005178 *)
mov r10_b L0x800e5ec;
mov r10_t L0x800e5ee;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5f0; Value = 0x04a105fa; PC = 0x80051c4 *)
mov r10_b L0x800e5f0;
mov r10_t L0x800e5f2;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a590; PC = 0x8005284 *)
mov L0x2001a590 r2_b;
mov L0x2001a592 r2_t;
mov L0x2001a594 r3_b;
mov L0x2001a596 r3_t;
mov L0x2001a598 r4_b;
mov L0x2001a59a r4_t;
mov L0x2001a59c r5_b;
mov L0x2001a59e r5_t;
mov L0x2001a5a0 r6_b;
mov L0x2001a5a2 r6_t;
mov L0x2001a5a4 r7_b;
mov L0x2001a5a6 r7_t;
mov L0x2001a5a8 r8_b;
mov L0x2001a5aa r8_t;
mov L0x2001a5ac r9_b;
mov L0x2001a5ae r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000d; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a5b0; Value = 0xf935fbe1; PC = 0x8005174 *)
mov r2_b L0x2001a5b0;
mov r2_t L0x2001a5b2;
mov r3_b L0x2001a5b4;
mov r3_t L0x2001a5b6;
mov r4_b L0x2001a5b8;
mov r4_t L0x2001a5ba;
mov r5_b L0x2001a5bc;
mov r5_t L0x2001a5be;
mov r6_b L0x2001a5c0;
mov r6_t L0x2001a5c2;
mov r7_b L0x2001a5c4;
mov r7_t L0x2001a5c6;
mov r8_b L0x2001a5c8;
mov r8_t L0x2001a5ca;
mov r9_b L0x2001a5cc;
mov r9_t L0x2001a5ce;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5f4; Value = 0x04a3067b; PC = 0x8005178 *)
mov r10_b L0x800e5f4;
mov r10_t L0x800e5f6;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5f8; Value = 0x036a0c25; PC = 0x80051c4 *)
mov r10_b L0x800e5f8;
mov r10_t L0x800e5fa;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a5b0; PC = 0x8005284 *)
mov L0x2001a5b0 r2_b;
mov L0x2001a5b2 r2_t;
mov L0x2001a5b4 r3_b;
mov L0x2001a5b6 r3_t;
mov L0x2001a5b8 r4_b;
mov L0x2001a5ba r4_t;
mov L0x2001a5bc r5_b;
mov L0x2001a5be r5_t;
mov L0x2001a5c0 r6_b;
mov L0x2001a5c2 r6_t;
mov L0x2001a5c4 r7_b;
mov L0x2001a5c6 r7_t;
mov L0x2001a5c8 r8_b;
mov L0x2001a5ca r8_t;
mov L0x2001a5cc r9_b;
mov L0x2001a5ce r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000c; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a5d0; Value = 0xfd0b0222; PC = 0x8005174 *)
mov r2_b L0x2001a5d0;
mov r2_t L0x2001a5d2;
mov r3_b L0x2001a5d4;
mov r3_t L0x2001a5d6;
mov r4_b L0x2001a5d8;
mov r4_t L0x2001a5da;
mov r5_b L0x2001a5dc;
mov r5_t L0x2001a5de;
mov r6_b L0x2001a5e0;
mov r6_t L0x2001a5e2;
mov r7_b L0x2001a5e4;
mov r7_t L0x2001a5e6;
mov r8_b L0x2001a5e8;
mov r8_t L0x2001a5ea;
mov r9_b L0x2001a5ec;
mov r9_t L0x2001a5ee;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e5fc; Value = 0x083f0537; PC = 0x8005178 *)
mov r10_b L0x800e5fc;
mov r10_t L0x800e5fe;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e600; Value = 0x04bf0088; PC = 0x80051c4 *)
mov r10_b L0x800e600;
mov r10_t L0x800e602;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a5d0; PC = 0x8005284 *)
mov L0x2001a5d0 r2_b;
mov L0x2001a5d2 r2_t;
mov L0x2001a5d4 r3_b;
mov L0x2001a5d6 r3_t;
mov L0x2001a5d8 r4_b;
mov L0x2001a5da r4_t;
mov L0x2001a5dc r5_b;
mov L0x2001a5de r5_t;
mov L0x2001a5e0 r6_b;
mov L0x2001a5e2 r6_t;
mov L0x2001a5e4 r7_b;
mov L0x2001a5e6 r7_t;
mov L0x2001a5e8 r8_b;
mov L0x2001a5ea r8_t;
mov L0x2001a5ec r9_b;
mov L0x2001a5ee r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000b; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a5f0; Value = 0x016cfc43; PC = 0x8005174 *)
mov r2_b L0x2001a5f0;
mov r2_t L0x2001a5f2;
mov r3_b L0x2001a5f4;
mov r3_t L0x2001a5f6;
mov r4_b L0x2001a5f8;
mov r4_t L0x2001a5fa;
mov r5_b L0x2001a5fc;
mov r5_t L0x2001a5fe;
mov r6_b L0x2001a600;
mov r6_t L0x2001a602;
mov r7_b L0x2001a604;
mov r7_t L0x2001a606;
mov r8_b L0x2001a608;
mov r8_t L0x2001a60a;
mov r9_b L0x2001a60c;
mov r9_t L0x2001a60e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e604; Value = 0x05b90b81; PC = 0x8005178 *)
mov r10_b L0x800e604;
mov r10_t L0x800e606;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e608; Value = 0x07d70505; PC = 0x80051c4 *)
mov r10_b L0x800e608;
mov r10_t L0x800e60a;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a5f0; PC = 0x8005284 *)
mov L0x2001a5f0 r2_b;
mov L0x2001a5f2 r2_t;
mov L0x2001a5f4 r3_b;
mov L0x2001a5f6 r3_t;
mov L0x2001a5f8 r4_b;
mov L0x2001a5fa r4_t;
mov L0x2001a5fc r5_b;
mov L0x2001a5fe r5_t;
mov L0x2001a600 r6_b;
mov L0x2001a602 r6_t;
mov L0x2001a604 r7_b;
mov L0x2001a606 r7_t;
mov L0x2001a608 r8_b;
mov L0x2001a60a r8_t;
mov L0x2001a60c r9_b;
mov L0x2001a60e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000a; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a610; Value = 0x0113f8fe; PC = 0x8005174 *)
mov r2_b L0x2001a610;
mov r2_t L0x2001a612;
mov r3_b L0x2001a614;
mov r3_t L0x2001a616;
mov r4_b L0x2001a618;
mov r4_t L0x2001a61a;
mov r5_b L0x2001a61c;
mov r5_t L0x2001a61e;
mov r6_b L0x2001a620;
mov r6_t L0x2001a622;
mov r7_b L0x2001a624;
mov r7_t L0x2001a626;
mov r8_b L0x2001a628;
mov r8_t L0x2001a62a;
mov r9_b L0x2001a62c;
mov r9_t L0x2001a62e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e60c; Value = 0x0aa60a9f; PC = 0x8005178 *)
mov r10_b L0x800e60c;
mov r10_t L0x800e60e;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e610; Value = 0x09d008b8; PC = 0x80051c4 *)
mov r10_b L0x800e610;
mov r10_t L0x800e612;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a610; PC = 0x8005284 *)
mov L0x2001a610 r2_b;
mov L0x2001a612 r2_t;
mov L0x2001a614 r3_b;
mov L0x2001a616 r3_t;
mov L0x2001a618 r4_b;
mov L0x2001a61a r4_t;
mov L0x2001a61c r5_b;
mov L0x2001a61e r5_t;
mov L0x2001a620 r6_b;
mov L0x2001a622 r6_t;
mov L0x2001a624 r7_b;
mov L0x2001a626 r7_t;
mov L0x2001a628 r8_b;
mov L0x2001a62a r8_t;
mov L0x2001a62c r9_b;
mov L0x2001a62e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000009; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a630; Value = 0xff3d0b4b; PC = 0x8005174 *)
mov r2_b L0x2001a630;
mov r2_t L0x2001a632;
mov r3_b L0x2001a634;
mov r3_t L0x2001a636;
mov r4_b L0x2001a638;
mov r4_t L0x2001a63a;
mov r5_b L0x2001a63c;
mov r5_t L0x2001a63e;
mov r6_b L0x2001a640;
mov r6_t L0x2001a642;
mov r7_b L0x2001a644;
mov r7_t L0x2001a646;
mov r8_b L0x2001a648;
mov r8_t L0x2001a64a;
mov r9_b L0x2001a64c;
mov r9_t L0x2001a64e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e614; Value = 0x009c004b; PC = 0x8005178 *)
mov r10_b L0x800e614;
mov r10_t L0x800e616;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e618; Value = 0x0b5f0bb8; PC = 0x80051c4 *)
mov r10_b L0x800e618;
mov r10_t L0x800e61a;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a630; PC = 0x8005284 *)
mov L0x2001a630 r2_b;
mov L0x2001a632 r2_t;
mov L0x2001a634 r3_b;
mov L0x2001a636 r3_t;
mov L0x2001a638 r4_b;
mov L0x2001a63a r4_t;
mov L0x2001a63c r5_b;
mov L0x2001a63e r5_t;
mov L0x2001a640 r6_b;
mov L0x2001a642 r6_t;
mov L0x2001a644 r7_b;
mov L0x2001a646 r7_t;
mov L0x2001a648 r8_b;
mov L0x2001a64a r8_t;
mov L0x2001a64c r9_b;
mov L0x2001a64e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000008; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a650; Value = 0xf76102c9; PC = 0x8005174 *)
mov r2_b L0x2001a650;
mov r2_t L0x2001a652;
mov r3_b L0x2001a654;
mov r3_t L0x2001a656;
mov r4_b L0x2001a658;
mov r4_t L0x2001a65a;
mov r5_b L0x2001a65c;
mov r5_t L0x2001a65e;
mov r6_b L0x2001a660;
mov r6_t L0x2001a662;
mov r7_b L0x2001a664;
mov r7_t L0x2001a666;
mov r8_b L0x2001a668;
mov r8_t L0x2001a66a;
mov r9_b L0x2001a66c;
mov r9_t L0x2001a66e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e61c; Value = 0x03680ba4; PC = 0x8005178 *)
mov r10_b L0x800e61c;
mov r10_t L0x800e61e;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e620; Value = 0x06360a7d; PC = 0x80051c4 *)
mov r10_b L0x800e620;
mov r10_t L0x800e622;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a650; PC = 0x8005284 *)
mov L0x2001a650 r2_b;
mov L0x2001a652 r2_t;
mov L0x2001a654 r3_b;
mov L0x2001a656 r3_t;
mov L0x2001a658 r4_b;
mov L0x2001a65a r4_t;
mov L0x2001a65c r5_b;
mov L0x2001a65e r5_t;
mov L0x2001a660 r6_b;
mov L0x2001a662 r6_t;
mov L0x2001a664 r7_b;
mov L0x2001a666 r7_t;
mov L0x2001a668 r8_b;
mov L0x2001a66a r8_t;
mov L0x2001a66c r9_b;
mov L0x2001a66e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000007; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a670; Value = 0xf7d5034a; PC = 0x8005174 *)
mov r2_b L0x2001a670;
mov r2_t L0x2001a672;
mov r3_b L0x2001a674;
mov r3_t L0x2001a676;
mov r4_b L0x2001a678;
mov r4_t L0x2001a67a;
mov r5_b L0x2001a67c;
mov r5_t L0x2001a67e;
mov r6_b L0x2001a680;
mov r6_t L0x2001a682;
mov r7_b L0x2001a684;
mov r7_t L0x2001a686;
mov r8_b L0x2001a688;
mov r8_t L0x2001a68a;
mov r9_b L0x2001a68c;
mov r9_t L0x2001a68e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e624; Value = 0x025a08a2; PC = 0x8005178 *)
mov r10_b L0x800e624;
mov r10_t L0x800e626;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e628; Value = 0x03090736; PC = 0x80051c4 *)
mov r10_b L0x800e628;
mov r10_t L0x800e62a;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a670; PC = 0x8005284 *)
mov L0x2001a670 r2_b;
mov L0x2001a672 r2_t;
mov L0x2001a674 r3_b;
mov L0x2001a676 r3_t;
mov L0x2001a678 r4_b;
mov L0x2001a67a r4_t;
mov L0x2001a67c r5_b;
mov L0x2001a67e r5_t;
mov L0x2001a680 r6_b;
mov L0x2001a682 r6_t;
mov L0x2001a684 r7_b;
mov L0x2001a686 r7_t;
mov L0x2001a688 r8_b;
mov L0x2001a68a r8_t;
mov L0x2001a68c r9_b;
mov L0x2001a68e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000006; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a690; Value = 0xfdd601a7; PC = 0x8005174 *)
mov r2_b L0x2001a690;
mov r2_t L0x2001a692;
mov r3_b L0x2001a694;
mov r3_t L0x2001a696;
mov r4_b L0x2001a698;
mov r4_t L0x2001a69a;
mov r5_b L0x2001a69c;
mov r5_t L0x2001a69e;
mov r6_b L0x2001a6a0;
mov r6_t L0x2001a6a2;
mov r7_b L0x2001a6a4;
mov r7_t L0x2001a6a6;
mov r8_b L0x2001a6a8;
mov r8_t L0x2001a6aa;
mov r9_b L0x2001a6ac;
mov r9_t L0x2001a6ae;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e62c; Value = 0x087a0093; PC = 0x8005178 *)
mov r10_b L0x800e62c;
mov r10_t L0x800e62e;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e630; Value = 0x00f609f7; PC = 0x80051c4 *)
mov r10_b L0x800e630;
mov r10_t L0x800e632;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a690; PC = 0x8005284 *)
mov L0x2001a690 r2_b;
mov L0x2001a692 r2_t;
mov L0x2001a694 r3_b;
mov L0x2001a696 r3_t;
mov L0x2001a698 r4_b;
mov L0x2001a69a r4_t;
mov L0x2001a69c r5_b;
mov L0x2001a69e r5_t;
mov L0x2001a6a0 r6_b;
mov L0x2001a6a2 r6_t;
mov L0x2001a6a4 r7_b;
mov L0x2001a6a6 r7_t;
mov L0x2001a6a8 r8_b;
mov L0x2001a6aa r8_t;
mov L0x2001a6ac r9_b;
mov L0x2001a6ae r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000005; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a6b0; Value = 0x0da805b9; PC = 0x8005174 *)
mov r2_b L0x2001a6b0;
mov r2_t L0x2001a6b2;
mov r3_b L0x2001a6b4;
mov r3_t L0x2001a6b6;
mov r4_b L0x2001a6b8;
mov r4_t L0x2001a6ba;
mov r5_b L0x2001a6bc;
mov r5_t L0x2001a6be;
mov r6_b L0x2001a6c0;
mov r6_t L0x2001a6c2;
mov r7_b L0x2001a6c4;
mov r7_t L0x2001a6c6;
mov r8_b L0x2001a6c8;
mov r8_t L0x2001a6ca;
mov r9_b L0x2001a6cc;
mov r9_t L0x2001a6ce;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e634; Value = 0x06db068c; PC = 0x8005178 *)
mov r10_b L0x800e634;
mov r10_t L0x800e636;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e638; Value = 0x012301cc; PC = 0x80051c4 *)
mov r10_b L0x800e638;
mov r10_t L0x800e63a;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a6b0; PC = 0x8005284 *)
mov L0x2001a6b0 r2_b;
mov L0x2001a6b2 r2_t;
mov L0x2001a6b4 r3_b;
mov L0x2001a6b6 r3_t;
mov L0x2001a6b8 r4_b;
mov L0x2001a6ba r4_t;
mov L0x2001a6bc r5_b;
mov L0x2001a6be r5_t;
mov L0x2001a6c0 r6_b;
mov L0x2001a6c2 r6_t;
mov L0x2001a6c4 r7_b;
mov L0x2001a6c6 r7_t;
mov L0x2001a6c8 r8_b;
mov L0x2001a6ca r8_t;
mov L0x2001a6cc r9_b;
mov L0x2001a6ce r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000004; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a6d0; Value = 0xfa6dfaaa; PC = 0x8005174 *)
mov r2_b L0x2001a6d0;
mov r2_t L0x2001a6d2;
mov r3_b L0x2001a6d4;
mov r3_t L0x2001a6d6;
mov r4_b L0x2001a6d8;
mov r4_t L0x2001a6da;
mov r5_b L0x2001a6dc;
mov r5_t L0x2001a6de;
mov r6_b L0x2001a6e0;
mov r6_t L0x2001a6e2;
mov r7_b L0x2001a6e4;
mov r7_t L0x2001a6e6;
mov r8_b L0x2001a6e8;
mov r8_t L0x2001a6ea;
mov r9_b L0x2001a6ec;
mov r9_t L0x2001a6ee;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e63c; Value = 0x0c5000eb; PC = 0x8005178 *)
mov r10_b L0x800e63c;
mov r10_t L0x800e63e;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e640; Value = 0x0b5b0ab6; PC = 0x80051c4 *)
mov r10_b L0x800e640;
mov r10_t L0x800e642;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a6d0; PC = 0x8005284 *)
mov L0x2001a6d0 r2_b;
mov L0x2001a6d2 r2_t;
mov L0x2001a6d4 r3_b;
mov L0x2001a6d6 r3_t;
mov L0x2001a6d8 r4_b;
mov L0x2001a6da r4_t;
mov L0x2001a6dc r5_b;
mov L0x2001a6de r5_t;
mov L0x2001a6e0 r6_b;
mov L0x2001a6e2 r6_t;
mov L0x2001a6e4 r7_b;
mov L0x2001a6e6 r7_t;
mov L0x2001a6e8 r8_b;
mov L0x2001a6ea r8_t;
mov L0x2001a6ec r9_b;
mov L0x2001a6ee r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000003; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a6f0; Value = 0x03c20624; PC = 0x8005174 *)
mov r2_b L0x2001a6f0;
mov r2_t L0x2001a6f2;
mov r3_b L0x2001a6f4;
mov r3_t L0x2001a6f6;
mov r4_b L0x2001a6f8;
mov r4_t L0x2001a6fa;
mov r5_b L0x2001a6fc;
mov r5_t L0x2001a6fe;
mov r6_b L0x2001a700;
mov r6_t L0x2001a702;
mov r7_b L0x2001a704;
mov r7_t L0x2001a706;
mov r8_b L0x2001a708;
mov r8_t L0x2001a70a;
mov r9_b L0x2001a70c;
mov r9_t L0x2001a70e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e644; Value = 0x06f30c98; PC = 0x8005178 *)
mov r10_b L0x800e644;
mov r10_t L0x800e646;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e648; Value = 0x04e3099a; PC = 0x80051c4 *)
mov r10_b L0x800e648;
mov r10_t L0x800e64a;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a6f0; PC = 0x8005284 *)
mov L0x2001a6f0 r2_b;
mov L0x2001a6f2 r2_t;
mov L0x2001a6f4 r3_b;
mov L0x2001a6f6 r3_t;
mov L0x2001a6f8 r4_b;
mov L0x2001a6fa r4_t;
mov L0x2001a6fc r5_b;
mov L0x2001a6fe r5_t;
mov L0x2001a700 r6_b;
mov L0x2001a702 r6_t;
mov L0x2001a704 r7_b;
mov L0x2001a706 r7_t;
mov L0x2001a708 r8_b;
mov L0x2001a70a r8_t;
mov L0x2001a70c r9_b;
mov L0x2001a70e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000002; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x8005170 *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldmia.w	r0, {r2, r3, r4, r5, r6, r7, r8, r9}    #! EA = L0x2001a710; Value = 0x0067f653; PC = 0x8005174 *)
mov r2_b L0x2001a710;
mov r2_t L0x2001a712;
mov r3_b L0x2001a714;
mov r3_t L0x2001a716;
mov r4_b L0x2001a718;
mov r4_t L0x2001a71a;
mov r5_b L0x2001a71c;
mov r5_t L0x2001a71e;
mov r6_b L0x2001a720;
mov r6_t L0x2001a722;
mov r7_b L0x2001a724;
mov r7_t L0x2001a726;
mov r8_b L0x2001a728;
mov r8_t L0x2001a72a;
mov r9_b L0x2001a72c;
mov r9_t L0x2001a72e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e64c; Value = 0x0ad609b6; PC = 0x8005178 *)
mov r10_b L0x800e64c;
mov r10_t L0x800e64e;
(* usub16	r12, r2, r3                              #! PC = 0x800517c *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x8005180 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005184 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005188 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x800518c *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005190 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005194 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005198 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x800519c *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80051a0 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80051a4 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80051a8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051ac *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80051b0 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80051b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80051b8 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80051bc *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80051c0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e650; Value = 0x044f0b53; PC = 0x80051c4 *)
mov r10_b L0x800e650;
mov r10_t L0x800e652;
(* usub16	r12, r6, r7                              #! PC = 0x80051c8 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x80051cc *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x80051d0 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80051d4 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x80051d8 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x80051dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80051e0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80051e4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80051e8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80051ec *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80051f0 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80051f4 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80051f8 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80051fc *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005200 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005204 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005208 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800520c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005210 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005214 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005218 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800521c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005220 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005224 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005228 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800522c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005230 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005234 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005238 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800523c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005240 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005244 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005248 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r6, r10                              #! PC = 0x800524c *)
mull lr_t lr_b r6_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005250 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005254 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r6, r6, r10                              #! PC = 0x8005258 *)
mull r6_t r6_b r6_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x800525c *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005260 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r6, lr, r12, asr #16                      #! PC = 0x8005264 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* smulbb	lr, r8, r10                              #! PC = 0x8005268 *)
mull lr_t lr_b r8_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x800526c *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005270 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r8, r8, r10                              #! PC = 0x8005274 *)
mull r8_t r8_b r8_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005278 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800527c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r8, lr, r12, asr #16                      #! PC = 0x8005280 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* stmia.w	r0!, {r2, r3, r4, r5, r6, r7, r8, r9}   #! EA = L0x2001a710; PC = 0x8005284 *)
mov L0x2001a710 r2_b;
mov L0x2001a712 r2_t;
mov L0x2001a714 r3_b;
mov L0x2001a716 r3_t;
mov L0x2001a718 r4_b;
mov L0x2001a71a r4_t;
mov L0x2001a71c r5_b;
mov L0x2001a71e r5_t;
mov L0x2001a720 r6_b;
mov L0x2001a722 r6_t;
mov L0x2001a724 r7_b;
mov L0x2001a726 r7_t;
mov L0x2001a728 r8_b;
mov L0x2001a72a r8_t;
mov L0x2001a72c r9_b;
mov L0x2001a72e r9_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000001; PC = 0x8005288 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800528c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x8005170 <invntt_fast+16>               #! PC = 0x8005290 *)
#bne.w	0x8005170 <invntt_fast+16>               #! 0x8005290 = 0x8005290;
(* # END of layer 1 *)
# END of layer 1;

(* === layer 1 === *)
cut
  (* algebraic *)
  and [
    (* inp_poly_0 *)
    eqmod 2 * (inp_poly_0 * inp_poly_0)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3)
          )
          [3329, x**2 - 17],
    (* inp_poly_1 *)
    eqmod 2 * (inp_poly_1 * inp_poly_1)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3)
          )
          [3329, x**2 - 3312],
    (* inp_poly_2 *)
    eqmod 2 * (inp_poly_2 * inp_poly_2)
          (
            L0x2001a538 * (x**0) + L0x2001a53a * (x**1) + 
            L0x2001a53c * (x**2) + L0x2001a53e * (x**3)
          )
          [3329, x**2 - 2761],
    (* inp_poly_3 *)
    eqmod 2 * (inp_poly_3 * inp_poly_3)
          (
            L0x2001a538 * (x**0) + L0x2001a53a * (x**1) + 
            L0x2001a53c * (x**2) + L0x2001a53e * (x**3)
          )
          [3329, x**2 - 568],
    (* inp_poly_4 *)
    eqmod 2 * (inp_poly_4 * inp_poly_4)
          (
            L0x2001a540 * (x**0) + L0x2001a542 * (x**1) + 
            L0x2001a544 * (x**2) + L0x2001a546 * (x**3)
          )
          [3329, x**2 - 583],
    (* inp_poly_5 *)
    eqmod 2 * (inp_poly_5 * inp_poly_5)
          (
            L0x2001a540 * (x**0) + L0x2001a542 * (x**1) + 
            L0x2001a544 * (x**2) + L0x2001a546 * (x**3)
          )
          [3329, x**2 - 2746],
    (* inp_poly_6 *)
    eqmod 2 * (inp_poly_6 * inp_poly_6)
          (
            L0x2001a548 * (x**0) + L0x2001a54a * (x**1) + 
            L0x2001a54c * (x**2) + L0x2001a54e * (x**3)
          )
          [3329, x**2 - 2649],
    (* inp_poly_7 *)
    eqmod 2 * (inp_poly_7 * inp_poly_7)
          (
            L0x2001a548 * (x**0) + L0x2001a54a * (x**1) + 
            L0x2001a54c * (x**2) + L0x2001a54e * (x**3)
          )
          [3329, x**2 - 680],
    (* inp_poly_8 *)
    eqmod 2 * (inp_poly_8 * inp_poly_8)
          (
            L0x2001a550 * (x**0) + L0x2001a552 * (x**1) + 
            L0x2001a554 * (x**2) + L0x2001a556 * (x**3)
          )
          [3329, x**2 - 1637],
    (* inp_poly_9 *)
    eqmod 2 * (inp_poly_9 * inp_poly_9)
          (
            L0x2001a550 * (x**0) + L0x2001a552 * (x**1) + 
            L0x2001a554 * (x**2) + L0x2001a556 * (x**3)
          )
          [3329, x**2 - 1692],
    (* inp_poly_10 *)
    eqmod 2 * (inp_poly_10 * inp_poly_10)
          (
            L0x2001a558 * (x**0) + L0x2001a55a * (x**1) + 
            L0x2001a55c * (x**2) + L0x2001a55e * (x**3)
          )
          [3329, x**2 - 723],
    (* inp_poly_11 *)
    eqmod 2 * (inp_poly_11 * inp_poly_11)
          (
            L0x2001a558 * (x**0) + L0x2001a55a * (x**1) + 
            L0x2001a55c * (x**2) + L0x2001a55e * (x**3)
          )
          [3329, x**2 - 2606],
    (* inp_poly_12 *)
    eqmod 2 * (inp_poly_12 * inp_poly_12)
          (
            L0x2001a560 * (x**0) + L0x2001a562 * (x**1) + 
            L0x2001a564 * (x**2) + L0x2001a566 * (x**3)
          )
          [3329, x**2 - 2288],
    (* inp_poly_13 *)
    eqmod 2 * (inp_poly_13 * inp_poly_13)
          (
            L0x2001a560 * (x**0) + L0x2001a562 * (x**1) + 
            L0x2001a564 * (x**2) + L0x2001a566 * (x**3)
          )
          [3329, x**2 - 1041],
    (* inp_poly_14 *)
    eqmod 2 * (inp_poly_14 * inp_poly_14)
          (
            L0x2001a568 * (x**0) + L0x2001a56a * (x**1) + 
            L0x2001a56c * (x**2) + L0x2001a56e * (x**3)
          )
          [3329, x**2 - 1100],
    (* inp_poly_15 *)
    eqmod 2 * (inp_poly_15 * inp_poly_15)
          (
            L0x2001a568 * (x**0) + L0x2001a56a * (x**1) + 
            L0x2001a56c * (x**2) + L0x2001a56e * (x**3)
          )
          [3329, x**2 - 2229],
    (* inp_poly_16 *)
    eqmod 2 * (inp_poly_16 * inp_poly_16)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3)
          )
          [3329, x**2 - 1409],
    (* inp_poly_17 *)
    eqmod 2 * (inp_poly_17 * inp_poly_17)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3)
          )
          [3329, x**2 - 1920],
    (* inp_poly_18 *)
    eqmod 2 * (inp_poly_18 * inp_poly_18)
          (
            L0x2001a578 * (x**0) + L0x2001a57a * (x**1) + 
            L0x2001a57c * (x**2) + L0x2001a57e * (x**3)
          )
          [3329, x**2 - 2662],
    (* inp_poly_19 *)
    eqmod 2 * (inp_poly_19 * inp_poly_19)
          (
            L0x2001a578 * (x**0) + L0x2001a57a * (x**1) + 
            L0x2001a57c * (x**2) + L0x2001a57e * (x**3)
          )
          [3329, x**2 - 667],
    (* inp_poly_20 *)
    eqmod 2 * (inp_poly_20 * inp_poly_20)
          (
            L0x2001a580 * (x**0) + L0x2001a582 * (x**1) + 
            L0x2001a584 * (x**2) + L0x2001a586 * (x**3)
          )
          [3329, x**2 - 3281],
    (* inp_poly_21 *)
    eqmod 2 * (inp_poly_21 * inp_poly_21)
          (
            L0x2001a580 * (x**0) + L0x2001a582 * (x**1) + 
            L0x2001a584 * (x**2) + L0x2001a586 * (x**3)
          )
          [3329, x**2 - 48],
    (* inp_poly_22 *)
    eqmod 2 * (inp_poly_22 * inp_poly_22)
          (
            L0x2001a588 * (x**0) + L0x2001a58a * (x**1) + 
            L0x2001a58c * (x**2) + L0x2001a58e * (x**3)
          )
          [3329, x**2 - 233],
    (* inp_poly_23 *)
    eqmod 2 * (inp_poly_23 * inp_poly_23)
          (
            L0x2001a588 * (x**0) + L0x2001a58a * (x**1) + 
            L0x2001a58c * (x**2) + L0x2001a58e * (x**3)
          )
          [3329, x**2 - 3096],
    (* inp_poly_24 *)
    eqmod 2 * (inp_poly_24 * inp_poly_24)
          (
            L0x2001a590 * (x**0) + L0x2001a592 * (x**1) + 
            L0x2001a594 * (x**2) + L0x2001a596 * (x**3)
          )
          [3329, x**2 - 756],
    (* inp_poly_25 *)
    eqmod 2 * (inp_poly_25 * inp_poly_25)
          (
            L0x2001a590 * (x**0) + L0x2001a592 * (x**1) + 
            L0x2001a594 * (x**2) + L0x2001a596 * (x**3)
          )
          [3329, x**2 - 2573],
    (* inp_poly_26 *)
    eqmod 2 * (inp_poly_26 * inp_poly_26)
          (
            L0x2001a598 * (x**0) + L0x2001a59a * (x**1) + 
            L0x2001a59c * (x**2) + L0x2001a59e * (x**3)
          )
          [3329, x**2 - 2156],
    (* inp_poly_27 *)
    eqmod 2 * (inp_poly_27 * inp_poly_27)
          (
            L0x2001a598 * (x**0) + L0x2001a59a * (x**1) + 
            L0x2001a59c * (x**2) + L0x2001a59e * (x**3)
          )
          [3329, x**2 - 1173],
    (* inp_poly_28 *)
    eqmod 2 * (inp_poly_28 * inp_poly_28)
          (
            L0x2001a5a0 * (x**0) + L0x2001a5a2 * (x**1) + 
            L0x2001a5a4 * (x**2) + L0x2001a5a6 * (x**3)
          )
          [3329, x**2 - 3015],
    (* inp_poly_29 *)
    eqmod 2 * (inp_poly_29 * inp_poly_29)
          (
            L0x2001a5a0 * (x**0) + L0x2001a5a2 * (x**1) + 
            L0x2001a5a4 * (x**2) + L0x2001a5a6 * (x**3)
          )
          [3329, x**2 - 314],
    (* inp_poly_30 *)
    eqmod 2 * (inp_poly_30 * inp_poly_30)
          (
            L0x2001a5a8 * (x**0) + L0x2001a5aa * (x**1) + 
            L0x2001a5ac * (x**2) + L0x2001a5ae * (x**3)
          )
          [3329, x**2 - 3050],
    (* inp_poly_31 *)
    eqmod 2 * (inp_poly_31 * inp_poly_31)
          (
            L0x2001a5a8 * (x**0) + L0x2001a5aa * (x**1) + 
            L0x2001a5ac * (x**2) + L0x2001a5ae * (x**3)
          )
          [3329, x**2 - 279],
    (* inp_poly_32 *)
    eqmod 2 * (inp_poly_32 * inp_poly_32)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3)
          )
          [3329, x**2 - 1703],
    (* inp_poly_33 *)
    eqmod 2 * (inp_poly_33 * inp_poly_33)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3)
          )
          [3329, x**2 - 1626],
    (* inp_poly_34 *)
    eqmod 2 * (inp_poly_34 * inp_poly_34)
          (
            L0x2001a5b8 * (x**0) + L0x2001a5ba * (x**1) + 
            L0x2001a5bc * (x**2) + L0x2001a5be * (x**3)
          )
          [3329, x**2 - 1651],
    (* inp_poly_35 *)
    eqmod 2 * (inp_poly_35 * inp_poly_35)
          (
            L0x2001a5b8 * (x**0) + L0x2001a5ba * (x**1) + 
            L0x2001a5bc * (x**2) + L0x2001a5be * (x**3)
          )
          [3329, x**2 - 1678],
    (* inp_poly_36 *)
    eqmod 2 * (inp_poly_36 * inp_poly_36)
          (
            L0x2001a5c0 * (x**0) + L0x2001a5c2 * (x**1) + 
            L0x2001a5c4 * (x**2) + L0x2001a5c6 * (x**3)
          )
          [3329, x**2 - 2789],
    (* inp_poly_37 *)
    eqmod 2 * (inp_poly_37 * inp_poly_37)
          (
            L0x2001a5c0 * (x**0) + L0x2001a5c2 * (x**1) + 
            L0x2001a5c4 * (x**2) + L0x2001a5c6 * (x**3)
          )
          [3329, x**2 - 540],
    (* inp_poly_38 *)
    eqmod 2 * (inp_poly_38 * inp_poly_38)
          (
            L0x2001a5c8 * (x**0) + L0x2001a5ca * (x**1) + 
            L0x2001a5cc * (x**2) + L0x2001a5ce * (x**3)
          )
          [3329, x**2 - 1789],
    (* inp_poly_39 *)
    eqmod 2 * (inp_poly_39 * inp_poly_39)
          (
            L0x2001a5c8 * (x**0) + L0x2001a5ca * (x**1) + 
            L0x2001a5cc * (x**2) + L0x2001a5ce * (x**3)
          )
          [3329, x**2 - 1540],
    (* inp_poly_40 *)
    eqmod 2 * (inp_poly_40 * inp_poly_40)
          (
            L0x2001a5d0 * (x**0) + L0x2001a5d2 * (x**1) + 
            L0x2001a5d4 * (x**2) + L0x2001a5d6 * (x**3)
          )
          [3329, x**2 - 1847],
    (* inp_poly_41 *)
    eqmod 2 * (inp_poly_41 * inp_poly_41)
          (
            L0x2001a5d0 * (x**0) + L0x2001a5d2 * (x**1) + 
            L0x2001a5d4 * (x**2) + L0x2001a5d6 * (x**3)
          )
          [3329, x**2 - 1482],
    (* inp_poly_42 *)
    eqmod 2 * (inp_poly_42 * inp_poly_42)
          (
            L0x2001a5d8 * (x**0) + L0x2001a5da * (x**1) + 
            L0x2001a5dc * (x**2) + L0x2001a5de * (x**3)
          )
          [3329, x**2 - 952],
    (* inp_poly_43 *)
    eqmod 2 * (inp_poly_43 * inp_poly_43)
          (
            L0x2001a5d8 * (x**0) + L0x2001a5da * (x**1) + 
            L0x2001a5dc * (x**2) + L0x2001a5de * (x**3)
          )
          [3329, x**2 - 2377],
    (* inp_poly_44 *)
    eqmod 2 * (inp_poly_44 * inp_poly_44)
          (
            L0x2001a5e0 * (x**0) + L0x2001a5e2 * (x**1) + 
            L0x2001a5e4 * (x**2) + L0x2001a5e6 * (x**3)
          )
          [3329, x**2 - 1461],
    (* inp_poly_45 *)
    eqmod 2 * (inp_poly_45 * inp_poly_45)
          (
            L0x2001a5e0 * (x**0) + L0x2001a5e2 * (x**1) + 
            L0x2001a5e4 * (x**2) + L0x2001a5e6 * (x**3)
          )
          [3329, x**2 - 1868],
    (* inp_poly_46 *)
    eqmod 2 * (inp_poly_46 * inp_poly_46)
          (
            L0x2001a5e8 * (x**0) + L0x2001a5ea * (x**1) + 
            L0x2001a5ec * (x**2) + L0x2001a5ee * (x**3)
          )
          [3329, x**2 - 2687],
    (* inp_poly_47 *)
    eqmod 2 * (inp_poly_47 * inp_poly_47)
          (
            L0x2001a5e8 * (x**0) + L0x2001a5ea * (x**1) + 
            L0x2001a5ec * (x**2) + L0x2001a5ee * (x**3)
          )
          [3329, x**2 - 642],
    (* inp_poly_48 *)
    eqmod 2 * (inp_poly_48 * inp_poly_48)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3)
          )
          [3329, x**2 - 939],
    (* inp_poly_49 *)
    eqmod 2 * (inp_poly_49 * inp_poly_49)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3)
          )
          [3329, x**2 - 2390],
    (* inp_poly_50 *)
    eqmod 2 * (inp_poly_50 * inp_poly_50)
          (
            L0x2001a5f8 * (x**0) + L0x2001a5fa * (x**1) + 
            L0x2001a5fc * (x**2) + L0x2001a5fe * (x**3)
          )
          [3329, x**2 - 2308],
    (* inp_poly_51 *)
    eqmod 2 * (inp_poly_51 * inp_poly_51)
          (
            L0x2001a5f8 * (x**0) + L0x2001a5fa * (x**1) + 
            L0x2001a5fc * (x**2) + L0x2001a5fe * (x**3)
          )
          [3329, x**2 - 1021],
    (* inp_poly_52 *)
    eqmod 2 * (inp_poly_52 * inp_poly_52)
          (
            L0x2001a600 * (x**0) + L0x2001a602 * (x**1) + 
            L0x2001a604 * (x**2) + L0x2001a606 * (x**3)
          )
          [3329, x**2 - 2437],
    (* inp_poly_53 *)
    eqmod 2 * (inp_poly_53 * inp_poly_53)
          (
            L0x2001a600 * (x**0) + L0x2001a602 * (x**1) + 
            L0x2001a604 * (x**2) + L0x2001a606 * (x**3)
          )
          [3329, x**2 - 892],
    (* inp_poly_54 *)
    eqmod 2 * (inp_poly_54 * inp_poly_54)
          (
            L0x2001a608 * (x**0) + L0x2001a60a * (x**1) + 
            L0x2001a60c * (x**2) + L0x2001a60e * (x**3)
          )
          [3329, x**2 - 2388],
    (* inp_poly_55 *)
    eqmod 2 * (inp_poly_55 * inp_poly_55)
          (
            L0x2001a608 * (x**0) + L0x2001a60a * (x**1) + 
            L0x2001a60c * (x**2) + L0x2001a60e * (x**3)
          )
          [3329, x**2 - 941],
    (* inp_poly_56 *)
    eqmod 2 * (inp_poly_56 * inp_poly_56)
          (
            L0x2001a610 * (x**0) + L0x2001a612 * (x**1) + 
            L0x2001a614 * (x**2) + L0x2001a616 * (x**3)
          )
          [3329, x**2 - 733],
    (* inp_poly_57 *)
    eqmod 2 * (inp_poly_57 * inp_poly_57)
          (
            L0x2001a610 * (x**0) + L0x2001a612 * (x**1) + 
            L0x2001a614 * (x**2) + L0x2001a616 * (x**3)
          )
          [3329, x**2 - 2596],
    (* inp_poly_58 *)
    eqmod 2 * (inp_poly_58 * inp_poly_58)
          (
            L0x2001a618 * (x**0) + L0x2001a61a * (x**1) + 
            L0x2001a61c * (x**2) + L0x2001a61e * (x**3)
          )
          [3329, x**2 - 2337],
    (* inp_poly_59 *)
    eqmod 2 * (inp_poly_59 * inp_poly_59)
          (
            L0x2001a618 * (x**0) + L0x2001a61a * (x**1) + 
            L0x2001a61c * (x**2) + L0x2001a61e * (x**3)
          )
          [3329, x**2 - 992],
    (* inp_poly_60 *)
    eqmod 2 * (inp_poly_60 * inp_poly_60)
          (
            L0x2001a620 * (x**0) + L0x2001a622 * (x**1) + 
            L0x2001a624 * (x**2) + L0x2001a626 * (x**3)
          )
          [3329, x**2 - 268],
    (* inp_poly_61 *)
    eqmod 2 * (inp_poly_61 * inp_poly_61)
          (
            L0x2001a620 * (x**0) + L0x2001a622 * (x**1) + 
            L0x2001a624 * (x**2) + L0x2001a626 * (x**3)
          )
          [3329, x**2 - 3061],
    (* inp_poly_62 *)
    eqmod 2 * (inp_poly_62 * inp_poly_62)
          (
            L0x2001a628 * (x**0) + L0x2001a62a * (x**1) + 
            L0x2001a62c * (x**2) + L0x2001a62e * (x**3)
          )
          [3329, x**2 - 641],
    (* inp_poly_63 *)
    eqmod 2 * (inp_poly_63 * inp_poly_63)
          (
            L0x2001a628 * (x**0) + L0x2001a62a * (x**1) + 
            L0x2001a62c * (x**2) + L0x2001a62e * (x**3)
          )
          [3329, x**2 - 2688],
    (* inp_poly_64 *)
    eqmod 2 * (inp_poly_64 * inp_poly_64)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3)
          )
          [3329, x**2 - 1584],
    (* inp_poly_65 *)
    eqmod 2 * (inp_poly_65 * inp_poly_65)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3)
          )
          [3329, x**2 - 1745],
    (* inp_poly_66 *)
    eqmod 2 * (inp_poly_66 * inp_poly_66)
          (
            L0x2001a638 * (x**0) + L0x2001a63a * (x**1) + 
            L0x2001a63c * (x**2) + L0x2001a63e * (x**3)
          )
          [3329, x**2 - 2298],
    (* inp_poly_67 *)
    eqmod 2 * (inp_poly_67 * inp_poly_67)
          (
            L0x2001a638 * (x**0) + L0x2001a63a * (x**1) + 
            L0x2001a63c * (x**2) + L0x2001a63e * (x**3)
          )
          [3329, x**2 - 1031],
    (* inp_poly_68 *)
    eqmod 2 * (inp_poly_68 * inp_poly_68)
          (
            L0x2001a640 * (x**0) + L0x2001a642 * (x**1) + 
            L0x2001a644 * (x**2) + L0x2001a646 * (x**3)
          )
          [3329, x**2 - 2037],
    (* inp_poly_69 *)
    eqmod 2 * (inp_poly_69 * inp_poly_69)
          (
            L0x2001a640 * (x**0) + L0x2001a642 * (x**1) + 
            L0x2001a644 * (x**2) + L0x2001a646 * (x**3)
          )
          [3329, x**2 - 1292],
    (* inp_poly_70 *)
    eqmod 2 * (inp_poly_70 * inp_poly_70)
          (
            L0x2001a648 * (x**0) + L0x2001a64a * (x**1) + 
            L0x2001a64c * (x**2) + L0x2001a64e * (x**3)
          )
          [3329, x**2 - 3220],
    (* inp_poly_71 *)
    eqmod 2 * (inp_poly_71 * inp_poly_71)
          (
            L0x2001a648 * (x**0) + L0x2001a64a * (x**1) + 
            L0x2001a64c * (x**2) + L0x2001a64e * (x**3)
          )
          [3329, x**2 - 109],
    (* inp_poly_72 *)
    eqmod 2 * (inp_poly_72 * inp_poly_72)
          (
            L0x2001a650 * (x**0) + L0x2001a652 * (x**1) + 
            L0x2001a654 * (x**2) + L0x2001a656 * (x**3)
          )
          [3329, x**2 - 375],
    (* inp_poly_73 *)
    eqmod 2 * (inp_poly_73 * inp_poly_73)
          (
            L0x2001a650 * (x**0) + L0x2001a652 * (x**1) + 
            L0x2001a654 * (x**2) + L0x2001a656 * (x**3)
          )
          [3329, x**2 - 2954],
    (* inp_poly_74 *)
    eqmod 2 * (inp_poly_74 * inp_poly_74)
          (
            L0x2001a658 * (x**0) + L0x2001a65a * (x**1) + 
            L0x2001a65c * (x**2) + L0x2001a65e * (x**3)
          )
          [3329, x**2 - 2549],
    (* inp_poly_75 *)
    eqmod 2 * (inp_poly_75 * inp_poly_75)
          (
            L0x2001a658 * (x**0) + L0x2001a65a * (x**1) + 
            L0x2001a65c * (x**2) + L0x2001a65e * (x**3)
          )
          [3329, x**2 - 780],
    (* inp_poly_76 *)
    eqmod 2 * (inp_poly_76 * inp_poly_76)
          (
            L0x2001a660 * (x**0) + L0x2001a662 * (x**1) + 
            L0x2001a664 * (x**2) + L0x2001a666 * (x**3)
          )
          [3329, x**2 - 2090],
    (* inp_poly_77 *)
    eqmod 2 * (inp_poly_77 * inp_poly_77)
          (
            L0x2001a660 * (x**0) + L0x2001a662 * (x**1) + 
            L0x2001a664 * (x**2) + L0x2001a666 * (x**3)
          )
          [3329, x**2 - 1239],
    (* inp_poly_78 *)
    eqmod 2 * (inp_poly_78 * inp_poly_78)
          (
            L0x2001a668 * (x**0) + L0x2001a66a * (x**1) + 
            L0x2001a66c * (x**2) + L0x2001a66e * (x**3)
          )
          [3329, x**2 - 1645],
    (* inp_poly_79 *)
    eqmod 2 * (inp_poly_79 * inp_poly_79)
          (
            L0x2001a668 * (x**0) + L0x2001a66a * (x**1) + 
            L0x2001a66c * (x**2) + L0x2001a66e * (x**3)
          )
          [3329, x**2 - 1684],
    (* inp_poly_80 *)
    eqmod 2 * (inp_poly_80 * inp_poly_80)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3)
          )
          [3329, x**2 - 1063],
    (* inp_poly_81 *)
    eqmod 2 * (inp_poly_81 * inp_poly_81)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3)
          )
          [3329, x**2 - 2266],
    (* inp_poly_82 *)
    eqmod 2 * (inp_poly_82 * inp_poly_82)
          (
            L0x2001a678 * (x**0) + L0x2001a67a * (x**1) + 
            L0x2001a67c * (x**2) + L0x2001a67e * (x**3)
          )
          [3329, x**2 - 319],
    (* inp_poly_83 *)
    eqmod 2 * (inp_poly_83 * inp_poly_83)
          (
            L0x2001a678 * (x**0) + L0x2001a67a * (x**1) + 
            L0x2001a67c * (x**2) + L0x2001a67e * (x**3)
          )
          [3329, x**2 - 3010],
    (* inp_poly_84 *)
    eqmod 2 * (inp_poly_84 * inp_poly_84)
          (
            L0x2001a680 * (x**0) + L0x2001a682 * (x**1) + 
            L0x2001a684 * (x**2) + L0x2001a686 * (x**3)
          )
          [3329, x**2 - 2773],
    (* inp_poly_85 *)
    eqmod 2 * (inp_poly_85 * inp_poly_85)
          (
            L0x2001a680 * (x**0) + L0x2001a682 * (x**1) + 
            L0x2001a684 * (x**2) + L0x2001a686 * (x**3)
          )
          [3329, x**2 - 556],
    (* inp_poly_86 *)
    eqmod 2 * (inp_poly_86 * inp_poly_86)
          (
            L0x2001a688 * (x**0) + L0x2001a68a * (x**1) + 
            L0x2001a68c * (x**2) + L0x2001a68e * (x**3)
          )
          [3329, x**2 - 757],
    (* inp_poly_87 *)
    eqmod 2 * (inp_poly_87 * inp_poly_87)
          (
            L0x2001a688 * (x**0) + L0x2001a68a * (x**1) + 
            L0x2001a68c * (x**2) + L0x2001a68e * (x**3)
          )
          [3329, x**2 - 2572],
    (* inp_poly_88 *)
    eqmod 2 * (inp_poly_88 * inp_poly_88)
          (
            L0x2001a690 * (x**0) + L0x2001a692 * (x**1) + 
            L0x2001a694 * (x**2) + L0x2001a696 * (x**3)
          )
          [3329, x**2 - 2099],
    (* inp_poly_89 *)
    eqmod 2 * (inp_poly_89 * inp_poly_89)
          (
            L0x2001a690 * (x**0) + L0x2001a692 * (x**1) + 
            L0x2001a694 * (x**2) + L0x2001a696 * (x**3)
          )
          [3329, x**2 - 1230],
    (* inp_poly_90 *)
    eqmod 2 * (inp_poly_90 * inp_poly_90)
          (
            L0x2001a698 * (x**0) + L0x2001a69a * (x**1) + 
            L0x2001a69c * (x**2) + L0x2001a69e * (x**3)
          )
          [3329, x**2 - 561],
    (* inp_poly_91 *)
    eqmod 2 * (inp_poly_91 * inp_poly_91)
          (
            L0x2001a698 * (x**0) + L0x2001a69a * (x**1) + 
            L0x2001a69c * (x**2) + L0x2001a69e * (x**3)
          )
          [3329, x**2 - 2768],
    (* inp_poly_92 *)
    eqmod 2 * (inp_poly_92 * inp_poly_92)
          (
            L0x2001a6a0 * (x**0) + L0x2001a6a2 * (x**1) + 
            L0x2001a6a4 * (x**2) + L0x2001a6a6 * (x**3)
          )
          [3329, x**2 - 2466],
    (* inp_poly_93 *)
    eqmod 2 * (inp_poly_93 * inp_poly_93)
          (
            L0x2001a6a0 * (x**0) + L0x2001a6a2 * (x**1) + 
            L0x2001a6a4 * (x**2) + L0x2001a6a6 * (x**3)
          )
          [3329, x**2 - 863],
    (* inp_poly_94 *)
    eqmod 2 * (inp_poly_94 * inp_poly_94)
          (
            L0x2001a6a8 * (x**0) + L0x2001a6aa * (x**1) + 
            L0x2001a6ac * (x**2) + L0x2001a6ae * (x**3)
          )
          [3329, x**2 - 2594],
    (* inp_poly_95 *)
    eqmod 2 * (inp_poly_95 * inp_poly_95)
          (
            L0x2001a6a8 * (x**0) + L0x2001a6aa * (x**1) + 
            L0x2001a6ac * (x**2) + L0x2001a6ae * (x**3)
          )
          [3329, x**2 - 735],
    (* inp_poly_96 *)
    eqmod 2 * (inp_poly_96 * inp_poly_96)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3)
          )
          [3329, x**2 - 2804],
    (* inp_poly_97 *)
    eqmod 2 * (inp_poly_97 * inp_poly_97)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3)
          )
          [3329, x**2 - 525],
    (* inp_poly_98 *)
    eqmod 2 * (inp_poly_98 * inp_poly_98)
          (
            L0x2001a6b8 * (x**0) + L0x2001a6ba * (x**1) + 
            L0x2001a6bc * (x**2) + L0x2001a6be * (x**3)
          )
          [3329, x**2 - 1092],
    (* inp_poly_99 *)
    eqmod 2 * (inp_poly_99 * inp_poly_99)
          (
            L0x2001a6b8 * (x**0) + L0x2001a6ba * (x**1) + 
            L0x2001a6bc * (x**2) + L0x2001a6be * (x**3)
          )
          [3329, x**2 - 2237],
    (* inp_poly_100 *)
    eqmod 2 * (inp_poly_100 * inp_poly_100)
          (
            L0x2001a6c0 * (x**0) + L0x2001a6c2 * (x**1) + 
            L0x2001a6c4 * (x**2) + L0x2001a6c6 * (x**3)
          )
          [3329, x**2 - 403],
    (* inp_poly_101 *)
    eqmod 2 * (inp_poly_101 * inp_poly_101)
          (
            L0x2001a6c0 * (x**0) + L0x2001a6c2 * (x**1) + 
            L0x2001a6c4 * (x**2) + L0x2001a6c6 * (x**3)
          )
          [3329, x**2 - 2926],
    (* inp_poly_102 *)
    eqmod 2 * (inp_poly_102 * inp_poly_102)
          (
            L0x2001a6c8 * (x**0) + L0x2001a6ca * (x**1) + 
            L0x2001a6cc * (x**2) + L0x2001a6ce * (x**3)
          )
          [3329, x**2 - 1026],
    (* inp_poly_103 *)
    eqmod 2 * (inp_poly_103 * inp_poly_103)
          (
            L0x2001a6c8 * (x**0) + L0x2001a6ca * (x**1) + 
            L0x2001a6cc * (x**2) + L0x2001a6ce * (x**3)
          )
          [3329, x**2 - 2303],
    (* inp_poly_104 *)
    eqmod 2 * (inp_poly_104 * inp_poly_104)
          (
            L0x2001a6d0 * (x**0) + L0x2001a6d2 * (x**1) + 
            L0x2001a6d4 * (x**2) + L0x2001a6d6 * (x**3)
          )
          [3329, x**2 - 1143],
    (* inp_poly_105 *)
    eqmod 2 * (inp_poly_105 * inp_poly_105)
          (
            L0x2001a6d0 * (x**0) + L0x2001a6d2 * (x**1) + 
            L0x2001a6d4 * (x**2) + L0x2001a6d6 * (x**3)
          )
          [3329, x**2 - 2186],
    (* inp_poly_106 *)
    eqmod 2 * (inp_poly_106 * inp_poly_106)
          (
            L0x2001a6d8 * (x**0) + L0x2001a6da * (x**1) + 
            L0x2001a6dc * (x**2) + L0x2001a6de * (x**3)
          )
          [3329, x**2 - 2150],
    (* inp_poly_107 *)
    eqmod 2 * (inp_poly_107 * inp_poly_107)
          (
            L0x2001a6d8 * (x**0) + L0x2001a6da * (x**1) + 
            L0x2001a6dc * (x**2) + L0x2001a6de * (x**3)
          )
          [3329, x**2 - 1179],
    (* inp_poly_108 *)
    eqmod 2 * (inp_poly_108 * inp_poly_108)
          (
            L0x2001a6e0 * (x**0) + L0x2001a6e2 * (x**1) + 
            L0x2001a6e4 * (x**2) + L0x2001a6e6 * (x**3)
          )
          [3329, x**2 - 2775],
    (* inp_poly_109 *)
    eqmod 2 * (inp_poly_109 * inp_poly_109)
          (
            L0x2001a6e0 * (x**0) + L0x2001a6e2 * (x**1) + 
            L0x2001a6e4 * (x**2) + L0x2001a6e6 * (x**3)
          )
          [3329, x**2 - 554],
    (* inp_poly_110 *)
    eqmod 2 * (inp_poly_110 * inp_poly_110)
          (
            L0x2001a6e8 * (x**0) + L0x2001a6ea * (x**1) + 
            L0x2001a6ec * (x**2) + L0x2001a6ee * (x**3)
          )
          [3329, x**2 - 886],
    (* inp_poly_111 *)
    eqmod 2 * (inp_poly_111 * inp_poly_111)
          (
            L0x2001a6e8 * (x**0) + L0x2001a6ea * (x**1) + 
            L0x2001a6ec * (x**2) + L0x2001a6ee * (x**3)
          )
          [3329, x**2 - 2443],
    (* inp_poly_112 *)
    eqmod 2 * (inp_poly_112 * inp_poly_112)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3)
          )
          [3329, x**2 - 1722],
    (* inp_poly_113 *)
    eqmod 2 * (inp_poly_113 * inp_poly_113)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3)
          )
          [3329, x**2 - 1607],
    (* inp_poly_114 *)
    eqmod 2 * (inp_poly_114 * inp_poly_114)
          (
            L0x2001a6f8 * (x**0) + L0x2001a6fa * (x**1) + 
            L0x2001a6fc * (x**2) + L0x2001a6fe * (x**3)
          )
          [3329, x**2 - 1212],
    (* inp_poly_115 *)
    eqmod 2 * (inp_poly_115 * inp_poly_115)
          (
            L0x2001a6f8 * (x**0) + L0x2001a6fa * (x**1) + 
            L0x2001a6fc * (x**2) + L0x2001a6fe * (x**3)
          )
          [3329, x**2 - 2117],
    (* inp_poly_116 *)
    eqmod 2 * (inp_poly_116 * inp_poly_116)
          (
            L0x2001a700 * (x**0) + L0x2001a702 * (x**1) + 
            L0x2001a704 * (x**2) + L0x2001a706 * (x**3)
          )
          [3329, x**2 - 1874],
    (* inp_poly_117 *)
    eqmod 2 * (inp_poly_117 * inp_poly_117)
          (
            L0x2001a700 * (x**0) + L0x2001a702 * (x**1) + 
            L0x2001a704 * (x**2) + L0x2001a706 * (x**3)
          )
          [3329, x**2 - 1455],
    (* inp_poly_118 *)
    eqmod 2 * (inp_poly_118 * inp_poly_118)
          (
            L0x2001a708 * (x**0) + L0x2001a70a * (x**1) + 
            L0x2001a70c * (x**2) + L0x2001a70e * (x**3)
          )
          [3329, x**2 - 1029],
    (* inp_poly_119 *)
    eqmod 2 * (inp_poly_119 * inp_poly_119)
          (
            L0x2001a708 * (x**0) + L0x2001a70a * (x**1) + 
            L0x2001a70c * (x**2) + L0x2001a70e * (x**3)
          )
          [3329, x**2 - 2300],
    (* inp_poly_120 *)
    eqmod 2 * (inp_poly_120 * inp_poly_120)
          (
            L0x2001a710 * (x**0) + L0x2001a712 * (x**1) + 
            L0x2001a714 * (x**2) + L0x2001a716 * (x**3)
          )
          [3329, x**2 - 2110],
    (* inp_poly_121 *)
    eqmod 2 * (inp_poly_121 * inp_poly_121)
          (
            L0x2001a710 * (x**0) + L0x2001a712 * (x**1) + 
            L0x2001a714 * (x**2) + L0x2001a716 * (x**3)
          )
          [3329, x**2 - 1219],
    (* inp_poly_122 *)
    eqmod 2 * (inp_poly_122 * inp_poly_122)
          (
            L0x2001a718 * (x**0) + L0x2001a71a * (x**1) + 
            L0x2001a71c * (x**2) + L0x2001a71e * (x**3)
          )
          [3329, x**2 - 2935],
    (* inp_poly_123 *)
    eqmod 2 * (inp_poly_123 * inp_poly_123)
          (
            L0x2001a718 * (x**0) + L0x2001a71a * (x**1) + 
            L0x2001a71c * (x**2) + L0x2001a71e * (x**3)
          )
          [3329, x**2 - 394],
    (* inp_poly_124 *)
    eqmod 2 * (inp_poly_124 * inp_poly_124)
          (
            L0x2001a720 * (x**0) + L0x2001a722 * (x**1) + 
            L0x2001a724 * (x**2) + L0x2001a726 * (x**3)
          )
          [3329, x**2 - 885],
    (* inp_poly_125 *)
    eqmod 2 * (inp_poly_125 * inp_poly_125)
          (
            L0x2001a720 * (x**0) + L0x2001a722 * (x**1) + 
            L0x2001a724 * (x**2) + L0x2001a726 * (x**3)
          )
          [3329, x**2 - 2444],
    (* inp_poly_126 *)
    eqmod 2 * (inp_poly_126 * inp_poly_126)
          (
            L0x2001a728 * (x**0) + L0x2001a72a * (x**1) + 
            L0x2001a72c * (x**2) + L0x2001a72e * (x**3)
          )
          [3329, x**2 - 2154],
    (* inp_poly_127 *)
    eqmod 2 * (inp_poly_127 * inp_poly_127)
          (
            L0x2001a728 * (x**0) + L0x2001a72a * (x**1) + 
            L0x2001a72c * (x**2) + L0x2001a72e * (x**3)
          )
          [3329, x**2 - 1175]
  ]
  &&
  (* range *)
  and [
    1@16 * (-3329)@16 <=s L0x2001a530, L0x2001a530 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a532, L0x2001a532 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a534, L0x2001a534 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a536, L0x2001a536 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a538, L0x2001a538 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53a, L0x2001a53a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53c, L0x2001a53c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53e, L0x2001a53e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a540, L0x2001a540 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a542, L0x2001a542 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a544, L0x2001a544 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a546, L0x2001a546 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a548, L0x2001a548 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54a, L0x2001a54a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54c, L0x2001a54c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54e, L0x2001a54e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a550, L0x2001a550 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a552, L0x2001a552 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a554, L0x2001a554 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a556, L0x2001a556 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a558, L0x2001a558 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55a, L0x2001a55a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55c, L0x2001a55c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55e, L0x2001a55e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a560, L0x2001a560 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a562, L0x2001a562 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a564, L0x2001a564 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a566, L0x2001a566 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a568, L0x2001a568 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56a, L0x2001a56a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56c, L0x2001a56c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56e, L0x2001a56e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a570, L0x2001a570 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a572, L0x2001a572 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a574, L0x2001a574 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a576, L0x2001a576 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a578, L0x2001a578 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57a, L0x2001a57a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57c, L0x2001a57c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57e, L0x2001a57e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a580, L0x2001a580 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a582, L0x2001a582 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a584, L0x2001a584 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a586, L0x2001a586 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a588, L0x2001a588 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58a, L0x2001a58a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58c, L0x2001a58c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58e, L0x2001a58e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a590, L0x2001a590 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a592, L0x2001a592 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a594, L0x2001a594 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a596, L0x2001a596 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a598, L0x2001a598 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59a, L0x2001a59a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59c, L0x2001a59c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59e, L0x2001a59e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a0, L0x2001a5a0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a2, L0x2001a5a2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a4, L0x2001a5a4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a6, L0x2001a5a6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a8, L0x2001a5a8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5aa, L0x2001a5aa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ac, L0x2001a5ac <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ae, L0x2001a5ae <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b0, L0x2001a5b0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b2, L0x2001a5b2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b4, L0x2001a5b4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b6, L0x2001a5b6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b8, L0x2001a5b8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ba, L0x2001a5ba <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5bc, L0x2001a5bc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5be, L0x2001a5be <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c0, L0x2001a5c0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c2, L0x2001a5c2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c4, L0x2001a5c4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c6, L0x2001a5c6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c8, L0x2001a5c8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ca, L0x2001a5ca <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5cc, L0x2001a5cc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ce, L0x2001a5ce <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d0, L0x2001a5d0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d2, L0x2001a5d2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d4, L0x2001a5d4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d6, L0x2001a5d6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d8, L0x2001a5d8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5da, L0x2001a5da <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5dc, L0x2001a5dc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5de, L0x2001a5de <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e0, L0x2001a5e0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e2, L0x2001a5e2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e4, L0x2001a5e4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e6, L0x2001a5e6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e8, L0x2001a5e8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ea, L0x2001a5ea <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ec, L0x2001a5ec <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ee, L0x2001a5ee <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f0, L0x2001a5f0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f2, L0x2001a5f2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f4, L0x2001a5f4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f6, L0x2001a5f6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f8, L0x2001a5f8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fa, L0x2001a5fa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fc, L0x2001a5fc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fe, L0x2001a5fe <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a600, L0x2001a600 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a602, L0x2001a602 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a604, L0x2001a604 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a606, L0x2001a606 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a608, L0x2001a608 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60a, L0x2001a60a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60c, L0x2001a60c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60e, L0x2001a60e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a610, L0x2001a610 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a612, L0x2001a612 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a614, L0x2001a614 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a616, L0x2001a616 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a618, L0x2001a618 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61a, L0x2001a61a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61c, L0x2001a61c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61e, L0x2001a61e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a620, L0x2001a620 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a622, L0x2001a622 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a624, L0x2001a624 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a626, L0x2001a626 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a628, L0x2001a628 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62a, L0x2001a62a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62c, L0x2001a62c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62e, L0x2001a62e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a630, L0x2001a630 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a632, L0x2001a632 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a634, L0x2001a634 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a636, L0x2001a636 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a638, L0x2001a638 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63a, L0x2001a63a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63c, L0x2001a63c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63e, L0x2001a63e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a640, L0x2001a640 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a642, L0x2001a642 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a644, L0x2001a644 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a646, L0x2001a646 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a648, L0x2001a648 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64a, L0x2001a64a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64c, L0x2001a64c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64e, L0x2001a64e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a650, L0x2001a650 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a652, L0x2001a652 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a654, L0x2001a654 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a656, L0x2001a656 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a658, L0x2001a658 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65a, L0x2001a65a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65c, L0x2001a65c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65e, L0x2001a65e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a660, L0x2001a660 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a662, L0x2001a662 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a664, L0x2001a664 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a666, L0x2001a666 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a668, L0x2001a668 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66a, L0x2001a66a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66c, L0x2001a66c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66e, L0x2001a66e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a670, L0x2001a670 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a672, L0x2001a672 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a674, L0x2001a674 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a676, L0x2001a676 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a678, L0x2001a678 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67a, L0x2001a67a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67c, L0x2001a67c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67e, L0x2001a67e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a680, L0x2001a680 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a682, L0x2001a682 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a684, L0x2001a684 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a686, L0x2001a686 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a688, L0x2001a688 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68a, L0x2001a68a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68c, L0x2001a68c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68e, L0x2001a68e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a690, L0x2001a690 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a692, L0x2001a692 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a694, L0x2001a694 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a696, L0x2001a696 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a698, L0x2001a698 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69a, L0x2001a69a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69c, L0x2001a69c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69e, L0x2001a69e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a0, L0x2001a6a0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a2, L0x2001a6a2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a4, L0x2001a6a4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a6, L0x2001a6a6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a8, L0x2001a6a8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6aa, L0x2001a6aa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ac, L0x2001a6ac <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ae, L0x2001a6ae <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b0, L0x2001a6b0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b2, L0x2001a6b2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b4, L0x2001a6b4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b6, L0x2001a6b6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b8, L0x2001a6b8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ba, L0x2001a6ba <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6bc, L0x2001a6bc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6be, L0x2001a6be <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c0, L0x2001a6c0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c2, L0x2001a6c2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c4, L0x2001a6c4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c6, L0x2001a6c6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c8, L0x2001a6c8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ca, L0x2001a6ca <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6cc, L0x2001a6cc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ce, L0x2001a6ce <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d0, L0x2001a6d0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d2, L0x2001a6d2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d4, L0x2001a6d4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d6, L0x2001a6d6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d8, L0x2001a6d8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6da, L0x2001a6da <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6dc, L0x2001a6dc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6de, L0x2001a6de <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e0, L0x2001a6e0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e2, L0x2001a6e2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e4, L0x2001a6e4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e6, L0x2001a6e6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e8, L0x2001a6e8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ea, L0x2001a6ea <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ec, L0x2001a6ec <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ee, L0x2001a6ee <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f0, L0x2001a6f0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f2, L0x2001a6f2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f4, L0x2001a6f4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f6, L0x2001a6f6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f8, L0x2001a6f8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fa, L0x2001a6fa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fc, L0x2001a6fc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fe, L0x2001a6fe <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a700, L0x2001a700 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a702, L0x2001a702 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a704, L0x2001a704 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a706, L0x2001a706 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a708, L0x2001a708 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70a, L0x2001a70a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70c, L0x2001a70c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70e, L0x2001a70e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a710, L0x2001a710 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a712, L0x2001a712 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a714, L0x2001a714 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a716, L0x2001a716 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a718, L0x2001a718 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71a, L0x2001a71a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71c, L0x2001a71c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71e, L0x2001a71e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a720, L0x2001a720 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a722, L0x2001a722 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a724, L0x2001a724 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a726, L0x2001a726 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a728, L0x2001a728 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72a, L0x2001a72a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72c, L0x2001a72c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72e, L0x2001a72e <s 1@16 * 3329@16
  ]
;


(* sub.w	r0, r0, #512	; 0x200                      #! PC = 0x8005294 *)
subs discard r0 r0 512@uint32;
(* movw	r12, #8                                    #! PC = 0x8005298 *)
mov r12_b 8@sint16;
mov r12_t 0@sint16;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a530; Value = 0x042d039e; PC = 0x80052a0 *)
mov r2_b L0x2001a530;
mov r2_t L0x2001a532;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a538; Value = 0xfbc6fd2b; PC = 0x80052a4 *)
mov r3_b L0x2001a538;
mov r3_t L0x2001a53a;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a540; Value = 0x0539ff2b; PC = 0x80052a8 *)
mov r4_b L0x2001a540;
mov r4_t L0x2001a542;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a548; Value = 0xffad04e7; PC = 0x80052ac *)
mov r5_b L0x2001a548;
mov r5_t L0x2001a54a;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a550; Value = 0xfedd05e9; PC = 0x80052b0 *)
mov r6_b L0x2001a550;
mov r6_t L0x2001a552;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a558; Value = 0xfb1f04b4; PC = 0x80052b4 *)
mov r7_b L0x2001a558;
mov r7_t L0x2001a55a;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a560; Value = 0xfeeb00fb; PC = 0x80052b8 *)
mov r8_b L0x2001a560;
mov r8_t L0x2001a562;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a568; Value = 0x044402c8; PC = 0x80052bc *)
mov r9_b L0x2001a568;
mov r9_t L0x2001a56a;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e654; Value = 0x0a5c04fb; PC = 0x80052c0 *)
mov r10_b L0x800e654;
mov r10_t L0x800e656;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e658; Value = 0x0b410429; PC = 0x800530c *)
mov r10_b L0x800e658;
mov r10_t L0x800e65a;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e65c; Value = 0x00cd0623; PC = 0x8005358 *)
mov r10_b L0x800e65c;
mov r10_t L0x800e65e;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e660; Value = 0x02d50745; PC = 0x80053ec *)
mov r10_b L0x800e660;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a550; PC = 0x80054f4 *)
mov L0x2001a550 r6_b;
mov L0x2001a552 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a558; PC = 0x80054f8 *)
mov L0x2001a558 r7_b;
mov L0x2001a55a r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a560; PC = 0x80054fc *)
mov L0x2001a560 r8_b;
mov L0x2001a562 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a568; PC = 0x8005500 *)
mov L0x2001a568 r9_b;
mov L0x2001a56a r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a538; PC = 0x8005504 *)
mov L0x2001a538 r3_b;
mov L0x2001a53a r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a540; PC = 0x8005508 *)
mov L0x2001a540 r4_b;
mov L0x2001a542 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a548; PC = 0x800550c *)
mov L0x2001a548 r5_b;
mov L0x2001a54a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a530; PC = 0x8005510 *)
mov L0x2001a530 r2_b;
mov L0x2001a532 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a534; Value = 0x000bfb4e; PC = 0x8005514 *)
mov r2_b L0x2001a534;
mov r2_t L0x2001a536;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a53c; Value = 0x02820047; PC = 0x8005518 *)
mov r3_b L0x2001a53c;
mov r3_t L0x2001a53e;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a544; Value = 0x00410211; PC = 0x800551c *)
mov r4_b L0x2001a544;
mov r4_t L0x2001a546;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a54c; Value = 0x013702d0; PC = 0x8005520 *)
mov r5_b L0x2001a54c;
mov r5_t L0x2001a54e;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a554; Value = 0xfa4e00b2; PC = 0x8005524 *)
mov r6_b L0x2001a554;
mov r6_t L0x2001a556;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a55c; Value = 0xfc97056e; PC = 0x8005528 *)
mov r7_b L0x2001a55c;
mov r7_t L0x2001a55e;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a564; Value = 0x04b4fd45; PC = 0x800552c *)
mov r8_b L0x2001a564;
mov r8_t L0x2001a566;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a56c; Value = 0x03affb68; PC = 0x8005530 *)
mov r9_b L0x2001a56c;
mov r9_t L0x2001a56e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e654; Value = 0x0a5c04fb; PC = 0x8005534 *)
mov r10_b L0x800e654;
mov r10_t L0x800e656;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e658; Value = 0x0b410429; PC = 0x8005580 *)
mov r10_b L0x800e658;
mov r10_t L0x800e65a;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e65c; Value = 0x00cd0623; PC = 0x80055cc *)
mov r10_b L0x800e65c;
mov r10_t L0x800e65e;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e660; Value = 0x02d50745; PC = 0x8005660 *)
mov r10_b L0x800e660;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a554; PC = 0x8005768 *)
mov L0x2001a554 r6_b;
mov L0x2001a556 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a55c; PC = 0x800576c *)
mov L0x2001a55c r7_b;
mov L0x2001a55e r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a564; PC = 0x8005770 *)
mov L0x2001a564 r8_b;
mov L0x2001a566 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a56c; PC = 0x8005774 *)
mov L0x2001a56c r9_b;
mov L0x2001a56e r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a53c; PC = 0x8005778 *)
mov L0x2001a53c r3_b;
mov L0x2001a53e r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a544; PC = 0x800577c *)
mov L0x2001a544 r4_b;
mov L0x2001a546 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a54c; PC = 0x8005780 *)
mov L0x2001a54c r5_b;
mov L0x2001a54e r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a534; PC = 0x8005784 *)
mov L0x2001a534 r2_b;
mov L0x2001a536 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000008; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a570; Value = 0xfbc9036c; PC = 0x80052a0 *)
mov r2_b L0x2001a570;
mov r2_t L0x2001a572;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a578; Value = 0xfd14fbf6; PC = 0x80052a4 *)
mov r3_b L0x2001a578;
mov r3_t L0x2001a57a;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a580; Value = 0x02a9fce1; PC = 0x80052a8 *)
mov r4_b L0x2001a580;
mov r4_t L0x2001a582;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a588; Value = 0x02d7fe7e; PC = 0x80052ac *)
mov r5_b L0x2001a588;
mov r5_t L0x2001a58a;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a590; Value = 0xffd40250; PC = 0x80052b0 *)
mov r6_b L0x2001a590;
mov r6_t L0x2001a592;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a598; Value = 0xff04fca6; PC = 0x80052b4 *)
mov r7_b L0x2001a598;
mov r7_t L0x2001a59a;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5a0; Value = 0x05de00e0; PC = 0x80052b8 *)
mov r8_b L0x2001a5a0;
mov r8_t L0x2001a5a2;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5a8; Value = 0xfa520634; PC = 0x80052bc *)
mov r9_b L0x2001a5a8;
mov r9_t L0x2001a5aa;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e662; Value = 0x05e402d5; PC = 0x80052c0 *)
mov r10_b L0x800e662;
mov r10_t L0x800e664;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e666; Value = 0x018e0940; PC = 0x800530c *)
mov r10_b L0x800e666;
mov r10_t L0x800e668;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e66a; Value = 0x06060b66; PC = 0x8005358 *)
mov r10_b L0x800e66a;
mov r10_t L0x800e66c;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e66e; Value = 0x03b705c2; PC = 0x80053ec *)
mov r10_b L0x800e66e;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a590; PC = 0x80054f4 *)
mov L0x2001a590 r6_b;
mov L0x2001a592 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a598; PC = 0x80054f8 *)
mov L0x2001a598 r7_b;
mov L0x2001a59a r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5a0; PC = 0x80054fc *)
mov L0x2001a5a0 r8_b;
mov L0x2001a5a2 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5a8; PC = 0x8005500 *)
mov L0x2001a5a8 r9_b;
mov L0x2001a5aa r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a578; PC = 0x8005504 *)
mov L0x2001a578 r3_b;
mov L0x2001a57a r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a580; PC = 0x8005508 *)
mov L0x2001a580 r4_b;
mov L0x2001a582 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a588; PC = 0x800550c *)
mov L0x2001a588 r5_b;
mov L0x2001a58a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a570; PC = 0x8005510 *)
mov L0x2001a570 r2_b;
mov L0x2001a572 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a574; Value = 0xfc89055c; PC = 0x8005514 *)
mov r2_b L0x2001a574;
mov r2_t L0x2001a576;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a57c; Value = 0xfc830375; PC = 0x8005518 *)
mov r3_b L0x2001a57c;
mov r3_t L0x2001a57e;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a584; Value = 0x001503e9; PC = 0x800551c *)
mov r4_b L0x2001a584;
mov r4_t L0x2001a586;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a58c; Value = 0x017bfe08; PC = 0x8005520 *)
mov r5_b L0x2001a58c;
mov r5_t L0x2001a58e;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a594; Value = 0xfbbbfe28; PC = 0x8005524 *)
mov r6_b L0x2001a594;
mov r6_t L0x2001a596;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a59c; Value = 0x004afbf2; PC = 0x8005528 *)
mov r7_b L0x2001a59c;
mov r7_t L0x2001a59e;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5a4; Value = 0x060800b8; PC = 0x800552c *)
mov r8_b L0x2001a5a4;
mov r8_t L0x2001a5a6;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5ac; Value = 0x05c502bf; PC = 0x8005530 *)
mov r9_b L0x2001a5ac;
mov r9_t L0x2001a5ae;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e662; Value = 0x05e402d5; PC = 0x8005534 *)
mov r10_b L0x800e662;
mov r10_t L0x800e664;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e666; Value = 0x018e0940; PC = 0x8005580 *)
mov r10_b L0x800e666;
mov r10_t L0x800e668;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e66a; Value = 0x06060b66; PC = 0x80055cc *)
mov r10_b L0x800e66a;
mov r10_t L0x800e66c;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e66e; Value = 0x03b705c2; PC = 0x8005660 *)
mov r10_b L0x800e66e;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a594; PC = 0x8005768 *)
mov L0x2001a594 r6_b;
mov L0x2001a596 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a59c; PC = 0x800576c *)
mov L0x2001a59c r7_b;
mov L0x2001a59e r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5a4; PC = 0x8005770 *)
mov L0x2001a5a4 r8_b;
mov L0x2001a5a6 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5ac; PC = 0x8005774 *)
mov L0x2001a5ac r9_b;
mov L0x2001a5ae r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a57c; PC = 0x8005778 *)
mov L0x2001a57c r3_b;
mov L0x2001a57e r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a584; PC = 0x800577c *)
mov L0x2001a584 r4_b;
mov L0x2001a586 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a58c; PC = 0x8005780 *)
mov L0x2001a58c r5_b;
mov L0x2001a58e r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a574; PC = 0x8005784 *)
mov L0x2001a574 r2_b;
mov L0x2001a576 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000007; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a5b0; Value = 0xff98f955; PC = 0x80052a0 *)
mov r2_b L0x2001a5b0;
mov r2_t L0x2001a5b2;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a5b8; Value = 0xfd42036b; PC = 0x80052a4 *)
mov r3_b L0x2001a5b8;
mov r3_t L0x2001a5ba;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a5c0; Value = 0xfa3a05c9; PC = 0x80052a8 *)
mov r4_b L0x2001a5c0;
mov r4_t L0x2001a5c2;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a5c8; Value = 0xfe4cfbf6; PC = 0x80052ac *)
mov r5_b L0x2001a5c8;
mov r5_t L0x2001a5ca;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a5d0; Value = 0xfdf5037b; PC = 0x80052b0 *)
mov r6_b L0x2001a5d0;
mov r6_t L0x2001a5d2;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a5d8; Value = 0xfe71fd2a; PC = 0x80052b4 *)
mov r7_b L0x2001a5d8;
mov r7_t L0x2001a5da;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5e0; Value = 0x05cf04b1; PC = 0x80052b8 *)
mov r8_b L0x2001a5e0;
mov r8_t L0x2001a5e2;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5e8; Value = 0x05a8fbec; PC = 0x80052bc *)
mov r9_b L0x2001a5e8;
mov r9_t L0x2001a5ea;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e670; Value = 0x00f703b7; PC = 0x80052c0 *)
mov r10_b L0x800e670;
mov r10_t L0x800e672;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e674; Value = 0x0c96058d; PC = 0x800530c *)
mov r10_b L0x800e674;
mov r10_t L0x800e676;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e678; Value = 0x0a250aa1; PC = 0x8005358 *)
mov r10_b L0x800e678;
mov r10_t L0x800e67a;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e67c; Value = 0x09c304b2; PC = 0x80053ec *)
mov r10_b L0x800e67c;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a5d0; PC = 0x80054f4 *)
mov L0x2001a5d0 r6_b;
mov L0x2001a5d2 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a5d8; PC = 0x80054f8 *)
mov L0x2001a5d8 r7_b;
mov L0x2001a5da r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5e0; PC = 0x80054fc *)
mov L0x2001a5e0 r8_b;
mov L0x2001a5e2 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5e8; PC = 0x8005500 *)
mov L0x2001a5e8 r9_b;
mov L0x2001a5ea r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a5b8; PC = 0x8005504 *)
mov L0x2001a5b8 r3_b;
mov L0x2001a5ba r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a5c0; PC = 0x8005508 *)
mov L0x2001a5c0 r4_b;
mov L0x2001a5c2 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a5c8; PC = 0x800550c *)
mov L0x2001a5c8 r5_b;
mov L0x2001a5ca r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a5b0; PC = 0x8005510 *)
mov L0x2001a5b0 r2_b;
mov L0x2001a5b2 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a5b4; Value = 0x00d7004c; PC = 0x8005514 *)
mov r2_b L0x2001a5b4;
mov r2_t L0x2001a5b6;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a5bc; Value = 0x05440063; PC = 0x8005518 *)
mov r3_b L0x2001a5bc;
mov r3_t L0x2001a5be;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a5c4; Value = 0xf969fd6f; PC = 0x800551c *)
mov r4_b L0x2001a5c4;
mov r4_t L0x2001a5c6;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a5cc; Value = 0xfb14fd9a; PC = 0x8005520 *)
mov r5_b L0x2001a5cc;
mov r5_t L0x2001a5ce;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a5d4; Value = 0x048a03d1; PC = 0x8005524 *)
mov r6_b L0x2001a5d4;
mov r6_t L0x2001a5d6;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a5dc; Value = 0x01c9fd32; PC = 0x8005528 *)
mov r7_b L0x2001a5dc;
mov r7_t L0x2001a5de;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5e4; Value = 0x0627fcf6; PC = 0x800552c *)
mov r8_b L0x2001a5e4;
mov r8_t L0x2001a5e6;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5ec; Value = 0xfe28fc41; PC = 0x8005530 *)
mov r9_b L0x2001a5ec;
mov r9_t L0x2001a5ee;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e670; Value = 0x00f703b7; PC = 0x8005534 *)
mov r10_b L0x800e670;
mov r10_t L0x800e672;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e674; Value = 0x0c96058d; PC = 0x8005580 *)
mov r10_b L0x800e674;
mov r10_t L0x800e676;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e678; Value = 0x0a250aa1; PC = 0x80055cc *)
mov r10_b L0x800e678;
mov r10_t L0x800e67a;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e67c; Value = 0x09c304b2; PC = 0x8005660 *)
mov r10_b L0x800e67c;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a5d4; PC = 0x8005768 *)
mov L0x2001a5d4 r6_b;
mov L0x2001a5d6 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a5dc; PC = 0x800576c *)
mov L0x2001a5dc r7_b;
mov L0x2001a5de r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a5e4; PC = 0x8005770 *)
mov L0x2001a5e4 r8_b;
mov L0x2001a5e6 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a5ec; PC = 0x8005774 *)
mov L0x2001a5ec r9_b;
mov L0x2001a5ee r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a5bc; PC = 0x8005778 *)
mov L0x2001a5bc r3_b;
mov L0x2001a5be r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a5c4; PC = 0x800577c *)
mov L0x2001a5c4 r4_b;
mov L0x2001a5c6 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a5cc; PC = 0x8005780 *)
mov L0x2001a5cc r5_b;
mov L0x2001a5ce r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a5b4; PC = 0x8005784 *)
mov L0x2001a5b4 r2_b;
mov L0x2001a5b6 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000006; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a5f0; Value = 0x008705ef; PC = 0x80052a0 *)
mov r2_b L0x2001a5f0;
mov r2_t L0x2001a5f2;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a5f8; Value = 0x032905f8; PC = 0x80052a4 *)
mov r3_b L0x2001a5f8;
mov r3_t L0x2001a5fa;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a600; Value = 0xff8bfff9; PC = 0x80052a8 *)
mov r4_b L0x2001a600;
mov r4_t L0x2001a602;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a608; Value = 0x02f9037f; PC = 0x80052ac *)
mov r5_b L0x2001a608;
mov r5_t L0x2001a60a;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a610; Value = 0xff0003c4; PC = 0x80052b0 *)
mov r6_b L0x2001a610;
mov r6_t L0x2001a612;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a618; Value = 0x0412fa4c; PC = 0x80052b4 *)
mov r7_b L0x2001a618;
mov r7_t L0x2001a61a;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a620; Value = 0xfdd4fcee; PC = 0x80052b8 *)
mov r8_b L0x2001a620;
mov r8_t L0x2001a622;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a628; Value = 0x00260438; PC = 0x80052bc *)
mov r9_b L0x2001a628;
mov r9_t L0x2001a62a;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e67e; Value = 0x010f09c3; PC = 0x80052c0 *)
mov r10_b L0x800e67e;
mov r10_t L0x800e680;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e682; Value = 0x0355005a; PC = 0x800530c *)
mov r10_b L0x800e682;
mov r10_t L0x800e684;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e686; Value = 0x02a90908; PC = 0x8005358 *)
mov r10_b L0x800e686;
mov r10_t L0x800e688;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e68a; Value = 0x0744093f; PC = 0x80053ec *)
mov r10_b L0x800e68a;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a610; PC = 0x80054f4 *)
mov L0x2001a610 r6_b;
mov L0x2001a612 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a618; PC = 0x80054f8 *)
mov L0x2001a618 r7_b;
mov L0x2001a61a r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a620; PC = 0x80054fc *)
mov L0x2001a620 r8_b;
mov L0x2001a622 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a628; PC = 0x8005500 *)
mov L0x2001a628 r9_b;
mov L0x2001a62a r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a5f8; PC = 0x8005504 *)
mov L0x2001a5f8 r3_b;
mov L0x2001a5fa r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a600; PC = 0x8005508 *)
mov L0x2001a600 r4_b;
mov L0x2001a602 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a608; PC = 0x800550c *)
mov L0x2001a608 r5_b;
mov L0x2001a60a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a5f0; PC = 0x8005510 *)
mov L0x2001a5f0 r2_b;
mov L0x2001a5f2 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a5f4; Value = 0xffa80515; PC = 0x8005514 *)
mov r2_b L0x2001a5f4;
mov r2_t L0x2001a5f6;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a5fc; Value = 0xfa570281; PC = 0x8005518 *)
mov r3_b L0x2001a5fc;
mov r3_t L0x2001a5fe;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a604; Value = 0x0290fad9; PC = 0x800551c *)
mov r4_b L0x2001a604;
mov r4_t L0x2001a606;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a60c; Value = 0xfa8cfc3b; PC = 0x8005520 *)
mov r5_b L0x2001a60c;
mov r5_t L0x2001a60e;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a614; Value = 0x0514ff6d; PC = 0x8005524 *)
mov r6_b L0x2001a614;
mov r6_t L0x2001a616;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a61c; Value = 0xfacd01af; PC = 0x8005528 *)
mov r7_b L0x2001a61c;
mov r7_t L0x2001a61e;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a624; Value = 0xf9cbfe59; PC = 0x800552c *)
mov r8_b L0x2001a624;
mov r8_t L0x2001a626;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a62c; Value = 0x053a0254; PC = 0x8005530 *)
mov r9_b L0x2001a62c;
mov r9_t L0x2001a62e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e67e; Value = 0x010f09c3; PC = 0x8005534 *)
mov r10_b L0x800e67e;
mov r10_t L0x800e680;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e682; Value = 0x0355005a; PC = 0x8005580 *)
mov r10_b L0x800e682;
mov r10_t L0x800e684;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e686; Value = 0x02a90908; PC = 0x80055cc *)
mov r10_b L0x800e686;
mov r10_t L0x800e688;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e68a; Value = 0x0744093f; PC = 0x8005660 *)
mov r10_b L0x800e68a;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a614; PC = 0x8005768 *)
mov L0x2001a614 r6_b;
mov L0x2001a616 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a61c; PC = 0x800576c *)
mov L0x2001a61c r7_b;
mov L0x2001a61e r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a624; PC = 0x8005770 *)
mov L0x2001a624 r8_b;
mov L0x2001a626 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a62c; PC = 0x8005774 *)
mov L0x2001a62c r9_b;
mov L0x2001a62e r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a5fc; PC = 0x8005778 *)
mov L0x2001a5fc r3_b;
mov L0x2001a5fe r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a604; PC = 0x800577c *)
mov L0x2001a604 r4_b;
mov L0x2001a606 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a60c; PC = 0x8005780 *)
mov L0x2001a60c r5_b;
mov L0x2001a60e r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a5f4; PC = 0x8005784 *)
mov L0x2001a5f4 r2_b;
mov L0x2001a5f6 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000005; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a630; Value = 0xfbc6fc21; PC = 0x80052a0 *)
mov r2_b L0x2001a630;
mov r2_t L0x2001a632;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a638; Value = 0x04000121; PC = 0x80052a4 *)
mov r3_b L0x2001a638;
mov r3_t L0x2001a63a;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a640; Value = 0x0106fcbe; PC = 0x80052a8 *)
mov r4_b L0x2001a640;
mov r4_t L0x2001a642;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a648; Value = 0x00bdfcbe; PC = 0x80052ac *)
mov r5_b L0x2001a648;
mov r5_t L0x2001a64a;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a650; Value = 0x03d7f9f3; PC = 0x80052b0 *)
mov r6_b L0x2001a650;
mov r6_t L0x2001a652;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a658; Value = 0xf984ff79; PC = 0x80052b4 *)
mov r7_b L0x2001a658;
mov r7_t L0x2001a65a;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a660; Value = 0x03a9faad; PC = 0x80052b8 *)
mov r8_b L0x2001a660;
mov r8_t L0x2001a662;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a668; Value = 0x0507fa66; PC = 0x80052bc *)
mov r9_b L0x2001a668;
mov r9_t L0x2001a66a;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e68c; Value = 0x0c830744; PC = 0x80052c0 *)
mov r10_b L0x800e68c;
mov r10_t L0x800e68e;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e690; Value = 0x0652048a; PC = 0x800530c *)
mov r10_b L0x800e690;
mov r10_t L0x800e692;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e694; Value = 0x06420082; PC = 0x8005358 *)
mov r10_b L0x800e694;
mov r10_t L0x800e696;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e698; Value = 0x029a0c4b; PC = 0x80053ec *)
mov r10_b L0x800e698;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a650; PC = 0x80054f4 *)
mov L0x2001a650 r6_b;
mov L0x2001a652 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a658; PC = 0x80054f8 *)
mov L0x2001a658 r7_b;
mov L0x2001a65a r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a660; PC = 0x80054fc *)
mov L0x2001a660 r8_b;
mov L0x2001a662 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a668; PC = 0x8005500 *)
mov L0x2001a668 r9_b;
mov L0x2001a66a r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a638; PC = 0x8005504 *)
mov L0x2001a638 r3_b;
mov L0x2001a63a r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a640; PC = 0x8005508 *)
mov L0x2001a640 r4_b;
mov L0x2001a642 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a648; PC = 0x800550c *)
mov L0x2001a648 r5_b;
mov L0x2001a64a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a630; PC = 0x8005510 *)
mov L0x2001a630 r2_b;
mov L0x2001a632 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a634; Value = 0xfcd1fe23; PC = 0x8005514 *)
mov r2_b L0x2001a634;
mov r2_t L0x2001a636;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a63c; Value = 0x01b8029b; PC = 0x8005518 *)
mov r3_b L0x2001a63c;
mov r3_t L0x2001a63e;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a644; Value = 0x0002ffc3; PC = 0x800551c *)
mov r4_b L0x2001a644;
mov r4_t L0x2001a646;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a64c; Value = 0x066dfb21; PC = 0x8005520 *)
mov r5_b L0x2001a64c;
mov r5_t L0x2001a64e;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a654; Value = 0xf8c4ff2a; PC = 0x8005524 *)
mov r6_b L0x2001a654;
mov r6_t L0x2001a656;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a65c; Value = 0xf97af9de; PC = 0x8005528 *)
mov r7_b L0x2001a65c;
mov r7_t L0x2001a65e;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a664; Value = 0x061c05c3; PC = 0x800552c *)
mov r8_b L0x2001a664;
mov r8_t L0x2001a666;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a66c; Value = 0xfa25fc87; PC = 0x8005530 *)
mov r9_b L0x2001a66c;
mov r9_t L0x2001a66e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e68c; Value = 0x0c830744; PC = 0x8005534 *)
mov r10_b L0x800e68c;
mov r10_t L0x800e68e;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e690; Value = 0x0652048a; PC = 0x8005580 *)
mov r10_b L0x800e690;
mov r10_t L0x800e692;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e694; Value = 0x06420082; PC = 0x80055cc *)
mov r10_b L0x800e694;
mov r10_t L0x800e696;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e698; Value = 0x029a0c4b; PC = 0x8005660 *)
mov r10_b L0x800e698;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a654; PC = 0x8005768 *)
mov L0x2001a654 r6_b;
mov L0x2001a656 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a65c; PC = 0x800576c *)
mov L0x2001a65c r7_b;
mov L0x2001a65e r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a664; PC = 0x8005770 *)
mov L0x2001a664 r8_b;
mov L0x2001a666 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a66c; PC = 0x8005774 *)
mov L0x2001a66c r9_b;
mov L0x2001a66e r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a63c; PC = 0x8005778 *)
mov L0x2001a63c r3_b;
mov L0x2001a63e r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a644; PC = 0x800577c *)
mov L0x2001a644 r4_b;
mov L0x2001a646 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a64c; PC = 0x8005780 *)
mov L0x2001a64c r5_b;
mov L0x2001a64e r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a634; PC = 0x8005784 *)
mov L0x2001a634 r2_b;
mov L0x2001a636 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000004; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a670; Value = 0xfd39008d; PC = 0x80052a0 *)
mov r2_b L0x2001a670;
mov r2_t L0x2001a672;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a678; Value = 0xfc95fea0; PC = 0x80052a4 *)
mov r3_b L0x2001a678;
mov r3_t L0x2001a67a;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a680; Value = 0x0180ff93; PC = 0x80052a8 *)
mov r4_b L0x2001a680;
mov r4_t L0x2001a682;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a688; Value = 0x050cfdca; PC = 0x80052ac *)
mov r5_b L0x2001a688;
mov r5_t L0x2001a68a;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a690; Value = 0xf9f40526; PC = 0x80052b0 *)
mov r6_b L0x2001a690;
mov r6_t L0x2001a692;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a698; Value = 0xfe9cfa43; PC = 0x80052b4 *)
mov r7_b L0x2001a698;
mov r7_t L0x2001a69a;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6a0; Value = 0xfd7601d6; PC = 0x80052b8 *)
mov r8_b L0x2001a6a0;
mov r8_t L0x2001a6a2;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6a8; Value = 0xfc630039; PC = 0x80052bc *)
mov r9_b L0x2001a6a8;
mov r9_t L0x2001a6aa;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e69a; Value = 0x0140029a; PC = 0x80052c0 *)
mov r10_b L0x800e69a;
mov r10_t L0x800e69c;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e69e; Value = 0x0afd0008; PC = 0x800530c *)
mov r10_b L0x800e69e;
mov r10_t L0x800e6a0;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6a2; Value = 0x033d074f; PC = 0x8005358 *)
mov r10_b L0x800e6a2;
mov r10_t L0x800e6a4;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e6a6; Value = 0x060806d8; PC = 0x80053ec *)
mov r10_b L0x800e6a6;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a690; PC = 0x80054f4 *)
mov L0x2001a690 r6_b;
mov L0x2001a692 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a698; PC = 0x80054f8 *)
mov L0x2001a698 r7_b;
mov L0x2001a69a r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6a0; PC = 0x80054fc *)
mov L0x2001a6a0 r8_b;
mov L0x2001a6a2 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6a8; PC = 0x8005500 *)
mov L0x2001a6a8 r9_b;
mov L0x2001a6aa r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a678; PC = 0x8005504 *)
mov L0x2001a678 r3_b;
mov L0x2001a67a r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a680; PC = 0x8005508 *)
mov L0x2001a680 r4_b;
mov L0x2001a682 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a688; PC = 0x800550c *)
mov L0x2001a688 r5_b;
mov L0x2001a68a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a670; PC = 0x8005510 *)
mov L0x2001a670 r2_b;
mov L0x2001a672 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a674; Value = 0xfafffa64; PC = 0x8005514 *)
mov r2_b L0x2001a674;
mov r2_t L0x2001a676;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a67c; Value = 0xfeff0217; PC = 0x8005518 *)
mov r3_b L0x2001a67c;
mov r3_t L0x2001a67e;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a684; Value = 0x049e01d4; PC = 0x800551c *)
mov r4_b L0x2001a684;
mov r4_t L0x2001a686;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a68c; Value = 0x028ef9e2; PC = 0x8005520 *)
mov r5_b L0x2001a68c;
mov r5_t L0x2001a68e;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a694; Value = 0xfa14fb7a; PC = 0x8005524 *)
mov r6_b L0x2001a694;
mov r6_t L0x2001a696;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a69c; Value = 0x0094f9fd; PC = 0x8005528 *)
mov r7_b L0x2001a69c;
mov r7_t L0x2001a69e;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6a4; Value = 0xff8d0334; PC = 0x800552c *)
mov r8_b L0x2001a6a4;
mov r8_t L0x2001a6a6;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6ac; Value = 0x04d90351; PC = 0x8005530 *)
mov r9_b L0x2001a6ac;
mov r9_t L0x2001a6ae;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e69a; Value = 0x0140029a; PC = 0x8005534 *)
mov r10_b L0x800e69a;
mov r10_t L0x800e69c;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e69e; Value = 0x0afd0008; PC = 0x8005580 *)
mov r10_b L0x800e69e;
mov r10_t L0x800e6a0;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e6a2; Value = 0x033d074f; PC = 0x80055cc *)
mov r10_b L0x800e6a2;
mov r10_t L0x800e6a4;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e6a6; Value = 0x060806d8; PC = 0x8005660 *)
mov r10_b L0x800e6a6;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a694; PC = 0x8005768 *)
mov L0x2001a694 r6_b;
mov L0x2001a696 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a69c; PC = 0x800576c *)
mov L0x2001a69c r7_b;
mov L0x2001a69e r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6a4; PC = 0x8005770 *)
mov L0x2001a6a4 r8_b;
mov L0x2001a6a6 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6ac; PC = 0x8005774 *)
mov L0x2001a6ac r9_b;
mov L0x2001a6ae r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a67c; PC = 0x8005778 *)
mov L0x2001a67c r3_b;
mov L0x2001a67e r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a684; PC = 0x800577c *)
mov L0x2001a684 r4_b;
mov L0x2001a686 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a68c; PC = 0x8005780 *)
mov L0x2001a68c r5_b;
mov L0x2001a68e r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a674; PC = 0x8005784 *)
mov L0x2001a674 r2_b;
mov L0x2001a676 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000003; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a6b0; Value = 0xfcc4fdf7; PC = 0x80052a0 *)
mov r2_b L0x2001a6b0;
mov r2_t L0x2001a6b2;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a6b8; Value = 0xfc3dfa55; PC = 0x80052a4 *)
mov r3_b L0x2001a6b8;
mov r3_t L0x2001a6ba;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a6c0; Value = 0xfbbe01f4; PC = 0x80052a8 *)
mov r4_b L0x2001a6c0;
mov r4_t L0x2001a6c2;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a6c8; Value = 0x048f05d2; PC = 0x80052ac *)
mov r5_b L0x2001a6c8;
mov r5_t L0x2001a6ca;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a6d0; Value = 0xfb09029f; PC = 0x80052b0 *)
mov r6_b L0x2001a6d0;
mov r6_t L0x2001a6d2;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a6d8; Value = 0x02d0fddf; PC = 0x80052b4 *)
mov r7_b L0x2001a6d8;
mov r7_t L0x2001a6da;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6e0; Value = 0x0162fa17; PC = 0x80052b8 *)
mov r8_b L0x2001a6e0;
mov r8_t L0x2001a6e2;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6e8; Value = 0xfea70241; PC = 0x80052bc *)
mov r9_b L0x2001a6e8;
mov r9_t L0x2001a6ea;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6a8; Value = 0x011a0608; PC = 0x80052c0 *)
mov r10_b L0x800e6a8;
mov r10_t L0x800e6aa;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6ac; Value = 0x050d072e; PC = 0x800530c *)
mov r10_b L0x800e6ac;
mov r10_t L0x800e6ae;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6b0; Value = 0x0bf90b82; PC = 0x8005358 *)
mov r10_b L0x800e6b0;
mov r10_t L0x800e6b2;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e6b4; Value = 0x090a0a93; PC = 0x80053ec *)
mov r10_b L0x800e6b4;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a6d0; PC = 0x80054f4 *)
mov L0x2001a6d0 r6_b;
mov L0x2001a6d2 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a6d8; PC = 0x80054f8 *)
mov L0x2001a6d8 r7_b;
mov L0x2001a6da r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6e0; PC = 0x80054fc *)
mov L0x2001a6e0 r8_b;
mov L0x2001a6e2 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6e8; PC = 0x8005500 *)
mov L0x2001a6e8 r9_b;
mov L0x2001a6ea r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a6b8; PC = 0x8005504 *)
mov L0x2001a6b8 r3_b;
mov L0x2001a6ba r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a6c0; PC = 0x8005508 *)
mov L0x2001a6c0 r4_b;
mov L0x2001a6c2 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a6c8; PC = 0x800550c *)
mov L0x2001a6c8 r5_b;
mov L0x2001a6ca r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a6b0; PC = 0x8005510 *)
mov L0x2001a6b0 r2_b;
mov L0x2001a6b2 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a6b4; Value = 0x050502ec; PC = 0x8005514 *)
mov r2_b L0x2001a6b4;
mov r2_t L0x2001a6b6;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a6bc; Value = 0x02b8ffff; PC = 0x8005518 *)
mov r3_b L0x2001a6bc;
mov r3_t L0x2001a6be;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a6c4; Value = 0xf9e3032b; PC = 0x800551c *)
mov r4_b L0x2001a6c4;
mov r4_t L0x2001a6c6;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a6cc; Value = 0xf9a6fea0; PC = 0x8005520 *)
mov r5_b L0x2001a6cc;
mov r5_t L0x2001a6ce;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a6d4; Value = 0xfd580255; PC = 0x8005524 *)
mov r6_b L0x2001a6d4;
mov r6_t L0x2001a6d6;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a6dc; Value = 0xfe85002d; PC = 0x8005528 *)
mov r7_b L0x2001a6dc;
mov r7_t L0x2001a6de;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6e4; Value = 0xfe36ffad; PC = 0x800552c *)
mov r8_b L0x2001a6e4;
mov r8_t L0x2001a6e6;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6ec; Value = 0x0427fd36; PC = 0x8005530 *)
mov r9_b L0x2001a6ec;
mov r9_t L0x2001a6ee;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e6a8; Value = 0x011a0608; PC = 0x8005534 *)
mov r10_b L0x800e6a8;
mov r10_t L0x800e6aa;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e6ac; Value = 0x050d072e; PC = 0x8005580 *)
mov r10_b L0x800e6ac;
mov r10_t L0x800e6ae;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e6b0; Value = 0x0bf90b82; PC = 0x80055cc *)
mov r10_b L0x800e6b0;
mov r10_t L0x800e6b2;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e6b4; Value = 0x090a0a93; PC = 0x8005660 *)
mov r10_b L0x800e6b4;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a6d4; PC = 0x8005768 *)
mov L0x2001a6d4 r6_b;
mov L0x2001a6d6 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a6dc; PC = 0x800576c *)
mov L0x2001a6dc r7_b;
mov L0x2001a6de r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a6e4; PC = 0x8005770 *)
mov L0x2001a6e4 r8_b;
mov L0x2001a6e6 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a6ec; PC = 0x8005774 *)
mov L0x2001a6ec r9_b;
mov L0x2001a6ee r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a6bc; PC = 0x8005778 *)
mov L0x2001a6bc r3_b;
mov L0x2001a6be r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a6c4; PC = 0x800577c *)
mov L0x2001a6c4 r4_b;
mov L0x2001a6c6 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a6cc; PC = 0x8005780 *)
mov L0x2001a6cc r5_b;
mov L0x2001a6ce r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a6b4; PC = 0x8005784 *)
mov L0x2001a6b4 r2_b;
mov L0x2001a6b6 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000002; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800529c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a6f0; Value = 0xfc7a021b; PC = 0x80052a0 *)
mov r2_b L0x2001a6f0;
mov r2_t L0x2001a6f2;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a6f8; Value = 0xfcbbfef2; PC = 0x80052a4 *)
mov r3_b L0x2001a6f8;
mov r3_t L0x2001a6fa;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a700; Value = 0x0036ffa7; PC = 0x80052a8 *)
mov r4_b L0x2001a700;
mov r4_t L0x2001a702;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a708; Value = 0x00e1fe16; PC = 0x80052ac *)
mov r5_b L0x2001a708;
mov r5_t L0x2001a70a;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a710; Value = 0x062dfbe3; PC = 0x80052b0 *)
mov r6_b L0x2001a710;
mov r6_t L0x2001a712;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a718; Value = 0x00ecfef9; PC = 0x80052b4 *)
mov r7_b L0x2001a718;
mov r7_t L0x2001a71a;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a720; Value = 0xfa7d0139; PC = 0x80052b8 *)
mov r8_b L0x2001a720;
mov r8_t L0x2001a722;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a728; Value = 0xfe97f9f2; PC = 0x80052bc *)
mov r9_b L0x2001a728;
mov r9_t L0x2001a72a;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6b6; Value = 0x0228090a; PC = 0x80052c0 *)
mov r10_b L0x800e6b6;
mov r10_t L0x800e6b8;
(* usub16	r12, r2, r3                              #! PC = 0x80052c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80052c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80052cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80052d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80052d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80052d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80052dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80052e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80052e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80052e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80052ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80052f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80052f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80052f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80052fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005300 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005304 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005308 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6ba; Value = 0x083a0a75; PC = 0x800530c *)
mov r10_b L0x800e6ba;
mov r10_t L0x800e6bc;
(* usub16	r12, r6, r7                              #! PC = 0x8005310 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005314 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005318 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800531c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005320 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005324 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005328 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800532c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005330 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005334 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005338 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800533c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005340 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005344 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005348 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800534c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005350 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005354 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6be; Value = 0x0ac4052d; PC = 0x8005358 *)
mov r10_b L0x800e6be;
mov r10_t L0x800e6c0;
(* usub16	r12, r2, r4                              #! PC = 0x800535c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005360 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005364 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005368 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800536c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005370 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005374 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005378 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800537c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005380 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005384 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005388 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800538c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005390 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005394 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005398 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800539c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80053a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80053a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80053a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80053ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80053b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80053b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80053bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80053c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80053c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80053c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80053cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80053d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80053d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80053d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80053dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80053e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80053e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80053e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1, #12]                           #! EA = L0x800e6c2; Value = 0x0c3700ab; PC = 0x80053ec *)
mov r10_b L0x800e6c2;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x80053f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80053f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80053f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80053fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005400 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005404 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005408 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800540c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005410 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005414 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005418 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800541c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005420 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005424 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005428 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800542c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005430 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005434 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005438 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800543c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005440 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005444 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005448 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800544c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005450 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005454 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005458 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800545c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005460 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005464 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005468 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800546c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005470 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005474 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005478 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800547c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x8005480 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x8005484 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005488 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800548c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005490 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005494 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x8005498 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x800549c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x80054a0 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054a4 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054a8 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x80054ac *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80054b0 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80054b4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x80054b8 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x80054bc *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054c0 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054c4 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x80054c8 *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80054cc *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80054d0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x80054d4 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x80054d8 *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80054dc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x80054e0 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x80054e4 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x80054e8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80054ec *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x80054f0 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a710; PC = 0x80054f4 *)
mov L0x2001a710 r6_b;
mov L0x2001a712 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a718; PC = 0x80054f8 *)
mov L0x2001a718 r7_b;
mov L0x2001a71a r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a720; PC = 0x80054fc *)
mov L0x2001a720 r8_b;
mov L0x2001a722 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a728; PC = 0x8005500 *)
mov L0x2001a728 r9_b;
mov L0x2001a72a r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a6f8; PC = 0x8005504 *)
mov L0x2001a6f8 r3_b;
mov L0x2001a6fa r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a700; PC = 0x8005508 *)
mov L0x2001a700 r4_b;
mov L0x2001a702 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a708; PC = 0x800550c *)
mov L0x2001a708 r5_b;
mov L0x2001a70a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a6f0; PC = 0x8005510 *)
mov L0x2001a6f0 r2_b;
mov L0x2001a6f2 r2_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a6f4; Value = 0x02ae0301; PC = 0x8005514 *)
mov r2_b L0x2001a6f4;
mov r2_t L0x2001a6f6;
(* ldr.w	r3, [r0, #8]                              #! EA = L0x2001a6fc; Value = 0x0555fade; PC = 0x8005518 *)
mov r3_b L0x2001a6fc;
mov r3_t L0x2001a6fe;
(* ldr.w	r4, [r0, #16]                             #! EA = L0x2001a704; Value = 0xfb99fbb3; PC = 0x800551c *)
mov r4_b L0x2001a704;
mov r4_t L0x2001a706;
(* ldr.w	r5, [r0, #24]                             #! EA = L0x2001a70c; Value = 0x068a060e; PC = 0x8005520 *)
mov r5_b L0x2001a70c;
mov r5_t L0x2001a70e;
(* ldr.w	r6, [r0, #32]                             #! EA = L0x2001a714; Value = 0x01c10215; PC = 0x8005524 *)
mov r6_b L0x2001a714;
mov r6_t L0x2001a716;
(* ldr.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a71c; Value = 0x0655fbdb; PC = 0x8005528 *)
mov r7_b L0x2001a71c;
mov r7_t L0x2001a71e;
(* ldr.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a724; Value = 0x04f3fa1c; PC = 0x800552c *)
mov r8_b L0x2001a724;
mov r8_t L0x2001a726;
(* ldr.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a72c; Value = 0xfe470320; PC = 0x8005530 *)
mov r9_b L0x2001a72c;
mov r9_t L0x2001a72e;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e6b6; Value = 0x0228090a; PC = 0x8005534 *)
mov r10_b L0x800e6b6;
mov r10_t L0x800e6b8;
(* usub16	r12, r2, r3                              #! PC = 0x8005538 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x800553c *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x8005540 *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005544 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005548 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x800554c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x8005550 *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x8005554 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x8005558 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x800555c *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x8005560 *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x8005564 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005568 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x800556c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005570 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005574 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005578 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x800557c *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e6ba; Value = 0x083a0a75; PC = 0x8005580 *)
mov r10_b L0x800e6ba;
mov r10_t L0x800e6bc;
(* usub16	r12, r6, r7                              #! PC = 0x8005584 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005588 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800558c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005590 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005594 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005598 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800559c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80055a0 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80055a4 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x80055a8 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x80055ac *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80055b0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80055b4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80055b8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80055bc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80055c0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80055c4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80055c8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1], #4                             #! EA = L0x800e6be; Value = 0x0ac4052d; PC = 0x80055cc *)
mov r10_b L0x800e6be;
mov r10_t L0x800e6c0;
(* usub16	r12, r2, r4                              #! PC = 0x80055d0 *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x80055d4 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x80055d8 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80055dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x80055e0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80055e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80055e8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80055ec *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x80055f0 *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x80055f4 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x80055f8 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x80055fc *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005600 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005604 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005608 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x800560c *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005610 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005614 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x8005618 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x800561c *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x8005620 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005624 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x8005628 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800562c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005630 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005634 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005638 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x800563c *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x8005640 *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x8005644 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005648 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x800564c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005650 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005654 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005658 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800565c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldrh.w	r10, [r1], #2                            #! EA = L0x800e6c2; Value = 0x0c3700ab; PC = 0x8005660 *)
mov r10_b L0x800e6c2;
mov r10_t 0@sint16;
(* usub16	r12, r2, r6                              #! PC = 0x8005664 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x8005668 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x800566c *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005670 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005674 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005678 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x800567c *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x8005680 *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005684 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005688 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x800568c *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005690 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005694 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005698 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x800569c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x80056a0 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x80056a4 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x80056a8 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x80056ac *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x80056b0 *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x80056b4 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056b8 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x80056bc *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80056c0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80056c4 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80056c8 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80056cc *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x80056d0 *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x80056d4 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x80056d8 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80056dc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x80056e0 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80056e4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80056e8 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80056ec *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80056f0 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* movw	r10, #2285	; 0x8ed                         #! PC = 0x80056f4 *)
mov r10_b 2285@sint16;
mov r10_t 0@sint16;
(* smulbb	lr, r2, r10                              #! PC = 0x80056f8 *)
mull lr_t lr_b r2_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x80056fc *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005700 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r2, r2, r10                              #! PC = 0x8005704 *)
mull r2_t r2_b r2_t r10_b;
(* smulbt	lr, r2, r11                              #! PC = 0x8005708 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800570c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r2, lr, r12, asr #16                      #! PC = 0x8005710 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbb	lr, r3, r10                              #! PC = 0x8005714 *)
mull lr_t lr_b r3_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005718 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x800571c *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r3, r3, r10                              #! PC = 0x8005720 *)
mull r3_t r3_b r3_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x8005724 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x8005728 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r3, lr, r12, asr #16                      #! PC = 0x800572c *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbb	lr, r4, r10                              #! PC = 0x8005730 *)
mull lr_t lr_b r4_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005734 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005738 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r4, r4, r10                              #! PC = 0x800573c *)
mull r4_t r4_b r4_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x8005740 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005744 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r4, lr, r12, asr #16                      #! PC = 0x8005748 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbb	lr, r5, r10                              #! PC = 0x800574c *)
mull lr_t lr_b r5_b r10_b;
(* smulbt	r12, lr, r11                             #! PC = 0x8005750 *)
cast lr_sb@sint16 lr_b;
mull r12_t r12_b lr_sb r11_t;
(* smlabb	r12, r11, r12, lr                        #! PC = 0x8005754 *)
cast r12_sb@sint16 r12_b;
mull tmp_t tmp_b r11_b r12_sb;
uadds carry r12_b tmp_b lr_b;
adc r12_t tmp_t lr_t carry;
assert eqmod r12_b 0 (2**16) && true;
assume r12_b = 0 && true;
(* smultb	r5, r5, r10                              #! PC = 0x8005758 *)
mull r5_t r5_b r5_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x800575c *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005760 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* pkhtb	r5, lr, r12, asr #16                      #! PC = 0x8005764 *)
mov tmp_t lr_t;
mov tmp_b r12_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #32]                             #! EA = L0x2001a714; PC = 0x8005768 *)
mov L0x2001a714 r6_b;
mov L0x2001a716 r6_t;
(* str.w	r7, [r0, #40]	; 0x28                      #! EA = L0x2001a71c; PC = 0x800576c *)
mov L0x2001a71c r7_b;
mov L0x2001a71e r7_t;
(* str.w	r8, [r0, #48]	; 0x30                      #! EA = L0x2001a724; PC = 0x8005770 *)
mov L0x2001a724 r8_b;
mov L0x2001a726 r8_t;
(* str.w	r9, [r0, #56]	; 0x38                      #! EA = L0x2001a72c; PC = 0x8005774 *)
mov L0x2001a72c r9_b;
mov L0x2001a72e r9_t;
(* str.w	r3, [r0, #8]                              #! EA = L0x2001a6fc; PC = 0x8005778 *)
mov L0x2001a6fc r3_b;
mov L0x2001a6fe r3_t;
(* str.w	r4, [r0, #16]                             #! EA = L0x2001a704; PC = 0x800577c *)
mov L0x2001a704 r4_b;
mov L0x2001a706 r4_t;
(* str.w	r5, [r0, #24]                             #! EA = L0x2001a70c; PC = 0x8005780 *)
mov L0x2001a70c r5_b;
mov L0x2001a70e r5_t;
(* str.w	r2, [r0], #60                             #! EA = L0x2001a6f4; PC = 0x8005784 *)
mov L0x2001a6f4 r2_b;
mov L0x2001a6f6 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000001; PC = 0x8005788 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x800578c *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800529c <invntt_fast+316>              #! PC = 0x8005790 *)
#bne.w	0x800529c <invntt_fast+316>              #! 0x8005790 = 0x8005790;
(* # END of layer 2+3+4 *)
# END of layer 2+3+4;

(* === layer 2+3+4 === *)
cut
  (* algebraic *)
  and [
    (* inp_poly_0 *)
    eqmod 16 * (inp_poly_0 * inp_poly_0)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 17],
    (* inp_poly_1 *)
    eqmod 16 * (inp_poly_1 * inp_poly_1)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 3312],
    (* inp_poly_2 *)
    eqmod 16 * (inp_poly_2 * inp_poly_2)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 2761],
    (* inp_poly_3 *)
    eqmod 16 * (inp_poly_3 * inp_poly_3)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 568],
    (* inp_poly_4 *)
    eqmod 16 * (inp_poly_4 * inp_poly_4)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 583],
    (* inp_poly_5 *)
    eqmod 16 * (inp_poly_5 * inp_poly_5)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 2746],
    (* inp_poly_6 *)
    eqmod 16 * (inp_poly_6 * inp_poly_6)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 2649],
    (* inp_poly_7 *)
    eqmod 16 * (inp_poly_7 * inp_poly_7)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 680],
    (* inp_poly_8 *)
    eqmod 16 * (inp_poly_8 * inp_poly_8)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 1637],
    (* inp_poly_9 *)
    eqmod 16 * (inp_poly_9 * inp_poly_9)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 1692],
    (* inp_poly_10 *)
    eqmod 16 * (inp_poly_10 * inp_poly_10)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 723],
    (* inp_poly_11 *)
    eqmod 16 * (inp_poly_11 * inp_poly_11)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 2606],
    (* inp_poly_12 *)
    eqmod 16 * (inp_poly_12 * inp_poly_12)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 2288],
    (* inp_poly_13 *)
    eqmod 16 * (inp_poly_13 * inp_poly_13)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 1041],
    (* inp_poly_14 *)
    eqmod 16 * (inp_poly_14 * inp_poly_14)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 1100],
    (* inp_poly_15 *)
    eqmod 16 * (inp_poly_15 * inp_poly_15)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31)
          )
          [3329, x**2 - 2229],
    (* inp_poly_16 *)
    eqmod 16 * (inp_poly_16 * inp_poly_16)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 1409],
    (* inp_poly_17 *)
    eqmod 16 * (inp_poly_17 * inp_poly_17)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 1920],
    (* inp_poly_18 *)
    eqmod 16 * (inp_poly_18 * inp_poly_18)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 2662],
    (* inp_poly_19 *)
    eqmod 16 * (inp_poly_19 * inp_poly_19)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 667],
    (* inp_poly_20 *)
    eqmod 16 * (inp_poly_20 * inp_poly_20)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 3281],
    (* inp_poly_21 *)
    eqmod 16 * (inp_poly_21 * inp_poly_21)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 48],
    (* inp_poly_22 *)
    eqmod 16 * (inp_poly_22 * inp_poly_22)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 233],
    (* inp_poly_23 *)
    eqmod 16 * (inp_poly_23 * inp_poly_23)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 3096],
    (* inp_poly_24 *)
    eqmod 16 * (inp_poly_24 * inp_poly_24)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 756],
    (* inp_poly_25 *)
    eqmod 16 * (inp_poly_25 * inp_poly_25)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 2573],
    (* inp_poly_26 *)
    eqmod 16 * (inp_poly_26 * inp_poly_26)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 2156],
    (* inp_poly_27 *)
    eqmod 16 * (inp_poly_27 * inp_poly_27)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 1173],
    (* inp_poly_28 *)
    eqmod 16 * (inp_poly_28 * inp_poly_28)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 3015],
    (* inp_poly_29 *)
    eqmod 16 * (inp_poly_29 * inp_poly_29)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 314],
    (* inp_poly_30 *)
    eqmod 16 * (inp_poly_30 * inp_poly_30)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 3050],
    (* inp_poly_31 *)
    eqmod 16 * (inp_poly_31 * inp_poly_31)
          (
            L0x2001a570 * (x**0) + L0x2001a572 * (x**1) + 
            L0x2001a574 * (x**2) + L0x2001a576 * (x**3) + 
            L0x2001a578 * (x**4) + L0x2001a57a * (x**5) + 
            L0x2001a57c * (x**6) + L0x2001a57e * (x**7) + 
            L0x2001a580 * (x**8) + L0x2001a582 * (x**9) + 
            L0x2001a584 * (x**10) + L0x2001a586 * (x**11) + 
            L0x2001a588 * (x**12) + L0x2001a58a * (x**13) + 
            L0x2001a58c * (x**14) + L0x2001a58e * (x**15) + 
            L0x2001a590 * (x**16) + L0x2001a592 * (x**17) + 
            L0x2001a594 * (x**18) + L0x2001a596 * (x**19) + 
            L0x2001a598 * (x**20) + L0x2001a59a * (x**21) + 
            L0x2001a59c * (x**22) + L0x2001a59e * (x**23) + 
            L0x2001a5a0 * (x**24) + L0x2001a5a2 * (x**25) + 
            L0x2001a5a4 * (x**26) + L0x2001a5a6 * (x**27) + 
            L0x2001a5a8 * (x**28) + L0x2001a5aa * (x**29) + 
            L0x2001a5ac * (x**30) + L0x2001a5ae * (x**31)
          )
          [3329, x**2 - 279],
    (* inp_poly_32 *)
    eqmod 16 * (inp_poly_32 * inp_poly_32)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1703],
    (* inp_poly_33 *)
    eqmod 16 * (inp_poly_33 * inp_poly_33)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1626],
    (* inp_poly_34 *)
    eqmod 16 * (inp_poly_34 * inp_poly_34)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1651],
    (* inp_poly_35 *)
    eqmod 16 * (inp_poly_35 * inp_poly_35)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1678],
    (* inp_poly_36 *)
    eqmod 16 * (inp_poly_36 * inp_poly_36)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 2789],
    (* inp_poly_37 *)
    eqmod 16 * (inp_poly_37 * inp_poly_37)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 540],
    (* inp_poly_38 *)
    eqmod 16 * (inp_poly_38 * inp_poly_38)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1789],
    (* inp_poly_39 *)
    eqmod 16 * (inp_poly_39 * inp_poly_39)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1540],
    (* inp_poly_40 *)
    eqmod 16 * (inp_poly_40 * inp_poly_40)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1847],
    (* inp_poly_41 *)
    eqmod 16 * (inp_poly_41 * inp_poly_41)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1482],
    (* inp_poly_42 *)
    eqmod 16 * (inp_poly_42 * inp_poly_42)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 952],
    (* inp_poly_43 *)
    eqmod 16 * (inp_poly_43 * inp_poly_43)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 2377],
    (* inp_poly_44 *)
    eqmod 16 * (inp_poly_44 * inp_poly_44)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1461],
    (* inp_poly_45 *)
    eqmod 16 * (inp_poly_45 * inp_poly_45)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 1868],
    (* inp_poly_46 *)
    eqmod 16 * (inp_poly_46 * inp_poly_46)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 2687],
    (* inp_poly_47 *)
    eqmod 16 * (inp_poly_47 * inp_poly_47)
          (
            L0x2001a5b0 * (x**0) + L0x2001a5b2 * (x**1) + 
            L0x2001a5b4 * (x**2) + L0x2001a5b6 * (x**3) + 
            L0x2001a5b8 * (x**4) + L0x2001a5ba * (x**5) + 
            L0x2001a5bc * (x**6) + L0x2001a5be * (x**7) + 
            L0x2001a5c0 * (x**8) + L0x2001a5c2 * (x**9) + 
            L0x2001a5c4 * (x**10) + L0x2001a5c6 * (x**11) + 
            L0x2001a5c8 * (x**12) + L0x2001a5ca * (x**13) + 
            L0x2001a5cc * (x**14) + L0x2001a5ce * (x**15) + 
            L0x2001a5d0 * (x**16) + L0x2001a5d2 * (x**17) + 
            L0x2001a5d4 * (x**18) + L0x2001a5d6 * (x**19) + 
            L0x2001a5d8 * (x**20) + L0x2001a5da * (x**21) + 
            L0x2001a5dc * (x**22) + L0x2001a5de * (x**23) + 
            L0x2001a5e0 * (x**24) + L0x2001a5e2 * (x**25) + 
            L0x2001a5e4 * (x**26) + L0x2001a5e6 * (x**27) + 
            L0x2001a5e8 * (x**28) + L0x2001a5ea * (x**29) + 
            L0x2001a5ec * (x**30) + L0x2001a5ee * (x**31)
          )
          [3329, x**2 - 642],
    (* inp_poly_48 *)
    eqmod 16 * (inp_poly_48 * inp_poly_48)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 939],
    (* inp_poly_49 *)
    eqmod 16 * (inp_poly_49 * inp_poly_49)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 2390],
    (* inp_poly_50 *)
    eqmod 16 * (inp_poly_50 * inp_poly_50)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 2308],
    (* inp_poly_51 *)
    eqmod 16 * (inp_poly_51 * inp_poly_51)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 1021],
    (* inp_poly_52 *)
    eqmod 16 * (inp_poly_52 * inp_poly_52)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 2437],
    (* inp_poly_53 *)
    eqmod 16 * (inp_poly_53 * inp_poly_53)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 892],
    (* inp_poly_54 *)
    eqmod 16 * (inp_poly_54 * inp_poly_54)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 2388],
    (* inp_poly_55 *)
    eqmod 16 * (inp_poly_55 * inp_poly_55)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 941],
    (* inp_poly_56 *)
    eqmod 16 * (inp_poly_56 * inp_poly_56)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 733],
    (* inp_poly_57 *)
    eqmod 16 * (inp_poly_57 * inp_poly_57)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 2596],
    (* inp_poly_58 *)
    eqmod 16 * (inp_poly_58 * inp_poly_58)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 2337],
    (* inp_poly_59 *)
    eqmod 16 * (inp_poly_59 * inp_poly_59)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 992],
    (* inp_poly_60 *)
    eqmod 16 * (inp_poly_60 * inp_poly_60)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 268],
    (* inp_poly_61 *)
    eqmod 16 * (inp_poly_61 * inp_poly_61)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 3061],
    (* inp_poly_62 *)
    eqmod 16 * (inp_poly_62 * inp_poly_62)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 641],
    (* inp_poly_63 *)
    eqmod 16 * (inp_poly_63 * inp_poly_63)
          (
            L0x2001a5f0 * (x**0) + L0x2001a5f2 * (x**1) + 
            L0x2001a5f4 * (x**2) + L0x2001a5f6 * (x**3) + 
            L0x2001a5f8 * (x**4) + L0x2001a5fa * (x**5) + 
            L0x2001a5fc * (x**6) + L0x2001a5fe * (x**7) + 
            L0x2001a600 * (x**8) + L0x2001a602 * (x**9) + 
            L0x2001a604 * (x**10) + L0x2001a606 * (x**11) + 
            L0x2001a608 * (x**12) + L0x2001a60a * (x**13) + 
            L0x2001a60c * (x**14) + L0x2001a60e * (x**15) + 
            L0x2001a610 * (x**16) + L0x2001a612 * (x**17) + 
            L0x2001a614 * (x**18) + L0x2001a616 * (x**19) + 
            L0x2001a618 * (x**20) + L0x2001a61a * (x**21) + 
            L0x2001a61c * (x**22) + L0x2001a61e * (x**23) + 
            L0x2001a620 * (x**24) + L0x2001a622 * (x**25) + 
            L0x2001a624 * (x**26) + L0x2001a626 * (x**27) + 
            L0x2001a628 * (x**28) + L0x2001a62a * (x**29) + 
            L0x2001a62c * (x**30) + L0x2001a62e * (x**31)
          )
          [3329, x**2 - 2688],
    (* inp_poly_64 *)
    eqmod 16 * (inp_poly_64 * inp_poly_64)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 1584],
    (* inp_poly_65 *)
    eqmod 16 * (inp_poly_65 * inp_poly_65)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 1745],
    (* inp_poly_66 *)
    eqmod 16 * (inp_poly_66 * inp_poly_66)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 2298],
    (* inp_poly_67 *)
    eqmod 16 * (inp_poly_67 * inp_poly_67)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 1031],
    (* inp_poly_68 *)
    eqmod 16 * (inp_poly_68 * inp_poly_68)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 2037],
    (* inp_poly_69 *)
    eqmod 16 * (inp_poly_69 * inp_poly_69)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 1292],
    (* inp_poly_70 *)
    eqmod 16 * (inp_poly_70 * inp_poly_70)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 3220],
    (* inp_poly_71 *)
    eqmod 16 * (inp_poly_71 * inp_poly_71)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 109],
    (* inp_poly_72 *)
    eqmod 16 * (inp_poly_72 * inp_poly_72)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 375],
    (* inp_poly_73 *)
    eqmod 16 * (inp_poly_73 * inp_poly_73)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 2954],
    (* inp_poly_74 *)
    eqmod 16 * (inp_poly_74 * inp_poly_74)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 2549],
    (* inp_poly_75 *)
    eqmod 16 * (inp_poly_75 * inp_poly_75)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 780],
    (* inp_poly_76 *)
    eqmod 16 * (inp_poly_76 * inp_poly_76)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 2090],
    (* inp_poly_77 *)
    eqmod 16 * (inp_poly_77 * inp_poly_77)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 1239],
    (* inp_poly_78 *)
    eqmod 16 * (inp_poly_78 * inp_poly_78)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 1645],
    (* inp_poly_79 *)
    eqmod 16 * (inp_poly_79 * inp_poly_79)
          (
            L0x2001a630 * (x**0) + L0x2001a632 * (x**1) + 
            L0x2001a634 * (x**2) + L0x2001a636 * (x**3) + 
            L0x2001a638 * (x**4) + L0x2001a63a * (x**5) + 
            L0x2001a63c * (x**6) + L0x2001a63e * (x**7) + 
            L0x2001a640 * (x**8) + L0x2001a642 * (x**9) + 
            L0x2001a644 * (x**10) + L0x2001a646 * (x**11) + 
            L0x2001a648 * (x**12) + L0x2001a64a * (x**13) + 
            L0x2001a64c * (x**14) + L0x2001a64e * (x**15) + 
            L0x2001a650 * (x**16) + L0x2001a652 * (x**17) + 
            L0x2001a654 * (x**18) + L0x2001a656 * (x**19) + 
            L0x2001a658 * (x**20) + L0x2001a65a * (x**21) + 
            L0x2001a65c * (x**22) + L0x2001a65e * (x**23) + 
            L0x2001a660 * (x**24) + L0x2001a662 * (x**25) + 
            L0x2001a664 * (x**26) + L0x2001a666 * (x**27) + 
            L0x2001a668 * (x**28) + L0x2001a66a * (x**29) + 
            L0x2001a66c * (x**30) + L0x2001a66e * (x**31)
          )
          [3329, x**2 - 1684],
    (* inp_poly_80 *)
    eqmod 16 * (inp_poly_80 * inp_poly_80)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 1063],
    (* inp_poly_81 *)
    eqmod 16 * (inp_poly_81 * inp_poly_81)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 2266],
    (* inp_poly_82 *)
    eqmod 16 * (inp_poly_82 * inp_poly_82)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 319],
    (* inp_poly_83 *)
    eqmod 16 * (inp_poly_83 * inp_poly_83)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 3010],
    (* inp_poly_84 *)
    eqmod 16 * (inp_poly_84 * inp_poly_84)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 2773],
    (* inp_poly_85 *)
    eqmod 16 * (inp_poly_85 * inp_poly_85)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 556],
    (* inp_poly_86 *)
    eqmod 16 * (inp_poly_86 * inp_poly_86)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 757],
    (* inp_poly_87 *)
    eqmod 16 * (inp_poly_87 * inp_poly_87)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 2572],
    (* inp_poly_88 *)
    eqmod 16 * (inp_poly_88 * inp_poly_88)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 2099],
    (* inp_poly_89 *)
    eqmod 16 * (inp_poly_89 * inp_poly_89)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 1230],
    (* inp_poly_90 *)
    eqmod 16 * (inp_poly_90 * inp_poly_90)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 561],
    (* inp_poly_91 *)
    eqmod 16 * (inp_poly_91 * inp_poly_91)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 2768],
    (* inp_poly_92 *)
    eqmod 16 * (inp_poly_92 * inp_poly_92)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 2466],
    (* inp_poly_93 *)
    eqmod 16 * (inp_poly_93 * inp_poly_93)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 863],
    (* inp_poly_94 *)
    eqmod 16 * (inp_poly_94 * inp_poly_94)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 2594],
    (* inp_poly_95 *)
    eqmod 16 * (inp_poly_95 * inp_poly_95)
          (
            L0x2001a670 * (x**0) + L0x2001a672 * (x**1) + 
            L0x2001a674 * (x**2) + L0x2001a676 * (x**3) + 
            L0x2001a678 * (x**4) + L0x2001a67a * (x**5) + 
            L0x2001a67c * (x**6) + L0x2001a67e * (x**7) + 
            L0x2001a680 * (x**8) + L0x2001a682 * (x**9) + 
            L0x2001a684 * (x**10) + L0x2001a686 * (x**11) + 
            L0x2001a688 * (x**12) + L0x2001a68a * (x**13) + 
            L0x2001a68c * (x**14) + L0x2001a68e * (x**15) + 
            L0x2001a690 * (x**16) + L0x2001a692 * (x**17) + 
            L0x2001a694 * (x**18) + L0x2001a696 * (x**19) + 
            L0x2001a698 * (x**20) + L0x2001a69a * (x**21) + 
            L0x2001a69c * (x**22) + L0x2001a69e * (x**23) + 
            L0x2001a6a0 * (x**24) + L0x2001a6a2 * (x**25) + 
            L0x2001a6a4 * (x**26) + L0x2001a6a6 * (x**27) + 
            L0x2001a6a8 * (x**28) + L0x2001a6aa * (x**29) + 
            L0x2001a6ac * (x**30) + L0x2001a6ae * (x**31)
          )
          [3329, x**2 - 735],
    (* inp_poly_96 *)
    eqmod 16 * (inp_poly_96 * inp_poly_96)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2804],
    (* inp_poly_97 *)
    eqmod 16 * (inp_poly_97 * inp_poly_97)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 525],
    (* inp_poly_98 *)
    eqmod 16 * (inp_poly_98 * inp_poly_98)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 1092],
    (* inp_poly_99 *)
    eqmod 16 * (inp_poly_99 * inp_poly_99)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2237],
    (* inp_poly_100 *)
    eqmod 16 * (inp_poly_100 * inp_poly_100)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 403],
    (* inp_poly_101 *)
    eqmod 16 * (inp_poly_101 * inp_poly_101)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2926],
    (* inp_poly_102 *)
    eqmod 16 * (inp_poly_102 * inp_poly_102)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 1026],
    (* inp_poly_103 *)
    eqmod 16 * (inp_poly_103 * inp_poly_103)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2303],
    (* inp_poly_104 *)
    eqmod 16 * (inp_poly_104 * inp_poly_104)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 1143],
    (* inp_poly_105 *)
    eqmod 16 * (inp_poly_105 * inp_poly_105)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2186],
    (* inp_poly_106 *)
    eqmod 16 * (inp_poly_106 * inp_poly_106)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2150],
    (* inp_poly_107 *)
    eqmod 16 * (inp_poly_107 * inp_poly_107)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 1179],
    (* inp_poly_108 *)
    eqmod 16 * (inp_poly_108 * inp_poly_108)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2775],
    (* inp_poly_109 *)
    eqmod 16 * (inp_poly_109 * inp_poly_109)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 554],
    (* inp_poly_110 *)
    eqmod 16 * (inp_poly_110 * inp_poly_110)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 886],
    (* inp_poly_111 *)
    eqmod 16 * (inp_poly_111 * inp_poly_111)
          (
            L0x2001a6b0 * (x**0) + L0x2001a6b2 * (x**1) + 
            L0x2001a6b4 * (x**2) + L0x2001a6b6 * (x**3) + 
            L0x2001a6b8 * (x**4) + L0x2001a6ba * (x**5) + 
            L0x2001a6bc * (x**6) + L0x2001a6be * (x**7) + 
            L0x2001a6c0 * (x**8) + L0x2001a6c2 * (x**9) + 
            L0x2001a6c4 * (x**10) + L0x2001a6c6 * (x**11) + 
            L0x2001a6c8 * (x**12) + L0x2001a6ca * (x**13) + 
            L0x2001a6cc * (x**14) + L0x2001a6ce * (x**15) + 
            L0x2001a6d0 * (x**16) + L0x2001a6d2 * (x**17) + 
            L0x2001a6d4 * (x**18) + L0x2001a6d6 * (x**19) + 
            L0x2001a6d8 * (x**20) + L0x2001a6da * (x**21) + 
            L0x2001a6dc * (x**22) + L0x2001a6de * (x**23) + 
            L0x2001a6e0 * (x**24) + L0x2001a6e2 * (x**25) + 
            L0x2001a6e4 * (x**26) + L0x2001a6e6 * (x**27) + 
            L0x2001a6e8 * (x**28) + L0x2001a6ea * (x**29) + 
            L0x2001a6ec * (x**30) + L0x2001a6ee * (x**31)
          )
          [3329, x**2 - 2443],
    (* inp_poly_112 *)
    eqmod 16 * (inp_poly_112 * inp_poly_112)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1722],
    (* inp_poly_113 *)
    eqmod 16 * (inp_poly_113 * inp_poly_113)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1607],
    (* inp_poly_114 *)
    eqmod 16 * (inp_poly_114 * inp_poly_114)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1212],
    (* inp_poly_115 *)
    eqmod 16 * (inp_poly_115 * inp_poly_115)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 2117],
    (* inp_poly_116 *)
    eqmod 16 * (inp_poly_116 * inp_poly_116)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1874],
    (* inp_poly_117 *)
    eqmod 16 * (inp_poly_117 * inp_poly_117)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1455],
    (* inp_poly_118 *)
    eqmod 16 * (inp_poly_118 * inp_poly_118)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1029],
    (* inp_poly_119 *)
    eqmod 16 * (inp_poly_119 * inp_poly_119)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 2300],
    (* inp_poly_120 *)
    eqmod 16 * (inp_poly_120 * inp_poly_120)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 2110],
    (* inp_poly_121 *)
    eqmod 16 * (inp_poly_121 * inp_poly_121)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1219],
    (* inp_poly_122 *)
    eqmod 16 * (inp_poly_122 * inp_poly_122)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 2935],
    (* inp_poly_123 *)
    eqmod 16 * (inp_poly_123 * inp_poly_123)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 394],
    (* inp_poly_124 *)
    eqmod 16 * (inp_poly_124 * inp_poly_124)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 885],
    (* inp_poly_125 *)
    eqmod 16 * (inp_poly_125 * inp_poly_125)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 2444],
    (* inp_poly_126 *)
    eqmod 16 * (inp_poly_126 * inp_poly_126)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 2154],
    (* inp_poly_127 *)
    eqmod 16 * (inp_poly_127 * inp_poly_127)
          (
            L0x2001a6f0 * (x**0) + L0x2001a6f2 * (x**1) + 
            L0x2001a6f4 * (x**2) + L0x2001a6f6 * (x**3) + 
            L0x2001a6f8 * (x**4) + L0x2001a6fa * (x**5) + 
            L0x2001a6fc * (x**6) + L0x2001a6fe * (x**7) + 
            L0x2001a700 * (x**8) + L0x2001a702 * (x**9) + 
            L0x2001a704 * (x**10) + L0x2001a706 * (x**11) + 
            L0x2001a708 * (x**12) + L0x2001a70a * (x**13) + 
            L0x2001a70c * (x**14) + L0x2001a70e * (x**15) + 
            L0x2001a710 * (x**16) + L0x2001a712 * (x**17) + 
            L0x2001a714 * (x**18) + L0x2001a716 * (x**19) + 
            L0x2001a718 * (x**20) + L0x2001a71a * (x**21) + 
            L0x2001a71c * (x**22) + L0x2001a71e * (x**23) + 
            L0x2001a720 * (x**24) + L0x2001a722 * (x**25) + 
            L0x2001a724 * (x**26) + L0x2001a726 * (x**27) + 
            L0x2001a728 * (x**28) + L0x2001a72a * (x**29) + 
            L0x2001a72c * (x**30) + L0x2001a72e * (x**31)
          )
          [3329, x**2 - 1175]
  ]
  &&
  (* range *)
  and [
    1@16 * (-3329)@16 <=s L0x2001a530, L0x2001a530 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a532, L0x2001a532 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a534, L0x2001a534 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a536, L0x2001a536 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a538, L0x2001a538 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53a, L0x2001a53a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53c, L0x2001a53c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53e, L0x2001a53e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a540, L0x2001a540 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a542, L0x2001a542 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a544, L0x2001a544 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a546, L0x2001a546 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a548, L0x2001a548 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54a, L0x2001a54a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54c, L0x2001a54c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54e, L0x2001a54e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a550, L0x2001a550 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a552, L0x2001a552 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a554, L0x2001a554 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a556, L0x2001a556 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a558, L0x2001a558 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55a, L0x2001a55a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55c, L0x2001a55c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55e, L0x2001a55e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a560, L0x2001a560 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a562, L0x2001a562 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a564, L0x2001a564 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a566, L0x2001a566 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a568, L0x2001a568 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56a, L0x2001a56a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56c, L0x2001a56c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56e, L0x2001a56e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a570, L0x2001a570 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a572, L0x2001a572 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a574, L0x2001a574 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a576, L0x2001a576 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a578, L0x2001a578 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57a, L0x2001a57a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57c, L0x2001a57c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57e, L0x2001a57e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a580, L0x2001a580 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a582, L0x2001a582 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a584, L0x2001a584 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a586, L0x2001a586 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a588, L0x2001a588 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58a, L0x2001a58a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58c, L0x2001a58c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58e, L0x2001a58e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a590, L0x2001a590 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a592, L0x2001a592 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a594, L0x2001a594 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a596, L0x2001a596 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a598, L0x2001a598 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59a, L0x2001a59a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59c, L0x2001a59c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59e, L0x2001a59e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a0, L0x2001a5a0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a2, L0x2001a5a2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a4, L0x2001a5a4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a6, L0x2001a5a6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a8, L0x2001a5a8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5aa, L0x2001a5aa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ac, L0x2001a5ac <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ae, L0x2001a5ae <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b0, L0x2001a5b0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b2, L0x2001a5b2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b4, L0x2001a5b4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b6, L0x2001a5b6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b8, L0x2001a5b8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ba, L0x2001a5ba <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5bc, L0x2001a5bc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5be, L0x2001a5be <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c0, L0x2001a5c0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c2, L0x2001a5c2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c4, L0x2001a5c4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c6, L0x2001a5c6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c8, L0x2001a5c8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ca, L0x2001a5ca <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5cc, L0x2001a5cc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ce, L0x2001a5ce <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d0, L0x2001a5d0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d2, L0x2001a5d2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d4, L0x2001a5d4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d6, L0x2001a5d6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d8, L0x2001a5d8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5da, L0x2001a5da <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5dc, L0x2001a5dc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5de, L0x2001a5de <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e0, L0x2001a5e0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e2, L0x2001a5e2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e4, L0x2001a5e4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e6, L0x2001a5e6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e8, L0x2001a5e8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ea, L0x2001a5ea <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ec, L0x2001a5ec <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ee, L0x2001a5ee <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f0, L0x2001a5f0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f2, L0x2001a5f2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f4, L0x2001a5f4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f6, L0x2001a5f6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f8, L0x2001a5f8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fa, L0x2001a5fa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fc, L0x2001a5fc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fe, L0x2001a5fe <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a600, L0x2001a600 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a602, L0x2001a602 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a604, L0x2001a604 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a606, L0x2001a606 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a608, L0x2001a608 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60a, L0x2001a60a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60c, L0x2001a60c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60e, L0x2001a60e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a610, L0x2001a610 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a612, L0x2001a612 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a614, L0x2001a614 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a616, L0x2001a616 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a618, L0x2001a618 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61a, L0x2001a61a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61c, L0x2001a61c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61e, L0x2001a61e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a620, L0x2001a620 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a622, L0x2001a622 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a624, L0x2001a624 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a626, L0x2001a626 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a628, L0x2001a628 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62a, L0x2001a62a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62c, L0x2001a62c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62e, L0x2001a62e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a630, L0x2001a630 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a632, L0x2001a632 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a634, L0x2001a634 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a636, L0x2001a636 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a638, L0x2001a638 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63a, L0x2001a63a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63c, L0x2001a63c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63e, L0x2001a63e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a640, L0x2001a640 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a642, L0x2001a642 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a644, L0x2001a644 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a646, L0x2001a646 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a648, L0x2001a648 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64a, L0x2001a64a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64c, L0x2001a64c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64e, L0x2001a64e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a650, L0x2001a650 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a652, L0x2001a652 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a654, L0x2001a654 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a656, L0x2001a656 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a658, L0x2001a658 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65a, L0x2001a65a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65c, L0x2001a65c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65e, L0x2001a65e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a660, L0x2001a660 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a662, L0x2001a662 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a664, L0x2001a664 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a666, L0x2001a666 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a668, L0x2001a668 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66a, L0x2001a66a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66c, L0x2001a66c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66e, L0x2001a66e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a670, L0x2001a670 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a672, L0x2001a672 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a674, L0x2001a674 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a676, L0x2001a676 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a678, L0x2001a678 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67a, L0x2001a67a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67c, L0x2001a67c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67e, L0x2001a67e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a680, L0x2001a680 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a682, L0x2001a682 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a684, L0x2001a684 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a686, L0x2001a686 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a688, L0x2001a688 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68a, L0x2001a68a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68c, L0x2001a68c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68e, L0x2001a68e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a690, L0x2001a690 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a692, L0x2001a692 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a694, L0x2001a694 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a696, L0x2001a696 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a698, L0x2001a698 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69a, L0x2001a69a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69c, L0x2001a69c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69e, L0x2001a69e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a0, L0x2001a6a0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a2, L0x2001a6a2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a4, L0x2001a6a4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a6, L0x2001a6a6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a8, L0x2001a6a8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6aa, L0x2001a6aa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ac, L0x2001a6ac <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ae, L0x2001a6ae <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b0, L0x2001a6b0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b2, L0x2001a6b2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b4, L0x2001a6b4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b6, L0x2001a6b6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b8, L0x2001a6b8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ba, L0x2001a6ba <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6bc, L0x2001a6bc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6be, L0x2001a6be <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c0, L0x2001a6c0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c2, L0x2001a6c2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c4, L0x2001a6c4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c6, L0x2001a6c6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c8, L0x2001a6c8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ca, L0x2001a6ca <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6cc, L0x2001a6cc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ce, L0x2001a6ce <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d0, L0x2001a6d0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d2, L0x2001a6d2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d4, L0x2001a6d4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d6, L0x2001a6d6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d8, L0x2001a6d8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6da, L0x2001a6da <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6dc, L0x2001a6dc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6de, L0x2001a6de <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e0, L0x2001a6e0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e2, L0x2001a6e2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e4, L0x2001a6e4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e6, L0x2001a6e6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e8, L0x2001a6e8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ea, L0x2001a6ea <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ec, L0x2001a6ec <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ee, L0x2001a6ee <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f0, L0x2001a6f0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f2, L0x2001a6f2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f4, L0x2001a6f4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f6, L0x2001a6f6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f8, L0x2001a6f8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fa, L0x2001a6fa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fc, L0x2001a6fc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fe, L0x2001a6fe <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a700, L0x2001a700 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a702, L0x2001a702 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a704, L0x2001a704 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a706, L0x2001a706 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a708, L0x2001a708 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70a, L0x2001a70a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70c, L0x2001a70c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70e, L0x2001a70e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a710, L0x2001a710 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a712, L0x2001a712 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a714, L0x2001a714 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a716, L0x2001a716 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a718, L0x2001a718 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71a, L0x2001a71a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71c, L0x2001a71c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71e, L0x2001a71e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a720, L0x2001a720 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a722, L0x2001a722 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a724, L0x2001a724 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a726, L0x2001a726 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a728, L0x2001a728 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72a, L0x2001a72a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72c, L0x2001a72c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72e, L0x2001a72e <s 1@16 * 3329@16
  ]
;


(* sub.w	r0, r0, #512	; 0x200                      #! PC = 0x8005794 *)
subs discard r0 r0 512@uint32;
(* movw	r12, #16                                   #! PC = 0x8005798 *)
mov r12_b 16@sint16;
mov r12_t 0@sint16;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a530; Value = 0x0204063a; PC = 0x80057a0 *)
mov r2_b L0x2001a530;
mov r2_t L0x2001a532;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a570; Value = 0xfd6500cb; PC = 0x80057a4 *)
mov r3_b L0x2001a570;
mov r3_t L0x2001a572;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5b0; Value = 0xfd3dffc1; PC = 0x80057a8 *)
mov r4_b L0x2001a5b0;
mov r4_t L0x2001a5b2;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5f0; Value = 0xfa3f0194; PC = 0x80057ac *)
mov r5_b L0x2001a5f0;
mov r5_t L0x2001a5f2;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a630; Value = 0xfa93ff3f; PC = 0x80057b0 *)
mov r6_b L0x2001a630;
mov r6_t L0x2001a632;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a670; Value = 0xffc4fe02; PC = 0x80057b4 *)
mov r7_b L0x2001a670;
mov r7_t L0x2001a672;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6b0; Value = 0x0431fce8; PC = 0x80057b8 *)
mov r8_b L0x2001a6b0;
mov r8_t L0x2001a6b2;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6f0; Value = 0xfa7901d2; PC = 0x80057bc *)
mov r9_b L0x2001a6f0;
mov r9_t L0x2001a6f2;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a630; PC = 0x80059f0 *)
mov L0x2001a630 r6_b;
mov L0x2001a632 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a670; PC = 0x80059f4 *)
mov L0x2001a670 r7_b;
mov L0x2001a672 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6b0; PC = 0x80059f8 *)
mov L0x2001a6b0 r8_b;
mov L0x2001a6b2 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6f0; PC = 0x80059fc *)
mov L0x2001a6f0 r9_b;
mov L0x2001a6f2 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a570; PC = 0x8005a00 *)
mov L0x2001a570 r3_b;
mov L0x2001a572 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5b0; PC = 0x8005a04 *)
mov L0x2001a5b0 r4_b;
mov L0x2001a5b2 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5f0; PC = 0x8005a08 *)
mov L0x2001a5f0 r5_b;
mov L0x2001a5f2 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a530; PC = 0x8005a0c *)
mov L0x2001a530 r2_b;
mov L0x2001a532 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000010; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a534; Value = 0x034dff43; PC = 0x80057a0 *)
mov r2_b L0x2001a534;
mov r2_t L0x2001a536;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a574; Value = 0x026efb52; PC = 0x80057a4 *)
mov r3_b L0x2001a574;
mov r3_t L0x2001a576;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5b4; Value = 0x053a02f3; PC = 0x80057a8 *)
mov r4_b L0x2001a5b4;
mov r4_t L0x2001a5b6;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5f4; Value = 0x03020073; PC = 0x80057ac *)
mov r5_b L0x2001a5f4;
mov r5_t L0x2001a5f6;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a634; Value = 0x047803f5; PC = 0x80057b0 *)
mov r6_b L0x2001a634;
mov r6_t L0x2001a636;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a674; Value = 0x0038012e; PC = 0x80057b4 *)
mov r7_b L0x2001a674;
mov r7_t L0x2001a676;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6b4; Value = 0xf980041b; PC = 0x80057b8 *)
mov r8_b L0x2001a6b4;
mov r8_t L0x2001a6b6;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6f4; Value = 0xfb74facc; PC = 0x80057bc *)
mov r9_b L0x2001a6f4;
mov r9_t L0x2001a6f6;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a634; PC = 0x80059f0 *)
mov L0x2001a634 r6_b;
mov L0x2001a636 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a674; PC = 0x80059f4 *)
mov L0x2001a674 r7_b;
mov L0x2001a676 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6b4; PC = 0x80059f8 *)
mov L0x2001a6b4 r8_b;
mov L0x2001a6b6 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6f4; PC = 0x80059fc *)
mov L0x2001a6f4 r9_b;
mov L0x2001a6f6 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a574; PC = 0x8005a00 *)
mov L0x2001a574 r3_b;
mov L0x2001a576 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5b4; PC = 0x8005a04 *)
mov L0x2001a5b4 r4_b;
mov L0x2001a5b6 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5f4; PC = 0x8005a08 *)
mov L0x2001a5f4 r5_b;
mov L0x2001a5f6 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a534; PC = 0x8005a0c *)
mov L0x2001a534 r2_b;
mov L0x2001a536 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000f; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a538; Value = 0x009dfbfe; PC = 0x80057a0 *)
mov r2_b L0x2001a538;
mov r2_t L0x2001a53a;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a578; Value = 0xff8ffb3a; PC = 0x80057a4 *)
mov r3_b L0x2001a578;
mov r3_t L0x2001a57a;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5b8; Value = 0xfb830383; PC = 0x80057a8 *)
mov r4_b L0x2001a5b8;
mov r4_t L0x2001a5ba;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5f8; Value = 0xfb80fe21; PC = 0x80057ac *)
mov r5_b L0x2001a5f8;
mov r5_t L0x2001a5fa;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a638; Value = 0xfa0f02fe; PC = 0x80057b0 *)
mov r6_b L0x2001a638;
mov r6_t L0x2001a63a;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a678; Value = 0x067afba0; PC = 0x80057b4 *)
mov r7_b L0x2001a678;
mov r7_t L0x2001a67a;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6b8; Value = 0x00caff7d; PC = 0x80057b8 *)
mov r8_b L0x2001a6b8;
mov r8_t L0x2001a6ba;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6f8; Value = 0xfd730310; PC = 0x80057bc *)
mov r9_b L0x2001a6f8;
mov r9_t L0x2001a6fa;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a638; PC = 0x80059f0 *)
mov L0x2001a638 r6_b;
mov L0x2001a63a r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a678; PC = 0x80059f4 *)
mov L0x2001a678 r7_b;
mov L0x2001a67a r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6b8; PC = 0x80059f8 *)
mov L0x2001a6b8 r8_b;
mov L0x2001a6ba r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6f8; PC = 0x80059fc *)
mov L0x2001a6f8 r9_b;
mov L0x2001a6fa r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a578; PC = 0x8005a00 *)
mov L0x2001a578 r3_b;
mov L0x2001a57a r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5b8; PC = 0x8005a04 *)
mov L0x2001a5b8 r4_b;
mov L0x2001a5ba r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5f8; PC = 0x8005a08 *)
mov L0x2001a5f8 r5_b;
mov L0x2001a5fa r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a538; PC = 0x8005a0c *)
mov L0x2001a538 r2_b;
mov L0x2001a53a r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000e; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a53c; Value = 0xfc30020d; PC = 0x80057a0 *)
mov r2_b L0x2001a53c;
mov r2_t L0x2001a53e;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a57c; Value = 0x02fa0517; PC = 0x80057a4 *)
mov r3_b L0x2001a57c;
mov r3_t L0x2001a57e;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5bc; Value = 0xfbabff54; PC = 0x80057a8 *)
mov r4_b L0x2001a5bc;
mov r4_t L0x2001a5be;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5fc; Value = 0xfb05028e; PC = 0x80057ac *)
mov r5_b L0x2001a5fc;
mov r5_t L0x2001a5fe;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a63c; Value = 0x01d1fe54; PC = 0x80057b0 *)
mov r6_b L0x2001a63c;
mov r6_t L0x2001a63e;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a67c; Value = 0xfd4f0209; PC = 0x80057b4 *)
mov r7_b L0x2001a67c;
mov r7_t L0x2001a67e;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6bc; Value = 0xfed3030e; PC = 0x80057b8 *)
mov r8_b L0x2001a6bc;
mov r8_t L0x2001a6be;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6fc; Value = 0x0622facb; PC = 0x80057bc *)
mov r9_b L0x2001a6fc;
mov r9_t L0x2001a6fe;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a63c; PC = 0x80059f0 *)
mov L0x2001a63c r6_b;
mov L0x2001a63e r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a67c; PC = 0x80059f4 *)
mov L0x2001a67c r7_b;
mov L0x2001a67e r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6bc; PC = 0x80059f8 *)
mov L0x2001a6bc r8_b;
mov L0x2001a6be r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a6fc; PC = 0x80059fc *)
mov L0x2001a6fc r9_b;
mov L0x2001a6fe r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a57c; PC = 0x8005a00 *)
mov L0x2001a57c r3_b;
mov L0x2001a57e r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5bc; PC = 0x8005a04 *)
mov L0x2001a5bc r4_b;
mov L0x2001a5be r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a5fc; PC = 0x8005a08 *)
mov L0x2001a5fc r5_b;
mov L0x2001a5fe r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a53c; PC = 0x8005a0c *)
mov L0x2001a53c r2_b;
mov L0x2001a53e r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000d; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a540; Value = 0xfee40462; PC = 0x80057a0 *)
mov r2_b L0x2001a540;
mov r2_t L0x2001a542;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a580; Value = 0xffd0fa53; PC = 0x80057a4 *)
mov r3_b L0x2001a580;
mov r3_t L0x2001a582;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5c0; Value = 0xfb32ffb4; PC = 0x80057a8 *)
mov r4_b L0x2001a5c0;
mov r4_t L0x2001a5c2;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a600; Value = 0xfc530496; PC = 0x80057ac *)
mov r5_b L0x2001a600;
mov r5_t L0x2001a602;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a640; Value = 0xfdb503b2; PC = 0x80057b0 *)
mov r6_b L0x2001a640;
mov r6_t L0x2001a642;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a680; Value = 0xfec2fa3f; PC = 0x80057b4 *)
mov r7_b L0x2001a680;
mov r7_t L0x2001a682;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6c0; Value = 0x0623f974; PC = 0x80057b8 *)
mov r8_b L0x2001a6c0;
mov r8_t L0x2001a6c2;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a700; Value = 0x02eafc10; PC = 0x80057bc *)
mov r9_b L0x2001a700;
mov r9_t L0x2001a702;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a640; PC = 0x80059f0 *)
mov L0x2001a640 r6_b;
mov L0x2001a642 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a680; PC = 0x80059f4 *)
mov L0x2001a680 r7_b;
mov L0x2001a682 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6c0; PC = 0x80059f8 *)
mov L0x2001a6c0 r8_b;
mov L0x2001a6c2 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a700; PC = 0x80059fc *)
mov L0x2001a700 r9_b;
mov L0x2001a702 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a580; PC = 0x8005a00 *)
mov L0x2001a580 r3_b;
mov L0x2001a582 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5c0; PC = 0x8005a04 *)
mov L0x2001a5c0 r4_b;
mov L0x2001a5c2 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a600; PC = 0x8005a08 *)
mov L0x2001a600 r5_b;
mov L0x2001a602 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a540; PC = 0x8005a0c *)
mov L0x2001a540 r2_b;
mov L0x2001a542 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000c; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a544; Value = 0x002004a9; PC = 0x80057a0 *)
mov r2_b L0x2001a544;
mov r2_t L0x2001a546;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a584; Value = 0x054fff6c; PC = 0x80057a4 *)
mov r3_b L0x2001a584;
mov r3_t L0x2001a586;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5c4; Value = 0xfb7b0505; PC = 0x80057a8 *)
mov r4_b L0x2001a5c4;
mov r4_t L0x2001a5c6;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a604; Value = 0x012702e8; PC = 0x80057ac *)
mov r5_b L0x2001a604;
mov r5_t L0x2001a606;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a644; Value = 0x0347fe7b; PC = 0x80057b0 *)
mov r6_b L0x2001a644;
mov r6_t L0x2001a646;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a684; Value = 0xfca1f9e4; PC = 0x80057b4 *)
mov r7_b L0x2001a684;
mov r7_t L0x2001a686;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6c4; Value = 0x0208069e; PC = 0x80057b8 *)
mov r8_b L0x2001a6c4;
mov r8_t L0x2001a6c6;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a704; Value = 0xfe40fb53; PC = 0x80057bc *)
mov r9_b L0x2001a704;
mov r9_t L0x2001a706;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a644; PC = 0x80059f0 *)
mov L0x2001a644 r6_b;
mov L0x2001a646 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a684; PC = 0x80059f4 *)
mov L0x2001a684 r7_b;
mov L0x2001a686 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6c4; PC = 0x80059f8 *)
mov L0x2001a6c4 r8_b;
mov L0x2001a6c6 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a704; PC = 0x80059fc *)
mov L0x2001a704 r9_b;
mov L0x2001a706 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a584; PC = 0x8005a00 *)
mov L0x2001a584 r3_b;
mov L0x2001a586 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5c4; PC = 0x8005a04 *)
mov L0x2001a5c4 r4_b;
mov L0x2001a5c6 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a604; PC = 0x8005a08 *)
mov L0x2001a604 r5_b;
mov L0x2001a606 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a544; PC = 0x8005a0c *)
mov L0x2001a544 r2_b;
mov L0x2001a546 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000b; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a548; Value = 0xfd4bfda8; PC = 0x80057a0 *)
mov r2_b L0x2001a548;
mov r2_t L0x2001a54a;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a588; Value = 0xfb6f0002; PC = 0x80057a4 *)
mov r3_b L0x2001a588;
mov r3_t L0x2001a58a;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5c8; Value = 0x031cff6f; PC = 0x80057a8 *)
mov r4_b L0x2001a5c8;
mov r4_t L0x2001a5ca;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a608; Value = 0x0318fa59; PC = 0x80057ac *)
mov r5_b L0x2001a608;
mov r5_t L0x2001a60a;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a648; Value = 0x0042fb95; PC = 0x80057b0 *)
mov r6_b L0x2001a648;
mov r6_t L0x2001a64a;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a688; Value = 0xfd78013d; PC = 0x80057b4 *)
mov r7_b L0x2001a688;
mov r7_t L0x2001a68a;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6c8; Value = 0x0100fadc; PC = 0x80057b8 *)
mov r8_b L0x2001a6c8;
mov r8_t L0x2001a6ca;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a708; Value = 0x026e01a3; PC = 0x80057bc *)
mov r9_b L0x2001a708;
mov r9_t L0x2001a70a;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a648; PC = 0x80059f0 *)
mov L0x2001a648 r6_b;
mov L0x2001a64a r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a688; PC = 0x80059f4 *)
mov L0x2001a688 r7_b;
mov L0x2001a68a r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6c8; PC = 0x80059f8 *)
mov L0x2001a6c8 r8_b;
mov L0x2001a6ca r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a708; PC = 0x80059fc *)
mov L0x2001a708 r9_b;
mov L0x2001a70a r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a588; PC = 0x8005a00 *)
mov L0x2001a588 r3_b;
mov L0x2001a58a r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5c8; PC = 0x8005a04 *)
mov L0x2001a5c8 r4_b;
mov L0x2001a5ca r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a608; PC = 0x8005a08 *)
mov L0x2001a608 r5_b;
mov L0x2001a60a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a548; PC = 0x8005a0c *)
mov L0x2001a548 r2_b;
mov L0x2001a54a r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x0000000a; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a54c; Value = 0x0413feab; PC = 0x80057a0 *)
mov r2_b L0x2001a54c;
mov r2_t L0x2001a54e;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a58c; Value = 0x054dfe6a; PC = 0x80057a4 *)
mov r3_b L0x2001a58c;
mov r3_t L0x2001a58e;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5cc; Value = 0xfb83ff9a; PC = 0x80057a8 *)
mov r4_b L0x2001a5cc;
mov r4_t L0x2001a5ce;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a60c; Value = 0xfcce05f4; PC = 0x80057ac *)
mov r5_b L0x2001a60c;
mov r5_t L0x2001a60e;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a64c; Value = 0x024efc4c; PC = 0x80057b0 *)
mov r6_b L0x2001a64c;
mov r6_t L0x2001a64e;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a68c; Value = 0x03d2ff61; PC = 0x80057b4 *)
mov r7_b L0x2001a68c;
mov r7_t L0x2001a68e;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6cc; Value = 0xfae3fb07; PC = 0x80057b8 *)
mov r8_b L0x2001a6cc;
mov r8_t L0x2001a6ce;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a70c; Value = 0xfec3fe4b; PC = 0x80057bc *)
mov r9_b L0x2001a70c;
mov r9_t L0x2001a70e;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a64c; PC = 0x80059f0 *)
mov L0x2001a64c r6_b;
mov L0x2001a64e r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a68c; PC = 0x80059f4 *)
mov L0x2001a68c r7_b;
mov L0x2001a68e r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6cc; PC = 0x80059f8 *)
mov L0x2001a6cc r8_b;
mov L0x2001a6ce r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a70c; PC = 0x80059fc *)
mov L0x2001a70c r9_b;
mov L0x2001a70e r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a58c; PC = 0x8005a00 *)
mov L0x2001a58c r3_b;
mov L0x2001a58e r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5cc; PC = 0x8005a04 *)
mov L0x2001a5cc r4_b;
mov L0x2001a5ce r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a60c; PC = 0x8005a08 *)
mov L0x2001a60c r5_b;
mov L0x2001a60e r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a54c; PC = 0x8005a0c *)
mov L0x2001a54c r2_b;
mov L0x2001a54e r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000009; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a550; Value = 0xfe4b021c; PC = 0x80057a0 *)
mov r2_b L0x2001a550;
mov r2_t L0x2001a552;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a590; Value = 0x02f6fd53; PC = 0x80057a4 *)
mov r3_b L0x2001a590;
mov r3_t L0x2001a592;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5d0; Value = 0xfeb10480; PC = 0x80057a8 *)
mov r4_b L0x2001a5d0;
mov r4_t L0x2001a5d2;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a610; Value = 0x0401fd54; PC = 0x80057ac *)
mov r5_b L0x2001a610;
mov r5_t L0x2001a612;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a650; Value = 0x03a6fad6; PC = 0x80057b0 *)
mov r6_b L0x2001a650;
mov r6_t L0x2001a652;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a690; Value = 0x011e0225; PC = 0x80057b4 *)
mov r7_b L0x2001a690;
mov r7_t L0x2001a692;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6d0; Value = 0xfac8fc19; PC = 0x80057b8 *)
mov r8_b L0x2001a6d0;
mov r8_t L0x2001a6d2;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a710; Value = 0x018605da; PC = 0x80057bc *)
mov r9_b L0x2001a710;
mov r9_t L0x2001a712;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a650; PC = 0x80059f0 *)
mov L0x2001a650 r6_b;
mov L0x2001a652 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a690; PC = 0x80059f4 *)
mov L0x2001a690 r7_b;
mov L0x2001a692 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6d0; PC = 0x80059f8 *)
mov L0x2001a6d0 r8_b;
mov L0x2001a6d2 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a710; PC = 0x80059fc *)
mov L0x2001a710 r9_b;
mov L0x2001a712 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a590; PC = 0x8005a00 *)
mov L0x2001a590 r3_b;
mov L0x2001a592 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5d0; PC = 0x8005a04 *)
mov L0x2001a5d0 r4_b;
mov L0x2001a5d2 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a610; PC = 0x8005a08 *)
mov L0x2001a610 r5_b;
mov L0x2001a612 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a550; PC = 0x8005a0c *)
mov L0x2001a550 r2_b;
mov L0x2001a552 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000008; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a554; Value = 0xfd72013d; PC = 0x80057a0 *)
mov r2_b L0x2001a554;
mov r2_t L0x2001a556;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a594; Value = 0x00c4fd58; PC = 0x80057a4 *)
mov r3_b L0x2001a594;
mov r3_t L0x2001a596;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5d4; Value = 0xfea3feee; PC = 0x80057a8 *)
mov r4_b L0x2001a5d4;
mov r4_t L0x2001a5d6;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a614; Value = 0xfab0fbc1; PC = 0x80057ac *)
mov r5_b L0x2001a614;
mov r5_t L0x2001a616;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a654; Value = 0xfdb7fe03; PC = 0x80057b0 *)
mov r6_b L0x2001a654;
mov r6_t L0x2001a656;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a694; Value = 0xfc0303d3; PC = 0x80057b4 *)
mov r7_b L0x2001a694;
mov r7_t L0x2001a696;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6d4; Value = 0xfd5805e2; PC = 0x80057b8 *)
mov r8_b L0x2001a6d4;
mov r8_t L0x2001a6d6;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a714; Value = 0x00dd0434; PC = 0x80057bc *)
mov r9_b L0x2001a714;
mov r9_t L0x2001a716;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a654; PC = 0x80059f0 *)
mov L0x2001a654 r6_b;
mov L0x2001a656 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a694; PC = 0x80059f4 *)
mov L0x2001a694 r7_b;
mov L0x2001a696 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6d4; PC = 0x80059f8 *)
mov L0x2001a6d4 r8_b;
mov L0x2001a6d6 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a714; PC = 0x80059fc *)
mov L0x2001a714 r9_b;
mov L0x2001a716 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a594; PC = 0x8005a00 *)
mov L0x2001a594 r3_b;
mov L0x2001a596 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5d4; PC = 0x8005a04 *)
mov L0x2001a5d4 r4_b;
mov L0x2001a5d6 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a614; PC = 0x8005a08 *)
mov L0x2001a614 r5_b;
mov L0x2001a616 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a554; PC = 0x8005a0c *)
mov L0x2001a554 r2_b;
mov L0x2001a556 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000007; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a558; Value = 0xfb080380; PC = 0x80057a0 *)
mov r2_b L0x2001a558;
mov r2_t L0x2001a55a;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a598; Value = 0xfbc0ff6d; PC = 0x80057a4 *)
mov r3_b L0x2001a598;
mov r3_t L0x2001a59a;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5d8; Value = 0xfbbc04ea; PC = 0x80057a8 *)
mov r4_b L0x2001a5d8;
mov r4_t L0x2001a5da;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a618; Value = 0x029003d1; PC = 0x80057ac *)
mov r5_b L0x2001a618;
mov r5_t L0x2001a61a;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a658; Value = 0xff76fcc8; PC = 0x80057b0 *)
mov r6_b L0x2001a658;
mov r6_t L0x2001a65a;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a698; Value = 0x04510179; PC = 0x80057b4 *)
mov r7_b L0x2001a698;
mov r7_t L0x2001a69a;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6d8; Value = 0xfc4bffaf; PC = 0x80057b8 *)
mov r8_b L0x2001a6d8;
mov r8_t L0x2001a6da;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a718; Value = 0xfdd7fc07; PC = 0x80057bc *)
mov r9_b L0x2001a718;
mov r9_t L0x2001a71a;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a658; PC = 0x80059f0 *)
mov L0x2001a658 r6_b;
mov L0x2001a65a r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a698; PC = 0x80059f4 *)
mov L0x2001a698 r7_b;
mov L0x2001a69a r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6d8; PC = 0x80059f8 *)
mov L0x2001a6d8 r8_b;
mov L0x2001a6da r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a718; PC = 0x80059fc *)
mov L0x2001a718 r9_b;
mov L0x2001a71a r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a598; PC = 0x8005a00 *)
mov L0x2001a598 r3_b;
mov L0x2001a59a r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5d8; PC = 0x8005a04 *)
mov L0x2001a5d8 r4_b;
mov L0x2001a5da r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a618; PC = 0x8005a08 *)
mov L0x2001a618 r5_b;
mov L0x2001a61a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a558; PC = 0x8005a0c *)
mov L0x2001a558 r2_b;
mov L0x2001a55a r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000006; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a55c; Value = 0x05330562; PC = 0x80057a0 *)
mov r2_b L0x2001a55c;
mov r2_t L0x2001a55e;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a59c; Value = 0x018803ba; PC = 0x80057a4 *)
mov r3_b L0x2001a59c;
mov r3_t L0x2001a59e;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5dc; Value = 0x04fa0168; PC = 0x80057a8 *)
mov r4_b L0x2001a5dc;
mov r4_t L0x2001a5de;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a61c; Value = 0xfbf80299; PC = 0x80057ac *)
mov r5_b L0x2001a61c;
mov r5_t L0x2001a61e;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a65c; Value = 0x03ddfa6d; PC = 0x80057b0 *)
mov r6_b L0x2001a65c;
mov r6_t L0x2001a65e;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a69c; Value = 0x03fc0110; PC = 0x80057b4 *)
mov r7_b L0x2001a69c;
mov r7_t L0x2001a69e;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6dc; Value = 0xfa75fdc9; PC = 0x80057b8 *)
mov r8_b L0x2001a6dc;
mov r8_t L0x2001a6de;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a71c; Value = 0x028c0391; PC = 0x80057bc *)
mov r9_b L0x2001a71c;
mov r9_t L0x2001a71e;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a65c; PC = 0x80059f0 *)
mov L0x2001a65c r6_b;
mov L0x2001a65e r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a69c; PC = 0x80059f4 *)
mov L0x2001a69c r7_b;
mov L0x2001a69e r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6dc; PC = 0x80059f8 *)
mov L0x2001a6dc r8_b;
mov L0x2001a6de r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a71c; PC = 0x80059fc *)
mov L0x2001a71c r9_b;
mov L0x2001a71e r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a59c; PC = 0x8005a00 *)
mov L0x2001a59c r3_b;
mov L0x2001a59e r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5dc; PC = 0x8005a04 *)
mov L0x2001a5dc r4_b;
mov L0x2001a5de r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a61c; PC = 0x8005a08 *)
mov L0x2001a61c r5_b;
mov L0x2001a61e r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a55c; PC = 0x8005a0c *)
mov L0x2001a55c r2_b;
mov L0x2001a55e r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000005; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a560; Value = 0xfc44ffb0; PC = 0x80057a0 *)
mov r2_b L0x2001a560;
mov r2_t L0x2001a562;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5a0; Value = 0xfd1c0367; PC = 0x80057a4 *)
mov r3_b L0x2001a5a0;
mov r3_t L0x2001a5a2;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5e0; Value = 0xfaf1fe04; PC = 0x80057a8 *)
mov r4_b L0x2001a5e0;
mov r4_t L0x2001a5e2;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a620; Value = 0xf9af0013; PC = 0x80057ac *)
mov r5_b L0x2001a620;
mov r5_t L0x2001a622;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a660; Value = 0xfe23fb5a; PC = 0x80057b0 *)
mov r6_b L0x2001a660;
mov r6_t L0x2001a662;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6a0; Value = 0xfaf10610; PC = 0x80057b4 *)
mov r7_b L0x2001a6a0;
mov r7_t L0x2001a6a2;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6e0; Value = 0x00230445; PC = 0x80057b8 *)
mov r8_b L0x2001a6e0;
mov r8_t L0x2001a6e2;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a720; Value = 0x03810337; PC = 0x80057bc *)
mov r9_b L0x2001a720;
mov r9_t L0x2001a722;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a660; PC = 0x80059f0 *)
mov L0x2001a660 r6_b;
mov L0x2001a662 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6a0; PC = 0x80059f4 *)
mov L0x2001a6a0 r7_b;
mov L0x2001a6a2 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6e0; PC = 0x80059f8 *)
mov L0x2001a6e0 r8_b;
mov L0x2001a6e2 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a720; PC = 0x80059fc *)
mov L0x2001a720 r9_b;
mov L0x2001a722 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5a0; PC = 0x8005a00 *)
mov L0x2001a5a0 r3_b;
mov L0x2001a5a2 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5e0; PC = 0x8005a04 *)
mov L0x2001a5e0 r4_b;
mov L0x2001a5e2 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a620; PC = 0x8005a08 *)
mov L0x2001a620 r5_b;
mov L0x2001a622 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a560; PC = 0x8005a0c *)
mov L0x2001a560 r2_b;
mov L0x2001a562 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000004; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a564; Value = 0xff5bfc36; PC = 0x80057a0 *)
mov r2_b L0x2001a564;
mov r2_t L0x2001a566;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5a4; Value = 0xfb49ff3a; PC = 0x80057a4 *)
mov r3_b L0x2001a5a4;
mov r3_t L0x2001a5a6;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5e4; Value = 0xfd23fa9b; PC = 0x80057a8 *)
mov r4_b L0x2001a5e4;
mov r4_t L0x2001a5e6;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a624; Value = 0x01d200ce; PC = 0x80057ac *)
mov r5_b L0x2001a624;
mov r5_t L0x2001a626;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a664; Value = 0x02cdfe1f; PC = 0x80057b0 *)
mov r6_b L0x2001a664;
mov r6_t L0x2001a666;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6a4; Value = 0xfd070670; PC = 0x80057b4 *)
mov r7_b L0x2001a6a4;
mov r7_t L0x2001a6a6;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6e4; Value = 0x04f3ff2e; PC = 0x80057b8 *)
mov r8_b L0x2001a6e4;
mov r8_t L0x2001a6e6;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a724; Value = 0x022bfb7a; PC = 0x80057bc *)
mov r9_b L0x2001a724;
mov r9_t L0x2001a726;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a664; PC = 0x80059f0 *)
mov L0x2001a664 r6_b;
mov L0x2001a666 r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6a4; PC = 0x80059f4 *)
mov L0x2001a6a4 r7_b;
mov L0x2001a6a6 r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6e4; PC = 0x80059f8 *)
mov L0x2001a6e4 r8_b;
mov L0x2001a6e6 r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a724; PC = 0x80059fc *)
mov L0x2001a724 r9_b;
mov L0x2001a726 r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5a4; PC = 0x8005a00 *)
mov L0x2001a5a4 r3_b;
mov L0x2001a5a6 r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5e4; PC = 0x8005a04 *)
mov L0x2001a5e4 r4_b;
mov L0x2001a5e6 r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a624; PC = 0x8005a08 *)
mov L0x2001a624 r5_b;
mov L0x2001a626 r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a564; PC = 0x8005a0c *)
mov L0x2001a564 r2_b;
mov L0x2001a566 r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000003; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a568; Value = 0x0591fd37; PC = 0x80057a0 *)
mov r2_b L0x2001a568;
mov r2_t L0x2001a56a;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5a8; Value = 0xfd86fdfd; PC = 0x80057a4 *)
mov r3_b L0x2001a5a8;
mov r3_t L0x2001a5aa;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5e8; Value = 0x011c017e; PC = 0x80057a8 *)
mov r4_b L0x2001a5e8;
mov r4_t L0x2001a5ea;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a628; Value = 0x01d7fa6d; PC = 0x80057ac *)
mov r5_b L0x2001a628;
mov r5_t L0x2001a62a;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a668; Value = 0xfaaafc52; PC = 0x80057b0 *)
mov r6_b L0x2001a668;
mov r6_t L0x2001a66a;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6a8; Value = 0x0281fbec; PC = 0x80057b4 *)
mov r7_b L0x2001a6a8;
mov r7_t L0x2001a6aa;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6e8; Value = 0xff7cfe07; PC = 0x80057b8 *)
mov r8_b L0x2001a6e8;
mov r8_t L0x2001a6ea;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a728; Value = 0x0048fab2; PC = 0x80057bc *)
mov r9_b L0x2001a728;
mov r9_t L0x2001a72a;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a668; PC = 0x80059f0 *)
mov L0x2001a668 r6_b;
mov L0x2001a66a r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6a8; PC = 0x80059f4 *)
mov L0x2001a6a8 r7_b;
mov L0x2001a6aa r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6e8; PC = 0x80059f8 *)
mov L0x2001a6e8 r8_b;
mov L0x2001a6ea r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a728; PC = 0x80059fc *)
mov L0x2001a728 r9_b;
mov L0x2001a72a r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5a8; PC = 0x8005a00 *)
mov L0x2001a5a8 r3_b;
mov L0x2001a5aa r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5e8; PC = 0x8005a04 *)
mov L0x2001a5e8 r4_b;
mov L0x2001a5ea r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a628; PC = 0x8005a08 *)
mov L0x2001a628 r5_b;
mov L0x2001a62a r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a568; PC = 0x8005a0c *)
mov L0x2001a568 r2_b;
mov L0x2001a56a r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000002; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* str.w	r12, [sp, #-4]!                           #! EA = L0x2001a498; PC = 0x800579c *)
mov L0x2001a498 r12_b;
mov L0x2001a49a r12_t;
(* ldr.w	r2, [r0]                                  #! EA = L0x2001a56c; Value = 0xfa1ef9c2; PC = 0x80057a0 *)
mov r2_b L0x2001a56c;
mov r2_t L0x2001a56e;
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5ac; Value = 0x012ffcfb; PC = 0x80057a4 *)
mov r3_b L0x2001a5ac;
mov r3_t L0x2001a5ae;
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5ec; Value = 0xfa8dfdba; PC = 0x80057a8 *)
mov r4_b L0x2001a5ec;
mov r4_t L0x2001a5ee;
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a62c; Value = 0xfb1bfa62; PC = 0x80057ac *)
mov r5_b L0x2001a62c;
mov r5_t L0x2001a62e;
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a66c; Value = 0x0326fd83; PC = 0x80057b0 *)
mov r6_b L0x2001a66c;
mov r6_t L0x2001a66e;
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6ac; Value = 0xfb4f0548; PC = 0x80057b4 *)
mov r7_b L0x2001a6ac;
mov r7_t L0x2001a6ae;
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6ec; Value = 0x000dff25; PC = 0x80057b8 *)
mov r8_b L0x2001a6ec;
mov r8_t L0x2001a6ee;
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a72c; Value = 0x03a8febe; PC = 0x80057bc *)
mov r9_b L0x2001a72c;
mov r9_t L0x2001a72e;
(* ldr.w	r10, [r1]                                 #! EA = L0x800e6c4; Value = 0x0be20c37; PC = 0x80057c0 *)
mov r10_b L0x800e6c4;
mov r10_t L0x800e6c6;
(* usub16	r12, r2, r3                              #! PC = 0x80057c4 *)
sub r12_b r2_b r3_b;
sub r12_t r2_t r3_t;
(* uadd16	r2, r2, r3                               #! PC = 0x80057c8 *)
add r2_b r2_b r3_b;
add r2_t r2_t r3_t;
(* smulbb	r3, r12, r10                             #! PC = 0x80057cc *)
mull r3_t r3_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80057d0 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r3, r11                              #! PC = 0x80057d4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80057d8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80057dc *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80057e0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x80057e4 *)
mov tmp_t r3_t;
mov tmp_b lr_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* usub16	r12, r4, r5                              #! PC = 0x80057e8 *)
sub r12_b r4_b r5_b;
sub r12_t r4_t r5_t;
(* uadd16	r4, r4, r5                               #! PC = 0x80057ec *)
add r4_b r4_b r5_b;
add r4_t r4_t r5_t;
(* smulbt	r5, r12, r10                             #! PC = 0x80057f0 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80057f4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80057f8 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80057fc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005800 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x8005804 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x8005808 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* ldr.w	r10, [r1, #4]                             #! EA = L0x800e6c8; Value = 0x072c0773; PC = 0x800580c *)
mov r10_b L0x800e6c8;
mov r10_t L0x800e6ca;
(* usub16	r12, r6, r7                              #! PC = 0x8005810 *)
sub r12_b r6_b r7_b;
sub r12_t r6_t r7_t;
(* uadd16	r6, r6, r7                               #! PC = 0x8005814 *)
add r6_b r6_b r7_b;
add r6_t r6_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x8005818 *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800581c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005820 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005824 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x8005828 *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x800582c *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005830 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r8, r9                              #! PC = 0x8005834 *)
sub r12_b r8_b r9_b;
sub r12_t r8_t r9_t;
(* uadd16	r8, r8, r9                               #! PC = 0x8005838 *)
add r8_b r8_b r9_b;
add r8_t r8_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x800583c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x8005840 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x8005844 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005848 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x800584c *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005850 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x8005854 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #8]                             #! EA = L0x800e6cc; Value = 0x016705ed; PC = 0x8005858 *)
mov r10_b L0x800e6cc;
mov r10_t L0x800e6ce;
(* usub16	r12, r2, r4                              #! PC = 0x800585c *)
sub r12_b r2_b r4_b;
sub r12_t r2_t r4_t;
(* uadd16	r2, r2, r4                               #! PC = 0x8005860 *)
add r2_b r2_b r4_b;
add r2_t r2_t r4_t;
(* smulbb	r4, r12, r10                             #! PC = 0x8005864 *)
mull r4_t r4_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005868 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r4, r11                              #! PC = 0x800586c *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x8005870 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x8005874 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x8005878 *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x800587c *)
mov tmp_t r4_t;
mov tmp_b lr_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* usub16	r12, r3, r5                              #! PC = 0x8005880 *)
sub r12_b r3_b r5_b;
sub r12_t r3_t r5_t;
(* uadd16	r3, r3, r5                               #! PC = 0x8005884 *)
add r3_b r3_b r5_b;
add r3_t r3_t r5_t;
(* smulbb	r5, r12, r10                             #! PC = 0x8005888 *)
mull r5_t r5_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x800588c *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r5, r11                              #! PC = 0x8005890 *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x8005894 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x8005898 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x800589c *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x80058a0 *)
mov tmp_t r5_t;
mov tmp_b lr_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* usub16	r12, r6, r8                              #! PC = 0x80058a4 *)
sub r12_b r6_b r8_b;
sub r12_t r6_t r8_t;
(* uadd16	r6, r6, r8                               #! PC = 0x80058a8 *)
add r6_b r6_b r8_b;
add r6_t r6_t r8_t;
(* smulbt	r8, r12, r10                             #! PC = 0x80058ac *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058b0 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r8, r11                              #! PC = 0x80058b4 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x80058b8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x80058bc *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x80058c0 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x80058c4 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r7, r9                              #! PC = 0x80058c8 *)
sub r12_b r7_b r9_b;
sub r12_t r7_t r9_t;
(* uadd16	r7, r7, r9                               #! PC = 0x80058cc *)
add r7_b r7_b r9_b;
add r7_t r7_t r9_t;
(* smulbt	r9, r12, r10                             #! PC = 0x80058d0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r10_t;
(* smultt	r12, r12, r10                            #! PC = 0x80058d4 *)
mull r12_t r12_b r12_t r10_t;
(* smulbt	lr, r9, r11                              #! PC = 0x80058d8 *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x80058dc *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x80058e0 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x80058e4 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x80058e8 *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* ldr.w	r10, [r1, #12]                            #! EA = L0x800e6d0; Value = 0x05a1078c; PC = 0x80058ec *)
mov r10_b L0x800e6d0;
mov r10_t L0x800e6d2;
(* usub16	r12, r2, r6                              #! PC = 0x80058f0 *)
sub r12_b r2_b r6_b;
sub r12_t r2_t r6_t;
(* uadd16	r2, r2, r6                               #! PC = 0x80058f4 *)
add r2_b r2_b r6_b;
add r2_t r2_t r6_t;
(* smulbb	r6, r12, r10                             #! PC = 0x80058f8 *)
mull r6_t r6_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x80058fc *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r6, r11                              #! PC = 0x8005900 *)
cast r6_sb@sint16 r6_b;
mull lr_t lr_b r6_sb r11_t;
(* smlabb	lr, r11, lr, r6                          #! PC = 0x8005904 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r6_b;
adc lr_t tmp_t r6_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r6, r12, r11                             #! PC = 0x8005908 *)
cast r12_sb@sint16 r12_b;
mull r6_t r6_b r12_sb r11_t;
(* smlabb	r6, r11, r6, r12                         #! PC = 0x800590c *)
cast r6_sb@sint16 r6_b;
mull tmp_t tmp_b r11_b r6_sb;
uadds carry r6_b tmp_b r12_b;
adc r6_t tmp_t r12_t carry;
assert eqmod r6_b 0 (2**16) && true;
assume r6_b = 0 && true;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x8005910 *)
mov tmp_t r6_t;
mov tmp_b lr_t;
mov r6_t tmp_t;
mov r6_b tmp_b;
(* usub16	r12, r3, r7                              #! PC = 0x8005914 *)
sub r12_b r3_b r7_b;
sub r12_t r3_t r7_t;
(* uadd16	r3, r3, r7                               #! PC = 0x8005918 *)
add r3_b r3_b r7_b;
add r3_t r3_t r7_t;
(* smulbb	r7, r12, r10                             #! PC = 0x800591c *)
mull r7_t r7_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005920 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r7, r11                              #! PC = 0x8005924 *)
cast r7_sb@sint16 r7_b;
mull lr_t lr_b r7_sb r11_t;
(* smlabb	lr, r11, lr, r7                          #! PC = 0x8005928 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r7_b;
adc lr_t tmp_t r7_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r7, r12, r11                             #! PC = 0x800592c *)
cast r12_sb@sint16 r12_b;
mull r7_t r7_b r12_sb r11_t;
(* smlabb	r7, r11, r7, r12                         #! PC = 0x8005930 *)
cast r7_sb@sint16 r7_b;
mull tmp_t tmp_b r11_b r7_sb;
uadds carry r7_b tmp_b r12_b;
adc r7_t tmp_t r12_t carry;
assert eqmod r7_b 0 (2**16) && true;
assume r7_b = 0 && true;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x8005934 *)
mov tmp_t r7_t;
mov tmp_b lr_t;
mov r7_t tmp_t;
mov r7_b tmp_b;
(* usub16	r12, r4, r8                              #! PC = 0x8005938 *)
sub r12_b r4_b r8_b;
sub r12_t r4_t r8_t;
(* uadd16	r4, r4, r8                               #! PC = 0x800593c *)
add r4_b r4_b r8_b;
add r4_t r4_t r8_t;
(* smulbb	r8, r12, r10                             #! PC = 0x8005940 *)
mull r8_t r8_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005944 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r8, r11                              #! PC = 0x8005948 *)
cast r8_sb@sint16 r8_b;
mull lr_t lr_b r8_sb r11_t;
(* smlabb	lr, r11, lr, r8                          #! PC = 0x800594c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r8_b;
adc lr_t tmp_t r8_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r8, r12, r11                             #! PC = 0x8005950 *)
cast r12_sb@sint16 r12_b;
mull r8_t r8_b r12_sb r11_t;
(* smlabb	r8, r11, r8, r12                         #! PC = 0x8005954 *)
cast r8_sb@sint16 r8_b;
mull tmp_t tmp_b r11_b r8_sb;
uadds carry r8_b tmp_b r12_b;
adc r8_t tmp_t r12_t carry;
assert eqmod r8_b 0 (2**16) && true;
assume r8_b = 0 && true;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x8005958 *)
mov tmp_t r8_t;
mov tmp_b lr_t;
mov r8_t tmp_t;
mov r8_b tmp_b;
(* usub16	r12, r5, r9                              #! PC = 0x800595c *)
sub r12_b r5_b r9_b;
sub r12_t r5_t r9_t;
(* uadd16	r5, r5, r9                               #! PC = 0x8005960 *)
add r5_b r5_b r9_b;
add r5_t r5_t r9_t;
(* smulbb	r9, r12, r10                             #! PC = 0x8005964 *)
mull r9_t r9_b r12_b r10_b;
(* smultb	r12, r12, r10                            #! PC = 0x8005968 *)
mull r12_t r12_b r12_t r10_b;
(* smulbt	lr, r9, r11                              #! PC = 0x800596c *)
cast r9_sb@sint16 r9_b;
mull lr_t lr_b r9_sb r11_t;
(* smlabb	lr, r11, lr, r9                          #! PC = 0x8005970 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r9_b;
adc lr_t tmp_t r9_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r9, r12, r11                             #! PC = 0x8005974 *)
cast r12_sb@sint16 r12_b;
mull r9_t r9_b r12_sb r11_t;
(* smlabb	r9, r11, r9, r12                         #! PC = 0x8005978 *)
cast r9_sb@sint16 r9_b;
mull tmp_t tmp_b r11_b r9_sb;
uadds carry r9_b tmp_b r12_b;
adc r9_t tmp_t r12_t carry;
assert eqmod r9_b 0 (2**16) && true;
assume r9_b = 0 && true;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x800597c *)
mov tmp_t r9_t;
mov tmp_b lr_t;
mov r9_t tmp_t;
mov r9_b tmp_b;
(* smulbt	r12, r2, r10                             #! PC = 0x8005980 *)
cast r2_sb@sint16 r2_b;
mull r12_t r12_b r2_sb r10_t;
(* smultt	r2, r2, r10                              #! PC = 0x8005984 *)
mull r2_t r2_b r2_t r10_t;
(* smulbt	lr, r2, r11                              #! PC = 0x8005988 *)
cast r2_sb@sint16 r2_b;
mull lr_t lr_b r2_sb r11_t;
(* smlabb	lr, r11, lr, r2                          #! PC = 0x800598c *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r2_b;
adc lr_t tmp_t r2_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r2, r12, r11                             #! PC = 0x8005990 *)
cast r12_sb@sint16 r12_b;
mull r2_t r2_b r12_sb r11_t;
(* smlabb	r2, r11, r2, r12                         #! PC = 0x8005994 *)
cast r2_sb@sint16 r2_b;
mull tmp_t tmp_b r11_b r2_sb;
uadds carry r2_b tmp_b r12_b;
adc r2_t tmp_t r12_t carry;
assert eqmod r2_b 0 (2**16) && true;
assume r2_b = 0 && true;
(* pkhtb	r2, lr, r2, asr #16                       #! PC = 0x8005998 *)
mov tmp_t lr_t;
mov tmp_b r2_t;
mov r2_t tmp_t;
mov r2_b tmp_b;
(* smulbt	r12, r3, r10                             #! PC = 0x800599c *)
cast r3_sb@sint16 r3_b;
mull r12_t r12_b r3_sb r10_t;
(* smultt	r3, r3, r10                              #! PC = 0x80059a0 *)
mull r3_t r3_b r3_t r10_t;
(* smulbt	lr, r3, r11                              #! PC = 0x80059a4 *)
cast r3_sb@sint16 r3_b;
mull lr_t lr_b r3_sb r11_t;
(* smlabb	lr, r11, lr, r3                          #! PC = 0x80059a8 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r3_b;
adc lr_t tmp_t r3_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r3, r12, r11                             #! PC = 0x80059ac *)
cast r12_sb@sint16 r12_b;
mull r3_t r3_b r12_sb r11_t;
(* smlabb	r3, r11, r3, r12                         #! PC = 0x80059b0 *)
cast r3_sb@sint16 r3_b;
mull tmp_t tmp_b r11_b r3_sb;
uadds carry r3_b tmp_b r12_b;
adc r3_t tmp_t r12_t carry;
assert eqmod r3_b 0 (2**16) && true;
assume r3_b = 0 && true;
(* pkhtb	r3, lr, r3, asr #16                       #! PC = 0x80059b4 *)
mov tmp_t lr_t;
mov tmp_b r3_t;
mov r3_t tmp_t;
mov r3_b tmp_b;
(* smulbt	r12, r4, r10                             #! PC = 0x80059b8 *)
cast r4_sb@sint16 r4_b;
mull r12_t r12_b r4_sb r10_t;
(* smultt	r4, r4, r10                              #! PC = 0x80059bc *)
mull r4_t r4_b r4_t r10_t;
(* smulbt	lr, r4, r11                              #! PC = 0x80059c0 *)
cast r4_sb@sint16 r4_b;
mull lr_t lr_b r4_sb r11_t;
(* smlabb	lr, r11, lr, r4                          #! PC = 0x80059c4 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r4_b;
adc lr_t tmp_t r4_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r4, r12, r11                             #! PC = 0x80059c8 *)
cast r12_sb@sint16 r12_b;
mull r4_t r4_b r12_sb r11_t;
(* smlabb	r4, r11, r4, r12                         #! PC = 0x80059cc *)
cast r4_sb@sint16 r4_b;
mull tmp_t tmp_b r11_b r4_sb;
uadds carry r4_b tmp_b r12_b;
adc r4_t tmp_t r12_t carry;
assert eqmod r4_b 0 (2**16) && true;
assume r4_b = 0 && true;
(* pkhtb	r4, lr, r4, asr #16                       #! PC = 0x80059d0 *)
mov tmp_t lr_t;
mov tmp_b r4_t;
mov r4_t tmp_t;
mov r4_b tmp_b;
(* smulbt	r12, r5, r10                             #! PC = 0x80059d4 *)
cast r5_sb@sint16 r5_b;
mull r12_t r12_b r5_sb r10_t;
(* smultt	r5, r5, r10                              #! PC = 0x80059d8 *)
mull r5_t r5_b r5_t r10_t;
(* smulbt	lr, r5, r11                              #! PC = 0x80059dc *)
cast r5_sb@sint16 r5_b;
mull lr_t lr_b r5_sb r11_t;
(* smlabb	lr, r11, lr, r5                          #! PC = 0x80059e0 *)
cast lr_sb@sint16 lr_b;
mull tmp_t tmp_b r11_b lr_sb;
uadds carry lr_b tmp_b r5_b;
adc lr_t tmp_t r5_t carry;
assert eqmod lr_b 0 (2**16) && true;
assume lr_b = 0 && true;
(* smulbt	r5, r12, r11                             #! PC = 0x80059e4 *)
cast r12_sb@sint16 r12_b;
mull r5_t r5_b r12_sb r11_t;
(* smlabb	r5, r11, r5, r12                         #! PC = 0x80059e8 *)
cast r5_sb@sint16 r5_b;
mull tmp_t tmp_b r11_b r5_sb;
uadds carry r5_b tmp_b r12_b;
adc r5_t tmp_t r12_t carry;
assert eqmod r5_b 0 (2**16) && true;
assume r5_b = 0 && true;
(* pkhtb	r5, lr, r5, asr #16                       #! PC = 0x80059ec *)
mov tmp_t lr_t;
mov tmp_b r5_t;
mov r5_t tmp_t;
mov r5_b tmp_b;
(* str.w	r6, [r0, #256]	; 0x100                    #! EA = L0x2001a66c; PC = 0x80059f0 *)
mov L0x2001a66c r6_b;
mov L0x2001a66e r6_t;
(* str.w	r7, [r0, #320]	; 0x140                    #! EA = L0x2001a6ac; PC = 0x80059f4 *)
mov L0x2001a6ac r7_b;
mov L0x2001a6ae r7_t;
(* str.w	r8, [r0, #384]	; 0x180                    #! EA = L0x2001a6ec; PC = 0x80059f8 *)
mov L0x2001a6ec r8_b;
mov L0x2001a6ee r8_t;
(* str.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0x2001a72c; PC = 0x80059fc *)
mov L0x2001a72c r9_b;
mov L0x2001a72e r9_t;
(* str.w	r3, [r0, #64]	; 0x40                      #! EA = L0x2001a5ac; PC = 0x8005a00 *)
mov L0x2001a5ac r3_b;
mov L0x2001a5ae r3_t;
(* str.w	r4, [r0, #128]	; 0x80                     #! EA = L0x2001a5ec; PC = 0x8005a04 *)
mov L0x2001a5ec r4_b;
mov L0x2001a5ee r4_t;
(* str.w	r5, [r0, #192]	; 0xc0                     #! EA = L0x2001a62c; PC = 0x8005a08 *)
mov L0x2001a62c r5_b;
mov L0x2001a62e r5_t;
(* str.w	r2, [r0], #4                              #! EA = L0x2001a56c; PC = 0x8005a0c *)
mov L0x2001a56c r2_b;
mov L0x2001a56e r2_t;
(* ldr.w	r12, [sp], #4                             #! EA = L0x2001a498; Value = 0x00000001; PC = 0x8005a10 *)
mov r12_b L0x2001a498;
mov r12_t L0x2001a49a;
(* subs.w	r12, r12, #1                             #! PC = 0x8005a14 *)
subs dontcare r12_b r12_b 1@sint16;
(* #bne.w	0x800579c <invntt_fast+1596>             #! PC = 0x8005a18 *)
#bne.w	0x800579c <invntt_fast+1596>             #! 0x8005a18 = 0x8005a18;
(* # END of layer 5+6+7 *)
# END of layer 5+6+7;

(* === layer 5+6+7 === *)
(* === post condition === *)
{
  (* algebraic *)
  and [
    (* inp_poly_0 *)
    eqmod 65536 * (inp_poly_0 * inp_poly_0)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 17],
    (* inp_poly_1 *)
    eqmod 65536 * (inp_poly_1 * inp_poly_1)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3312],
    (* inp_poly_2 *)
    eqmod 65536 * (inp_poly_2 * inp_poly_2)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2761],
    (* inp_poly_3 *)
    eqmod 65536 * (inp_poly_3 * inp_poly_3)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 568],
    (* inp_poly_4 *)
    eqmod 65536 * (inp_poly_4 * inp_poly_4)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 583],
    (* inp_poly_5 *)
    eqmod 65536 * (inp_poly_5 * inp_poly_5)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2746],
    (* inp_poly_6 *)
    eqmod 65536 * (inp_poly_6 * inp_poly_6)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2649],
    (* inp_poly_7 *)
    eqmod 65536 * (inp_poly_7 * inp_poly_7)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 680],
    (* inp_poly_8 *)
    eqmod 65536 * (inp_poly_8 * inp_poly_8)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1637],
    (* inp_poly_9 *)
    eqmod 65536 * (inp_poly_9 * inp_poly_9)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1692],
    (* inp_poly_10 *)
    eqmod 65536 * (inp_poly_10 * inp_poly_10)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 723],
    (* inp_poly_11 *)
    eqmod 65536 * (inp_poly_11 * inp_poly_11)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2606],
    (* inp_poly_12 *)
    eqmod 65536 * (inp_poly_12 * inp_poly_12)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2288],
    (* inp_poly_13 *)
    eqmod 65536 * (inp_poly_13 * inp_poly_13)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1041],
    (* inp_poly_14 *)
    eqmod 65536 * (inp_poly_14 * inp_poly_14)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1100],
    (* inp_poly_15 *)
    eqmod 65536 * (inp_poly_15 * inp_poly_15)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2229],
    (* inp_poly_16 *)
    eqmod 65536 * (inp_poly_16 * inp_poly_16)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1409],
    (* inp_poly_17 *)
    eqmod 65536 * (inp_poly_17 * inp_poly_17)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1920],
    (* inp_poly_18 *)
    eqmod 65536 * (inp_poly_18 * inp_poly_18)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2662],
    (* inp_poly_19 *)
    eqmod 65536 * (inp_poly_19 * inp_poly_19)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 667],
    (* inp_poly_20 *)
    eqmod 65536 * (inp_poly_20 * inp_poly_20)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3281],
    (* inp_poly_21 *)
    eqmod 65536 * (inp_poly_21 * inp_poly_21)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 48],
    (* inp_poly_22 *)
    eqmod 65536 * (inp_poly_22 * inp_poly_22)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 233],
    (* inp_poly_23 *)
    eqmod 65536 * (inp_poly_23 * inp_poly_23)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3096],
    (* inp_poly_24 *)
    eqmod 65536 * (inp_poly_24 * inp_poly_24)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 756],
    (* inp_poly_25 *)
    eqmod 65536 * (inp_poly_25 * inp_poly_25)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2573],
    (* inp_poly_26 *)
    eqmod 65536 * (inp_poly_26 * inp_poly_26)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2156],
    (* inp_poly_27 *)
    eqmod 65536 * (inp_poly_27 * inp_poly_27)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1173],
    (* inp_poly_28 *)
    eqmod 65536 * (inp_poly_28 * inp_poly_28)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3015],
    (* inp_poly_29 *)
    eqmod 65536 * (inp_poly_29 * inp_poly_29)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 314],
    (* inp_poly_30 *)
    eqmod 65536 * (inp_poly_30 * inp_poly_30)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3050],
    (* inp_poly_31 *)
    eqmod 65536 * (inp_poly_31 * inp_poly_31)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 279],
    (* inp_poly_32 *)
    eqmod 65536 * (inp_poly_32 * inp_poly_32)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1703],
    (* inp_poly_33 *)
    eqmod 65536 * (inp_poly_33 * inp_poly_33)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1626],
    (* inp_poly_34 *)
    eqmod 65536 * (inp_poly_34 * inp_poly_34)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1651],
    (* inp_poly_35 *)
    eqmod 65536 * (inp_poly_35 * inp_poly_35)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1678],
    (* inp_poly_36 *)
    eqmod 65536 * (inp_poly_36 * inp_poly_36)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2789],
    (* inp_poly_37 *)
    eqmod 65536 * (inp_poly_37 * inp_poly_37)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 540],
    (* inp_poly_38 *)
    eqmod 65536 * (inp_poly_38 * inp_poly_38)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1789],
    (* inp_poly_39 *)
    eqmod 65536 * (inp_poly_39 * inp_poly_39)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1540],
    (* inp_poly_40 *)
    eqmod 65536 * (inp_poly_40 * inp_poly_40)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1847],
    (* inp_poly_41 *)
    eqmod 65536 * (inp_poly_41 * inp_poly_41)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1482],
    (* inp_poly_42 *)
    eqmod 65536 * (inp_poly_42 * inp_poly_42)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 952],
    (* inp_poly_43 *)
    eqmod 65536 * (inp_poly_43 * inp_poly_43)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2377],
    (* inp_poly_44 *)
    eqmod 65536 * (inp_poly_44 * inp_poly_44)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1461],
    (* inp_poly_45 *)
    eqmod 65536 * (inp_poly_45 * inp_poly_45)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1868],
    (* inp_poly_46 *)
    eqmod 65536 * (inp_poly_46 * inp_poly_46)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2687],
    (* inp_poly_47 *)
    eqmod 65536 * (inp_poly_47 * inp_poly_47)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 642],
    (* inp_poly_48 *)
    eqmod 65536 * (inp_poly_48 * inp_poly_48)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 939],
    (* inp_poly_49 *)
    eqmod 65536 * (inp_poly_49 * inp_poly_49)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2390],
    (* inp_poly_50 *)
    eqmod 65536 * (inp_poly_50 * inp_poly_50)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2308],
    (* inp_poly_51 *)
    eqmod 65536 * (inp_poly_51 * inp_poly_51)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1021],
    (* inp_poly_52 *)
    eqmod 65536 * (inp_poly_52 * inp_poly_52)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2437],
    (* inp_poly_53 *)
    eqmod 65536 * (inp_poly_53 * inp_poly_53)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 892],
    (* inp_poly_54 *)
    eqmod 65536 * (inp_poly_54 * inp_poly_54)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2388],
    (* inp_poly_55 *)
    eqmod 65536 * (inp_poly_55 * inp_poly_55)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 941],
    (* inp_poly_56 *)
    eqmod 65536 * (inp_poly_56 * inp_poly_56)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 733],
    (* inp_poly_57 *)
    eqmod 65536 * (inp_poly_57 * inp_poly_57)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2596],
    (* inp_poly_58 *)
    eqmod 65536 * (inp_poly_58 * inp_poly_58)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2337],
    (* inp_poly_59 *)
    eqmod 65536 * (inp_poly_59 * inp_poly_59)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 992],
    (* inp_poly_60 *)
    eqmod 65536 * (inp_poly_60 * inp_poly_60)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 268],
    (* inp_poly_61 *)
    eqmod 65536 * (inp_poly_61 * inp_poly_61)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3061],
    (* inp_poly_62 *)
    eqmod 65536 * (inp_poly_62 * inp_poly_62)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 641],
    (* inp_poly_63 *)
    eqmod 65536 * (inp_poly_63 * inp_poly_63)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2688],
    (* inp_poly_64 *)
    eqmod 65536 * (inp_poly_64 * inp_poly_64)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1584],
    (* inp_poly_65 *)
    eqmod 65536 * (inp_poly_65 * inp_poly_65)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1745],
    (* inp_poly_66 *)
    eqmod 65536 * (inp_poly_66 * inp_poly_66)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2298],
    (* inp_poly_67 *)
    eqmod 65536 * (inp_poly_67 * inp_poly_67)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1031],
    (* inp_poly_68 *)
    eqmod 65536 * (inp_poly_68 * inp_poly_68)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2037],
    (* inp_poly_69 *)
    eqmod 65536 * (inp_poly_69 * inp_poly_69)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1292],
    (* inp_poly_70 *)
    eqmod 65536 * (inp_poly_70 * inp_poly_70)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3220],
    (* inp_poly_71 *)
    eqmod 65536 * (inp_poly_71 * inp_poly_71)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 109],
    (* inp_poly_72 *)
    eqmod 65536 * (inp_poly_72 * inp_poly_72)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 375],
    (* inp_poly_73 *)
    eqmod 65536 * (inp_poly_73 * inp_poly_73)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2954],
    (* inp_poly_74 *)
    eqmod 65536 * (inp_poly_74 * inp_poly_74)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2549],
    (* inp_poly_75 *)
    eqmod 65536 * (inp_poly_75 * inp_poly_75)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 780],
    (* inp_poly_76 *)
    eqmod 65536 * (inp_poly_76 * inp_poly_76)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2090],
    (* inp_poly_77 *)
    eqmod 65536 * (inp_poly_77 * inp_poly_77)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1239],
    (* inp_poly_78 *)
    eqmod 65536 * (inp_poly_78 * inp_poly_78)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1645],
    (* inp_poly_79 *)
    eqmod 65536 * (inp_poly_79 * inp_poly_79)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1684],
    (* inp_poly_80 *)
    eqmod 65536 * (inp_poly_80 * inp_poly_80)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1063],
    (* inp_poly_81 *)
    eqmod 65536 * (inp_poly_81 * inp_poly_81)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2266],
    (* inp_poly_82 *)
    eqmod 65536 * (inp_poly_82 * inp_poly_82)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 319],
    (* inp_poly_83 *)
    eqmod 65536 * (inp_poly_83 * inp_poly_83)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 3010],
    (* inp_poly_84 *)
    eqmod 65536 * (inp_poly_84 * inp_poly_84)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2773],
    (* inp_poly_85 *)
    eqmod 65536 * (inp_poly_85 * inp_poly_85)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 556],
    (* inp_poly_86 *)
    eqmod 65536 * (inp_poly_86 * inp_poly_86)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 757],
    (* inp_poly_87 *)
    eqmod 65536 * (inp_poly_87 * inp_poly_87)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2572],
    (* inp_poly_88 *)
    eqmod 65536 * (inp_poly_88 * inp_poly_88)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2099],
    (* inp_poly_89 *)
    eqmod 65536 * (inp_poly_89 * inp_poly_89)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1230],
    (* inp_poly_90 *)
    eqmod 65536 * (inp_poly_90 * inp_poly_90)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 561],
    (* inp_poly_91 *)
    eqmod 65536 * (inp_poly_91 * inp_poly_91)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2768],
    (* inp_poly_92 *)
    eqmod 65536 * (inp_poly_92 * inp_poly_92)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2466],
    (* inp_poly_93 *)
    eqmod 65536 * (inp_poly_93 * inp_poly_93)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 863],
    (* inp_poly_94 *)
    eqmod 65536 * (inp_poly_94 * inp_poly_94)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2594],
    (* inp_poly_95 *)
    eqmod 65536 * (inp_poly_95 * inp_poly_95)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 735],
    (* inp_poly_96 *)
    eqmod 65536 * (inp_poly_96 * inp_poly_96)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2804],
    (* inp_poly_97 *)
    eqmod 65536 * (inp_poly_97 * inp_poly_97)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 525],
    (* inp_poly_98 *)
    eqmod 65536 * (inp_poly_98 * inp_poly_98)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1092],
    (* inp_poly_99 *)
    eqmod 65536 * (inp_poly_99 * inp_poly_99)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2237],
    (* inp_poly_100 *)
    eqmod 65536 * (inp_poly_100 * inp_poly_100)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 403],
    (* inp_poly_101 *)
    eqmod 65536 * (inp_poly_101 * inp_poly_101)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2926],
    (* inp_poly_102 *)
    eqmod 65536 * (inp_poly_102 * inp_poly_102)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1026],
    (* inp_poly_103 *)
    eqmod 65536 * (inp_poly_103 * inp_poly_103)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2303],
    (* inp_poly_104 *)
    eqmod 65536 * (inp_poly_104 * inp_poly_104)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1143],
    (* inp_poly_105 *)
    eqmod 65536 * (inp_poly_105 * inp_poly_105)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2186],
    (* inp_poly_106 *)
    eqmod 65536 * (inp_poly_106 * inp_poly_106)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2150],
    (* inp_poly_107 *)
    eqmod 65536 * (inp_poly_107 * inp_poly_107)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1179],
    (* inp_poly_108 *)
    eqmod 65536 * (inp_poly_108 * inp_poly_108)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2775],
    (* inp_poly_109 *)
    eqmod 65536 * (inp_poly_109 * inp_poly_109)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 554],
    (* inp_poly_110 *)
    eqmod 65536 * (inp_poly_110 * inp_poly_110)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 886],
    (* inp_poly_111 *)
    eqmod 65536 * (inp_poly_111 * inp_poly_111)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2443],
    (* inp_poly_112 *)
    eqmod 65536 * (inp_poly_112 * inp_poly_112)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1722],
    (* inp_poly_113 *)
    eqmod 65536 * (inp_poly_113 * inp_poly_113)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1607],
    (* inp_poly_114 *)
    eqmod 65536 * (inp_poly_114 * inp_poly_114)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1212],
    (* inp_poly_115 *)
    eqmod 65536 * (inp_poly_115 * inp_poly_115)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2117],
    (* inp_poly_116 *)
    eqmod 65536 * (inp_poly_116 * inp_poly_116)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1874],
    (* inp_poly_117 *)
    eqmod 65536 * (inp_poly_117 * inp_poly_117)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1455],
    (* inp_poly_118 *)
    eqmod 65536 * (inp_poly_118 * inp_poly_118)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1029],
    (* inp_poly_119 *)
    eqmod 65536 * (inp_poly_119 * inp_poly_119)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2300],
    (* inp_poly_120 *)
    eqmod 65536 * (inp_poly_120 * inp_poly_120)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2110],
    (* inp_poly_121 *)
    eqmod 65536 * (inp_poly_121 * inp_poly_121)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1219],
    (* inp_poly_122 *)
    eqmod 65536 * (inp_poly_122 * inp_poly_122)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2935],
    (* inp_poly_123 *)
    eqmod 65536 * (inp_poly_123 * inp_poly_123)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 394],
    (* inp_poly_124 *)
    eqmod 65536 * (inp_poly_124 * inp_poly_124)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 885],
    (* inp_poly_125 *)
    eqmod 65536 * (inp_poly_125 * inp_poly_125)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2444],
    (* inp_poly_126 *)
    eqmod 65536 * (inp_poly_126 * inp_poly_126)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 2154],
    (* inp_poly_127 *)
    eqmod 65536 * (inp_poly_127 * inp_poly_127)
          (
            L0x2001a530 * (x**0) + L0x2001a532 * (x**1) + 
            L0x2001a534 * (x**2) + L0x2001a536 * (x**3) + 
            L0x2001a538 * (x**4) + L0x2001a53a * (x**5) + 
            L0x2001a53c * (x**6) + L0x2001a53e * (x**7) + 
            L0x2001a540 * (x**8) + L0x2001a542 * (x**9) + 
            L0x2001a544 * (x**10) + L0x2001a546 * (x**11) + 
            L0x2001a548 * (x**12) + L0x2001a54a * (x**13) + 
            L0x2001a54c * (x**14) + L0x2001a54e * (x**15) + 
            L0x2001a550 * (x**16) + L0x2001a552 * (x**17) + 
            L0x2001a554 * (x**18) + L0x2001a556 * (x**19) + 
            L0x2001a558 * (x**20) + L0x2001a55a * (x**21) + 
            L0x2001a55c * (x**22) + L0x2001a55e * (x**23) + 
            L0x2001a560 * (x**24) + L0x2001a562 * (x**25) + 
            L0x2001a564 * (x**26) + L0x2001a566 * (x**27) + 
            L0x2001a568 * (x**28) + L0x2001a56a * (x**29) + 
            L0x2001a56c * (x**30) + L0x2001a56e * (x**31) + 
            L0x2001a570 * (x**32) + L0x2001a572 * (x**33) + 
            L0x2001a574 * (x**34) + L0x2001a576 * (x**35) + 
            L0x2001a578 * (x**36) + L0x2001a57a * (x**37) + 
            L0x2001a57c * (x**38) + L0x2001a57e * (x**39) + 
            L0x2001a580 * (x**40) + L0x2001a582 * (x**41) + 
            L0x2001a584 * (x**42) + L0x2001a586 * (x**43) + 
            L0x2001a588 * (x**44) + L0x2001a58a * (x**45) + 
            L0x2001a58c * (x**46) + L0x2001a58e * (x**47) + 
            L0x2001a590 * (x**48) + L0x2001a592 * (x**49) + 
            L0x2001a594 * (x**50) + L0x2001a596 * (x**51) + 
            L0x2001a598 * (x**52) + L0x2001a59a * (x**53) + 
            L0x2001a59c * (x**54) + L0x2001a59e * (x**55) + 
            L0x2001a5a0 * (x**56) + L0x2001a5a2 * (x**57) + 
            L0x2001a5a4 * (x**58) + L0x2001a5a6 * (x**59) + 
            L0x2001a5a8 * (x**60) + L0x2001a5aa * (x**61) + 
            L0x2001a5ac * (x**62) + L0x2001a5ae * (x**63) + 
            L0x2001a5b0 * (x**64) + L0x2001a5b2 * (x**65) + 
            L0x2001a5b4 * (x**66) + L0x2001a5b6 * (x**67) + 
            L0x2001a5b8 * (x**68) + L0x2001a5ba * (x**69) + 
            L0x2001a5bc * (x**70) + L0x2001a5be * (x**71) + 
            L0x2001a5c0 * (x**72) + L0x2001a5c2 * (x**73) + 
            L0x2001a5c4 * (x**74) + L0x2001a5c6 * (x**75) + 
            L0x2001a5c8 * (x**76) + L0x2001a5ca * (x**77) + 
            L0x2001a5cc * (x**78) + L0x2001a5ce * (x**79) + 
            L0x2001a5d0 * (x**80) + L0x2001a5d2 * (x**81) + 
            L0x2001a5d4 * (x**82) + L0x2001a5d6 * (x**83) + 
            L0x2001a5d8 * (x**84) + L0x2001a5da * (x**85) + 
            L0x2001a5dc * (x**86) + L0x2001a5de * (x**87) + 
            L0x2001a5e0 * (x**88) + L0x2001a5e2 * (x**89) + 
            L0x2001a5e4 * (x**90) + L0x2001a5e6 * (x**91) + 
            L0x2001a5e8 * (x**92) + L0x2001a5ea * (x**93) + 
            L0x2001a5ec * (x**94) + L0x2001a5ee * (x**95) + 
            L0x2001a5f0 * (x**96) + L0x2001a5f2 * (x**97) + 
            L0x2001a5f4 * (x**98) + L0x2001a5f6 * (x**99) + 
            L0x2001a5f8 * (x**100) + L0x2001a5fa * (x**101) + 
            L0x2001a5fc * (x**102) + L0x2001a5fe * (x**103) + 
            L0x2001a600 * (x**104) + L0x2001a602 * (x**105) + 
            L0x2001a604 * (x**106) + L0x2001a606 * (x**107) + 
            L0x2001a608 * (x**108) + L0x2001a60a * (x**109) + 
            L0x2001a60c * (x**110) + L0x2001a60e * (x**111) + 
            L0x2001a610 * (x**112) + L0x2001a612 * (x**113) + 
            L0x2001a614 * (x**114) + L0x2001a616 * (x**115) + 
            L0x2001a618 * (x**116) + L0x2001a61a * (x**117) + 
            L0x2001a61c * (x**118) + L0x2001a61e * (x**119) + 
            L0x2001a620 * (x**120) + L0x2001a622 * (x**121) + 
            L0x2001a624 * (x**122) + L0x2001a626 * (x**123) + 
            L0x2001a628 * (x**124) + L0x2001a62a * (x**125) + 
            L0x2001a62c * (x**126) + L0x2001a62e * (x**127) + 
            L0x2001a630 * (x**128) + L0x2001a632 * (x**129) + 
            L0x2001a634 * (x**130) + L0x2001a636 * (x**131) + 
            L0x2001a638 * (x**132) + L0x2001a63a * (x**133) + 
            L0x2001a63c * (x**134) + L0x2001a63e * (x**135) + 
            L0x2001a640 * (x**136) + L0x2001a642 * (x**137) + 
            L0x2001a644 * (x**138) + L0x2001a646 * (x**139) + 
            L0x2001a648 * (x**140) + L0x2001a64a * (x**141) + 
            L0x2001a64c * (x**142) + L0x2001a64e * (x**143) + 
            L0x2001a650 * (x**144) + L0x2001a652 * (x**145) + 
            L0x2001a654 * (x**146) + L0x2001a656 * (x**147) + 
            L0x2001a658 * (x**148) + L0x2001a65a * (x**149) + 
            L0x2001a65c * (x**150) + L0x2001a65e * (x**151) + 
            L0x2001a660 * (x**152) + L0x2001a662 * (x**153) + 
            L0x2001a664 * (x**154) + L0x2001a666 * (x**155) + 
            L0x2001a668 * (x**156) + L0x2001a66a * (x**157) + 
            L0x2001a66c * (x**158) + L0x2001a66e * (x**159) + 
            L0x2001a670 * (x**160) + L0x2001a672 * (x**161) + 
            L0x2001a674 * (x**162) + L0x2001a676 * (x**163) + 
            L0x2001a678 * (x**164) + L0x2001a67a * (x**165) + 
            L0x2001a67c * (x**166) + L0x2001a67e * (x**167) + 
            L0x2001a680 * (x**168) + L0x2001a682 * (x**169) + 
            L0x2001a684 * (x**170) + L0x2001a686 * (x**171) + 
            L0x2001a688 * (x**172) + L0x2001a68a * (x**173) + 
            L0x2001a68c * (x**174) + L0x2001a68e * (x**175) + 
            L0x2001a690 * (x**176) + L0x2001a692 * (x**177) + 
            L0x2001a694 * (x**178) + L0x2001a696 * (x**179) + 
            L0x2001a698 * (x**180) + L0x2001a69a * (x**181) + 
            L0x2001a69c * (x**182) + L0x2001a69e * (x**183) + 
            L0x2001a6a0 * (x**184) + L0x2001a6a2 * (x**185) + 
            L0x2001a6a4 * (x**186) + L0x2001a6a6 * (x**187) + 
            L0x2001a6a8 * (x**188) + L0x2001a6aa * (x**189) + 
            L0x2001a6ac * (x**190) + L0x2001a6ae * (x**191) + 
            L0x2001a6b0 * (x**192) + L0x2001a6b2 * (x**193) + 
            L0x2001a6b4 * (x**194) + L0x2001a6b6 * (x**195) + 
            L0x2001a6b8 * (x**196) + L0x2001a6ba * (x**197) + 
            L0x2001a6bc * (x**198) + L0x2001a6be * (x**199) + 
            L0x2001a6c0 * (x**200) + L0x2001a6c2 * (x**201) + 
            L0x2001a6c4 * (x**202) + L0x2001a6c6 * (x**203) + 
            L0x2001a6c8 * (x**204) + L0x2001a6ca * (x**205) + 
            L0x2001a6cc * (x**206) + L0x2001a6ce * (x**207) + 
            L0x2001a6d0 * (x**208) + L0x2001a6d2 * (x**209) + 
            L0x2001a6d4 * (x**210) + L0x2001a6d6 * (x**211) + 
            L0x2001a6d8 * (x**212) + L0x2001a6da * (x**213) + 
            L0x2001a6dc * (x**214) + L0x2001a6de * (x**215) + 
            L0x2001a6e0 * (x**216) + L0x2001a6e2 * (x**217) + 
            L0x2001a6e4 * (x**218) + L0x2001a6e6 * (x**219) + 
            L0x2001a6e8 * (x**220) + L0x2001a6ea * (x**221) + 
            L0x2001a6ec * (x**222) + L0x2001a6ee * (x**223) + 
            L0x2001a6f0 * (x**224) + L0x2001a6f2 * (x**225) + 
            L0x2001a6f4 * (x**226) + L0x2001a6f6 * (x**227) + 
            L0x2001a6f8 * (x**228) + L0x2001a6fa * (x**229) + 
            L0x2001a6fc * (x**230) + L0x2001a6fe * (x**231) + 
            L0x2001a700 * (x**232) + L0x2001a702 * (x**233) + 
            L0x2001a704 * (x**234) + L0x2001a706 * (x**235) + 
            L0x2001a708 * (x**236) + L0x2001a70a * (x**237) + 
            L0x2001a70c * (x**238) + L0x2001a70e * (x**239) + 
            L0x2001a710 * (x**240) + L0x2001a712 * (x**241) + 
            L0x2001a714 * (x**242) + L0x2001a716 * (x**243) + 
            L0x2001a718 * (x**244) + L0x2001a71a * (x**245) + 
            L0x2001a71c * (x**246) + L0x2001a71e * (x**247) + 
            L0x2001a720 * (x**248) + L0x2001a722 * (x**249) + 
            L0x2001a724 * (x**250) + L0x2001a726 * (x**251) + 
            L0x2001a728 * (x**252) + L0x2001a72a * (x**253) + 
            L0x2001a72c * (x**254) + L0x2001a72e * (x**255)
          )
          [3329, x**2 - 1175]
  ]
  &&
  (* range *)
  and [
    1@16 * (-3329)@16 <=s L0x2001a530, L0x2001a530 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a532, L0x2001a532 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a534, L0x2001a534 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a536, L0x2001a536 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a538, L0x2001a538 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53a, L0x2001a53a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53c, L0x2001a53c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a53e, L0x2001a53e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a540, L0x2001a540 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a542, L0x2001a542 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a544, L0x2001a544 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a546, L0x2001a546 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a548, L0x2001a548 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54a, L0x2001a54a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54c, L0x2001a54c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a54e, L0x2001a54e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a550, L0x2001a550 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a552, L0x2001a552 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a554, L0x2001a554 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a556, L0x2001a556 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a558, L0x2001a558 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55a, L0x2001a55a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55c, L0x2001a55c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a55e, L0x2001a55e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a560, L0x2001a560 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a562, L0x2001a562 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a564, L0x2001a564 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a566, L0x2001a566 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a568, L0x2001a568 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56a, L0x2001a56a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56c, L0x2001a56c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a56e, L0x2001a56e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a570, L0x2001a570 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a572, L0x2001a572 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a574, L0x2001a574 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a576, L0x2001a576 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a578, L0x2001a578 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57a, L0x2001a57a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57c, L0x2001a57c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a57e, L0x2001a57e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a580, L0x2001a580 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a582, L0x2001a582 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a584, L0x2001a584 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a586, L0x2001a586 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a588, L0x2001a588 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58a, L0x2001a58a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58c, L0x2001a58c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a58e, L0x2001a58e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a590, L0x2001a590 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a592, L0x2001a592 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a594, L0x2001a594 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a596, L0x2001a596 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a598, L0x2001a598 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59a, L0x2001a59a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59c, L0x2001a59c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a59e, L0x2001a59e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a0, L0x2001a5a0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a2, L0x2001a5a2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a4, L0x2001a5a4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a6, L0x2001a5a6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5a8, L0x2001a5a8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5aa, L0x2001a5aa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ac, L0x2001a5ac <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ae, L0x2001a5ae <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b0, L0x2001a5b0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b2, L0x2001a5b2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b4, L0x2001a5b4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b6, L0x2001a5b6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5b8, L0x2001a5b8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ba, L0x2001a5ba <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5bc, L0x2001a5bc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5be, L0x2001a5be <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c0, L0x2001a5c0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c2, L0x2001a5c2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c4, L0x2001a5c4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c6, L0x2001a5c6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5c8, L0x2001a5c8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ca, L0x2001a5ca <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5cc, L0x2001a5cc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ce, L0x2001a5ce <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d0, L0x2001a5d0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d2, L0x2001a5d2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d4, L0x2001a5d4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d6, L0x2001a5d6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5d8, L0x2001a5d8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5da, L0x2001a5da <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5dc, L0x2001a5dc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5de, L0x2001a5de <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e0, L0x2001a5e0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e2, L0x2001a5e2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e4, L0x2001a5e4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e6, L0x2001a5e6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5e8, L0x2001a5e8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ea, L0x2001a5ea <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ec, L0x2001a5ec <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5ee, L0x2001a5ee <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f0, L0x2001a5f0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f2, L0x2001a5f2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f4, L0x2001a5f4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f6, L0x2001a5f6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5f8, L0x2001a5f8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fa, L0x2001a5fa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fc, L0x2001a5fc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a5fe, L0x2001a5fe <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a600, L0x2001a600 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a602, L0x2001a602 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a604, L0x2001a604 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a606, L0x2001a606 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a608, L0x2001a608 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60a, L0x2001a60a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60c, L0x2001a60c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a60e, L0x2001a60e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a610, L0x2001a610 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a612, L0x2001a612 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a614, L0x2001a614 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a616, L0x2001a616 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a618, L0x2001a618 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61a, L0x2001a61a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61c, L0x2001a61c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a61e, L0x2001a61e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a620, L0x2001a620 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a622, L0x2001a622 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a624, L0x2001a624 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a626, L0x2001a626 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a628, L0x2001a628 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62a, L0x2001a62a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62c, L0x2001a62c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a62e, L0x2001a62e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a630, L0x2001a630 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a632, L0x2001a632 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a634, L0x2001a634 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a636, L0x2001a636 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a638, L0x2001a638 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63a, L0x2001a63a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63c, L0x2001a63c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a63e, L0x2001a63e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a640, L0x2001a640 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a642, L0x2001a642 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a644, L0x2001a644 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a646, L0x2001a646 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a648, L0x2001a648 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64a, L0x2001a64a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64c, L0x2001a64c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a64e, L0x2001a64e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a650, L0x2001a650 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a652, L0x2001a652 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a654, L0x2001a654 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a656, L0x2001a656 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a658, L0x2001a658 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65a, L0x2001a65a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65c, L0x2001a65c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a65e, L0x2001a65e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a660, L0x2001a660 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a662, L0x2001a662 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a664, L0x2001a664 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a666, L0x2001a666 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a668, L0x2001a668 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66a, L0x2001a66a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66c, L0x2001a66c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a66e, L0x2001a66e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a670, L0x2001a670 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a672, L0x2001a672 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a674, L0x2001a674 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a676, L0x2001a676 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a678, L0x2001a678 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67a, L0x2001a67a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67c, L0x2001a67c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a67e, L0x2001a67e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a680, L0x2001a680 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a682, L0x2001a682 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a684, L0x2001a684 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a686, L0x2001a686 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a688, L0x2001a688 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68a, L0x2001a68a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68c, L0x2001a68c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a68e, L0x2001a68e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a690, L0x2001a690 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a692, L0x2001a692 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a694, L0x2001a694 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a696, L0x2001a696 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a698, L0x2001a698 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69a, L0x2001a69a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69c, L0x2001a69c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a69e, L0x2001a69e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a0, L0x2001a6a0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a2, L0x2001a6a2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a4, L0x2001a6a4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a6, L0x2001a6a6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6a8, L0x2001a6a8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6aa, L0x2001a6aa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ac, L0x2001a6ac <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ae, L0x2001a6ae <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b0, L0x2001a6b0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b2, L0x2001a6b2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b4, L0x2001a6b4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b6, L0x2001a6b6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6b8, L0x2001a6b8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ba, L0x2001a6ba <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6bc, L0x2001a6bc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6be, L0x2001a6be <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c0, L0x2001a6c0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c2, L0x2001a6c2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c4, L0x2001a6c4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c6, L0x2001a6c6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6c8, L0x2001a6c8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ca, L0x2001a6ca <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6cc, L0x2001a6cc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ce, L0x2001a6ce <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d0, L0x2001a6d0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d2, L0x2001a6d2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d4, L0x2001a6d4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d6, L0x2001a6d6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6d8, L0x2001a6d8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6da, L0x2001a6da <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6dc, L0x2001a6dc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6de, L0x2001a6de <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e0, L0x2001a6e0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e2, L0x2001a6e2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e4, L0x2001a6e4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e6, L0x2001a6e6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6e8, L0x2001a6e8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ea, L0x2001a6ea <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ec, L0x2001a6ec <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6ee, L0x2001a6ee <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f0, L0x2001a6f0 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f2, L0x2001a6f2 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f4, L0x2001a6f4 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f6, L0x2001a6f6 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6f8, L0x2001a6f8 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fa, L0x2001a6fa <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fc, L0x2001a6fc <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a6fe, L0x2001a6fe <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a700, L0x2001a700 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a702, L0x2001a702 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a704, L0x2001a704 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a706, L0x2001a706 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a708, L0x2001a708 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70a, L0x2001a70a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70c, L0x2001a70c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a70e, L0x2001a70e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a710, L0x2001a710 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a712, L0x2001a712 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a714, L0x2001a714 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a716, L0x2001a716 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a718, L0x2001a718 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71a, L0x2001a71a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71c, L0x2001a71c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a71e, L0x2001a71e <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a720, L0x2001a720 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a722, L0x2001a722 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a724, L0x2001a724 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a726, L0x2001a726 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a728, L0x2001a728 <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72a, L0x2001a72a <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72c, L0x2001a72c <s 1@16 * 3329@16,
    1@16 * (-3329)@16 <=s L0x2001a72e, L0x2001a72e <s 1@16 * 3329@16
  ]
}


