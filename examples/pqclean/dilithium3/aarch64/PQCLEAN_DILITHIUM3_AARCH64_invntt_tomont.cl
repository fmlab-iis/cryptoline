(* quine: cv.exe -v -slicing -isafety -vo lex -jobs 40 -enable_rewriting:eqmod PQCLEAN_DILITHIUM3_AARCH64_invntt_tomont.cl
Parsing CryptoLine file:                    [OK]            0.3058 seconds
Checking well-formedness:                   [OK]            0.0886 seconds

Procedure main
--------------
Transforming to SSA form:                   [OK]            0.0816 seconds
Normalizing specification:                  [OK]            0.0698 seconds
Rewriting assignments:                      [OK]            0.0916 seconds
Verifying program safety:                   [OK]            162.9998 seconds
Verifying range assertions:                 [OK]            2.3695 seconds
Verifying range specification:              [OK]            9.2182 seconds
Rewriting value-preserved casting:          [OK]            0.0255 seconds
Verifying algebraic assertions:             [OK]            170.4136 seconds
Verifying algebraic specification:          [OK]            22.1666 seconds
Procedure verification:                     [OK]            367.4720 seconds

Summary
-------
Verification result:                        [OK]            367.8680 seconds
*)

proc main (
int32 L0xffffffff0610,int32 L0xffffffff0614,int32 L0xffffffff0618,
int32 L0xffffffff061c,int32 L0xffffffff0620,int32 L0xffffffff0624,
int32 L0xffffffff0628,int32 L0xffffffff062c,int32 L0xffffffff0630,
int32 L0xffffffff0634,int32 L0xffffffff0638,int32 L0xffffffff063c,
int32 L0xffffffff0640,int32 L0xffffffff0644,int32 L0xffffffff0648,
int32 L0xffffffff064c,int32 L0xffffffff0650,int32 L0xffffffff0654,
int32 L0xffffffff0658,int32 L0xffffffff065c,int32 L0xffffffff0660,
int32 L0xffffffff0664,int32 L0xffffffff0668,int32 L0xffffffff066c,
int32 L0xffffffff0670,int32 L0xffffffff0674,int32 L0xffffffff0678,
int32 L0xffffffff067c,int32 L0xffffffff0680,int32 L0xffffffff0684,
int32 L0xffffffff0688,int32 L0xffffffff068c,int32 L0xffffffff0690,
int32 L0xffffffff0694,int32 L0xffffffff0698,int32 L0xffffffff069c,
int32 L0xffffffff06a0,int32 L0xffffffff06a4,int32 L0xffffffff06a8,
int32 L0xffffffff06ac,int32 L0xffffffff06b0,int32 L0xffffffff06b4,
int32 L0xffffffff06b8,int32 L0xffffffff06bc,int32 L0xffffffff06c0,
int32 L0xffffffff06c4,int32 L0xffffffff06c8,int32 L0xffffffff06cc,
int32 L0xffffffff06d0,int32 L0xffffffff06d4,int32 L0xffffffff06d8,
int32 L0xffffffff06dc,int32 L0xffffffff06e0,int32 L0xffffffff06e4,
int32 L0xffffffff06e8,int32 L0xffffffff06ec,int32 L0xffffffff06f0,
int32 L0xffffffff06f4,int32 L0xffffffff06f8,int32 L0xffffffff06fc,
int32 L0xffffffff0700,int32 L0xffffffff0704,int32 L0xffffffff0708,
int32 L0xffffffff070c,int32 L0xffffffff0710,int32 L0xffffffff0714,
int32 L0xffffffff0718,int32 L0xffffffff071c,int32 L0xffffffff0720,
int32 L0xffffffff0724,int32 L0xffffffff0728,int32 L0xffffffff072c,
int32 L0xffffffff0730,int32 L0xffffffff0734,int32 L0xffffffff0738,
int32 L0xffffffff073c,int32 L0xffffffff0740,int32 L0xffffffff0744,
int32 L0xffffffff0748,int32 L0xffffffff074c,int32 L0xffffffff0750,
int32 L0xffffffff0754,int32 L0xffffffff0758,int32 L0xffffffff075c,
int32 L0xffffffff0760,int32 L0xffffffff0764,int32 L0xffffffff0768,
int32 L0xffffffff076c,int32 L0xffffffff0770,int32 L0xffffffff0774,
int32 L0xffffffff0778,int32 L0xffffffff077c,int32 L0xffffffff0780,
int32 L0xffffffff0784,int32 L0xffffffff0788,int32 L0xffffffff078c,
int32 L0xffffffff0790,int32 L0xffffffff0794,int32 L0xffffffff0798,
int32 L0xffffffff079c,int32 L0xffffffff07a0,int32 L0xffffffff07a4,
int32 L0xffffffff07a8,int32 L0xffffffff07ac,int32 L0xffffffff07b0,
int32 L0xffffffff07b4,int32 L0xffffffff07b8,int32 L0xffffffff07bc,
int32 L0xffffffff07c0,int32 L0xffffffff07c4,int32 L0xffffffff07c8,
int32 L0xffffffff07cc,int32 L0xffffffff07d0,int32 L0xffffffff07d4,
int32 L0xffffffff07d8,int32 L0xffffffff07dc,int32 L0xffffffff07e0,
int32 L0xffffffff07e4,int32 L0xffffffff07e8,int32 L0xffffffff07ec,
int32 L0xffffffff07f0,int32 L0xffffffff07f4,int32 L0xffffffff07f8,
int32 L0xffffffff07fc,int32 L0xffffffff0800,int32 L0xffffffff0804,
int32 L0xffffffff0808,int32 L0xffffffff080c,int32 L0xffffffff0810,
int32 L0xffffffff0814,int32 L0xffffffff0818,int32 L0xffffffff081c,
int32 L0xffffffff0820,int32 L0xffffffff0824,int32 L0xffffffff0828,
int32 L0xffffffff082c,int32 L0xffffffff0830,int32 L0xffffffff0834,
int32 L0xffffffff0838,int32 L0xffffffff083c,int32 L0xffffffff0840,
int32 L0xffffffff0844,int32 L0xffffffff0848,int32 L0xffffffff084c,
int32 L0xffffffff0850,int32 L0xffffffff0854,int32 L0xffffffff0858,
int32 L0xffffffff085c,int32 L0xffffffff0860,int32 L0xffffffff0864,
int32 L0xffffffff0868,int32 L0xffffffff086c,int32 L0xffffffff0870,
int32 L0xffffffff0874,int32 L0xffffffff0878,int32 L0xffffffff087c,
int32 L0xffffffff0880,int32 L0xffffffff0884,int32 L0xffffffff0888,
int32 L0xffffffff088c,int32 L0xffffffff0890,int32 L0xffffffff0894,
int32 L0xffffffff0898,int32 L0xffffffff089c,int32 L0xffffffff08a0,
int32 L0xffffffff08a4,int32 L0xffffffff08a8,int32 L0xffffffff08ac,
int32 L0xffffffff08b0,int32 L0xffffffff08b4,int32 L0xffffffff08b8,
int32 L0xffffffff08bc,int32 L0xffffffff08c0,int32 L0xffffffff08c4,
int32 L0xffffffff08c8,int32 L0xffffffff08cc,int32 L0xffffffff08d0,
int32 L0xffffffff08d4,int32 L0xffffffff08d8,int32 L0xffffffff08dc,
int32 L0xffffffff08e0,int32 L0xffffffff08e4,int32 L0xffffffff08e8,
int32 L0xffffffff08ec,int32 L0xffffffff08f0,int32 L0xffffffff08f4,
int32 L0xffffffff08f8,int32 L0xffffffff08fc,int32 L0xffffffff0900,
int32 L0xffffffff0904,int32 L0xffffffff0908,int32 L0xffffffff090c,
int32 L0xffffffff0910,int32 L0xffffffff0914,int32 L0xffffffff0918,
int32 L0xffffffff091c,int32 L0xffffffff0920,int32 L0xffffffff0924,
int32 L0xffffffff0928,int32 L0xffffffff092c,int32 L0xffffffff0930,
int32 L0xffffffff0934,int32 L0xffffffff0938,int32 L0xffffffff093c,
int32 L0xffffffff0940,int32 L0xffffffff0944,int32 L0xffffffff0948,
int32 L0xffffffff094c,int32 L0xffffffff0950,int32 L0xffffffff0954,
int32 L0xffffffff0958,int32 L0xffffffff095c,int32 L0xffffffff0960,
int32 L0xffffffff0964,int32 L0xffffffff0968,int32 L0xffffffff096c,
int32 L0xffffffff0970,int32 L0xffffffff0974,int32 L0xffffffff0978,
int32 L0xffffffff097c,int32 L0xffffffff0980,int32 L0xffffffff0984,
int32 L0xffffffff0988,int32 L0xffffffff098c,int32 L0xffffffff0990,
int32 L0xffffffff0994,int32 L0xffffffff0998,int32 L0xffffffff099c,
int32 L0xffffffff09a0,int32 L0xffffffff09a4,int32 L0xffffffff09a8,
int32 L0xffffffff09ac,int32 L0xffffffff09b0,int32 L0xffffffff09b4,
int32 L0xffffffff09b8,int32 L0xffffffff09bc,int32 L0xffffffff09c0,
int32 L0xffffffff09c4,int32 L0xffffffff09c8,int32 L0xffffffff09cc,
int32 L0xffffffff09d0,int32 L0xffffffff09d4,int32 L0xffffffff09d8,
int32 L0xffffffff09dc,int32 L0xffffffff09e0,int32 L0xffffffff09e4,
int32 L0xffffffff09e8,int32 L0xffffffff09ec,int32 L0xffffffff09f0,
int32 L0xffffffff09f4,int32 L0xffffffff09f8,int32 L0xffffffff09fc,
int32 L0xffffffff0a00,int32 L0xffffffff0a04,int32 L0xffffffff0a08,
int32 L0xffffffff0a0c,
int32 A00,int32 A01,int32 A02,int32 A03,int32 A04,int32 A05,int32 A06,
int32 A07,int32 A08,int32 A09,int32 A0a,int32 A0b,int32 A0c,int32 A0d,
int32 A0e,int32 A0f,int32 A10,int32 A11,int32 A12,int32 A13,int32 A14,
int32 A15,int32 A16,int32 A17,int32 A18,int32 A19,int32 A1a,int32 A1b,
int32 A1c,int32 A1d,int32 A1e,int32 A1f,int32 A20,int32 A21,int32 A22,
int32 A23,int32 A24,int32 A25,int32 A26,int32 A27,int32 A28,int32 A29,
int32 A2a,int32 A2b,int32 A2c,int32 A2d,int32 A2e,int32 A2f,int32 A30,
int32 A31,int32 A32,int32 A33,int32 A34,int32 A35,int32 A36,int32 A37,
int32 A38,int32 A39,int32 A3a,int32 A3b,int32 A3c,int32 A3d,int32 A3e,
int32 A3f,int32 A40,int32 A41,int32 A42,int32 A43,int32 A44,int32 A45,
int32 A46,int32 A47,int32 A48,int32 A49,int32 A4a,int32 A4b,int32 A4c,
int32 A4d,int32 A4e,int32 A4f,int32 A50,int32 A51,int32 A52,int32 A53,
int32 A54,int32 A55,int32 A56,int32 A57,int32 A58,int32 A59,int32 A5a,
int32 A5b,int32 A5c,int32 A5d,int32 A5e,int32 A5f,int32 A60,int32 A61,
int32 A62,int32 A63,int32 A64,int32 A65,int32 A66,int32 A67,int32 A68,
int32 A69,int32 A6a,int32 A6b,int32 A6c,int32 A6d,int32 A6e,int32 A6f,
int32 A70,int32 A71,int32 A72,int32 A73,int32 A74,int32 A75,int32 A76,
int32 A77,int32 A78,int32 A79,int32 A7a,int32 A7b,int32 A7c,int32 A7d,
int32 A7e,int32 A7f,int32 A80,int32 A81,int32 A82,int32 A83,int32 A84,
int32 A85,int32 A86,int32 A87,int32 A88,int32 A89,int32 A8a,int32 A8b,
int32 A8c,int32 A8d,int32 A8e,int32 A8f,int32 A90,int32 A91,int32 A92,
int32 A93,int32 A94,int32 A95,int32 A96,int32 A97,int32 A98,int32 A99,
int32 A9a,int32 A9b,int32 A9c,int32 A9d,int32 A9e,int32 A9f,int32 Aa0,
int32 Aa1,int32 Aa2,int32 Aa3,int32 Aa4,int32 Aa5,int32 Aa6,int32 Aa7,
int32 Aa8,int32 Aa9,int32 Aaa,int32 Aab,int32 Aac,int32 Aad,int32 Aae,
int32 Aaf,int32 Ab0,int32 Ab1,int32 Ab2,int32 Ab3,int32 Ab4,int32 Ab5,
int32 Ab6,int32 Ab7,int32 Ab8,int32 Ab9,int32 Aba,int32 Abb,int32 Abc,
int32 Abd,int32 Abe,int32 Abf,int32 Ac0,int32 Ac1,int32 Ac2,int32 Ac3,
int32 Ac4,int32 Ac5,int32 Ac6,int32 Ac7,int32 Ac8,int32 Ac9,int32 Aca,
int32 Acb,int32 Acc,int32 Acd,int32 Ace,int32 Acf,int32 Ad0,int32 Ad1,
int32 Ad2,int32 Ad3,int32 Ad4,int32 Ad5,int32 Ad6,int32 Ad7,int32 Ad8,
int32 Ad9,int32 Ada,int32 Adb,int32 Adc,int32 Add,int32 Ade,int32 Adf,
int32 Ae0,int32 Ae1,int32 Ae2,int32 Ae3,int32 Ae4,int32 Ae5,int32 Ae6,
int32 Ae7,int32 Ae8,int32 Ae9,int32 Aea,int32 Aeb,int32 Aec,int32 Aed,
int32 Aee,int32 Aef,int32 Af0,int32 Af1,int32 Af2,int32 Af3,int32 Af4,
int32 Af5,int32 Af6,int32 Af7,int32 Af8,int32 Af9,int32 Afa,int32 Afb,
int32 Afc,int32 Afd,int32 Afe,int32 Aff,
int32 Q, int32 Q2, int32 NQ, int32 NQ2, int32 X,
int32 F
) =
{
Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
eqmod (F**2) L0xffffffff0610 [Q, X - 1753**  1] /\
eqmod (F**2) L0xffffffff0614 [Q, X - 1753**257] /\
eqmod (F**2) L0xffffffff0618 [Q, X - 1753**129] /\
eqmod (F**2) L0xffffffff061c [Q, X - 1753**385] /\
eqmod (F**2) L0xffffffff0620 [Q, X - 1753** 65] /\
eqmod (F**2) L0xffffffff0624 [Q, X - 1753**321] /\
eqmod (F**2) L0xffffffff0628 [Q, X - 1753**193] /\
eqmod (F**2) L0xffffffff062c [Q, X - 1753**449] /\
eqmod (F**2) L0xffffffff0630 [Q, X - 1753** 33] /\
eqmod (F**2) L0xffffffff0634 [Q, X - 1753**289] /\
eqmod (F**2) L0xffffffff0638 [Q, X - 1753**161] /\
eqmod (F**2) L0xffffffff063c [Q, X - 1753**417] /\
eqmod (F**2) L0xffffffff0640 [Q, X - 1753** 97] /\
eqmod (F**2) L0xffffffff0644 [Q, X - 1753**353] /\
eqmod (F**2) L0xffffffff0648 [Q, X - 1753**225] /\
eqmod (F**2) L0xffffffff064c [Q, X - 1753**481] /\
eqmod (F**2) L0xffffffff0650 [Q, X - 1753** 17] /\
eqmod (F**2) L0xffffffff0654 [Q, X - 1753**273] /\
eqmod (F**2) L0xffffffff0658 [Q, X - 1753**145] /\
eqmod (F**2) L0xffffffff065c [Q, X - 1753**401] /\
eqmod (F**2) L0xffffffff0660 [Q, X - 1753** 81] /\
eqmod (F**2) L0xffffffff0664 [Q, X - 1753**337] /\
eqmod (F**2) L0xffffffff0668 [Q, X - 1753**209] /\
eqmod (F**2) L0xffffffff066c [Q, X - 1753**465] /\
eqmod (F**2) L0xffffffff0670 [Q, X - 1753** 49] /\
eqmod (F**2) L0xffffffff0674 [Q, X - 1753**305] /\
eqmod (F**2) L0xffffffff0678 [Q, X - 1753**177] /\
eqmod (F**2) L0xffffffff067c [Q, X - 1753**433] /\
eqmod (F**2) L0xffffffff0680 [Q, X - 1753**113] /\
eqmod (F**2) L0xffffffff0684 [Q, X - 1753**369] /\
eqmod (F**2) L0xffffffff0688 [Q, X - 1753**241] /\
eqmod (F**2) L0xffffffff068c [Q, X - 1753**497] /\
eqmod (F**2) L0xffffffff0690 [Q, X - 1753**  9] /\
eqmod (F**2) L0xffffffff0694 [Q, X - 1753**265] /\
eqmod (F**2) L0xffffffff0698 [Q, X - 1753**137] /\
eqmod (F**2) L0xffffffff069c [Q, X - 1753**393] /\
eqmod (F**2) L0xffffffff06a0 [Q, X - 1753** 73] /\
eqmod (F**2) L0xffffffff06a4 [Q, X - 1753**329] /\
eqmod (F**2) L0xffffffff06a8 [Q, X - 1753**201] /\
eqmod (F**2) L0xffffffff06ac [Q, X - 1753**457] /\
eqmod (F**2) L0xffffffff06b0 [Q, X - 1753** 41] /\
eqmod (F**2) L0xffffffff06b4 [Q, X - 1753**297] /\
eqmod (F**2) L0xffffffff06b8 [Q, X - 1753**169] /\
eqmod (F**2) L0xffffffff06bc [Q, X - 1753**425] /\
eqmod (F**2) L0xffffffff06c0 [Q, X - 1753**105] /\
eqmod (F**2) L0xffffffff06c4 [Q, X - 1753**361] /\
eqmod (F**2) L0xffffffff06c8 [Q, X - 1753**233] /\
eqmod (F**2) L0xffffffff06cc [Q, X - 1753**489] /\
eqmod (F**2) L0xffffffff06d0 [Q, X - 1753** 25] /\
eqmod (F**2) L0xffffffff06d4 [Q, X - 1753**281] /\
eqmod (F**2) L0xffffffff06d8 [Q, X - 1753**153] /\
eqmod (F**2) L0xffffffff06dc [Q, X - 1753**409] /\
eqmod (F**2) L0xffffffff06e0 [Q, X - 1753** 89] /\
eqmod (F**2) L0xffffffff06e4 [Q, X - 1753**345] /\
eqmod (F**2) L0xffffffff06e8 [Q, X - 1753**217] /\
eqmod (F**2) L0xffffffff06ec [Q, X - 1753**473] /\
eqmod (F**2) L0xffffffff06f0 [Q, X - 1753** 57] /\
eqmod (F**2) L0xffffffff06f4 [Q, X - 1753**313] /\
eqmod (F**2) L0xffffffff06f8 [Q, X - 1753**185] /\
eqmod (F**2) L0xffffffff06fc [Q, X - 1753**441] /\
eqmod (F**2) L0xffffffff0700 [Q, X - 1753**121] /\
eqmod (F**2) L0xffffffff0704 [Q, X - 1753**377] /\
eqmod (F**2) L0xffffffff0708 [Q, X - 1753**249] /\
eqmod (F**2) L0xffffffff070c [Q, X - 1753**505] /\
eqmod (F**2) L0xffffffff0710 [Q, X - 1753**  5] /\
eqmod (F**2) L0xffffffff0714 [Q, X - 1753**261] /\
eqmod (F**2) L0xffffffff0718 [Q, X - 1753**133] /\
eqmod (F**2) L0xffffffff071c [Q, X - 1753**389] /\
eqmod (F**2) L0xffffffff0720 [Q, X - 1753** 69] /\
eqmod (F**2) L0xffffffff0724 [Q, X - 1753**325] /\
eqmod (F**2) L0xffffffff0728 [Q, X - 1753**197] /\
eqmod (F**2) L0xffffffff072c [Q, X - 1753**453] /\
eqmod (F**2) L0xffffffff0730 [Q, X - 1753** 37] /\
eqmod (F**2) L0xffffffff0734 [Q, X - 1753**293] /\
eqmod (F**2) L0xffffffff0738 [Q, X - 1753**165] /\
eqmod (F**2) L0xffffffff073c [Q, X - 1753**421] /\
eqmod (F**2) L0xffffffff0740 [Q, X - 1753**101] /\
eqmod (F**2) L0xffffffff0744 [Q, X - 1753**357] /\
eqmod (F**2) L0xffffffff0748 [Q, X - 1753**229] /\
eqmod (F**2) L0xffffffff074c [Q, X - 1753**485] /\
eqmod (F**2) L0xffffffff0750 [Q, X - 1753** 21] /\
eqmod (F**2) L0xffffffff0754 [Q, X - 1753**277] /\
eqmod (F**2) L0xffffffff0758 [Q, X - 1753**149] /\
eqmod (F**2) L0xffffffff075c [Q, X - 1753**405] /\
eqmod (F**2) L0xffffffff0760 [Q, X - 1753** 85] /\
eqmod (F**2) L0xffffffff0764 [Q, X - 1753**341] /\
eqmod (F**2) L0xffffffff0768 [Q, X - 1753**213] /\
eqmod (F**2) L0xffffffff076c [Q, X - 1753**469] /\
eqmod (F**2) L0xffffffff0770 [Q, X - 1753** 53] /\
eqmod (F**2) L0xffffffff0774 [Q, X - 1753**309] /\
eqmod (F**2) L0xffffffff0778 [Q, X - 1753**181] /\
eqmod (F**2) L0xffffffff077c [Q, X - 1753**437] /\
eqmod (F**2) L0xffffffff0780 [Q, X - 1753**117] /\
eqmod (F**2) L0xffffffff0784 [Q, X - 1753**373] /\
eqmod (F**2) L0xffffffff0788 [Q, X - 1753**245] /\
eqmod (F**2) L0xffffffff078c [Q, X - 1753**501] /\
eqmod (F**2) L0xffffffff0790 [Q, X - 1753** 13] /\
eqmod (F**2) L0xffffffff0794 [Q, X - 1753**269] /\
eqmod (F**2) L0xffffffff0798 [Q, X - 1753**141] /\
eqmod (F**2) L0xffffffff079c [Q, X - 1753**397] /\
eqmod (F**2) L0xffffffff07a0 [Q, X - 1753** 77] /\
eqmod (F**2) L0xffffffff07a4 [Q, X - 1753**333] /\
eqmod (F**2) L0xffffffff07a8 [Q, X - 1753**205] /\
eqmod (F**2) L0xffffffff07ac [Q, X - 1753**461] /\
eqmod (F**2) L0xffffffff07b0 [Q, X - 1753** 45] /\
eqmod (F**2) L0xffffffff07b4 [Q, X - 1753**301] /\
eqmod (F**2) L0xffffffff07b8 [Q, X - 1753**173] /\
eqmod (F**2) L0xffffffff07bc [Q, X - 1753**429] /\
eqmod (F**2) L0xffffffff07c0 [Q, X - 1753**109] /\
eqmod (F**2) L0xffffffff07c4 [Q, X - 1753**365] /\
eqmod (F**2) L0xffffffff07c8 [Q, X - 1753**237] /\
eqmod (F**2) L0xffffffff07cc [Q, X - 1753**493] /\
eqmod (F**2) L0xffffffff07d0 [Q, X - 1753** 29] /\
eqmod (F**2) L0xffffffff07d4 [Q, X - 1753**285] /\
eqmod (F**2) L0xffffffff07d8 [Q, X - 1753**157] /\
eqmod (F**2) L0xffffffff07dc [Q, X - 1753**413] /\
eqmod (F**2) L0xffffffff07e0 [Q, X - 1753** 93] /\
eqmod (F**2) L0xffffffff07e4 [Q, X - 1753**349] /\
eqmod (F**2) L0xffffffff07e8 [Q, X - 1753**221] /\
eqmod (F**2) L0xffffffff07ec [Q, X - 1753**477] /\
eqmod (F**2) L0xffffffff07f0 [Q, X - 1753** 61] /\
eqmod (F**2) L0xffffffff07f4 [Q, X - 1753**317] /\
eqmod (F**2) L0xffffffff07f8 [Q, X - 1753**189] /\
eqmod (F**2) L0xffffffff07fc [Q, X - 1753**445] /\
eqmod (F**2) L0xffffffff0800 [Q, X - 1753**125] /\
eqmod (F**2) L0xffffffff0804 [Q, X - 1753**381] /\
eqmod (F**2) L0xffffffff0808 [Q, X - 1753**253] /\
eqmod (F**2) L0xffffffff080c [Q, X - 1753**509] /\
eqmod (F**2) L0xffffffff0810 [Q, X - 1753**  3] /\
eqmod (F**2) L0xffffffff0814 [Q, X - 1753**259] /\
eqmod (F**2) L0xffffffff0818 [Q, X - 1753**131] /\
eqmod (F**2) L0xffffffff081c [Q, X - 1753**387] /\
eqmod (F**2) L0xffffffff0820 [Q, X - 1753** 67] /\
eqmod (F**2) L0xffffffff0824 [Q, X - 1753**323] /\
eqmod (F**2) L0xffffffff0828 [Q, X - 1753**195] /\
eqmod (F**2) L0xffffffff082c [Q, X - 1753**451] /\
eqmod (F**2) L0xffffffff0830 [Q, X - 1753** 35] /\
eqmod (F**2) L0xffffffff0834 [Q, X - 1753**291] /\
eqmod (F**2) L0xffffffff0838 [Q, X - 1753**163] /\
eqmod (F**2) L0xffffffff083c [Q, X - 1753**419] /\
eqmod (F**2) L0xffffffff0840 [Q, X - 1753** 99] /\
eqmod (F**2) L0xffffffff0844 [Q, X - 1753**355] /\
eqmod (F**2) L0xffffffff0848 [Q, X - 1753**227] /\
eqmod (F**2) L0xffffffff084c [Q, X - 1753**483] /\
eqmod (F**2) L0xffffffff0850 [Q, X - 1753** 19] /\
eqmod (F**2) L0xffffffff0854 [Q, X - 1753**275] /\
eqmod (F**2) L0xffffffff0858 [Q, X - 1753**147] /\
eqmod (F**2) L0xffffffff085c [Q, X - 1753**403] /\
eqmod (F**2) L0xffffffff0860 [Q, X - 1753** 83] /\
eqmod (F**2) L0xffffffff0864 [Q, X - 1753**339] /\
eqmod (F**2) L0xffffffff0868 [Q, X - 1753**211] /\
eqmod (F**2) L0xffffffff086c [Q, X - 1753**467] /\
eqmod (F**2) L0xffffffff0870 [Q, X - 1753** 51] /\
eqmod (F**2) L0xffffffff0874 [Q, X - 1753**307] /\
eqmod (F**2) L0xffffffff0878 [Q, X - 1753**179] /\
eqmod (F**2) L0xffffffff087c [Q, X - 1753**435] /\
eqmod (F**2) L0xffffffff0880 [Q, X - 1753**115] /\
eqmod (F**2) L0xffffffff0884 [Q, X - 1753**371] /\
eqmod (F**2) L0xffffffff0888 [Q, X - 1753**243] /\
eqmod (F**2) L0xffffffff088c [Q, X - 1753**499] /\
eqmod (F**2) L0xffffffff0890 [Q, X - 1753** 11] /\
eqmod (F**2) L0xffffffff0894 [Q, X - 1753**267] /\
eqmod (F**2) L0xffffffff0898 [Q, X - 1753**139] /\
eqmod (F**2) L0xffffffff089c [Q, X - 1753**395] /\
eqmod (F**2) L0xffffffff08a0 [Q, X - 1753** 75] /\
eqmod (F**2) L0xffffffff08a4 [Q, X - 1753**331] /\
eqmod (F**2) L0xffffffff08a8 [Q, X - 1753**203] /\
eqmod (F**2) L0xffffffff08ac [Q, X - 1753**459] /\
eqmod (F**2) L0xffffffff08b0 [Q, X - 1753** 43] /\
eqmod (F**2) L0xffffffff08b4 [Q, X - 1753**299] /\
eqmod (F**2) L0xffffffff08b8 [Q, X - 1753**171] /\
eqmod (F**2) L0xffffffff08bc [Q, X - 1753**427] /\
eqmod (F**2) L0xffffffff08c0 [Q, X - 1753**107] /\
eqmod (F**2) L0xffffffff08c4 [Q, X - 1753**363] /\
eqmod (F**2) L0xffffffff08c8 [Q, X - 1753**235] /\
eqmod (F**2) L0xffffffff08cc [Q, X - 1753**491] /\
eqmod (F**2) L0xffffffff08d0 [Q, X - 1753** 27] /\
eqmod (F**2) L0xffffffff08d4 [Q, X - 1753**283] /\
eqmod (F**2) L0xffffffff08d8 [Q, X - 1753**155] /\
eqmod (F**2) L0xffffffff08dc [Q, X - 1753**411] /\
eqmod (F**2) L0xffffffff08e0 [Q, X - 1753** 91] /\
eqmod (F**2) L0xffffffff08e4 [Q, X - 1753**347] /\
eqmod (F**2) L0xffffffff08e8 [Q, X - 1753**219] /\
eqmod (F**2) L0xffffffff08ec [Q, X - 1753**475] /\
eqmod (F**2) L0xffffffff08f0 [Q, X - 1753** 59] /\
eqmod (F**2) L0xffffffff08f4 [Q, X - 1753**315] /\
eqmod (F**2) L0xffffffff08f8 [Q, X - 1753**187] /\
eqmod (F**2) L0xffffffff08fc [Q, X - 1753**443] /\
eqmod (F**2) L0xffffffff0900 [Q, X - 1753**123] /\
eqmod (F**2) L0xffffffff0904 [Q, X - 1753**379] /\
eqmod (F**2) L0xffffffff0908 [Q, X - 1753**251] /\
eqmod (F**2) L0xffffffff090c [Q, X - 1753**507] /\
eqmod (F**2) L0xffffffff0910 [Q, X - 1753**  7] /\
eqmod (F**2) L0xffffffff0914 [Q, X - 1753**263] /\
eqmod (F**2) L0xffffffff0918 [Q, X - 1753**135] /\
eqmod (F**2) L0xffffffff091c [Q, X - 1753**391] /\
eqmod (F**2) L0xffffffff0920 [Q, X - 1753** 71] /\
eqmod (F**2) L0xffffffff0924 [Q, X - 1753**327] /\
eqmod (F**2) L0xffffffff0928 [Q, X - 1753**199] /\
eqmod (F**2) L0xffffffff092c [Q, X - 1753**455] /\
eqmod (F**2) L0xffffffff0930 [Q, X - 1753** 39] /\
eqmod (F**2) L0xffffffff0934 [Q, X - 1753**295] /\
eqmod (F**2) L0xffffffff0938 [Q, X - 1753**167] /\
eqmod (F**2) L0xffffffff093c [Q, X - 1753**423] /\
eqmod (F**2) L0xffffffff0940 [Q, X - 1753**103] /\
eqmod (F**2) L0xffffffff0944 [Q, X - 1753**359] /\
eqmod (F**2) L0xffffffff0948 [Q, X - 1753**231] /\
eqmod (F**2) L0xffffffff094c [Q, X - 1753**487] /\
eqmod (F**2) L0xffffffff0950 [Q, X - 1753** 23] /\
eqmod (F**2) L0xffffffff0954 [Q, X - 1753**279] /\
eqmod (F**2) L0xffffffff0958 [Q, X - 1753**151] /\
eqmod (F**2) L0xffffffff095c [Q, X - 1753**407] /\
eqmod (F**2) L0xffffffff0960 [Q, X - 1753** 87] /\
eqmod (F**2) L0xffffffff0964 [Q, X - 1753**343] /\
eqmod (F**2) L0xffffffff0968 [Q, X - 1753**215] /\
eqmod (F**2) L0xffffffff096c [Q, X - 1753**471] /\
eqmod (F**2) L0xffffffff0970 [Q, X - 1753** 55] /\
eqmod (F**2) L0xffffffff0974 [Q, X - 1753**311] /\
eqmod (F**2) L0xffffffff0978 [Q, X - 1753**183] /\
eqmod (F**2) L0xffffffff097c [Q, X - 1753**439] /\
eqmod (F**2) L0xffffffff0980 [Q, X - 1753**119] /\
eqmod (F**2) L0xffffffff0984 [Q, X - 1753**375] /\
eqmod (F**2) L0xffffffff0988 [Q, X - 1753**247] /\
eqmod (F**2) L0xffffffff098c [Q, X - 1753**503] /\
eqmod (F**2) L0xffffffff0990 [Q, X - 1753** 15] /\
eqmod (F**2) L0xffffffff0994 [Q, X - 1753**271] /\
eqmod (F**2) L0xffffffff0998 [Q, X - 1753**143] /\
eqmod (F**2) L0xffffffff099c [Q, X - 1753**399] /\
eqmod (F**2) L0xffffffff09a0 [Q, X - 1753** 79] /\
eqmod (F**2) L0xffffffff09a4 [Q, X - 1753**335] /\
eqmod (F**2) L0xffffffff09a8 [Q, X - 1753**207] /\
eqmod (F**2) L0xffffffff09ac [Q, X - 1753**463] /\
eqmod (F**2) L0xffffffff09b0 [Q, X - 1753** 47] /\
eqmod (F**2) L0xffffffff09b4 [Q, X - 1753**303] /\
eqmod (F**2) L0xffffffff09b8 [Q, X - 1753**175] /\
eqmod (F**2) L0xffffffff09bc [Q, X - 1753**431] /\
eqmod (F**2) L0xffffffff09c0 [Q, X - 1753**111] /\
eqmod (F**2) L0xffffffff09c4 [Q, X - 1753**367] /\
eqmod (F**2) L0xffffffff09c8 [Q, X - 1753**239] /\
eqmod (F**2) L0xffffffff09cc [Q, X - 1753**495] /\
eqmod (F**2) L0xffffffff09d0 [Q, X - 1753** 31] /\
eqmod (F**2) L0xffffffff09d4 [Q, X - 1753**287] /\
eqmod (F**2) L0xffffffff09d8 [Q, X - 1753**159] /\
eqmod (F**2) L0xffffffff09dc [Q, X - 1753**415] /\
eqmod (F**2) L0xffffffff09e0 [Q, X - 1753** 95] /\
eqmod (F**2) L0xffffffff09e4 [Q, X - 1753**351] /\
eqmod (F**2) L0xffffffff09e8 [Q, X - 1753**223] /\
eqmod (F**2) L0xffffffff09ec [Q, X - 1753**479] /\
eqmod (F**2) L0xffffffff09f0 [Q, X - 1753** 63] /\
eqmod (F**2) L0xffffffff09f4 [Q, X - 1753**319] /\
eqmod (F**2) L0xffffffff09f8 [Q, X - 1753**191] /\
eqmod (F**2) L0xffffffff09fc [Q, X - 1753**447] /\
eqmod (F**2) L0xffffffff0a00 [Q, X - 1753**127] /\
eqmod (F**2) L0xffffffff0a04 [Q, X - 1753**383] /\
eqmod (F**2) L0xffffffff0a08 [Q, X - 1753**255] /\
eqmod (F**2) L0xffffffff0a0c [Q, X - 1753**511] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<[Q,Q,Q,Q]
&&
Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<s[Q,Q,Q,Q]
}

(**************** nondets ****************)


nondet x0@uint64;
nondet x19@uint64; nondet x20@uint64; nondet x21@uint64; nondet x22@uint64;
nondet x23@uint64; nondet x24@uint64; nondet x25@uint64; nondet x26@uint64;
nondet x27@uint64; nondet x28@uint64; nondet x29@uint64; nondet x30@uint64;
nondet  d8@uint64; nondet  d9@uint64; nondet d10@uint64; nondet d11@uint64;
nondet d12@uint64; nondet d13@uint64; nondet d14@uint64; nondet d15@uint64;


(**************** constants ****************)


mov L0x4159a0 8380417@int32;
mov L0x4159a8 0x0000000100000100@int64;
mov L0x4159b0 4197891@int32;
mov L0x4159b4 16382@int32;
mov L0x4159b8 (-75523344)@int32;
mov L0x4159bc (-294725)@int32;
mov L0x416260 (          0)@int32; mov L0x416264 (          0)@int32;
mov L0x416268 (  915382907)@int32; mov L0x41626c (    3572223)@int32;
mov L0x416270 ( -963888510)@int32; mov L0x416274 (   -3761513)@int32;
mov L0x416278 ( -964937599)@int32; mov L0x41627c (   -3765607)@int32;
mov L0x416280 (  820367122)@int32; mov L0x416284 (    3201430)@int32;
mov L0x416288 (  806080660)@int32; mov L0x41628c (    3145678)@int32;
mov L0x416290 (  738955404)@int32; mov L0x416294 (    2883726)@int32;
mov L0x416298 (  820383522)@int32; mov L0x41629c (    3201494)@int32;
mov L0x4162a0 (  312926867)@int32; mov L0x4162a4 (    1221177)@int32;
mov L0x4162a8 ( -142848732)@int32; mov L0x4162ac (    -557458)@int32;
mov L0x4162b0 (  257592709)@int32; mov L0x4162b4 (    1005239)@int32;
mov L0x4162b8 ( -964747974)@int32; mov L0x4162bc (   -3764867)@int32;
mov L0x4162c0 ( -545785280)@int32; mov L0x4162c4 (   -2129892)@int32;
mov L0x4162c8 ( -687336873)@int32; mov L0x4162cc (   -2682288)@int32;
mov L0x4162d0 ( -907762539)@int32; mov L0x4162d4 (   -3542485)@int32;
mov L0x4162d8 (  154181397)@int32; mov L0x4162dc (     601683)@int32;
mov L0x4162e0 (    8380417)@int32; mov L0x4162e4 (          0)@int32;
mov L0x4162e8 ( -585207070)@int32; mov L0x4162ec (   -2283733)@int32;
mov L0x4162f0 ( -476219497)@int32; mov L0x4162f4 (   -1858416)@int32;
mov L0x4162f8 ( -857403734)@int32; mov L0x4162fc (   -3345963)@int32;
mov L0x416300 ( -447030292)@int32; mov L0x416304 (  573161516)@int32;
mov L0x416308 (  492577742)@int32; mov L0x41630c (  978523985)@int32;
mov L0x416310 (   -1744507)@int32; mov L0x416314 (    2236726)@int32;
mov L0x416318 (    1922253)@int32; mov L0x41631c (    3818627)@int32;
mov L0x416320 (  187430119)@int32; mov L0x416324 (  200355636)@int32;
mov L0x416328 (  967019376)@int32; mov L0x41632c ( -904878186)@int32;
mov L0x416330 (     731434)@int32; mov L0x416334 (     781875)@int32;
mov L0x416338 (    3773731)@int32; mov L0x41633c (   -3531229)@int32;
mov L0x416340 ( -270210213)@int32; mov L0x416344 ( -486888731)@int32;
mov L0x416348 ( 1018462631)@int32; mov L0x41634c (   77645096)@int32;
mov L0x416350 (   -1054478)@int32; mov L0x416354 (   -1900052)@int32;
mov L0x416358 (    3974485)@int32; mov L0x41635c (     303005)@int32;
mov L0x416360 (    8380417)@int32; mov L0x416364 (          0)@int32;
mov L0x416368 ( -721508096)@int32; mov L0x41636c (   -2815639)@int32;
mov L0x416370 ( -475038184)@int32; mov L0x416374 (   -1853806)@int32;
mov L0x416378 ( -747568486)@int32; mov L0x41637c (   -2917338)@int32;
mov L0x416380 (  603268097)@int32; mov L0x416384 ( -259126110)@int32;
mov L0x416388 (   84011120)@int32; mov L0x41638c (  -89383150)@int32;
mov L0x416390 (    2354215)@int32; mov L0x416394 (   -1011223)@int32;
mov L0x416398 (     327848)@int32; mov L0x41639c (    -348812)@int32;
mov L0x4163a0 (  100631253)@int32; mov L0x4163a4 (  439933955)@int32;
mov L0x4163a8 (  561979013)@int32; mov L0x4163ac ( -800464680)@int32;
mov L0x4163b0 (     392707)@int32; mov L0x4163b4 (    1716814)@int32;
mov L0x4163b8 (    2193087)@int32; mov L0x4163bc (   -3123762)@int32;
mov L0x4163c0 ( -749801963)@int32; mov L0x4163c4 (  772445769)@int32;
mov L0x4163c8 ( -604333585)@int32; mov L0x4163cc (  559928242)@int32;
mov L0x4163d0 (   -2926054)@int32; mov L0x4163d4 (    3014420)@int32;
mov L0x4163d8 (   -2358373)@int32; mov L0x4163dc (    2185084)@int32;
mov L0x4163e0 (    8380417)@int32; mov L0x4163e4 (          0)@int32;
mov L0x4163e8 (  918682129)@int32; mov L0x4163ec (    3585098)@int32;
mov L0x4163f0 ( -991769559)@int32; mov L0x4163f4 (   -3870317)@int32;
mov L0x4163f8 ( -142694469)@int32; mov L0x4163fc (    -556856)@int32;
mov L0x416400 (  117660617)@int32; mov L0x416404 (  167401858)@int32;
mov L0x416408 ( -592665232)@int32; mov L0x41640c (  888589898)@int32;
mov L0x416410 (     459163)@int32; mov L0x416414 (     653275)@int32;
mov L0x416418 (   -2312838)@int32; mov L0x41641c (    3467665)@int32;
mov L0x416420 (  388001774)@int32; mov L0x416424 ( -879049958)@int32;
mov L0x416428 (  141890356)@int32; mov L0x41642c (  282732136)@int32;
mov L0x416430 (    1514152)@int32; mov L0x416434 (   -3430436)@int32;
mov L0x416438 (     553718)@int32; mov L0x41643c (    1103344)@int32;
mov L0x416440 (  -35937555)@int32; mov L0x416444 ( -220412084)@int32;
mov L0x416448 ( -130212265)@int32; mov L0x41644c ( -795799901)@int32;
mov L0x416450 (    -140244)@int32; mov L0x416454 (    -860144)@int32;
mov L0x416458 (    -508145)@int32; mov L0x41645c (   -3105558)@int32;
mov L0x416460 (    8380417)@int32; mov L0x416464 (          0)@int32;
mov L0x416468 (  164673562)@int32; mov L0x41646c (     642628)@int32;
mov L0x416470 ( -818041395)@int32; mov L0x416474 (   -3192354)@int32;
mov L0x416478 (  742437332)@int32; mov L0x41647c (    2897314)@int32;
mov L0x416480 (  712065019)@int32; mov L0x416484 ( -687588511)@int32;
mov L0x416488 (  711287812)@int32; mov L0x41648c ( -347590090)@int32;
mov L0x416490 (    2778788)@int32; mov L0x416494 (   -2683270)@int32;
mov L0x416498 (    2775755)@int32; mov L0x41649c (   -1356448)@int32;
mov L0x4164a0 (  197425671)@int32; mov L0x4164a4 (  -55063046)@int32;
mov L0x4164a8 ( -773976352)@int32; mov L0x4164ac (    3043996)@int32;
mov L0x4164b0 (     770441)@int32; mov L0x4164b4 (    -214880)@int32;
mov L0x4164b8 (   -3020393)@int32; mov L0x4164bc (      11879)@int32;
mov L0x4164c0 ( -139752717)@int32; mov L0x4164c4 ( -861908357)@int32;
mov L0x4164c8 (  351195274)@int32; mov L0x4164cc (-1023635298)@int32;
mov L0x4164d0 (    -545376)@int32; mov L0x4164d4 (   -3363542)@int32;
mov L0x4164d8 (    1370517)@int32; mov L0x4164dc (   -3994671)@int32;
mov L0x4164e0 (    8380417)@int32; mov L0x4164e4 (          0)@int32;
mov L0x4164e8 ( -374309300)@int32; mov L0x4164ec (   -1460718)@int32;
mov L0x4164f0 ( 1012201926)@int32; mov L0x4164f4 (    3950053)@int32;
mov L0x4164f8 (  439978542)@int32; mov L0x4164fc (    1716988)@int32;
mov L0x416500 ( -864652284)@int32; mov L0x416504 ( -749740976)@int32;
mov L0x416508 (  314332144)@int32; mov L0x41650c ( -999753034)@int32;
mov L0x416510 (   -3374250)@int32; mov L0x416514 (   -2925816)@int32;
mov L0x416518 (    1226661)@int32; mov L0x41651c (   -3901472)@int32;
mov L0x416520 (  863376927)@int32; mov L0x416524 ( -519685171)@int32;
mov L0x416528 ( -441577800)@int32; mov L0x41652c ( -658309618)@int32;
mov L0x416530 (    3369273)@int32; mov L0x416534 (   -2028038)@int32;
mov L0x416538 (   -1723229)@int32; mov L0x41653c (   -2569011)@int32;
mov L0x416540 ( -298172236)@int32; mov L0x416544 ( -426738094)@int32;
mov L0x416548 (  413979908)@int32; mov L0x41654c (-1020029345)@int32;
mov L0x416550 (   -1163598)@int32; mov L0x416554 (   -1665318)@int32;
mov L0x416558 (    1615530)@int32; mov L0x41655c (   -3980599)@int32;
mov L0x416560 (    8380417)@int32; mov L0x416564 (          0)@int32;
mov L0x416568 ( -628833668)@int32; mov L0x41656c (   -2453983)@int32;
mov L0x416570 (  496048908)@int32; mov L0x416574 (    1935799)@int32;
mov L0x416578 ( -962678241)@int32; mov L0x41657c (   -3756790)@int32;
mov L0x416580 ( -159173408)@int32; mov L0x416584 ( -777970524)@int32;
mov L0x416588 ( -630730945)@int32; mov L0x41658c (  337655269)@int32;
mov L0x416590 (    -621164)@int32; mov L0x416594 (   -3035980)@int32;
mov L0x416598 (   -2461387)@int32; mov L0x41659c (    1317678)@int32;
mov L0x4165a0 ( 1030830548)@int32; mov L0x4165a4 (-1063046068)@int32;
mov L0x4165a8 ( -771248568)@int32; mov L0x4165ac (   86720197)@int32;
mov L0x4165b0 (    4022750)@int32; mov L0x4165b4 (   -4148469)@int32;
mov L0x4165b8 (   -3009748)@int32; mov L0x4165bc (     338420)@int32;
mov L0x4165c0 ( -192079267)@int32; mov L0x4165c4 (  669544140)@int32;
mov L0x4165c8 ( -678549029)@int32; mov L0x4165cc (  777397036)@int32;
mov L0x4165d0 (    -749577)@int32; mov L0x4165d4 (    2612853)@int32;
mov L0x4165d8 (   -2647994)@int32; mov L0x4165dc (    3033742)@int32;
mov L0x4165e0 (    8380417)@int32; mov L0x4165e4 (          0)@int32;
mov L0x4165e8 ( -439288460)@int32; mov L0x4165ec (   -1714295)@int32;
mov L0x4165f0 (  915957677)@int32; mov L0x4165f4 (    3574466)@int32;
mov L0x4165f8 (  209493775)@int32; mov L0x4165fc (     817536)@int32;
mov L0x416600 (  605279149)@int32; mov L0x416604 (  333129378)@int32;
mov L0x416608 ( 1071872863)@int32; mov L0x41660c ( -892316032)@int32;
mov L0x416610 (    2362063)@int32; mov L0x416614 (    1300016)@int32;
mov L0x416618 (    4182915)@int32; mov L0x41661c (   -3482206)@int32;
mov L0x416620 (  470097680)@int32; mov L0x416624 (  304395785)@int32;
mov L0x416628 (  356997292)@int32; mov L0x41662c ( -510974714)@int32;
mov L0x416630 (    1834526)@int32; mov L0x416634 (    1187885)@int32;
mov L0x416638 (    1393159)@int32; mov L0x41663c (   -1994046)@int32;
mov L0x416640 (  185731180)@int32; mov L0x416644 ( -130156402)@int32;
mov L0x416648 ( -638402564)@int32; mov L0x41664c (  378477722)@int32;
mov L0x416650 (     724804)@int32; mov L0x416654 (    -507927)@int32;
mov L0x416658 (   -2491325)@int32; mov L0x41665c (    1476985)@int32;
mov L0x416660 (    8380417)@int32; mov L0x416664 (          0)@int32;
mov L0x416668 (  827143915)@int32; mov L0x41666c (    3227876)@int32;
mov L0x416670 ( -450833045)@int32; mov L0x416674 (   -1759347)@int32;
mov L0x416678 ( -875112161)@int32; mov L0x41667c (   -3415069)@int32;
mov L0x416680 (  577774276)@int32; mov L0x416684 (  612717067)@int32;
mov L0x416688 ( -458160776)@int32; mov L0x41668c (  660934133)@int32;
mov L0x416690 (    2254727)@int32; mov L0x416694 (    2391089)@int32;
mov L0x416698 (   -1787943)@int32; mov L0x41669c (    2579253)@int32;
mov L0x4166a0 (  702999655)@int32; mov L0x4166a4 (  302276083)@int32;
mov L0x4166a8 (  521163479)@int32; mov L0x4166ac ( -539479988)@int32;
mov L0x4166b0 (    2743411)@int32; mov L0x4166b4 (    1179613)@int32;
mov L0x4166b8 (    2033807)@int32; mov L0x4166bc (   -2105286)@int32;
mov L0x4166c0 ( -135295244)@int32; mov L0x4166c4 ( -150224382)@int32;
mov L0x4166c8 (  608441020)@int32; mov L0x4166cc (  415984810)@int32;
mov L0x4166d0 (    -527981)@int32; mov L0x4166d4 (    -586241)@int32;
mov L0x4166d8 (    2374402)@int32; mov L0x4166dc (    1623354)@int32;
mov L0x4166e0 (    8380417)@int32; mov L0x4166e4 (          0)@int32;
mov L0x4166e8 (  342333886)@int32; mov L0x4166ec (    1335936)@int32;
mov L0x4166f0 ( -552488273)@int32; mov L0x4166f4 (   -2156050)@int32;
mov L0x4166f8 ( -830756018)@int32; mov L0x4166fc (   -3241972)@int32;
mov L0x416700 ( -834980303)@int32; mov L0x416704 (  832852657)@int32;
mov L0x416708 (  -60323094)@int32; mov L0x41670c ( -444930577)@int32;
mov L0x416710 (   -3258457)@int32; mov L0x416714 (    3250154)@int32;
mov L0x416718 (    -235407)@int32; mov L0x41671c (   -1736313)@int32;
mov L0x416720 (  558360247)@int32; mov L0x416724 (  481719139)@int32;
mov L0x416728 (  889718424)@int32; mov L0x41672c (  492511373)@int32;
mov L0x416730 (    2178965)@int32; mov L0x416734 (    1879878)@int32;
mov L0x416738 (    3472069)@int32; mov L0x41673c (    1921994)@int32;
mov L0x416740 (  209807681)@int32; mov L0x416744 ( -522531086)@int32;
mov L0x416748 (-1035301089)@int32; mov L0x41674c (  117552223)@int32;
mov L0x416750 (     818761)@int32; mov L0x416754 (   -2039144)@int32;
mov L0x416758 (   -4040196)@int32; mov L0x41675c (     458740)@int32;
mov L0x416760 (    8380417)@int32; mov L0x416764 (          0)@int32;
mov L0x416768 ( -173376332)@int32; mov L0x41676c (    -676590)@int32;
mov L0x416770 ( 1029866791)@int32; mov L0x416774 (    4018989)@int32;
mov L0x416778 ( -530906624)@int32; mov L0x41677c (   -2071829)@int32;
mov L0x416780 (  819295484)@int32; mov L0x416784 ( -509377762)@int32;
mov L0x416788 (  893898890)@int32; mov L0x41678c ( 1067647297)@int32;
mov L0x416790 (    3197248)@int32; mov L0x416794 (   -1987814)@int32;
mov L0x416798 (    3488383)@int32; mov L0x41679c (    4166425)@int32;
mov L0x4167a0 (  568482643)@int32; mov L0x4167a4 ( -157142369)@int32;
mov L0x4167a8 ( -643961400)@int32; mov L0x4167ac (  -36345249)@int32;
mov L0x4167b0 (    2218467)@int32; mov L0x4167b4 (    -613238)@int32;
mov L0x4167b8 (   -2513018)@int32; mov L0x4167bc (    -141835)@int32;
mov L0x4167c0 (  335754661)@int32; mov L0x4167c4 (  347191365)@int32;
mov L0x4167c8 (   22883400)@int32; mov L0x4167cc ( -768294260)@int32;
mov L0x4167d0 (    1310261)@int32; mov L0x4167d4 (    1354892)@int32;
mov L0x4167d8 (      89301)@int32; mov L0x4167dc (   -2998219)@int32;
mov L0x4167e0 (    8380417)@int32; mov L0x4167e4 (          0)@int32;
mov L0x4167e8 (  111244624)@int32; mov L0x4167ec (     434125)@int32;
mov L0x4167f0 (  898510625)@int32; mov L0x4167f4 (    3506380)@int32;
mov L0x4167f8 ( -280713909)@int32; mov L0x4167fc (   -1095468)@int32;
mov L0x416800 (  854436357)@int32; mov L0x416804 ( -631001801)@int32;
mov L0x416808 (  -43482586)@int32; mov L0x41680c (  144935890)@int32;
mov L0x416810 (    3334383)@int32; mov L0x416814 (   -2462444)@int32;
mov L0x416818 (    -169688)@int32; mov L0x41681c (     565603)@int32;
mov L0x416820 (    3181859)@int32; mov L0x416824 ( -677264190)@int32;
mov L0x416828 (  983611064)@int32; mov L0x41682c ( -588375860)@int32;
mov L0x416830 (      12417)@int32; mov L0x416834 (   -2642980)@int32;
mov L0x416838 (    3838479)@int32; mov L0x41683c (   -2296099)@int32;
mov L0x416840 ( -321386456)@int32; mov L0x416844 ( -818892658)@int32;
mov L0x416848 ( -317727459)@int32; mov L0x41684c ( -960233614)@int32;
mov L0x416850 (   -1254190)@int32; mov L0x416854 (   -3195676)@int32;
mov L0x416858 (   -1239911)@int32; mov L0x41685c (   -3747250)@int32;
mov L0x416860 (    8380417)@int32; mov L0x416864 (          0)@int32;
mov L0x416868 (  903139016)@int32; mov L0x41686c (    3524442)@int32;
mov L0x416870 ( -237992130)@int32; mov L0x416874 (    -928749)@int32;
mov L0x416878 ( -101000509)@int32; mov L0x41687c (    -394148)@int32;
mov L0x416880 (  759080783)@int32; mov L0x416884 ( -294395108)@int32;
mov L0x416888 ( -123678909)@int32; mov L0x41688c ( -391567239)@int32;
mov L0x416890 (    2962264)@int32; mov L0x416894 (   -1148858)@int32;
mov L0x416898 (    -482649)@int32; mov L0x41689c (   -1528066)@int32;
mov L0x4168a0 (  814992530)@int32; mov L0x4168a4 (  925511710)@int32;
mov L0x4168a8 (  442566669)@int32; mov L0x4168ac (  454226054)@int32;
mov L0x4168b0 (    3180456)@int32; mov L0x4168b4 (    3611750)@int32;
mov L0x4168b8 (    1727088)@int32; mov L0x4168bc (    1772588)@int32;
mov L0x4168c0 (   68791907)@int32; mov L0x4168c4 ( -611800717)@int32;
mov L0x4168c8 ( -561940831)@int32; mov L0x4168cc ( 1062481036)@int32;
mov L0x4168d0 (     268456)@int32; mov L0x4168d4 (   -2387513)@int32;
mov L0x4168d8 (   -2192938)@int32; mov L0x4168dc (    4146264)@int32;
mov L0x4168e0 (    8380417)@int32; mov L0x4168e4 (          0)@int32;
mov L0x4168e8 (  429120452)@int32; mov L0x4168ec (    1674615)@int32;
mov L0x4168f0 ( -297218217)@int32; mov L0x4168f4 (   -1159875)@int32;
mov L0x4168f8 ( -949361686)@int32; mov L0x4168fc (   -3704823)@int32;
mov L0x416900 (-1065510939)@int32; mov L0x416904 (  284313712)@int32;
mov L0x416908 (  764594519)@int32; mov L0x41690c ( -720393920)@int32;
mov L0x416910 (   -4158088)@int32; mov L0x416914 (    1109516)@int32;
mov L0x416918 (    2983781)@int32; mov L0x41691c (   -2811291)@int32;
mov L0x416920 (  629190881)@int32; mov L0x416924 ( -162963861)@int32;
mov L0x416928 (  965793731)@int32; mov L0x41692c (  873958779)@int32;
mov L0x416930 (    2455377)@int32; mov L0x416934 (    -635956)@int32;
mov L0x416938 (    3768948)@int32; mov L0x41693c (    3410568)@int32;
mov L0x416940 (   64176841)@int32; mov L0x416944 (  909946047)@int32;
mov L0x416948 ( -686309310)@int32; mov L0x41694c (  431820817)@int32;
mov L0x416950 (     250446)@int32; mov L0x416954 (    3551006)@int32;
mov L0x416958 (   -2678278)@int32; mov L0x41695c (    1685153)@int32;
mov L0x416960 (    8380417)@int32; mov L0x416964 (          0)@int32;
mov L0x416968 ( -682491182)@int32; mov L0x41696c (   -2663378)@int32;
mov L0x416970 ( -538486762)@int32; mov L0x416974 (   -2101410)@int32;
mov L0x416978 (  797147778)@int32; mov L0x41697c (    3110818)@int32;
mov L0x416980 (  977780347)@int32; mov L0x416984 ( -496502727)@int32;
mov L0x416988 ( -519705671)@int32; mov L0x41698c ( -642926661)@int32;
mov L0x416990 (    3815725)@int32; mov L0x416994 (   -1937570)@int32;
mov L0x416998 (   -2028118)@int32; mov L0x41699c (   -2508980)@int32;
mov L0x4169a0 (  963363710)@int32; mov L0x4169a4 ( -409185979)@int32;
mov L0x4169a8 (  628875181)@int32; mov L0x4169ac ( -210776307)@int32;
mov L0x4169b0 (    3759465)@int32; mov L0x4169b4 (   -1596822)@int32;
mov L0x4169b8 (    2454145)@int32; mov L0x4169bc (    -822541)@int32;
mov L0x4169c0 ( 1013967746)@int32; mov L0x4169c4 (  507246529)@int32;
mov L0x4169c8 ( -258649997)@int32; mov L0x4169cc (    7126831)@int32;
mov L0x4169d0 (    3956944)@int32; mov L0x4169d4 (    1979497)@int32;
mov L0x4169d8 (   -1009365)@int32; mov L0x4169dc (      27812)@int32;
mov L0x4169e0 (    8380417)@int32; mov L0x4169e4 (          0)@int32;
mov L0x4169e8 ( 1041158200)@int32; mov L0x4169ec (    4063053)@int32;
mov L0x4169f0 (  919027554)@int32; mov L0x4169f4 (    3586446)@int32;
mov L0x4169f8 ( -702264730)@int32; mov L0x4169fc (   -2740543)@int32;
mov L0x416a00 (   70227934)@int32; mov L0x416a04 (  799869667)@int32;
mov L0x416a08 (  825844983)@int32; mov L0x416a0c (-1071989969)@int32;
mov L0x416a10 (     274060)@int32; mov L0x416a14 (    3121440)@int32;
mov L0x416a18 (    3222807)@int32; mov L0x416a1c (   -4183372)@int32;
mov L0x416a20 (  952468207)@int32; mov L0x416a24 (  588452222)@int32;
mov L0x416a28 ( 1016110510)@int32; mov L0x416a2c (  -22347069)@int32;
mov L0x416a30 (    3716946)@int32; mov L0x416a34 (    2296397)@int32;
mov L0x416a38 (    3965306)@int32; mov L0x416a3c (     -87208)@int32;
mov L0x416a40 (  841760171)@int32; mov L0x416a44 ( 1013916752)@int32;
mov L0x416a48 ( -163212680)@int32; mov L0x416a4c ( -302950022)@int32;
mov L0x416a50 (    3284915)@int32; mov L0x416a54 (    3956745)@int32;
mov L0x416a58 (    -636927)@int32; mov L0x416a5c (   -1182243)@int32;
mov L0x416a60 (    8380417)@int32; mov L0x416a64 (          0)@int32;
mov L0x416a68 (  863652652)@int32; mov L0x416a6c (    3370349)@int32;
mov L0x416a70 ( -815613168)@int32; mov L0x416a74 (   -3182878)@int32;
mov L0x416a78 ( -923069133)@int32; mov L0x416a7c (   -3602218)@int32;
mov L0x416a80 ( -987079667)@int32; mov L0x416a84 (  675340520)@int32;
mov L0x416a88 ( -327391679)@int32; mov L0x416a8c ( -787459213)@int32;
mov L0x416a90 (   -3852015)@int32; mov L0x416a94 (    2635473)@int32;
mov L0x416a98 (   -1277625)@int32; mov L0x416a9c (   -3073009)@int32;
mov L0x416aa0 ( -710479343)@int32; mov L0x416aa4 (  456183549)@int32;
mov L0x416aa8 (  373072124)@int32; mov L0x416aac (  495951789)@int32;
mov L0x416ab0 (   -2772600)@int32; mov L0x416ab4 (    1780227)@int32;
mov L0x416ab8 (    1455890)@int32; mov L0x416abc (    1935420)@int32;
mov L0x416ac0 (   15156688)@int32; mov L0x416ac4 ( -681730119)@int32;
mov L0x416ac8 (  681503850)@int32; mov L0x416acc (    -449207)@int32;
mov L0x416ad0 (      59148)@int32; mov L0x416ad4 (   -2660408)@int32;
mov L0x416ad8 (    2659525)@int32; mov L0x416adc (      -1753)@int32;

(* #! -> SP = 0xfffffffec500 *)
#! 0xfffffffec500 = 0xfffffffec500;
(* stp	x29, x30, [sp, #-48]!                       #! EA = L0xfffffffec4d0; PC = 0x413650 *)
mov L0xfffffffec4d0 x29; mov L0xfffffffec4d8 x30;
(* stp	x19, x20, [sp, #16]                         #! EA = L0xfffffffec4e0; PC = 0x413658 *)
mov L0xfffffffec4e0 x19; mov L0xfffffffec4e8 x20;
(* add	x19, x19, #0x9a0                            #! PC = 0x413660 *)
adds dc x19 x19 (0x9a0)@uint64;
(* str	x21, [sp, #32]                              #! EA = L0xfffffffec4f0; PC = 0x413664 *)
mov L0xfffffffec4f0 x21;
(* add	x21, x19, #0x8c0                            #! PC = 0x413668 *)
adds dc x21 x19 (0x8c0)@uint64;
(* mov	x2, x19                                     #! PC = 0x41366c *)
mov x2 x19;
(* mov	x20, x0                                     #! PC = 0x413670 *)
mov x20 x0;
(* mov	x1, x21                                     #! PC = 0x413674 *)
mov x1 x21;
(* #bl	0x414038 <_PQCLEAN_DILITHIUM3_AARCH64__asm_intt_SIMD_bot>#! PC = 0x413678 *)
#bl	0x414038 <_PQCLEAN_DILITHIUM3_AARCH64__asm_intt_SIMD_bot>#! 0x413678 = 0x413678;
(* #! -> SP = 0xfffffffec4d0 *)
#! 0xfffffffec4d0 = 0xfffffffec4d0;
(* stp	x19, x20, [sp]                              #! EA = L0xfffffffec440; PC = 0x41403c *)
mov L0xfffffffec440 x19; mov L0xfffffffec448 x20;
(* stp	x21, x22, [sp, #16]                         #! EA = L0xfffffffec450; PC = 0x414040 *)
mov L0xfffffffec450 x21; mov L0xfffffffec458 x22;
(* stp	x23, x24, [sp, #32]                         #! EA = L0xfffffffec460; PC = 0x414044 *)
mov L0xfffffffec460 x23; mov L0xfffffffec468 x24;
(* stp	x25, x26, [sp, #48]                         #! EA = L0xfffffffec470; PC = 0x414048 *)
mov L0xfffffffec470 x25; mov L0xfffffffec478 x26;
(* stp	x27, x28, [sp, #64]                         #! EA = L0xfffffffec480; PC = 0x41404c *)
mov L0xfffffffec480 x27; mov L0xfffffffec488 x28;
(* stp	d8, d9, [sp, #80]                           #! EA = L0xfffffffec490; PC = 0x414050 *)
mov L0xfffffffec490 d8; mov L0xfffffffec498 d9;
(* stp	d10, d11, [sp, #96]                         #! EA = L0xfffffffec4a0; PC = 0x414054 *)
mov L0xfffffffec4a0 d10; mov L0xfffffffec4a8 d11;
(* stp	d12, d13, [sp, #112]                        #! EA = L0xfffffffec4b0; PC = 0x414058 *)
mov L0xfffffffec4b0 d12; mov L0xfffffffec4b8 d13;
(* stp	d14, d15, [sp, #128]                        #! EA = L0xfffffffec4c0; PC = 0x41405c *)
mov L0xfffffffec4c0 d14; mov L0xfffffffec4c8 d15;
(* ldr	w20, [x2]                                   #! EA = L0x4159a0; Value = 0xfc7fdfff007fe001; PC = 0x414060 *)
mov w20 L0x4159a0;
(* ldr	x21, [x2, #8]                               #! EA = L0x4159a8; Value = 0x0000000100000100; PC = 0x414064 *)
mov x21 L0x4159a8;
(* add	x28, x1, #0x80                              #! PC = 0x414068 *)
adds dc x28 x1 (0x80)@uint64;
(* add	x27, x28, #0x400                            #! PC = 0x41406c *)
adds dc x27 x28 (0x400)@uint64;
(* add	x2, x0, #0x200                              #! PC = 0x414070 *)
adds dc x2 x0 (0x200)@uint64;
(* ldr	q8, [x28, #64]                              #! EA = L0x416320; Value = 0x0bf12f340b2bf4e7; PC = 0x414074 *)
mov %v8 [L0x416320, L0x416324, L0x416328, L0x41632c];
(* ldr	q9, [x28, #80]                              #! EA = L0x416330; Value = 0x000bee33000b292a; PC = 0x414078 *)
mov %v9 [L0x416330, L0x416334, L0x416338, L0x41633c];
(* ldr	q10, [x28, #96]                             #! EA = L0x416340; Value = 0xe2faaae5efe4eb5b; PC = 0x41407c *)
mov %v10 [L0x416340, L0x416344, L0x416348, L0x41634c];
(* ldr	q11, [x28, #112]                            #! EA = L0x416350; Value = 0xffe301ecffefe8f2; PC = 0x414080 *)
mov %v11 [L0x416350, L0x416354, L0x416358, L0x41635c];
(* ldr	q24, [x27, #64]                             #! EA = L0x416720; Value = 0x1cb673632147e6b7; PC = 0x414084 *)
mov %v24 [L0x416720, L0x416724, L0x416728, L0x41672c];
(* ldr	q25, [x27, #80]                             #! EA = L0x416730; Value = 0x001caf4600213f95; PC = 0x414088 *)
mov %v25 [L0x416730, L0x416734, L0x416738, L0x41673c];
(* ldr	q26, [x27, #96]                             #! EA = L0x416740; Value = 0xe0dacef20c816941; PC = 0x41408c *)
mov %v26 [L0x416740, L0x416744, L0x416748, L0x41674c];
(* ldr	q27, [x27, #112]                            #! EA = L0x416750; Value = 0xffe0e298000c7e49; PC = 0x414090 *)
mov %v27 [L0x416750, L0x416754, L0x416758, L0x41675c];
(* ldr	q0, [x0]                                    #! EA = L0xffffffff0610; Value = 0x002580110028dcbf; PC = 0x414094 *)
mov %v0 [L0xffffffff0610, L0xffffffff0614, L0xffffffff0618, L0xffffffff061c];
(* ldr	q1, [x0, #16]                               #! EA = L0xffffffff0620; Value = 0x002c52d500248820; PC = 0x414098 *)
mov %v1 [L0xffffffff0620, L0xffffffff0624, L0xffffffff0628, L0xffffffff062c];
(* ldr	q16, [x2]                                   #! EA = L0xffffffff0810; Value = 0xfff9fb470016a3c5; PC = 0x41409c *)
mov %v16 [L0xffffffff0810, L0xffffffff0814, L0xffffffff0818, L0xffffffff081c];
(* ldr	q17, [x2, #16]                              #! EA = L0xffffffff0820; Value = 0xffc5df4100283e08; PC = 0x4140a0 *)
mov %v17 [L0xffffffff0820, L0xffffffff0824, L0xffffffff0828, L0xffffffff082c];
(* ldr	q2, [x0, #32]                               #! EA = L0xffffffff0630; Value = 0xffcb93bbfff561ef; PC = 0x4140a4 *)
mov %v2 [L0xffffffff0630, L0xffffffff0634, L0xffffffff0638, L0xffffffff063c];
(* ldr	q3, [x0, #48]                               #! EA = L0xffffffff0640; Value = 0xffcee39affdf1f14; PC = 0x4140a8 *)
mov %v3 [L0xffffffff0640, L0xffffffff0644, L0xffffffff0648, L0xffffffff064c];
(* ldr	q18, [x2, #32]                              #! EA = L0xffffffff0830; Value = 0xfff69959ffee2f9d; PC = 0x4140ac *)
mov %v18 [L0xffffffff0830, L0xffffffff0834, L0xffffffff0838, L0xffffffff083c];
(* ldr	q19, [x2, #48]                              #! EA = L0xffffffff0840; Value = 0x00385aa2ffeaeb41; PC = 0x4140b0 *)
mov %v19 [L0xffffffff0840, L0xffffffff0844, L0xffffffff0848, L0xffffffff084c];
(* ldr	q4, [x28]                                   #! EA = L0x4162e0; Value = 0x00000000007fe001; PC = 0x4140b4 *)
mov %v4 [L0x4162e0, L0x4162e4, L0x4162e8, L0x4162ec];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4140b8 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4140bc *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x4162f0; Value = 0xffe3a490e39d7797; PC = 0x4140c0 *)
mov %v5 [L0x4162f0, L0x4162f4, L0x4162f8, L0x4162fc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4140c4 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4140c8 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416300; Value = 0x2229c02ce55adbec; PC = 0x4140cc *)
mov %v6 [L0x416300, L0x416304, L0x416308, L0x41630c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4140d0 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4140d4 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416310; Value = 0x00222136ffe56185; PC = 0x4140d8 *)
mov %v7 [L0x416310, L0x416314, L0x416318, L0x41631c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4140dc *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4140e0 *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x4166e0; Value = 0x00000000007fe001; PC = 0x4140e4 *)
mov %v20 [L0x4166e0, L0x4166e4, L0x4166e8, L0x4166ec];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4140e8 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4140ec *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x4166f0; Value = 0xffdf19eedf11b2af; PC = 0x4140f0 *)
mov %v21 [L0x4166f0, L0x4166f4, L0x4166f8, L0x4166fc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x4140f4 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x4140f8 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416700; Value = 0x31a452b1ce3b3631; PC = 0x4140fc *)
mov %v22 [L0x416700, L0x416704, L0x416708, L0x41670c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x414100 *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414104 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416710; Value = 0x003197eaffce47a7; PC = 0x414108 *)
mov %v23 [L0x416710, L0x416714, L0x416718, L0x41671c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x41410c *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x414110 *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414114 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414118 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o00@int32[4], %v2o00@int32[4]:
       %v0o00 =  %v0 /\  %v2o00 =  %v2 &&  %v0o00 =  %v0 /\  %v2o00 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x41411c *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414120 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414124 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x414128 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 0 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o00 +  %v1 /\ %v12 =  %v0o00 -  %v1 /\
     %v2 =  %v2o00 +  %v3 /\ %v13 =  %v2o00 -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o00@int32[4],%v18o00@int32[4],%v12o00@int32[4],%v13o00@int32[4]:
      %v16o00 = %v16 /\ %v18o00 = %v18 /\ %v12o00 = %v12 /\ %v13o00 = %v13
   && %v16o00 = %v16 /\ %v18o00 = %v18 /\ %v12o00 = %v12 /\ %v13o00 = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x41412c *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414130 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x414134 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x414138 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x41413c *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414140 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x414144 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x414148 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x41414c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414150 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o00*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o00*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o00*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o00*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 1 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o00 + %v17 /\ %v28 = %v16o00 - %v17 /\
    %v18 = %v18o00 + %v19 /\ %v29 = %v18o00 - %v19 /\
    eqmod  %v1 (%v12o00*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o00*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o01@int32[4], %v1o01@int32[4],%v28o01@int32[4],%v29o01@int32[4]:
       %v0o01 =  %v0 /\  %v1o01 =  %v1 /\%v28o01 = %v28 /\ %v29o01 = %v29
   &&  %v0o01 =  %v0 /\  %v1o01 =  %v1 /\%v28o01 = %v28 /\ %v29o01 = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x414154 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x414158 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x41415c *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414160 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x414164 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x414168 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x41416c *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414170 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414174 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x414178 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o01*%v25) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o01*%v27) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [0]] && true;
assume eqmod %v17 (%v28o01*%v25) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o01*%v27) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 2 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o01 +  %v2 /\ %v12 =  %v0o01 -  %v2 /\
     %v1 =  %v1o01 +  %v3 /\ %v13 =  %v1o01 -  %v3 /\
    eqmod %v17 (%v28o01*%v25) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o01*%v27) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [0]];

ghost %v16o01@int32[4],%v17o01@int32[4],%v12o01@int32[4],%v13o01@int32[4]:
      %v16o01 = %v16 /\ %v17o01 = %v17 /\%v12o01 = %v12 /\ %v13o01 = %v13
   && %v16o01 = %v16 /\ %v17o01 = %v17 /\%v12o01 = %v12 /\ %v13o01 = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x41417c *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414180 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414184 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414188 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x41418c *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414190 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414194 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414198 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x41419c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4141a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o01* %v7) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o01* %v7) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [1]] && true;
assume eqmod  %v2 (%v12o01* %v7) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o01* %v7) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 3 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o01 + %v18 /\ %v28 = %v16o01 - %v18 /\
    %v17 = %v17o01 + %v19 /\ %v29 = %v17o01 - %v19 /\
    eqmod  %v2 (%v12o01* %v7) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o01* %v7) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [1]];

ghost %v28o02@int32[4],%v29o02@int32[4]:
      %v28o02 = %v28 /\ %v29o02 = %v29 && %v28o02 = %v28 /\ %v29o02 = %v29;

(* mov	x19, #0x7                   	// #7          #! PC = 0x4141a4 *)
mov x19 (0x7)@uint64;
(* ldr	q8, [x28, #192]                             #! EA = L0x4163a0; Value = 0x1a38dc0305ff82d5; PC = 0x4141a8 *)
mov %v8 [L0x4163a0, L0x4163a4, L0x4163a8, L0x4163ac];
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x4141ac *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* ldr	q9, [x28, #208]                             #! EA = L0x4163b0; Value = 0x001a324e0005fe03; PC = 0x4141b0 *)
mov %v9 [L0x4163b0, L0x4163b4, L0x4163b8, L0x4163bc];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x4141b4 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* ldr	q10, [x28, #224]                            #! EA = L0x4163c0; Value = 0x2e0a9649d34eee15; PC = 0x4141b8 *)
mov %v10 [L0x4163c0, L0x4163c4, L0x4163c8, L0x4163cc];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4141bc *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4141c0 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q11, [x28, #240]                            #! EA = L0x4163d0; Value = 0x002dff14ffd35a1a; PC = 0x4141c4 *)
mov %v11 [L0x4163d0, L0x4163d4, L0x4163d8, L0x4163dc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4141c8 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4141cc *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x4141d0 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4141d4 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x4141d8 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4141dc *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4141e0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4141e4 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4141e8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o02*%v23) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o02*%v23) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o02*%v23) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o02*%v23) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 4 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o02*%v23) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o02*%v23) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4141ec *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q24, [x27, #192]                            #! EA = L0x4167a0; Value = 0xf6a2329f21e25b53; PC = 0x4141f0 *)
mov %v24 [L0x4167a0, L0x4167a4, L0x4167a8, L0x4167ac];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4141f4 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4141f8 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q25, [x27, #208]                            #! EA = L0x4167b0; Value = 0xfff6a48a0021d9e3; PC = 0x4141fc *)
mov %v25 [L0x4167b0, L0x4167b4, L0x4167b8, L0x4167bc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414200 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414204 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q26, [x27, #224]                            #! EA = L0x4167c0; Value = 0x14b1b845140335a5; PC = 0x414208 *)
mov %v26 [L0x4167c0, L0x4167c4, L0x4167c8, L0x4167cc];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41420c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414210 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q27, [x27, #240]                            #! EA = L0x4167d0; Value = 0x0014ac8c0013fe35; PC = 0x414214 *)
mov %v27 [L0x4167d0, L0x4167d4, L0x4167d8, L0x4167dc];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414218 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41421c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o02@int32[4], %v2o02@int32[4]:
       %v0o02 =  %v0 /\  %v2o02 =  %v2 &&  %v0o02 =  %v0 /\  %v2o02 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414220 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414224 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414228 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41422c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [2, 3]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 5 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o02 +  %v1 /\ %v12 =  %v0o02 -  %v1 /\
     %v2 =  %v2o02 +  %v3 /\ %v13 =  %v2o02 -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [2, 3]];

ghost %v16o02@int32[4],%v18o02@int32[4],%v12o02@int32[4],%v13o02@int32[4]:
      %v16o02 = %v16 /\ %v18o02 = %v18 /\%v12o02 = %v12 /\ %v13o02 = %v13
   && %v16o02 = %v16 /\ %v18o02 = %v18 /\%v12o02 = %v12 /\ %v13o02 = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414230 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414234 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414238 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41423c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x414240 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414244 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x414248 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x41424c *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x414250 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414254 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o02*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o02*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [3, 4]] && true;
assume eqmod  %v1 (%v12o02*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o02*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 6 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o02 + %v17 /\ %v28 = %v16o02 - %v17 /\
    %v18 = %v18o02 + %v19 /\ %v29 = %v18o02 - %v19 /\
    eqmod  %v1 (%v12o02*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o02*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [3, 4]];

ghost  %v0o03@int32[4], %v1o03@int32[4],%v28o03@int32[4],%v29o03@int32[4]:
       %v0o03 =  %v0 /\  %v1o03 =  %v1 /\%v28o03 = %v28 /\ %v29o03 = %v29
   &&  %v0o03 =  %v0 /\  %v1o03 =  %v1 /\%v28o03 = %v28 /\ %v29o03 = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x414258 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x41425c *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x414260 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414264 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x414268 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x41426c *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x414270 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414274 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414278 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41427c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o03*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o03*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [5]] && true;
assume eqmod %v17 (%v28o03*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o03*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 7 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o03 +  %v2 /\ %v12 =  %v0o03 -  %v2 /\
     %v1 =  %v1o03 +  %v3 /\ %v13 =  %v1o03 -  %v3 /\
    eqmod %v17 (%v28o03*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o03*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [5]];

ghost %v16o03@int32[4],%v17o03@int32[4],%v12o03@int32[4],%v13o03@int32[4]:
      %v16o03 = %v16 /\ %v17o03 = %v17 /\%v12o03 = %v12 /\ %v13o03 = %v13
   && %v16o03 = %v16 /\ %v17o03 = %v17 /\%v12o03 = %v12 /\ %v13o03 = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x414280 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414284 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x414288 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x41428c *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x414290 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414294 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x414298 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x41429c *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x4142a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4142a4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o03*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o03*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [6]] && true;
assume eqmod  %v2 (%v12o03*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o03*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 8 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o03 + %v18 /\ %v28 = %v16o03 - %v18 /\
    %v17 = %v17o03 + %v19 /\ %v29 = %v17o03 - %v19 /\
    eqmod  %v2 (%v12o03*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o03*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [6]];

ghost %v28o04@int32[4],%v29o04@int32[4]:
      %v28o04 = %v28 /\ %v29o04 = %v29 && %v28o04 = %v28 /\ %v29o04 = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x4142a8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x4142ac *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x4142b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x4142b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4142b8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4142bc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o04*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o04*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o04*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o04*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 9 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o04*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o04*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o04@int32[4], %v1o04@int32[4],%v16o04@int32[4],%v17o04@int32[4]:
       %v0o04 =  %v0 /\  %v1o04 =  %v1 /\%v16o04 = %v16 /\ %v17o04 = %v17
   &&  %v0o04 =  %v0 /\  %v1o04 =  %v1 /\%v16o04 = %v16 /\ %v17o04 = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff0630; PC = 0x4142c0 *)
mov [L0xffffffff0630, L0xffffffff0634, L0xffffffff0638, L0xffffffff063c] %v2;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x4142c4 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* ldr	q2, [x0, #96]                               #! EA = L0xffffffff0670; Value = 0x0031f5560039fe86; PC = 0x4142c8 *)
mov %v2 [L0xffffffff0670, L0xffffffff0674, L0xffffffff0678, L0xffffffff067c];
(* str	q3, [x0, #48]                               #! EA = L0xffffffff0640; PC = 0x4142cc *)
mov [L0xffffffff0640, L0xffffffff0644, L0xffffffff0648, L0xffffffff064c] %v3;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x4142d0 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* ldr	q3, [x0, #112]                              #! EA = L0xffffffff0680; Value = 0xffc582e4002b7a40; PC = 0x4142d4 *)
mov %v3 [L0xffffffff0680, L0xffffffff0684, L0xffffffff0688, L0xffffffff068c];
(* str	q18, [x2, #32]                              #! EA = L0xffffffff0830; PC = 0x4142d8 *)
mov [L0xffffffff0830, L0xffffffff0834, L0xffffffff0838, L0xffffffff083c] %v18;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x4142dc *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* ldr	q18, [x2, #96]                              #! EA = L0xffffffff0870; Value = 0xfff78435ffd70d48; PC = 0x4142e0 *)
mov %v18 [L0xffffffff0870, L0xffffffff0874, L0xffffffff0878, L0xffffffff087c];
(* str	q19, [x2, #48]                              #! EA = L0xffffffff0840; PC = 0x4142e4 *)
mov [L0xffffffff0840, L0xffffffff0844, L0xffffffff0848, L0xffffffff084c] %v19;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x4142e8 *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* ldr	q19, [x2, #112]                             #! EA = L0xffffffff0880; Value = 0x0022bb91ffe13f8c; PC = 0x4142ec *)
mov %v19 [L0xffffffff0880, L0xffffffff0884, L0xffffffff0888, L0xffffffff088c];
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x4142f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff0610; PC = 0x4142f4 *)
mov [L0xffffffff0610, L0xffffffff0614, L0xffffffff0618, L0xffffffff061c] %v0;
(* ldr	q0, [x0, #64]                               #! EA = L0xffffffff0650; Value = 0xffc0318900120bc2; PC = 0x4142f8 *)
mov %v0 [L0xffffffff0650, L0xffffffff0654, L0xffffffff0658, L0xffffffff065c];
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x4142fc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff0620; PC = 0x414300 *)
mov [L0xffffffff0620, L0xffffffff0624, L0xffffffff0628, L0xffffffff062c] %v1;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff0660; Value = 0xffc430f200321467; PC = 0x414304 *)
mov %v1 [L0xffffffff0660, L0xffffffff0664, L0xffffffff0668, L0xffffffff066c];
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414308 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* str	q16, [x2]                                   #! EA = L0xffffffff0810; PC = 0x41430c *)
mov [L0xffffffff0810, L0xffffffff0814, L0xffffffff0818, L0xffffffff081c] %v16;
(* ldr	q16, [x2, #64]                              #! EA = L0xffffffff0850; Value = 0xfff24653fff4d8d7; PC = 0x414310 *)
mov %v16 [L0xffffffff0850, L0xffffffff0854, L0xffffffff0858, L0xffffffff085c];
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x414314 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff0820; PC = 0x414318 *)
mov [L0xffffffff0820, L0xffffffff0824, L0xffffffff0828, L0xffffffff082c] %v17;

assert eqmod [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]
              %v0o04 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]
              %v1o04 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]
             %v16o04 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]
             %v17o04 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
       [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
       [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
       [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
       [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
       [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
       [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
       [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
       [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [7, 8]] && true;

assume eqmod [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]
              %v0o04 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]
              %v1o04 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]
             %v16o04 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]
             %v17o04 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
       [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
       [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
       [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
       [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
       [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
       [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
       [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
       [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
       [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
       [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
       [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
       [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
       [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
       [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
       [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
       [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<s[Q,Q,Q,Q];
(* CUT 10 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c,
                   L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c,
                   L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c,
                   L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c])
          (16*F**2) [Q, X**16 - 1753** 16] /\
    eqmod (poly X [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c,
                   L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c,
                   L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c,
                   L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c])
          (16*F**2) [Q, X**16 - 1753** 48] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
    [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
    [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
    [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
    [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
    [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
    [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
    [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
    [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
    [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
    [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
    [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
    [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
    [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
    [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
    [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
    [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<s[Q,Q,Q,Q];

(* ldr	q17, [x2, #80]                              #! EA = L0xffffffff0860; Value = 0x000dd4deffde8186; PC = 0x41431c *)
mov %v17 [L0xffffffff0860, L0xffffffff0864, L0xffffffff0868, L0xffffffff086c];
(* add	x28, x28, #0x80                             #! PC = 0x414320 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414324 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414328 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41432c *)
adds dc x2 x2 (0x40)@uint64;
(* ldr	q4, [x28]                                   #! EA = L0x416360; Value = 0x00000000007fe001; PC = 0x414330 *)
mov %v4 [L0x416360, L0x416364, L0x416368, L0x41636c];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x414334 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414338 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x416370; Value = 0xffe3b692e3af7e18; PC = 0x41433c *)
mov %v5 [L0x416370, L0x416374, L0x416378, L0x41637c];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x414340 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414344 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416380; Value = 0xf08e0ca223f52401; PC = 0x414348 *)
mov %v6 [L0x416380, L0x416384, L0x416388, L0x41638c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41434c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414350 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416390; Value = 0xfff091e90023ec27; PC = 0x414354 *)
mov %v7 [L0x416390, L0x416394, L0x416398, L0x41639c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414358 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41435c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x416760; Value = 0x00000000007fe001; PC = 0x414360 *)
mov %v20 [L0x416760, L0x416764, L0x416768, L0x41676c];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414364 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414368 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x416770; Value = 0x003d532d3d628527; PC = 0x41436c *)
mov %v21 [L0x416770, L0x416774, L0x416778, L0x41677c];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414370 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414374 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416780; Value = 0xe1a3831e30d574fc; PC = 0x414378 *)
mov %v22 [L0x416780, L0x416784, L0x416788, L0x41678c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41437c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414380 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416790; Value = 0xffe1ab1a0030c940; PC = 0x414384 *)
mov %v23 [L0x416790, L0x416794, L0x416798, L0x41679c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414388 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41438c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414390 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414394 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o05@int32[4], %v2o05@int32[4]:
       %v0o05 =  %v0 /\  %v2o05 =  %v2 &&  %v0o05 =  %v0 /\  %v2o05 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414398 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x41439c *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x4143a0 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x4143a4 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 11 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o05 +  %v1 /\ %v12 =  %v0o05 -  %v1 /\
     %v2 =  %v2o05 +  %v3 /\ %v13 =  %v2o05 -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o05@int32[4],%v18o05@int32[4],%v12o05@int32[4],%v13o05@int32[4]:
      %v16o05 = %v16 /\ %v18o05 = %v18 /\%v12o05 = %v12 /\ %v13o05 = %v13
   && %v16o05 = %v16 /\ %v18o05 = %v18 /\%v12o05 = %v12 /\ %v13o05 = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x4143a8 *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x4143ac *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x4143b0 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x4143b4 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x4143b8 *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4143bc *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x4143c0 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4143c4 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4143c8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4143cc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o05*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o05*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o05*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o05*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 12 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o05 + %v17 /\ %v28 = %v16o05 - %v17 /\
    %v18 = %v18o05 + %v19 /\ %v29 = %v18o05 - %v19 /\
    eqmod  %v1 (%v12o05*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o05*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o06@int32[4], %v1o06@int32[4],%v28o06@int32[4],%v29o06@int32[4]:
       %v0o06 =  %v0 /\  %v1o06 =  %v1 /\%v28o06 = %v28 /\ %v29o06 = %v29
   &&  %v0o06 =  %v0 /\  %v1o06 =  %v1 /\%v28o06 = %v28 /\ %v29o06 = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x4143d0 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4143d4 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x4143d8 *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4143dc *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x4143e0 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4143e4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x4143e8 *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4143ec *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4143f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4143f4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o06*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o06*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [11]] && true;
assume eqmod %v17 (%v28o06*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o06*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 13 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o06 +  %v2 /\ %v12 =  %v0o06 -  %v2 /\
     %v1 =  %v1o06 +  %v3 /\ %v13 =  %v1o06 -  %v3 /\
    eqmod %v17 (%v28o06*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o06*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [11]];

ghost %v16o06@int32[4],%v17o06@int32[4],%v12o06@int32[4],%v13o06@int32[4]:
      %v16o06 = %v16 /\ %v17o06 = %v17 /\%v12o06 = %v12 /\ %v13o06 = %v13
   && %v16o06 = %v16 /\ %v17o06 = %v17 /\%v12o06 = %v12 /\ %v13o06 = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x4143f8 *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4143fc *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414400 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414404 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x414408 *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x41440c *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414410 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414414 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414418 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x41441c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o06*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o06*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [12]] && true;
assume eqmod  %v2 (%v12o06*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o06*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 14 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o06 + %v18 /\ %v28 = %v16o06 - %v18 /\
    %v17 = %v17o06 + %v19 /\ %v29 = %v17o06 - %v19 /\
    eqmod  %v2 (%v12o06*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o06*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [12]];

ghost %v28o07@int32[4],%v29o07@int32[4]:
      %v28o07 = %v28 /\ %v29o07 = %v29 && %v28o07 = %v28 /\ %v29o07 = %v29;

(* sub	x19, x19, #0x1                              #! PC = 0x414420 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! PC = 0x414424 *)
#cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! 0x414424 = 0x414424;
(* ldr	q8, [x28, #192]                             #! EA = L0x416420; Value = 0xcb9ac31a17206fee; PC = 0x4141a8 *)
mov %v8 [L0x416420, L0x416424, L0x416428, L0x41642c];
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x4141ac *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* ldr	q9, [x28, #208]                             #! EA = L0x416430; Value = 0xffcba7dc00171aa8; PC = 0x4141b0 *)
mov %v9 [L0x416430, L0x416434, L0x416438, L0x41643c];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x4141b4 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* ldr	q10, [x28, #224]                            #! EA = L0x416440; Value = 0xf2dcc74cfddba2ed; PC = 0x4141b8 *)
mov %v10 [L0x416440, L0x416444, L0x416448, L0x41644c];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4141bc *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4141c0 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q11, [x28, #240]                            #! EA = L0x416450; Value = 0xfff2e010fffddc2c; PC = 0x4141c4 *)
mov %v11 [L0x416450, L0x416454, L0x416458, L0x41645c];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4141c8 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4141cc *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x4141d0 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4141d4 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x4141d8 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4141dc *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4141e0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4141e4 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4141e8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o07*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o07*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o07*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o07*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 15 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o07*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o07*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4141ec *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q24, [x27, #192]                            #! EA = L0x416820; Value = 0xd7a1c4c200308d23; PC = 0x4141f0 *)
mov %v24 [L0x416820, L0x416824, L0x416828, L0x41682c];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4141f4 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4141f8 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q25, [x27, #208]                            #! EA = L0x416830; Value = 0xffd7abdc00003081; PC = 0x4141fc *)
mov %v25 [L0x416830, L0x416834, L0x416838, L0x41683c];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414200 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414204 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q26, [x27, #224]                            #! EA = L0x416840; Value = 0xcf30b08eecd80828; PC = 0x414208 *)
mov %v26 [L0x416840, L0x416844, L0x416848, L0x41684c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41420c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414210 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q27, [x27, #240]                            #! EA = L0x416850; Value = 0xffcf3ce4ffecdcd2; PC = 0x414214 *)
mov %v27 [L0x416850, L0x416854, L0x416858, L0x41685c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414218 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41421c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o07@int32[4], %v2o07@int32[4]:
       %v0o07 =  %v0 /\  %v2o07 =  %v2 &&  %v0o07 =  %v0 /\  %v2o07 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414220 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414224 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414228 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41422c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [13, 14]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 16 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o07 +  %v1 /\ %v12 =  %v0o07 -  %v1 /\
     %v2 =  %v2o07 +  %v3 /\ %v13 =  %v2o07 -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [13, 14]];

ghost %v16o07@int32[4],%v18o07@int32[4],%v12o07@int32[4],%v13o07@int32[4]:
      %v16o07 = %v16 /\ %v18o07 = %v18 /\%v12o07 = %v12 /\ %v13o07 = %v13
   && %v16o07 = %v16 /\ %v18o07 = %v18 /\%v12o07 = %v12 /\ %v13o07 = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414230 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414234 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414238 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41423c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x414240 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414244 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x414248 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x41424c *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x414250 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414254 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o07*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o07*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [14, 15]] && true;
assume eqmod  %v1 (%v12o07*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o07*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 17 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o07 + %v17 /\ %v28 = %v16o07 - %v17 /\
    %v18 = %v18o07 + %v19 /\ %v29 = %v18o07 - %v19 /\
    eqmod  %v1 (%v12o07*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o07*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [14, 15]];

ghost  %v0o08@int32[4], %v1o08@int32[4],%v28o08@int32[4],%v29o08@int32[4]:
       %v0o08 =  %v0 /\  %v1o08 =  %v1 /\%v28o08 = %v28 /\ %v29o08 = %v29
   &&  %v0o08 =  %v0 /\  %v1o08 =  %v1 /\%v28o08 = %v28 /\ %v29o08 = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x414258 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x41425c *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x414260 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414264 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x414268 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x41426c *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x414270 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414274 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414278 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41427c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o08*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o08*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [16]] && true;
assume eqmod %v17 (%v28o08*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o08*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 18 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o08 +  %v2 /\ %v12 =  %v0o08 -  %v2 /\
     %v1 =  %v1o08 +  %v3 /\ %v13 =  %v1o08 -  %v3 /\
    eqmod %v17 (%v28o08*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o08*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [16]];

ghost %v16o08@int32[4],%v17o08@int32[4],%v12o08@int32[4],%v13o08@int32[4]:
      %v16o08 = %v16 /\ %v17o08 = %v17 /\%v12o08 = %v12 /\ %v13o08 = %v13
   && %v16o08 = %v16 /\ %v17o08 = %v17 /\%v12o08 = %v12 /\ %v13o08 = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x414280 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414284 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x414288 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x41428c *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x414290 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414294 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x414298 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x41429c *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x4142a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4142a4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o08*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o08*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [17]] && true;
assume eqmod  %v2 (%v12o08*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o08*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 19 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o08 + %v18 /\ %v28 = %v16o08 - %v18 /\
    %v17 = %v17o08 + %v19 /\ %v29 = %v17o08 - %v19 /\
    eqmod  %v2 (%v12o08*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o08*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [17]];

ghost %v28o09@int32[4],%v29o09@int32[4]:
      %v28o09 = %v28 /\ %v29o09 = %v29 && %v28o09 = %v28 /\ %v29o09 = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x4142a8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x4142ac *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x4142b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x4142b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4142b8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4142bc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o09*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o09*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o09*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o09*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 20 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o09*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o09*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o09@int32[4], %v1o09@int32[4],%v16o09@int32[4],%v17o09@int32[4]:
       %v0o09 =  %v0 /\  %v1o09 =  %v1 /\%v16o09 = %v16 /\ %v17o09 = %v17
   &&  %v0o09 =  %v0 /\  %v1o09 =  %v1 /\%v16o09 = %v16 /\ %v17o09 = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff0670; PC = 0x4142c0 *)
mov [L0xffffffff0670, L0xffffffff0674, L0xffffffff0678, L0xffffffff067c] %v2;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x4142c4 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* ldr	q2, [x0, #96]                               #! EA = L0xffffffff06b0; Value = 0xffea834dffd5a8d2; PC = 0x4142c8 *)
mov %v2 [L0xffffffff06b0, L0xffffffff06b4, L0xffffffff06b8, L0xffffffff06bc];
(* str	q3, [x0, #48]                               #! EA = L0xffffffff0680; PC = 0x4142cc *)
mov [L0xffffffff0680, L0xffffffff0684, L0xffffffff0688, L0xffffffff068c] %v3;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x4142d0 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* ldr	q3, [x0, #112]                              #! EA = L0xffffffff06c0; Value = 0x0001da4dffe6830e; PC = 0x4142d4 *)
mov %v3 [L0xffffffff06c0, L0xffffffff06c4, L0xffffffff06c8, L0xffffffff06cc];
(* str	q18, [x2, #32]                              #! EA = L0xffffffff0870; PC = 0x4142d8 *)
mov [L0xffffffff0870, L0xffffffff0874, L0xffffffff0878, L0xffffffff087c] %v18;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x4142dc *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* ldr	q18, [x2, #96]                              #! EA = L0xffffffff08b0; Value = 0xffdaf35cfffb7b73; PC = 0x4142e0 *)
mov %v18 [L0xffffffff08b0, L0xffffffff08b4, L0xffffffff08b8, L0xffffffff08bc];
(* str	q19, [x2, #48]                              #! EA = L0xffffffff0880; PC = 0x4142e4 *)
mov [L0xffffffff0880, L0xffffffff0884, L0xffffffff0888, L0xffffffff088c] %v19;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x4142e8 *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* ldr	q19, [x2, #112]                             #! EA = L0xffffffff08c0; Value = 0x002d7329003e211a; PC = 0x4142ec *)
mov %v19 [L0xffffffff08c0, L0xffffffff08c4, L0xffffffff08c8, L0xffffffff08cc];
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x4142f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff0650; PC = 0x4142f4 *)
mov [L0xffffffff0650, L0xffffffff0654, L0xffffffff0658, L0xffffffff065c] %v0;
(* ldr	q0, [x0, #64]                               #! EA = L0xffffffff0690; Value = 0x00294bbeffce2bab; PC = 0x4142f8 *)
mov %v0 [L0xffffffff0690, L0xffffffff0694, L0xffffffff0698, L0xffffffff069c];
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x4142fc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff0660; PC = 0x414300 *)
mov [L0xffffffff0660, L0xffffffff0664, L0xffffffff0668, L0xffffffff066c] %v1;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff06a0; Value = 0xffe0361600169b09; PC = 0x414304 *)
mov %v1 [L0xffffffff06a0, L0xffffffff06a4, L0xffffffff06a8, L0xffffffff06ac];
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414308 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* str	q16, [x2]                                   #! EA = L0xffffffff0850; PC = 0x41430c *)
mov [L0xffffffff0850, L0xffffffff0854, L0xffffffff0858, L0xffffffff085c] %v16;
(* ldr	q16, [x2, #64]                              #! EA = L0xffffffff0890; Value = 0xffc9951dffe6c615; PC = 0x414310 *)
mov %v16 [L0xffffffff0890, L0xffffffff0894, L0xffffffff0898, L0xffffffff089c];
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x414314 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff0860; PC = 0x414318 *)
mov [L0xffffffff0860, L0xffffffff0864, L0xffffffff0868, L0xffffffff086c] %v17;
(* ldr	q17, [x2, #80]                              #! EA = L0xffffffff08a0; Value = 0xffc432e80022c565; PC = 0x41431c *)
mov %v17 [L0xffffffff08a0, L0xffffffff08a4, L0xffffffff08a8, L0xffffffff08ac];

assert eqmod [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]
              %v0o09 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]
              %v1o09 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]
             %v16o09 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]
             %v17o09 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
       [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
       [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
       [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
       [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
       [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
       [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
       [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
       [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [18, 19]] && true;

assume eqmod [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]
              %v0o09 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]
              %v1o09 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]
             %v16o09 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]
             %v17o09 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
       [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
       [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
       [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
       [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
       [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
       [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
       [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
       [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
       [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
       [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
       [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
       [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
       [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
       [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
       [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
       [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<s[Q,Q,Q,Q];
(* CUT 21 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c,
                   L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c,
                   L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c,
                   L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c])
          (16*F**2) [Q, X**16 - 1753**272] /\
    eqmod (poly X [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c,
                   L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c,
                   L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c,
                   L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c])
          (16*F**2) [Q, X**16 - 1753**304] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
    [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
    [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
    [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
    [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
    [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
    [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
    [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
    [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
    [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
    [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
    [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
    [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
    [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
    [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
    [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
    [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<s[Q,Q,Q,Q];

(* add	x28, x28, #0x80                             #! PC = 0x414320 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414324 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414328 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41432c *)
adds dc x2 x2 (0x40)@uint64;
(* ldr	q4, [x28]                                   #! EA = L0x4163e0; Value = 0x00000000007fe001; PC = 0x414330 *)
mov %v4 [L0x4163e0, L0x4163e4, L0x4163e8, L0x4163ec];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x414334 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414338 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x4163f0; Value = 0xffc4f193c4e2cc29; PC = 0x41433c *)
mov %v5 [L0x4163f0, L0x4163f4, L0x4163f8, L0x4163fc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x414340 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414344 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416400; Value = 0x09fa598207035bc9; PC = 0x414348 *)
mov %v6 [L0x416400, L0x416404, L0x416408, L0x41640c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41434c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414350 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416410; Value = 0x0009f7db0007019b; PC = 0x414354 *)
mov %v7 [L0x416410, L0x416414, L0x416418, L0x41641c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414358 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41435c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x4167e0; Value = 0x00000000007fe001; PC = 0x414360 *)
mov %v20 [L0x4167e0, L0x4167e4, L0x4167e8, L0x4167ec];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414364 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414368 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x4167f0; Value = 0x003580cc358e2f21; PC = 0x41436c *)
mov %v21 [L0x4167f0, L0x4167f4, L0x4167f8, L0x4167fc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414370 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414374 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416800; Value = 0xda63ad3732edaa05; PC = 0x414378 *)
mov %v22 [L0x416800, L0x416804, L0x416808, L0x41680c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41437c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414380 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416810; Value = 0xffda6d140032e0ef; PC = 0x414384 *)
mov %v23 [L0x416810, L0x416814, L0x416818, L0x41681c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414388 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41438c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414390 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414394 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o0a@int32[4], %v2o0a@int32[4]:
       %v0o0a =  %v0 /\  %v2o0a =  %v2 &&  %v0o0a =  %v0 /\  %v2o0a =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414398 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x41439c *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x4143a0 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x4143a4 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 22 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o0a +  %v1 /\ %v12 =  %v0o0a -  %v1 /\
     %v2 =  %v2o0a +  %v3 /\ %v13 =  %v2o0a -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o0a@int32[4],%v18o0a@int32[4],%v12o0a@int32[4],%v13o0a@int32[4]:
      %v16o0a = %v16 /\ %v18o0a = %v18 /\%v12o0a = %v12 /\ %v13o0a = %v13
   && %v16o0a = %v16 /\ %v18o0a = %v18 /\%v12o0a = %v12 /\ %v13o0a = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x4143a8 *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x4143ac *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x4143b0 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x4143b4 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x4143b8 *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4143bc *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x4143c0 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4143c4 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4143c8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4143cc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o0a*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0a*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o0a*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0a*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 23 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o0a + %v17 /\ %v28 = %v16o0a - %v17 /\
    %v18 = %v18o0a + %v19 /\ %v29 = %v18o0a - %v19 /\
    eqmod  %v1 (%v12o0a*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o0a*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o0b@int32[4], %v1o0b@int32[4],%v28o0b@int32[4],%v29o0b@int32[4]:
       %v0o0b =  %v0 /\  %v1o0b =  %v1 /\%v28o0b = %v28 /\ %v29o0b = %v29
   &&  %v0o0b =  %v0 /\  %v1o0b =  %v1 /\%v28o0b = %v28 /\ %v29o0b = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x4143d0 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4143d4 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x4143d8 *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4143dc *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x4143e0 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4143e4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x4143e8 *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4143ec *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4143f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4143f4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o0b*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0b*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [22]] && true;
assume eqmod %v17 (%v28o0b*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0b*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 24 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o0b +  %v2 /\ %v12 =  %v0o0b -  %v2 /\
     %v1 =  %v1o0b +  %v3 /\ %v13 =  %v1o0b -  %v3 /\
    eqmod %v17 (%v28o0b*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o0b*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [22]];

ghost %v16o0b@int32[4],%v17o0b@int32[4],%v12o0b@int32[4],%v13o0b@int32[4]:
      %v16o0b = %v16 /\ %v17o0b = %v17 /\%v12o0b = %v12 /\ %v13o0b = %v13
   && %v16o0b = %v16 /\ %v17o0b = %v17 /\%v12o0b = %v12 /\ %v13o0b = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x4143f8 *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4143fc *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414400 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414404 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x414408 *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x41440c *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414410 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414414 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414418 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x41441c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o0b*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0b*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [23]] && true;
assume eqmod  %v2 (%v12o0b*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0b*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 25 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o0b + %v18 /\ %v28 = %v16o0b - %v18 /\
    %v17 = %v17o0b + %v19 /\ %v29 = %v17o0b - %v19 /\
    eqmod  %v2 (%v12o0b*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o0b*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [23]];

ghost %v28o0c@int32[4],%v29o0c@int32[4]:
      %v28o0c = %v28 /\ %v29o0c = %v29 && %v28o0c = %v28 /\ %v29o0c = %v29;

(* sub	x19, x19, #0x1                              #! PC = 0x414420 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! PC = 0x414424 *)
#cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! 0x414424 = 0x414424;
(* ldr	q8, [x28, #192]                             #! EA = L0x4164a0; Value = 0xfcb7cdfa0bc47a07; PC = 0x4141a8 *)
mov %v8 [L0x4164a0, L0x4164a4, L0x4164a8, L0x4164ac];
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x4141ac *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* ldr	q9, [x28, #208]                             #! EA = L0x4164b0; Value = 0xfffcb8a0000bc189; PC = 0x4141b0 *)
mov %v9 [L0x4164b0, L0x4164b4, L0x4164b8, L0x4164bc];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x4141b4 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* ldr	q10, [x28, #224]                            #! EA = L0x4164c0; Value = 0xcca0527bf7ab8af3; PC = 0x4141b8 *)
mov %v10 [L0x4164c0, L0x4164c4, L0x4164c8, L0x4164cc];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4141bc *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4141c0 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q11, [x28, #240]                            #! EA = L0x4164d0; Value = 0xffccad2afff7ada0; PC = 0x4141c4 *)
mov %v11 [L0x4164d0, L0x4164d4, L0x4164d8, L0x4164dc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4141c8 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4141cc *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x4141d0 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4141d4 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x4141d8 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4141dc *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4141e0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4141e4 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4141e8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o0c*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0c*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o0c*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0c*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 26 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o0c*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o0c*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4141ec *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q24, [x27, #192]                            #! EA = L0x4168a0; Value = 0x372a301e3093cc92; PC = 0x4141f0 *)
mov %v24 [L0x4168a0, L0x4168a4, L0x4168a8, L0x4168ac];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4141f4 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4141f8 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q25, [x27, #208]                            #! EA = L0x4168b0; Value = 0x00371c66003087a8; PC = 0x4141fc *)
mov %v25 [L0x4168b0, L0x4168b4, L0x4168b8, L0x4168bc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414200 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414204 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q26, [x27, #224]                            #! EA = L0x4168c0; Value = 0xdb88a9730419ae63; PC = 0x414208 *)
mov %v26 [L0x4168c0, L0x4168c4, L0x4168c8, L0x4168cc];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41420c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414210 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q27, [x27, #240]                            #! EA = L0x4168d0; Value = 0xffdb91c7000418a8; PC = 0x414214 *)
mov %v27 [L0x4168d0, L0x4168d4, L0x4168d8, L0x4168dc];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414218 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41421c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o0c@int32[4], %v2o0c@int32[4]:
       %v0o0c =  %v0 /\  %v2o0c =  %v2 &&  %v0o0c =  %v0 /\  %v2o0c =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414220 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414224 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414228 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41422c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [24, 25]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 27 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o0c +  %v1 /\ %v12 =  %v0o0c -  %v1 /\
     %v2 =  %v2o0c +  %v3 /\ %v13 =  %v2o0c -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [24, 25]];

ghost %v16o0c@int32[4],%v18o0c@int32[4],%v12o0c@int32[4],%v13o0c@int32[4]:
      %v16o0c = %v16 /\ %v18o0c = %v18 /\%v12o0c = %v12 /\ %v13o0c = %v13
   && %v16o0c = %v16 /\ %v18o0c = %v18 /\%v12o0c = %v12 /\ %v13o0c = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414230 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414234 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414238 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41423c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x414240 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414244 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x414248 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x41424c *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x414250 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414254 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o0c*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0c*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [25, 26]] && true;
assume eqmod  %v1 (%v12o0c*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0c*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 28 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o0c + %v17 /\ %v28 = %v16o0c - %v17 /\
    %v18 = %v18o0c + %v19 /\ %v29 = %v18o0c - %v19 /\
    eqmod  %v1 (%v12o0c*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o0c*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [25, 26]];

ghost  %v0o0d@int32[4], %v1o0d@int32[4],%v28o0d@int32[4],%v29o0d@int32[4]:
       %v0o0d =  %v0 /\  %v1o0d =  %v1 /\%v28o0d = %v28 /\ %v29o0d = %v29
   &&  %v0o0d =  %v0 /\  %v1o0d =  %v1 /\%v28o0d = %v28 /\ %v29o0d = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x414258 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x41425c *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x414260 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414264 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x414268 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x41426c *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x414270 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414274 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414278 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41427c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o0d*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0d*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [27]] && true;
assume eqmod %v17 (%v28o0d*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0d*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 29 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o0d +  %v2 /\ %v12 =  %v0o0d -  %v2 /\
     %v1 =  %v1o0d +  %v3 /\ %v13 =  %v1o0d -  %v3 /\
    eqmod %v17 (%v28o0d*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o0d*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [27]];

ghost %v16o0d@int32[4],%v17o0d@int32[4],%v12o0d@int32[4],%v13o0d@int32[4]:
      %v16o0d = %v16 /\ %v17o0d = %v17 /\%v12o0d = %v12 /\ %v13o0d = %v13
   && %v16o0d = %v16 /\ %v17o0d = %v17 /\%v12o0d = %v12 /\ %v13o0d = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x414280 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414284 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x414288 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x41428c *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x414290 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414294 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x414298 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x41429c *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x4142a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4142a4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o0d*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0d*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [28]] && true;
assume eqmod  %v2 (%v12o0d*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0d*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 30 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o0d + %v18 /\ %v28 = %v16o0d - %v18 /\
    %v17 = %v17o0d + %v19 /\ %v29 = %v17o0d - %v19 /\
    eqmod  %v2 (%v12o0d*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o0d*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [28]];

ghost %v28o0e@int32[4],%v29o0e@int32[4]:
      %v28o0e = %v28 /\ %v29o0e = %v29 && %v28o0e = %v28 /\ %v29o0e = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x4142a8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x4142ac *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x4142b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x4142b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4142b8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4142bc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o0e*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0e*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o0e*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o0e*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 31 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o0e*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o0e*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o0e@int32[4], %v1o0e@int32[4],%v16o0e@int32[4],%v17o0e@int32[4]:
       %v0o0e =  %v0 /\  %v1o0e =  %v1 /\%v16o0e = %v16 /\ %v17o0e = %v17
   &&  %v0o0e =  %v0 /\  %v1o0e =  %v1 /\%v16o0e = %v16 /\ %v17o0e = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff06b0; PC = 0x4142c0 *)
mov [L0xffffffff06b0, L0xffffffff06b4, L0xffffffff06b8, L0xffffffff06bc] %v2;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x4142c4 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* ldr	q2, [x0, #96]                               #! EA = L0xffffffff06f0; Value = 0x00018e5affce1dee; PC = 0x4142c8 *)
mov %v2 [L0xffffffff06f0, L0xffffffff06f4, L0xffffffff06f8, L0xffffffff06fc];
(* str	q3, [x0, #48]                               #! EA = L0xffffffff06c0; PC = 0x4142cc *)
mov [L0xffffffff06c0, L0xffffffff06c4, L0xffffffff06c8, L0xffffffff06cc] %v3;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x4142d0 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* ldr	q3, [x0, #112]                              #! EA = L0xffffffff0700; Value = 0xffce890d003a1f04; PC = 0x4142d4 *)
mov %v3 [L0xffffffff0700, L0xffffffff0704, L0xffffffff0708, L0xffffffff070c];
(* str	q18, [x2, #32]                              #! EA = L0xffffffff08b0; PC = 0x4142d8 *)
mov [L0xffffffff08b0, L0xffffffff08b4, L0xffffffff08b8, L0xffffffff08bc] %v18;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x4142dc *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* ldr	q18, [x2, #96]                              #! EA = L0xffffffff08f0; Value = 0x002f6648001f36ed; PC = 0x4142e0 *)
mov %v18 [L0xffffffff08f0, L0xffffffff08f4, L0xffffffff08f8, L0xffffffff08fc];
(* str	q19, [x2, #48]                              #! EA = L0xffffffff08c0; PC = 0x4142e4 *)
mov [L0xffffffff08c0, L0xffffffff08c4, L0xffffffff08c8, L0xffffffff08cc] %v19;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x4142e8 *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* ldr	q19, [x2, #112]                             #! EA = L0xffffffff0900; Value = 0xfff29f0700323cf2; PC = 0x4142ec *)
mov %v19 [L0xffffffff0900, L0xffffffff0904, L0xffffffff0908, L0xffffffff090c];
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x4142f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff0690; PC = 0x4142f4 *)
mov [L0xffffffff0690, L0xffffffff0694, L0xffffffff0698, L0xffffffff069c] %v0;
(* ldr	q0, [x0, #64]                               #! EA = L0xffffffff06d0; Value = 0x000b85f4002bd26b; PC = 0x4142f8 *)
mov %v0 [L0xffffffff06d0, L0xffffffff06d4, L0xffffffff06d8, L0xffffffff06dc];
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x4142fc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff06a0; PC = 0x414300 *)
mov [L0xffffffff06a0, L0xffffffff06a4, L0xffffffff06a8, L0xffffffff06ac] %v1;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff06e0; Value = 0x00217234001c9c0d; PC = 0x414304 *)
mov %v1 [L0xffffffff06e0, L0xffffffff06e4, L0xffffffff06e8, L0xffffffff06ec];
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414308 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* str	q16, [x2]                                   #! EA = L0xffffffff0890; PC = 0x41430c *)
mov [L0xffffffff0890, L0xffffffff0894, L0xffffffff0898, L0xffffffff089c] %v16;
(* ldr	q16, [x2, #64]                              #! EA = L0xffffffff08d0; Value = 0x0036e641002ecc22; PC = 0x414310 *)
mov %v16 [L0xffffffff08d0, L0xffffffff08d4, L0xffffffff08d8, L0xffffffff08dc];
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x414314 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff08a0; PC = 0x414318 *)
mov [L0xffffffff08a0, L0xffffffff08a4, L0xffffffff08a8, L0xffffffff08ac] %v17;
(* ldr	q17, [x2, #80]                              #! EA = L0xffffffff08e0; Value = 0xfff16d8b000cf5cf; PC = 0x41431c *)
mov %v17 [L0xffffffff08e0, L0xffffffff08e4, L0xffffffff08e8, L0xffffffff08ec];

assert eqmod [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]
              %v0o0e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]
              %v1o0e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]
             %v16o0e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]
             %v17o0e [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
       [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
       [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
       [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
       [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
       [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
       [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
       [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
       [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [29, 30]] && true;

assume eqmod [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]
              %v0o0e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]
              %v1o0e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]
             %v16o0e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]
             %v17o0e [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
       [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
       [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
       [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
       [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
       [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
       [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
       [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
       [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
       [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
       [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
       [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
       [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
       [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
       [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
       [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
       [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<s[Q,Q,Q,Q];
(* CUT 32 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c,
                   L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac,
                   L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc,
                   L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc])
          (16*F**2) [Q, X**16 - 1753**144] /\
    eqmod (poly X [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c,
                   L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac,
                   L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc,
                   L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc])
          (16*F**2) [Q, X**16 - 1753**176] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
    [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
    [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
    [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
    [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
    [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
    [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
    [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
    [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [22, 23, 24, 25, 26, 27, 28, 29, 30, 31]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
    [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
    [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
    [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
    [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
    [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
    [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
    [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
    [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<s[Q,Q,Q,Q];

(* add	x28, x28, #0x80                             #! PC = 0x414320 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414324 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414328 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41432c *)
adds dc x2 x2 (0x40)@uint64;
(* ldr	q4, [x28]                                   #! EA = L0x416460; Value = 0x00000000007fe001; PC = 0x414330 *)
mov %v4 [L0x416460, L0x416464, L0x416468, L0x41646c];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x414334 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414338 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x416470; Value = 0xffcf49decf3dadcd; PC = 0x41433c *)
mov %v5 [L0x416470, L0x416474, L0x416478, L0x41647c];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x414340 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414344 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416480; Value = 0xd7043b612a713ffb; PC = 0x414348 *)
mov %v6 [L0x416480, L0x416484, L0x416488, L0x41648c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41434c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414350 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416490; Value = 0xffd70e7a002a66a4; PC = 0x414354 *)
mov %v7 [L0x416490, L0x416494, L0x416498, L0x41649c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414358 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41435c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x416860; Value = 0x00000000007fe001; PC = 0x414360 *)
mov %v20 [L0x416860, L0x416864, L0x416868, L0x41686c];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414364 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414368 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x416870; Value = 0xfff1d413f1d0873e; PC = 0x41436c *)
mov %v21 [L0x416870, L0x416874, L0x416878, L0x41687c];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414370 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414374 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416880; Value = 0xee73e31c2d3ea74f; PC = 0x414378 *)
mov %v22 [L0x416880, L0x416884, L0x416888, L0x41688c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41437c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414380 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416890; Value = 0xffee7846002d3358; PC = 0x414384 *)
mov %v23 [L0x416890, L0x416894, L0x416898, L0x41689c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414388 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41438c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414390 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414394 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o0f@int32[4], %v2o0f@int32[4]:
       %v0o0f =  %v0 /\  %v2o0f =  %v2 &&  %v0o0f =  %v0 /\  %v2o0f =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414398 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x41439c *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x4143a0 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x4143a4 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 33 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o0f +  %v1 /\ %v12 =  %v0o0f -  %v1 /\
     %v2 =  %v2o0f +  %v3 /\ %v13 =  %v2o0f -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o0f@int32[4],%v18o0f@int32[4],%v12o0f@int32[4],%v13o0f@int32[4]:
      %v16o0f = %v16 /\ %v18o0f = %v18 /\%v12o0f = %v12 /\ %v13o0f = %v13
   && %v16o0f = %v16 /\ %v18o0f = %v18 /\%v12o0f = %v12 /\ %v13o0f = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x4143a8 *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x4143ac *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x4143b0 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x4143b4 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x4143b8 *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4143bc *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x4143c0 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4143c4 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4143c8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4143cc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o0f*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0f*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o0f*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o0f*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 34 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o0f + %v17 /\ %v28 = %v16o0f - %v17 /\
    %v18 = %v18o0f + %v19 /\ %v29 = %v18o0f - %v19 /\
    eqmod  %v1 (%v12o0f*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o0f*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o10@int32[4], %v1o10@int32[4],%v28o10@int32[4],%v29o10@int32[4]:
       %v0o10 =  %v0 /\  %v1o10 =  %v1 /\%v28o10 = %v28 /\ %v29o10 = %v29
   &&  %v0o10 =  %v0 /\  %v1o10 =  %v1 /\%v28o10 = %v28 /\ %v29o10 = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x4143d0 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4143d4 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x4143d8 *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4143dc *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x4143e0 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4143e4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x4143e8 *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4143ec *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4143f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4143f4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o10*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o10*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [33]] && true;
assume eqmod %v17 (%v28o10*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o10*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 35 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o10 +  %v2 /\ %v12 =  %v0o10 -  %v2 /\
     %v1 =  %v1o10 +  %v3 /\ %v13 =  %v1o10 -  %v3 /\
    eqmod %v17 (%v28o10*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o10*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [33]];

ghost %v16o10@int32[4],%v17o10@int32[4],%v12o10@int32[4],%v13o10@int32[4]:
      %v16o10 = %v16 /\ %v17o10 = %v17 /\%v12o10 = %v12 /\ %v13o10 = %v13
   && %v16o10 = %v16 /\ %v17o10 = %v17 /\%v12o10 = %v12 /\ %v13o10 = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x4143f8 *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4143fc *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414400 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414404 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x414408 *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x41440c *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414410 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414414 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414418 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x41441c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o10*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o10*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [34]] && true;
assume eqmod  %v2 (%v12o10*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o10*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 36 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o10 + %v18 /\ %v28 = %v16o10 - %v18 /\
    %v17 = %v17o10 + %v19 /\ %v29 = %v17o10 - %v19 /\
    eqmod  %v2 (%v12o10*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o10*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [34]];

ghost %v28o11@int32[4],%v29o11@int32[4]:
      %v28o11 = %v28 /\ %v29o11 = %v29 && %v28o11 = %v28 /\ %v29o11 = %v29;

(* sub	x19, x19, #0x1                              #! PC = 0x414420 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! PC = 0x414424 *)
#cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! 0x414424 = 0x414424;
(* ldr	q8, [x28, #192]                             #! EA = L0x416520; Value = 0xe1063bcd3376161f; PC = 0x4141a8 *)
mov %v8 [L0x416520, L0x416524, L0x416528, L0x41652c];
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x4141ac *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* ldr	q9, [x28, #208]                             #! EA = L0x416530; Value = 0xffe10dfa00336939; PC = 0x4141b0 *)
mov %v9 [L0x416530, L0x416534, L0x416538, L0x41653c];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x4141b4 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* ldr	q10, [x28, #224]                            #! EA = L0x416540; Value = 0xe6907e52ee3a40b4; PC = 0x4141b8 *)
mov %v10 [L0x416540, L0x416544, L0x416548, L0x41654c];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4141bc *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4141c0 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q11, [x28, #240]                            #! EA = L0x416550; Value = 0xffe696daffee3eb2; PC = 0x4141c4 *)
mov %v11 [L0x416550, L0x416554, L0x416558, L0x41655c];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4141c8 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4141cc *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x4141d0 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4141d4 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x4141d8 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4141dc *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4141e0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4141e4 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4141e8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o11*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o11*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o11*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o11*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 37 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o11*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o11*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4141ec *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q24, [x27, #192]                            #! EA = L0x416920; Value = 0xf6495e6b2580b0e1; PC = 0x4141f0 *)
mov %v24 [L0x416920, L0x416924, L0x416928, L0x41692c];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4141f4 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4141f8 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q25, [x27, #208]                            #! EA = L0x416930; Value = 0xfff64bcc00257751; PC = 0x4141fc *)
mov %v25 [L0x416930, L0x416934, L0x416938, L0x41693c];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414200 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414204 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q26, [x27, #224]                            #! EA = L0x416940; Value = 0x363cacbf03d342c9; PC = 0x414208 *)
mov %v26 [L0x416940, L0x416944, L0x416948, L0x41694c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41420c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414210 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q27, [x27, #240]                            #! EA = L0x416950; Value = 0x00362f1e0003d24e; PC = 0x414214 *)
mov %v27 [L0x416950, L0x416954, L0x416958, L0x41695c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414218 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41421c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o11@int32[4], %v2o11@int32[4]:
       %v0o11 =  %v0 /\  %v2o11 =  %v2 &&  %v0o11 =  %v0 /\  %v2o11 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414220 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414224 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414228 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41422c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [35, 36]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 38 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o11 +  %v1 /\ %v12 =  %v0o11 -  %v1 /\
     %v2 =  %v2o11 +  %v3 /\ %v13 =  %v2o11 -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [35, 36]];

ghost %v16o11@int32[4],%v18o11@int32[4],%v12o11@int32[4],%v13o11@int32[4]:
      %v16o11 = %v16 /\ %v18o11 = %v18 /\%v12o11 = %v12 /\ %v13o11 = %v13
   && %v16o11 = %v16 /\ %v18o11 = %v18 /\%v12o11 = %v12 /\ %v13o11 = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414230 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414234 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414238 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41423c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x414240 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414244 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x414248 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x41424c *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x414250 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414254 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o11*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o11*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [36, 37]] && true;
assume eqmod  %v1 (%v12o11*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o11*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 39 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o11 + %v17 /\ %v28 = %v16o11 - %v17 /\
    %v18 = %v18o11 + %v19 /\ %v29 = %v18o11 - %v19 /\
    eqmod  %v1 (%v12o11*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o11*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [36, 37]];

ghost  %v0o12@int32[4], %v1o12@int32[4],%v28o12@int32[4],%v29o12@int32[4]:
       %v0o12 =  %v0 /\  %v1o12 =  %v1 /\%v28o12 = %v28 /\ %v29o12 = %v29
   &&  %v0o12 =  %v0 /\  %v1o12 =  %v1 /\%v28o12 = %v28 /\ %v29o12 = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x414258 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x41425c *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x414260 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414264 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x414268 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x41426c *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x414270 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414274 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414278 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41427c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o12*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o12*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [38]] && true;
assume eqmod %v17 (%v28o12*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o12*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 40 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o12 +  %v2 /\ %v12 =  %v0o12 -  %v2 /\
     %v1 =  %v1o12 +  %v3 /\ %v13 =  %v1o12 -  %v3 /\
    eqmod %v17 (%v28o12*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o12*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [38]];

ghost %v16o12@int32[4],%v17o12@int32[4],%v12o12@int32[4],%v13o12@int32[4]:
      %v16o12 = %v16 /\ %v17o12 = %v17 /\%v12o12 = %v12 /\ %v13o12 = %v13
   && %v16o12 = %v16 /\ %v17o12 = %v17 /\%v12o12 = %v12 /\ %v13o12 = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x414280 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414284 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x414288 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x41428c *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x414290 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414294 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x414298 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x41429c *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x4142a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4142a4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o12*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o12*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [39]] && true;
assume eqmod  %v2 (%v12o12*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o12*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 41 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o12 + %v18 /\ %v28 = %v16o12 - %v18 /\
    %v17 = %v17o12 + %v19 /\ %v29 = %v17o12 - %v19 /\
    eqmod  %v2 (%v12o12*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o12*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [39]];

ghost %v28o13@int32[4],%v29o13@int32[4]:
      %v28o13 = %v28 /\ %v29o13 = %v29 && %v28o13 = %v28 /\ %v29o13 = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x4142a8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x4142ac *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x4142b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x4142b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4142b8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4142bc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o13*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o13*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o13*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o13*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 42 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o13*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o13*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o13@int32[4], %v1o13@int32[4],%v16o13@int32[4],%v17o13@int32[4]:
       %v0o13 =  %v0 /\  %v1o13 =  %v1 /\%v16o13 = %v16 /\ %v17o13 = %v17
   &&  %v0o13 =  %v0 /\  %v1o13 =  %v1 /\%v16o13 = %v16 /\ %v17o13 = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff06f0; PC = 0x4142c0 *)
mov [L0xffffffff06f0, L0xffffffff06f4, L0xffffffff06f8, L0xffffffff06fc] %v2;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x4142c4 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* ldr	q2, [x0, #96]                               #! EA = L0xffffffff0730; Value = 0x0016357f001da303; PC = 0x4142c8 *)
mov %v2 [L0xffffffff0730, L0xffffffff0734, L0xffffffff0738, L0xffffffff073c];
(* str	q3, [x0, #48]                               #! EA = L0xffffffff0700; PC = 0x4142cc *)
mov [L0xffffffff0700, L0xffffffff0704, L0xffffffff0708, L0xffffffff070c] %v3;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x4142d0 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* ldr	q3, [x0, #112]                              #! EA = L0xffffffff0740; Value = 0xffdcf001fffaf5bb; PC = 0x4142d4 *)
mov %v3 [L0xffffffff0740, L0xffffffff0744, L0xffffffff0748, L0xffffffff074c];
(* str	q18, [x2, #32]                              #! EA = L0xffffffff08f0; PC = 0x4142d8 *)
mov [L0xffffffff08f0, L0xffffffff08f4, L0xffffffff08f8, L0xffffffff08fc] %v18;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x4142dc *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* ldr	q18, [x2, #96]                              #! EA = L0xffffffff0930; Value = 0x001dfe96ffe9d3c5; PC = 0x4142e0 *)
mov %v18 [L0xffffffff0930, L0xffffffff0934, L0xffffffff0938, L0xffffffff093c];
(* str	q19, [x2, #48]                              #! EA = L0xffffffff0900; PC = 0x4142e4 *)
mov [L0xffffffff0900, L0xffffffff0904, L0xffffffff0908, L0xffffffff090c] %v19;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x4142e8 *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* ldr	q19, [x2, #112]                             #! EA = L0xffffffff0940; Value = 0xffcac80afff8dc06; PC = 0x4142ec *)
mov %v19 [L0xffffffff0940, L0xffffffff0944, L0xffffffff0948, L0xffffffff094c];
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x4142f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff06d0; PC = 0x4142f4 *)
mov [L0xffffffff06d0, L0xffffffff06d4, L0xffffffff06d8, L0xffffffff06dc] %v0;
(* ldr	q0, [x0, #64]                               #! EA = L0xffffffff0710; Value = 0x001a98740032def4; PC = 0x4142f8 *)
mov %v0 [L0xffffffff0710, L0xffffffff0714, L0xffffffff0718, L0xffffffff071c];
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x4142fc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff06e0; PC = 0x414300 *)
mov [L0xffffffff06e0, L0xffffffff06e4, L0xffffffff06e8, L0xffffffff06ec] %v1;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff0720; Value = 0x003de9a7ffcabea3; PC = 0x414304 *)
mov %v1 [L0xffffffff0720, L0xffffffff0724, L0xffffffff0728, L0xffffffff072c];
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414308 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* str	q16, [x2]                                   #! EA = L0xffffffff08d0; PC = 0x41430c *)
mov [L0xffffffff08d0, L0xffffffff08d4, L0xffffffff08d8, L0xffffffff08dc] %v16;
(* ldr	q16, [x2, #64]                              #! EA = L0xffffffff0910; Value = 0xffd7f0b3ffdcdf9e; PC = 0x414310 *)
mov %v16 [L0xffffffff0910, L0xffffffff0914, L0xffffffff0918, L0xffffffff091c];
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x414314 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff08e0; PC = 0x414318 *)
mov [L0xffffffff08e0, L0xffffffff08e4, L0xffffffff08e8, L0xffffffff08ec] %v17;
(* ldr	q17, [x2, #80]                              #! EA = L0xffffffff0920; Value = 0x002ab82bfffb6d3a; PC = 0x41431c *)
mov %v17 [L0xffffffff0920, L0xffffffff0924, L0xffffffff0928, L0xffffffff092c];

assert eqmod [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]
              %v0o13 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]
              %v1o13 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]
             %v16o13 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]
             %v17o13 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
       [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
       [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
       [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
       [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
       [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
       [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
       [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
       [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [40, 41]] && true;

assume eqmod [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]
              %v0o13 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]
              %v1o13 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]
             %v16o13 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]
             %v17o13 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
       [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
       [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
       [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
       [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
       [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
       [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
       [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
       [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
       [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
       [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
       [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
       [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
       [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
       [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
       [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
       [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<s[Q,Q,Q,Q];
(* CUT 43 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc,
                   L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec,
                   L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc,
                   L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c])
          (16*F**2) [Q, X**16 - 1753**400] /\
    eqmod (poly X [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc,
                   L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec,
                   L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc,
                   L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c])
          (16*F**2) [Q, X**16 - 1753**432] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
    [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
    [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
    [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
    [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
    [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
    [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
    [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
    [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [33, 34, 35, 36, 37, 38, 39, 40, 41, 42]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
    [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
    [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
    [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
    [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
    [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
    [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
    [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
    [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<s[Q,Q,Q,Q];

(* add	x28, x28, #0x80                             #! PC = 0x414320 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414324 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414328 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41432c *)
adds dc x2 x2 (0x40)@uint64;
(* ldr	q4, [x28]                                   #! EA = L0x4164e0; Value = 0x00000000007fe001; PC = 0x414330 *)
mov %v4 [L0x4164e0, L0x4164e4, L0x4164e8, L0x4164ec];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x414334 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414338 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x4164f0; Value = 0x003c45e53c54f9c6; PC = 0x41433c *)
mov %v5 [L0x4164f0, L0x4164f4, L0x4164f8, L0x4164fc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x414340 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414344 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416500; Value = 0xd34fdc50cc767404; PC = 0x414348 *)
mov %v6 [L0x416500, L0x416504, L0x416508, L0x41650c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41434c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414350 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416510; Value = 0xffd35b08ffcc8356; PC = 0x414354 *)
mov %v7 [L0x416510, L0x416514, L0x416518, L0x41651c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414358 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41435c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x4168e0; Value = 0x00000000007fe001; PC = 0x414360 *)
mov %v20 [L0x4168e0, L0x4168e4, L0x4168e8, L0x4168ec];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414364 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414368 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x4168f0; Value = 0xffee4d3dee48cf57; PC = 0x41436c *)
mov %v21 [L0x4168f0, L0x4168f4, L0x4168f8, L0x4168fc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414370 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414374 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416900; Value = 0x10f24870c07d97e5; PC = 0x414378 *)
mov %v22 [L0x416900, L0x416904, L0x416908, L0x41690c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41437c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414380 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416910; Value = 0x0010ee0cffc08d78; PC = 0x414384 *)
mov %v23 [L0x416910, L0x416914, L0x416918, L0x41691c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414388 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41438c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414390 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414394 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o14@int32[4], %v2o14@int32[4]:
       %v0o14 =  %v0 /\  %v2o14 =  %v2 &&  %v0o14 =  %v0 /\  %v2o14 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414398 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x41439c *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x4143a0 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x4143a4 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 44 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o14 +  %v1 /\ %v12 =  %v0o14 -  %v1 /\
     %v2 =  %v2o14 +  %v3 /\ %v13 =  %v2o14 -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o14@int32[4],%v18o14@int32[4],%v12o14@int32[4],%v13o14@int32[4]:
      %v16o14 = %v16 /\ %v18o14 = %v18 /\%v12o14 = %v12 /\ %v13o14 = %v13
   && %v16o14 = %v16 /\ %v18o14 = %v18 /\%v12o14 = %v12 /\ %v13o14 = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x4143a8 *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x4143ac *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x4143b0 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x4143b4 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x4143b8 *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4143bc *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x4143c0 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4143c4 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4143c8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4143cc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o14*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o14*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o14*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o14*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 45 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o14 + %v17 /\ %v28 = %v16o14 - %v17 /\
    %v18 = %v18o14 + %v19 /\ %v29 = %v18o14 - %v19 /\
    eqmod  %v1 (%v12o14*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o14*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o15@int32[4], %v1o15@int32[4],%v28o15@int32[4],%v29o15@int32[4]:
       %v0o15 =  %v0 /\  %v1o15 =  %v1 /\%v28o15 = %v28 /\ %v29o15 = %v29
   &&  %v0o15 =  %v0 /\  %v1o15 =  %v1 /\%v28o15 = %v28 /\ %v29o15 = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x4143d0 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4143d4 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x4143d8 *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4143dc *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x4143e0 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4143e4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x4143e8 *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4143ec *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4143f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4143f4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o15*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o15*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [44]] && true;
assume eqmod %v17 (%v28o15*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o15*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 46 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o15 +  %v2 /\ %v12 =  %v0o15 -  %v2 /\
     %v1 =  %v1o15 +  %v3 /\ %v13 =  %v1o15 -  %v3 /\
    eqmod %v17 (%v28o15*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o15*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [44]];

ghost %v16o15@int32[4],%v17o15@int32[4],%v12o15@int32[4],%v13o15@int32[4]:
      %v16o15 = %v16 /\ %v17o15 = %v17 /\%v12o15 = %v12 /\ %v13o15 = %v13
   && %v16o15 = %v16 /\ %v17o15 = %v17 /\%v12o15 = %v12 /\ %v13o15 = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x4143f8 *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4143fc *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414400 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414404 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x414408 *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x41440c *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414410 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414414 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414418 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x41441c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o15*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o15*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [45]] && true;
assume eqmod  %v2 (%v12o15*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o15*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 47 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o15 + %v18 /\ %v28 = %v16o15 - %v18 /\
    %v17 = %v17o15 + %v19 /\ %v29 = %v17o15 - %v19 /\
    eqmod  %v2 (%v12o15*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o15*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [45]];

ghost %v28o16@int32[4],%v29o16@int32[4]:
      %v28o16 = %v28 /\ %v29o16 = %v29 && %v28o16 = %v28 /\ %v29o16 = %v29;

(* sub	x19, x19, #0x1                              #! PC = 0x414420 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! PC = 0x414424 *)
#cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! 0x414424 = 0x414424;
(* ldr	q8, [x28, #192]                             #! EA = L0x4165a0; Value = 0xc0a3344c3d7139d4; PC = 0x4141a8 *)
mov %v8 [L0x4165a0, L0x4165a4, L0x4165a8, L0x4165ac];
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x4141ac *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* ldr	q9, [x28, #208]                             #! EA = L0x4165b0; Value = 0xffc0b30b003d61de; PC = 0x4141b0 *)
mov %v9 [L0x4165b0, L0x4165b4, L0x4165b8, L0x4165bc];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x4141b4 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* ldr	q10, [x28, #224]                            #! EA = L0x4165c0; Value = 0x27e86eccf48d1a5d; PC = 0x4141b8 *)
mov %v10 [L0x4165c0, L0x4165c4, L0x4165c8, L0x4165cc];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4141bc *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4141c0 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q11, [x28, #240]                            #! EA = L0x4165d0; Value = 0x0027de75fff48ff7; PC = 0x4141c4 *)
mov %v11 [L0x4165d0, L0x4165d4, L0x4165d8, L0x4165dc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4141c8 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4141cc *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x4141d0 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4141d4 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x4141d8 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4141dc *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4141e0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4141e4 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4141e8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o16*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o16*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o16*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o16*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 48 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o16*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o16*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4141ec *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q24, [x27, #192]                            #! EA = L0x4169a0; Value = 0xe79c5145396bc37e; PC = 0x4141f0 *)
mov %v24 [L0x4169a0, L0x4169a4, L0x4169a8, L0x4169ac];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4141f4 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4141f8 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q25, [x27, #208]                            #! EA = L0x4169b0; Value = 0xffe7a26a00395d69; PC = 0x4141fc *)
mov %v25 [L0x4169b0, L0x4169b4, L0x4169b8, L0x4169bc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414200 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414204 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q26, [x27, #224]                            #! EA = L0x4169c0; Value = 0x1e3bf7c13c6feb82; PC = 0x414208 *)
mov %v26 [L0x4169c0, L0x4169c4, L0x4169c8, L0x4169cc];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41420c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414210 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q27, [x27, #240]                            #! EA = L0x4169d0; Value = 0x001e3469003c60d0; PC = 0x414214 *)
mov %v27 [L0x4169d0, L0x4169d4, L0x4169d8, L0x4169dc];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414218 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41421c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o16@int32[4], %v2o16@int32[4]:
       %v0o16 =  %v0 /\  %v2o16 =  %v2 &&  %v0o16 =  %v0 /\  %v2o16 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414220 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414224 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414228 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41422c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [46, 47]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 49 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o16 +  %v1 /\ %v12 =  %v0o16 -  %v1 /\
     %v2 =  %v2o16 +  %v3 /\ %v13 =  %v2o16 -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [46, 47]];

ghost %v16o16@int32[4],%v18o16@int32[4],%v12o16@int32[4],%v13o16@int32[4]:
      %v16o16 = %v16 /\ %v18o16 = %v18 /\%v12o16 = %v12 /\ %v13o16 = %v13
   && %v16o16 = %v16 /\ %v18o16 = %v18 /\%v12o16 = %v12 /\ %v13o16 = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414230 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414234 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414238 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41423c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x414240 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414244 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x414248 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x41424c *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x414250 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414254 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o16*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o16*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [47, 48]] && true;
assume eqmod  %v1 (%v12o16*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o16*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 50 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o16 + %v17 /\ %v28 = %v16o16 - %v17 /\
    %v18 = %v18o16 + %v19 /\ %v29 = %v18o16 - %v19 /\
    eqmod  %v1 (%v12o16*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o16*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [47, 48]];

ghost  %v0o17@int32[4], %v1o17@int32[4],%v28o17@int32[4],%v29o17@int32[4]:
       %v0o17 =  %v0 /\  %v1o17 =  %v1 /\%v28o17 = %v28 /\ %v29o17 = %v29
   &&  %v0o17 =  %v0 /\  %v1o17 =  %v1 /\%v28o17 = %v28 /\ %v29o17 = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x414258 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x41425c *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x414260 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414264 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x414268 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x41426c *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x414270 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414274 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414278 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41427c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o17*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o17*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [49]] && true;
assume eqmod %v17 (%v28o17*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o17*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 51 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o17 +  %v2 /\ %v12 =  %v0o17 -  %v2 /\
     %v1 =  %v1o17 +  %v3 /\ %v13 =  %v1o17 -  %v3 /\
    eqmod %v17 (%v28o17*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o17*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [49]];

ghost %v16o17@int32[4],%v17o17@int32[4],%v12o17@int32[4],%v13o17@int32[4]:
      %v16o17 = %v16 /\ %v17o17 = %v17 /\%v12o17 = %v12 /\ %v13o17 = %v13
   && %v16o17 = %v16 /\ %v17o17 = %v17 /\%v12o17 = %v12 /\ %v13o17 = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x414280 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414284 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x414288 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x41428c *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x414290 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414294 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x414298 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x41429c *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x4142a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4142a4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o17*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o17*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [50]] && true;
assume eqmod  %v2 (%v12o17*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o17*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 52 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o17 + %v18 /\ %v28 = %v16o17 - %v18 /\
    %v17 = %v17o17 + %v19 /\ %v29 = %v17o17 - %v19 /\
    eqmod  %v2 (%v12o17*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o17*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [50]];

ghost %v28o18@int32[4],%v29o18@int32[4]:
      %v28o18 = %v28 /\ %v29o18 = %v29 && %v28o18 = %v28 /\ %v29o18 = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x4142a8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x4142ac *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x4142b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x4142b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4142b8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4142bc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o18*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o18*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o18*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o18*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 53 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o18*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o18*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o18@int32[4], %v1o18@int32[4],%v16o18@int32[4],%v17o18@int32[4]:
       %v0o18 =  %v0 /\  %v1o18 =  %v1 /\%v16o18 = %v16 /\ %v17o18 = %v17
   &&  %v0o18 =  %v0 /\  %v1o18 =  %v1 /\%v16o18 = %v16 /\ %v17o18 = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff0730; PC = 0x4142c0 *)
mov [L0xffffffff0730, L0xffffffff0734, L0xffffffff0738, L0xffffffff073c] %v2;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x4142c4 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* ldr	q2, [x0, #96]                               #! EA = L0xffffffff0770; Value = 0x002d834d0014dff5; PC = 0x4142c8 *)
mov %v2 [L0xffffffff0770, L0xffffffff0774, L0xffffffff0778, L0xffffffff077c];
(* str	q3, [x0, #48]                               #! EA = L0xffffffff0740; PC = 0x4142cc *)
mov [L0xffffffff0740, L0xffffffff0744, L0xffffffff0748, L0xffffffff074c] %v3;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x4142d0 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* ldr	q3, [x0, #112]                              #! EA = L0xffffffff0780; Value = 0xfffb52c70003c34e; PC = 0x4142d4 *)
mov %v3 [L0xffffffff0780, L0xffffffff0784, L0xffffffff0788, L0xffffffff078c];
(* str	q18, [x2, #32]                              #! EA = L0xffffffff0930; PC = 0x4142d8 *)
mov [L0xffffffff0930, L0xffffffff0934, L0xffffffff0938, L0xffffffff093c] %v18;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x4142dc *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* ldr	q18, [x2, #96]                              #! EA = L0xffffffff0970; Value = 0x001ea7070014fc73; PC = 0x4142e0 *)
mov %v18 [L0xffffffff0970, L0xffffffff0974, L0xffffffff0978, L0xffffffff097c];
(* str	q19, [x2, #48]                              #! EA = L0xffffffff0940; PC = 0x4142e4 *)
mov [L0xffffffff0940, L0xffffffff0944, L0xffffffff0948, L0xffffffff094c] %v19;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x4142e8 *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* ldr	q19, [x2, #112]                             #! EA = L0xffffffff0980; Value = 0x001b4f0500011bdf; PC = 0x4142ec *)
mov %v19 [L0xffffffff0980, L0xffffffff0984, L0xffffffff0988, L0xffffffff098c];
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x4142f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff0710; PC = 0x4142f4 *)
mov [L0xffffffff0710, L0xffffffff0714, L0xffffffff0718, L0xffffffff071c] %v0;
(* ldr	q0, [x0, #64]                               #! EA = L0xffffffff0750; Value = 0xffc9f26a003a2b26; PC = 0x4142f8 *)
mov %v0 [L0xffffffff0750, L0xffffffff0754, L0xffffffff0758, L0xffffffff075c];
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x4142fc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff0720; PC = 0x414300 *)
mov [L0xffffffff0720, L0xffffffff0724, L0xffffffff0728, L0xffffffff072c] %v1;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff0760; Value = 0xfffaf679ffe15bd4; PC = 0x414304 *)
mov %v1 [L0xffffffff0760, L0xffffffff0764, L0xffffffff0768, L0xffffffff076c];
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414308 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* str	q16, [x2]                                   #! EA = L0xffffffff0910; PC = 0x41430c *)
mov [L0xffffffff0910, L0xffffffff0914, L0xffffffff0918, L0xffffffff091c] %v16;
(* ldr	q16, [x2, #64]                              #! EA = L0xffffffff0950; Value = 0x000f0158ffdc5e96; PC = 0x414310 *)
mov %v16 [L0xffffffff0950, L0xffffffff0954, L0xffffffff0958, L0xffffffff095c];
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x414314 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff0920; PC = 0x414318 *)
mov [L0xffffffff0920, L0xffffffff0924, L0xffffffff0928, L0xffffffff092c] %v17;
(* ldr	q17, [x2, #80]                              #! EA = L0xffffffff0960; Value = 0x001b95c2002ceb1a; PC = 0x41431c *)
mov %v17 [L0xffffffff0960, L0xffffffff0964, L0xffffffff0968, L0xffffffff096c];

assert eqmod [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]
              %v0o18 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]
              %v1o18 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]
             %v16o18 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]
             %v17o18 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
       [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
       [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
       [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
       [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
       [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
       [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
       [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
       [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [51, 52]] && true;

assume eqmod [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]
              %v0o18 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]
              %v1o18 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]
             %v16o18 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]
             %v17o18 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
       [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
       [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
       [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
       [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
       [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
       [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
       [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
       [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
       [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
       [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
       [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
       [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
       [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
       [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
       [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
       [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<s[Q,Q,Q,Q];
(* CUT 54 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c,
                   L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c,
                   L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c,
                   L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c])
          (16*F**2) [Q, X**16 - 1753** 80] /\
    eqmod (poly X [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c,
                   L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c,
                   L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c,
                   L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c])
          (16*F**2) [Q, X**16 - 1753**112] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
    [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
    [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
    [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
    [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
    [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
    [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
    [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
    [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [44, 45, 46, 47, 48, 49, 50, 51, 52, 53]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
    [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
    [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
    [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
    [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
    [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
    [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
    [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
    [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<s[Q,Q,Q,Q];

(* add	x28, x28, #0x80                             #! PC = 0x414320 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414324 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414328 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41432c *)
adds dc x2 x2 (0x40)@uint64;
(* ldr	q4, [x28]                                   #! EA = L0x416560; Value = 0x00000000007fe001; PC = 0x414330 *)
mov %v4 [L0x416560, L0x416564, L0x416568, L0x41656c];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x414334 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414338 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x416570; Value = 0x001d89b71d911b0c; PC = 0x41433c *)
mov %v5 [L0x416570, L0x416574, L0x416578, L0x41657c];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x414340 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414344 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416580; Value = 0xd1a11ca4f68334e0; PC = 0x414348 *)
mov %v6 [L0x416580, L0x416584, L0x416588, L0x41658c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41434c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414350 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416590; Value = 0xffd1acb4fff68594; PC = 0x414354 *)
mov %v7 [L0x416590, L0x416594, L0x416598, L0x41659c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414358 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41435c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x416960; Value = 0x00000000007fe001; PC = 0x414360 *)
mov %v20 [L0x416960, L0x416964, L0x416968, L0x41696c];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414364 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414368 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x416970; Value = 0xffdfef5edfe75816; PC = 0x41436c *)
mov %v21 [L0x416970, L0x416974, L0x416978, L0x41697c];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414370 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414374 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416980; Value = 0xe267f8393a47be7b; PC = 0x414378 *)
mov %v22 [L0x416980, L0x416984, L0x416988, L0x41698c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41437c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414380 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416990; Value = 0xffe26f5e003a392d; PC = 0x414384 *)
mov %v23 [L0x416990, L0x416994, L0x416998, L0x41699c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414388 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41438c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414390 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414394 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o19@int32[4], %v2o19@int32[4]:
       %v0o19 =  %v0 /\  %v2o19 =  %v2 &&  %v0o19 =  %v0 /\  %v2o19 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414398 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x41439c *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x4143a0 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x4143a4 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 55 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o19 +  %v1 /\ %v12 =  %v0o19 -  %v1 /\
     %v2 =  %v2o19 +  %v3 /\ %v13 =  %v2o19 -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o19@int32[4],%v18o19@int32[4],%v12o19@int32[4],%v13o19@int32[4]:
      %v16o19 = %v16 /\ %v18o19 = %v18 /\%v12o19 = %v12 /\ %v13o19 = %v13
   && %v16o19 = %v16 /\ %v18o19 = %v18 /\%v12o19 = %v12 /\ %v13o19 = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x4143a8 *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x4143ac *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x4143b0 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x4143b4 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x4143b8 *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4143bc *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x4143c0 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4143c4 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4143c8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4143cc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o19*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o19*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o19*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o19*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 56 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o19 + %v17 /\ %v28 = %v16o19 - %v17 /\
    %v18 = %v18o19 + %v19 /\ %v29 = %v18o19 - %v19 /\
    eqmod  %v1 (%v12o19*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o19*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o1a@int32[4], %v1o1a@int32[4],%v28o1a@int32[4],%v29o1a@int32[4]:
       %v0o1a =  %v0 /\  %v1o1a =  %v1 /\%v28o1a = %v28 /\ %v29o1a = %v29
   &&  %v0o1a =  %v0 /\  %v1o1a =  %v1 /\%v28o1a = %v28 /\ %v29o1a = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x4143d0 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4143d4 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x4143d8 *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4143dc *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x4143e0 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4143e4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x4143e8 *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4143ec *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4143f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4143f4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o1a*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1a*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [55]] && true;
assume eqmod %v17 (%v28o1a*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1a*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 57 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o1a +  %v2 /\ %v12 =  %v0o1a -  %v2 /\
     %v1 =  %v1o1a +  %v3 /\ %v13 =  %v1o1a -  %v3 /\
    eqmod %v17 (%v28o1a*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o1a*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [55]];

ghost %v16o1a@int32[4],%v17o1a@int32[4],%v12o1a@int32[4],%v13o1a@int32[4]:
      %v16o1a = %v16 /\ %v17o1a = %v17 /\%v12o1a = %v12 /\ %v13o1a = %v13
   && %v16o1a = %v16 /\ %v17o1a = %v17 /\%v12o1a = %v12 /\ %v13o1a = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x4143f8 *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4143fc *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414400 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414404 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x414408 *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x41440c *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414410 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414414 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414418 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x41441c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o1a*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1a*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [56]] && true;
assume eqmod  %v2 (%v12o1a*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1a*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 58 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o1a + %v18 /\ %v28 = %v16o1a - %v18 /\
    %v17 = %v17o1a + %v19 /\ %v29 = %v17o1a - %v19 /\
    eqmod  %v2 (%v12o1a*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o1a*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [56]];

ghost %v28o1b@int32[4],%v29o1b@int32[4]:
      %v28o1b = %v28 /\ %v29o1b = %v29 && %v28o1b = %v28 /\ %v29o1b = %v29;

(* sub	x19, x19, #0x1                              #! PC = 0x414420 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! PC = 0x414424 *)
#cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! 0x414424 = 0x414424;
(* ldr	q8, [x28, #192]                             #! EA = L0x416620; Value = 0x1224b6091c051f10; PC = 0x4141a8 *)
mov %v8 [L0x416620, L0x416624, L0x416628, L0x41662c];
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x4141ac *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* ldr	q9, [x28, #208]                             #! EA = L0x416630; Value = 0x0012202d001bfe1e; PC = 0x4141b0 *)
mov %v9 [L0x416630, L0x416634, L0x416638, L0x41663c];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x4141b4 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* ldr	q10, [x28, #224]                            #! EA = L0x416640; Value = 0xf83df88e0b12086c; PC = 0x4141b8 *)
mov %v10 [L0x416640, L0x416644, L0x416648, L0x41664c];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4141bc *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4141c0 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q11, [x28, #240]                            #! EA = L0x416650; Value = 0xfff83fe9000b0f44; PC = 0x4141c4 *)
mov %v11 [L0x416650, L0x416654, L0x416658, L0x41665c];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4141c8 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4141cc *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x4141d0 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4141d4 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x4141d8 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4141dc *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4141e0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4141e4 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4141e8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o1b*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1b*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o1b*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1b*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 59 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o1b*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o1b*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4141ec *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q24, [x27, #192]                            #! EA = L0x416a20; Value = 0x2313117e38c582ef; PC = 0x4141f0 *)
mov %v24 [L0x416a20, L0x416a24, L0x416a28, L0x416a2c];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4141f4 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4141f8 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q25, [x27, #208]                            #! EA = L0x416a30; Value = 0x00230a4d0038b752; PC = 0x4141fc *)
mov %v25 [L0x416a30, L0x416a34, L0x416a38, L0x416a3c];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414200 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414204 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q26, [x27, #224]                            #! EA = L0x416a40; Value = 0x3c6f2450322c3dab; PC = 0x414208 *)
mov %v26 [L0x416a40, L0x416a44, L0x416a48, L0x416a4c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41420c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414210 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q27, [x27, #240]                            #! EA = L0x416a50; Value = 0x003c600900321fb3; PC = 0x414214 *)
mov %v27 [L0x416a50, L0x416a54, L0x416a58, L0x416a5c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414218 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41421c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o1b@int32[4], %v2o1b@int32[4]:
       %v0o1b =  %v0 /\  %v2o1b =  %v2 &&  %v0o1b =  %v0 /\  %v2o1b =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414220 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414224 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414228 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41422c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [57, 58]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 60 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o1b +  %v1 /\ %v12 =  %v0o1b -  %v1 /\
     %v2 =  %v2o1b +  %v3 /\ %v13 =  %v2o1b -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [57, 58]];

ghost %v16o1b@int32[4],%v18o1b@int32[4],%v12o1b@int32[4],%v13o1b@int32[4]:
      %v16o1b = %v16 /\ %v18o1b = %v18 /\%v12o1b = %v12 /\ %v13o1b = %v13
   && %v16o1b = %v16 /\ %v18o1b = %v18 /\%v12o1b = %v12 /\ %v13o1b = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414230 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414234 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414238 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41423c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x414240 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414244 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x414248 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x41424c *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x414250 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414254 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o1b*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1b*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [58, 59]] && true;
assume eqmod  %v1 (%v12o1b*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1b*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 61 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o1b + %v17 /\ %v28 = %v16o1b - %v17 /\
    %v18 = %v18o1b + %v19 /\ %v29 = %v18o1b - %v19 /\
    eqmod  %v1 (%v12o1b*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o1b*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [58, 59]];

ghost  %v0o1c@int32[4], %v1o1c@int32[4],%v28o1c@int32[4],%v29o1c@int32[4]:
       %v0o1c =  %v0 /\  %v1o1c =  %v1 /\%v28o1c = %v28 /\ %v29o1c = %v29
   &&  %v0o1c =  %v0 /\  %v1o1c =  %v1 /\%v28o1c = %v28 /\ %v29o1c = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x414258 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x41425c *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x414260 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414264 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x414268 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x41426c *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x414270 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414274 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414278 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41427c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o1c*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1c*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [60]] && true;
assume eqmod %v17 (%v28o1c*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1c*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 62 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o1c +  %v2 /\ %v12 =  %v0o1c -  %v2 /\
     %v1 =  %v1o1c +  %v3 /\ %v13 =  %v1o1c -  %v3 /\
    eqmod %v17 (%v28o1c*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o1c*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [60]];

ghost %v16o1c@int32[4],%v17o1c@int32[4],%v12o1c@int32[4],%v13o1c@int32[4]:
      %v16o1c = %v16 /\ %v17o1c = %v17 /\%v12o1c = %v12 /\ %v13o1c = %v13
   && %v16o1c = %v16 /\ %v17o1c = %v17 /\%v12o1c = %v12 /\ %v13o1c = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x414280 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414284 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x414288 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x41428c *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x414290 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414294 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x414298 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x41429c *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x4142a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4142a4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o1c*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1c*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [61]] && true;
assume eqmod  %v2 (%v12o1c*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1c*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 63 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o1c + %v18 /\ %v28 = %v16o1c - %v18 /\
    %v17 = %v17o1c + %v19 /\ %v29 = %v17o1c - %v19 /\
    eqmod  %v2 (%v12o1c*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o1c*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [61]];

ghost %v28o1d@int32[4],%v29o1d@int32[4]:
      %v28o1d = %v28 /\ %v29o1d = %v29 && %v28o1d = %v28 /\ %v29o1d = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x4142a8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x4142ac *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x4142b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x4142b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4142b8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4142bc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o1d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o1d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 64 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o1d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o1d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o1d@int32[4], %v1o1d@int32[4],%v16o1d@int32[4],%v17o1d@int32[4]:
       %v0o1d =  %v0 /\  %v1o1d =  %v1 /\%v16o1d = %v16 /\ %v17o1d = %v17
   &&  %v0o1d =  %v0 /\  %v1o1d =  %v1 /\%v16o1d = %v16 /\ %v17o1d = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff0770; PC = 0x4142c0 *)
mov [L0xffffffff0770, L0xffffffff0774, L0xffffffff0778, L0xffffffff077c] %v2;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x4142c4 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* ldr	q2, [x0, #96]                               #! EA = L0xffffffff07b0; Value = 0x0035cc0a00219b93; PC = 0x4142c8 *)
mov %v2 [L0xffffffff07b0, L0xffffffff07b4, L0xffffffff07b8, L0xffffffff07bc];
(* str	q3, [x0, #48]                               #! EA = L0xffffffff0780; PC = 0x4142cc *)
mov [L0xffffffff0780, L0xffffffff0784, L0xffffffff0788, L0xffffffff078c] %v3;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x4142d0 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* ldr	q3, [x0, #112]                              #! EA = L0xffffffff07c0; Value = 0x0020be51ffd458b8; PC = 0x4142d4 *)
mov %v3 [L0xffffffff07c0, L0xffffffff07c4, L0xffffffff07c8, L0xffffffff07cc];
(* str	q18, [x2, #32]                              #! EA = L0xffffffff0970; PC = 0x4142d8 *)
mov [L0xffffffff0970, L0xffffffff0974, L0xffffffff0978, L0xffffffff097c] %v18;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x4142dc *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* ldr	q18, [x2, #96]                              #! EA = L0xffffffff09b0; Value = 0xffff9de5ffc14349; PC = 0x4142e0 *)
mov %v18 [L0xffffffff09b0, L0xffffffff09b4, L0xffffffff09b8, L0xffffffff09bc];
(* str	q19, [x2, #48]                              #! EA = L0xffffffff0980; PC = 0x4142e4 *)
mov [L0xffffffff0980, L0xffffffff0984, L0xffffffff0988, L0xffffffff098c] %v19;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x4142e8 *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* ldr	q19, [x2, #112]                             #! EA = L0xffffffff09c0; Value = 0xffe1fa3fffdccf0d; PC = 0x4142ec *)
mov %v19 [L0xffffffff09c0, L0xffffffff09c4, L0xffffffff09c8, L0xffffffff09cc];
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x4142f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff0750; PC = 0x4142f4 *)
mov [L0xffffffff0750, L0xffffffff0754, L0xffffffff0758, L0xffffffff075c] %v0;
(* ldr	q0, [x0, #64]                               #! EA = L0xffffffff0790; Value = 0xfff29dc800120404; PC = 0x4142f8 *)
mov %v0 [L0xffffffff0790, L0xffffffff0794, L0xffffffff0798, L0xffffffff079c];
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x4142fc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff0760; PC = 0x414300 *)
mov [L0xffffffff0760, L0xffffffff0764, L0xffffffff0768, L0xffffffff076c] %v1;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff07a0; Value = 0xffecba0600294431; PC = 0x414304 *)
mov %v1 [L0xffffffff07a0, L0xffffffff07a4, L0xffffffff07a8, L0xffffffff07ac];
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414308 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* str	q16, [x2]                                   #! EA = L0xffffffff0950; PC = 0x41430c *)
mov [L0xffffffff0950, L0xffffffff0954, L0xffffffff0958, L0xffffffff095c] %v16;
(* ldr	q16, [x2, #64]                              #! EA = L0xffffffff0990; Value = 0x0003725700032c61; PC = 0x414310 *)
mov %v16 [L0xffffffff0990, L0xffffffff0994, L0xffffffff0998, L0xffffffff099c];
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x414314 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff0960; PC = 0x414318 *)
mov [L0xffffffff0960, L0xffffffff0964, L0xffffffff0968, L0xffffffff096c] %v17;
(* ldr	q17, [x2, #80]                              #! EA = L0xffffffff09a0; Value = 0x00200205000d02da; PC = 0x41431c *)
mov %v17 [L0xffffffff09a0, L0xffffffff09a4, L0xffffffff09a8, L0xffffffff09ac];

assert eqmod [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]
              %v0o1d [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]
              %v1o1d [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]
             %v16o1d [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]
             %v17o1d [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
       [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
       [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
       [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
       [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
       [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
       [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
       [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
       [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [62, 63]] && true;

assume eqmod [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]
              %v0o1d [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]
              %v1o1d [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]
             %v16o1d [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]
             %v17o1d [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
       [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
       [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
       [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
       [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
       [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
       [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
       [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
       [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
       [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
       [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
       [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
       [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
       [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
       [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
       [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
       [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<s[Q,Q,Q,Q];
(* CUT 65 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c,
                   L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c,
                   L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c,
                   L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c])
          (16*F**2) [Q, X**16 - 1753**336] /\
    eqmod (poly X [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c,
                   L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c,
                   L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c,
                   L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c])
          (16*F**2) [Q, X**16 - 1753**368] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
    [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
    [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
    [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
    [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
    [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
    [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
    [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
    [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [55, 56, 57, 58, 59, 60, 61, 62, 63, 64]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
    [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
    [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
    [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
    [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
    [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
    [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
    [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
    [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<s[Q,Q,Q,Q];

(* add	x28, x28, #0x80                             #! PC = 0x414320 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414324 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414328 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41432c *)
adds dc x2 x2 (0x40)@uint64;
(* ldr	q4, [x28]                                   #! EA = L0x4165e0; Value = 0x00000000007fe001; PC = 0x414330 *)
mov %v4 [L0x4165e0, L0x4165e4, L0x4165e8, L0x4165ec];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x414334 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414338 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x4165f0; Value = 0x00368ac2369867ad; PC = 0x41433c *)
mov %v5 [L0x4165f0, L0x4165f4, L0x4165f8, L0x4165fc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x414340 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414344 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416600; Value = 0x13db26a22413d3ad; PC = 0x414348 *)
mov %v6 [L0x416600, L0x416604, L0x416608, L0x41660c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41434c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414350 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416610; Value = 0x0013d63000240acf; PC = 0x414354 *)
mov %v7 [L0x416610, L0x416614, L0x416618, L0x41661c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414358 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41435c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x4169e0; Value = 0x00000000007fe001; PC = 0x414360 *)
mov %v20 [L0x4169e0, L0x4169e4, L0x4169e8, L0x4169ec];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414364 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414368 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x4169f0; Value = 0x0036b98e36c73f62; PC = 0x41436c *)
mov %v21 [L0x4169f0, L0x4169f4, L0x4169f8, L0x4169fc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414370 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414374 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416a00; Value = 0x2fad0ae3042f97de; PC = 0x414378 *)
mov %v22 [L0x416a00, L0x416a04, L0x416a08, L0x416a0c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41437c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414380 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416a10; Value = 0x002fa12000042e8c; PC = 0x414384 *)
mov %v23 [L0x416a10, L0x416a14, L0x416a18, L0x416a1c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414388 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41438c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414390 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414394 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o1e@int32[4], %v2o1e@int32[4]:
       %v0o1e =  %v0 /\  %v2o1e =  %v2 &&  %v0o1e =  %v0 /\  %v2o1e =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414398 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x41439c *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x4143a0 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x4143a4 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 66 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o1e +  %v1 /\ %v12 =  %v0o1e -  %v1 /\
     %v2 =  %v2o1e +  %v3 /\ %v13 =  %v2o1e -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o1e@int32[4],%v18o1e@int32[4],%v12o1e@int32[4],%v13o1e@int32[4]:
      %v16o1e = %v16 /\ %v18o1e = %v18 /\%v12o1e = %v12 /\ %v13o1e = %v13
   && %v16o1e = %v16 /\ %v18o1e = %v18 /\%v12o1e = %v12 /\ %v13o1e = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x4143a8 *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x4143ac *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x4143b0 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x4143b4 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x4143b8 *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4143bc *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x4143c0 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4143c4 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4143c8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4143cc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o1e*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1e*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o1e*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1e*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 67 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o1e + %v17 /\ %v28 = %v16o1e - %v17 /\
    %v18 = %v18o1e + %v19 /\ %v29 = %v18o1e - %v19 /\
    eqmod  %v1 (%v12o1e*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o1e*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o1f@int32[4], %v1o1f@int32[4],%v28o1f@int32[4],%v29o1f@int32[4]:
       %v0o1f =  %v0 /\  %v1o1f =  %v1 /\%v28o1f = %v28 /\ %v29o1f = %v29
   &&  %v0o1f =  %v0 /\  %v1o1f =  %v1 /\%v28o1f = %v28 /\ %v29o1f = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x4143d0 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4143d4 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x4143d8 *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4143dc *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x4143e0 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4143e4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x4143e8 *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4143ec *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4143f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4143f4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o1f*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1f*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [66]] && true;
assume eqmod %v17 (%v28o1f*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o1f*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 68 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o1f +  %v2 /\ %v12 =  %v0o1f -  %v2 /\
     %v1 =  %v1o1f +  %v3 /\ %v13 =  %v1o1f -  %v3 /\
    eqmod %v17 (%v28o1f*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o1f*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [66]];

ghost %v16o1f@int32[4],%v17o1f@int32[4],%v12o1f@int32[4],%v13o1f@int32[4]:
      %v16o1f = %v16 /\ %v17o1f = %v17 /\%v12o1f = %v12 /\ %v13o1f = %v13
   && %v16o1f = %v16 /\ %v17o1f = %v17 /\%v12o1f = %v12 /\ %v13o1f = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x4143f8 *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4143fc *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414400 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414404 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x414408 *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x41440c *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414410 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414414 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414418 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x41441c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o1f*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1f*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [67]] && true;
assume eqmod  %v2 (%v12o1f*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o1f*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 69 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o1f + %v18 /\ %v28 = %v16o1f - %v18 /\
    %v17 = %v17o1f + %v19 /\ %v29 = %v17o1f - %v19 /\
    eqmod  %v2 (%v12o1f*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o1f*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [67]];

ghost %v28o20@int32[4],%v29o20@int32[4]:
      %v28o20 = %v28 /\ %v29o20 = %v29 && %v28o20 = %v28 /\ %v29o20 = %v29;

(* sub	x19, x19, #0x1                              #! PC = 0x414420 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! PC = 0x414424 *)
#cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! 0x414424 = 0x414424;
(* ldr	q8, [x28, #192]                             #! EA = L0x4166a0; Value = 0x12045df329e6ec67; PC = 0x4141a8 *)
mov %v8 [L0x4166a0, L0x4166a4, L0x4166a8, L0x4166ac];
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x4141ac *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* ldr	q9, [x28, #208]                             #! EA = L0x4166b0; Value = 0x0011ffdd0029dc73; PC = 0x4141b0 *)
mov %v9 [L0x4166b0, L0x4166b4, L0x4166b8, L0x4166bc];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x4141b4 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* ldr	q10, [x28, #224]                            #! EA = L0x4166c0; Value = 0xf70bc202f7ef8ef4; PC = 0x4141b8 *)
mov %v10 [L0x4166c0, L0x4166c4, L0x4166c8, L0x4166cc];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x4141bc *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x4141c0 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q11, [x28, #240]                            #! EA = L0x4166d0; Value = 0xfff70dfffff7f193; PC = 0x4141c4 *)
mov %v11 [L0x4166d0, L0x4166d4, L0x4166d8, L0x4166dc];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x4141c8 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x4141cc *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x4141d0 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x4141d4 *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x4141d8 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x4141dc *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4141e0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x4141e4 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4141e8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o20*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o20*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o20*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o20*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 70 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o20*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o20*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x4141ec *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q24, [x27, #192]                            #! EA = L0x416aa0; Value = 0x1b30cefdd5a6f211; PC = 0x4141f0 *)
mov %v24 [L0x416aa0, L0x416aa4, L0x416aa8, L0x416aac];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x4141f4 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x4141f8 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q25, [x27, #208]                            #! EA = L0x416ab0; Value = 0x001b2a03ffd5b188; PC = 0x4141fc *)
mov %v25 [L0x416ab0, L0x416ab4, L0x416ab8, L0x416abc];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414200 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414204 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q26, [x27, #224]                            #! EA = L0x416ac0; Value = 0xd75d9fb900e745d0; PC = 0x414208 *)
mov %v26 [L0x416ac0, L0x416ac4, L0x416ac8, L0x416acc];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41420c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414210 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q27, [x27, #240]                            #! EA = L0x416ad0; Value = 0xffd767c80000e70c; PC = 0x414214 *)
mov %v27 [L0x416ad0, L0x416ad4, L0x416ad8, L0x416adc];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414218 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41421c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o20@int32[4], %v2o20@int32[4]:
       %v0o20 =  %v0 /\  %v2o20 =  %v2 &&  %v0o20 =  %v0 /\  %v2o20 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414220 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414224 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414228 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41422c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [68, 69]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 71 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o20 +  %v1 /\ %v12 =  %v0o20 -  %v1 /\
     %v2 =  %v2o20 +  %v3 /\ %v13 =  %v2o20 -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [68, 69]];

ghost %v16o20@int32[4],%v18o20@int32[4],%v12o20@int32[4],%v13o20@int32[4]:
      %v16o20 = %v16 /\ %v18o20 = %v18 /\%v12o20 = %v12 /\ %v13o20 = %v13
   && %v16o20 = %v16 /\ %v18o20 = %v18 /\%v12o20 = %v12 /\ %v13o20 = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414230 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414234 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414238 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41423c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x414240 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x414244 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x414248 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x41424c *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x414250 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414254 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o20*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o20*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [69, 70]] && true;
assume eqmod  %v1 (%v12o20*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o20*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 72 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o20 + %v17 /\ %v28 = %v16o20 - %v17 /\
    %v18 = %v18o20 + %v19 /\ %v29 = %v18o20 - %v19 /\
    eqmod  %v1 (%v12o20*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o20*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [69, 70]];

ghost  %v0o21@int32[4], %v1o21@int32[4],%v28o21@int32[4],%v29o21@int32[4]:
       %v0o21 =  %v0 /\  %v1o21 =  %v1 /\%v28o21 = %v28 /\ %v29o21 = %v29
   &&  %v0o21 =  %v0 /\  %v1o21 =  %v1 /\%v28o21 = %v28 /\ %v29o21 = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x414258 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x41425c *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x414260 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x414264 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x414268 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x41426c *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x414270 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x414274 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x414278 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41427c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o21*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o21*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [71]] && true;
assume eqmod %v17 (%v28o21*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o21*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 73 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o21 +  %v2 /\ %v12 =  %v0o21 -  %v2 /\
     %v1 =  %v1o21 +  %v3 /\ %v13 =  %v1o21 -  %v3 /\
    eqmod %v17 (%v28o21*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o21*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [71]];

ghost %v16o21@int32[4],%v17o21@int32[4],%v12o21@int32[4],%v13o21@int32[4]:
      %v16o21 = %v16 /\ %v17o21 = %v17 /\%v12o21 = %v12 /\ %v13o21 = %v13
   && %v16o21 = %v16 /\ %v17o21 = %v17 /\%v12o21 = %v12 /\ %v13o21 = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x414280 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x414284 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x414288 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x41428c *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x414290 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x414294 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x414298 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x41429c *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x4142a0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4142a4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o21*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o21*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [72]] && true;
assume eqmod  %v2 (%v12o21*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o21*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 74 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o21 + %v18 /\ %v28 = %v16o21 - %v18 /\
    %v17 = %v17o21 + %v19 /\ %v29 = %v17o21 - %v19 /\
    eqmod  %v2 (%v12o21*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o21*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [72]];

ghost %v28o22@int32[4],%v29o22@int32[4]:
      %v28o22 = %v28 /\ %v29o22 = %v29 && %v28o22 = %v28 /\ %v29o22 = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x4142a8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x4142ac *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x4142b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x4142b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x4142b8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4142bc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o22*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o22*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o22*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o22*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 75 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o22*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o22*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o22@int32[4], %v1o22@int32[4],%v16o22@int32[4],%v17o22@int32[4]:
       %v0o22 =  %v0 /\  %v1o22 =  %v1 /\%v16o22 = %v16 /\ %v17o22 = %v17
   &&  %v0o22 =  %v0 /\  %v1o22 =  %v1 /\%v16o22 = %v16 /\ %v17o22 = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff07b0; PC = 0x4142c0 *)
mov [L0xffffffff07b0, L0xffffffff07b4, L0xffffffff07b8, L0xffffffff07bc] %v2;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x4142c4 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* ldr	q2, [x0, #96]                               #! EA = L0xffffffff07f0; Value = 0xffdc21c0ffd04c9b; PC = 0x4142c8 *)
mov %v2 [L0xffffffff07f0, L0xffffffff07f4, L0xffffffff07f8, L0xffffffff07fc];
(* str	q3, [x0, #48]                               #! EA = L0xffffffff07c0; PC = 0x4142cc *)
mov [L0xffffffff07c0, L0xffffffff07c4, L0xffffffff07c8, L0xffffffff07cc] %v3;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x4142d0 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* ldr	q3, [x0, #112]                              #! EA = L0xffffffff0800; Value = 0x001e6652ffc5027e; PC = 0x4142d4 *)
mov %v3 [L0xffffffff0800, L0xffffffff0804, L0xffffffff0808, L0xffffffff080c];
(* str	q18, [x2, #32]                              #! EA = L0xffffffff09b0; PC = 0x4142d8 *)
mov [L0xffffffff09b0, L0xffffffff09b4, L0xffffffff09b8, L0xffffffff09bc] %v18;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x4142dc *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* ldr	q18, [x2, #96]                              #! EA = L0xffffffff09f0; Value = 0xffeaa876ffd15941; PC = 0x4142e0 *)
mov %v18 [L0xffffffff09f0, L0xffffffff09f4, L0xffffffff09f8, L0xffffffff09fc];
(* str	q19, [x2, #48]                              #! EA = L0xffffffff09c0; PC = 0x4142e4 *)
mov [L0xffffffff09c0, L0xffffffff09c4, L0xffffffff09c8, L0xffffffff09cc] %v19;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x4142e8 *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* ldr	q19, [x2, #112]                             #! EA = L0xffffffff0a00; Value = 0xfff44032fff55d61; PC = 0x4142ec *)
mov %v19 [L0xffffffff0a00, L0xffffffff0a04, L0xffffffff0a08, L0xffffffff0a0c];
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x4142f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff0790; PC = 0x4142f4 *)
mov [L0xffffffff0790, L0xffffffff0794, L0xffffffff0798, L0xffffffff079c] %v0;
(* ldr	q0, [x0, #64]                               #! EA = L0xffffffff07d0; Value = 0x002944870013f8a2; PC = 0x4142f8 *)
mov %v0 [L0xffffffff07d0, L0xffffffff07d4, L0xffffffff07d8, L0xffffffff07dc];
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x4142fc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff07a0; PC = 0x414300 *)
mov [L0xffffffff07a0, L0xffffffff07a4, L0xffffffff07a8, L0xffffffff07ac] %v1;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff07e0; Value = 0x001a2c74ffc79307; PC = 0x414304 *)
mov %v1 [L0xffffffff07e0, L0xffffffff07e4, L0xffffffff07e8, L0xffffffff07ec];
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414308 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* str	q16, [x2]                                   #! EA = L0xffffffff0990; PC = 0x41430c *)
mov [L0xffffffff0990, L0xffffffff0994, L0xffffffff0998, L0xffffffff099c] %v16;
(* ldr	q16, [x2, #64]                              #! EA = L0xffffffff09d0; Value = 0xfff303b90007c183; PC = 0x414310 *)
mov %v16 [L0xffffffff09d0, L0xffffffff09d4, L0xffffffff09d8, L0xffffffff09dc];
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x414314 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff09a0; PC = 0x414318 *)
mov [L0xffffffff09a0, L0xffffffff09a4, L0xffffffff09a8, L0xffffffff09ac] %v17;
(* ldr	q17, [x2, #80]                              #! EA = L0xffffffff09e0; Value = 0x00349d5affe68188; PC = 0x41431c *)
mov %v17 [L0xffffffff09e0, L0xffffffff09e4, L0xffffffff09e8, L0xffffffff09ec];

assert eqmod [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]
              %v0o22 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]
              %v1o22 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]
             %v16o22 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]
             %v17o22 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
       [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
       [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
       [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
       [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
       [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
       [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
       [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
       [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [73, 74]] && true;

assume eqmod [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]
              %v0o22 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]
              %v1o22 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]
             %v16o22 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]
             %v17o22 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
       [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
       [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
       [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
       [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
       [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
       [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
       [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
       [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
       [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
       [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
       [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
       [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
       [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
       [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
       [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
       [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<s[Q,Q,Q,Q];
(* CUT 76 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c,
                   L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac,
                   L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc,
                   L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc])
          (16*F**2) [Q, X**16 - 1753**208] /\
    eqmod (poly X [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c,
                   L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac,
                   L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc,
                   L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc])
          (16*F**2) [Q, X**16 - 1753**240] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
    [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
    [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
    [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
    [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
    [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
    [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
    [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
    [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [66, 67, 68, 69, 70, 71, 72, 73, 74, 75]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
    [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
    [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
    [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
    [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
    [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
    [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
    [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
    [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<s[Q,Q,Q,Q];

(* add	x28, x28, #0x80                             #! PC = 0x414320 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414324 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414328 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41432c *)
adds dc x2 x2 (0x40)@uint64;
(* ldr	q4, [x28]                                   #! EA = L0x416660; Value = 0x00000000007fe001; PC = 0x414330 *)
mov %v4 [L0x416660, L0x416664, L0x416668, L0x41666c];
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x414334 *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414338 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* ldr	q5, [x28, #16]                              #! EA = L0x416670; Value = 0xffe5278de520d56b; PC = 0x41433c *)
mov %v5 [L0x416670, L0x416674, L0x416678, L0x41667c];
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x414340 *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414344 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* ldr	q6, [x28, #32]                              #! EA = L0x416680; Value = 0x2485520b227022c4; PC = 0x414348 *)
mov %v6 [L0x416680, L0x416684, L0x416688, L0x41668c];
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41434c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414350 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* ldr	q7, [x28, #48]                              #! EA = L0x416690; Value = 0x00247c3100226787; PC = 0x414354 *)
mov %v7 [L0x416690, L0x416694, L0x416698, L0x41669c];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414358 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41435c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* ldr	q20, [x27]                                  #! EA = L0x416a60; Value = 0x00000000007fe001; PC = 0x414360 *)
mov %v20 [L0x416a60, L0x416a64, L0x416a68, L0x416a6c];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414364 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414368 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* ldr	q21, [x27, #16]                             #! EA = L0x416a70; Value = 0xffcf6ee2cf62bb10; PC = 0x41436c *)
mov %v21 [L0x416a70, L0x416a74, L0x416a78, L0x416a7c];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414370 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x414374 *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* ldr	q22, [x27, #32]                             #! EA = L0x416a80; Value = 0x2840e0e8c52a5c0d; PC = 0x414378 *)
mov %v22 [L0x416a80, L0x416a84, L0x416a88, L0x416a8c];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x41437c *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414380 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* ldr	q23, [x27, #48]                             #! EA = L0x416a90; Value = 0x002836d1ffc53911; PC = 0x414384 *)
mov %v23 [L0x416a90, L0x416a94, L0x416a98, L0x416a9c];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414388 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41438c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];
(* mov	v4.s[0], w20                                #! PC = 0x414390 *)
mov [_, m1, m2, m3] %v4; mov %v4 [w20, m1, m2, m3];
(* mov	v20.d[0], x21                               #! PC = 0x414394 *)
spl H L x21 32; cast L@int32 L; mov [_, _, m2, m3] %v20; mov %v20 [L, H, m2, m3];

ghost  %v0o23@int32[4], %v2o23@int32[4]:
       %v0o23 =  %v0 /\  %v2o23 =  %v2 &&  %v0o23 =  %v0 /\  %v2o23 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414398 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x41439c *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x4143a0 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x4143a4 *)
add %v2 %v2 %v3;

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, precondition] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 77 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o23 +  %v1 /\ %v12 =  %v0o23 -  %v1 /\
     %v2 =  %v2o23 +  %v3 /\ %v13 =  %v2o23 -  %v3 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [precondition];

ghost %v16o23@int32[4],%v18o23@int32[4],%v12o23@int32[4],%v13o23@int32[4]:
      %v16o23 = %v16 /\ %v18o23 = %v18 /\%v12o23 = %v12 /\ %v13o23 = %v13
   && %v16o23 = %v16 /\ %v18o23 = %v18 /\%v12o23 = %v12 /\ %v13o23 = %v13;

(* mul	v1.4s, v12.4s, v9.4s                        #! PC = 0x4143a8 *)
mull %dc %v1 %v12 %v9; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x4143ac *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v11.4s                       #! PC = 0x4143b0 *)
mull %dc %v3 %v13 %v11; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x4143b4 *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v8.4s                  #! PC = 0x4143b8 *)
mulj %mm %v12 %v8; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4143bc *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v10.4s                 #! PC = 0x4143c0 *)
mulj %mm %v13 %v10; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4143c4 *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4143c8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4143cc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o23*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o23*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, precondition] && true;
assume eqmod  %v1 (%v12o23*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o23*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 78 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o23 + %v17 /\ %v28 = %v16o23 - %v17 /\
    %v18 = %v18o23 + %v19 /\ %v29 = %v18o23 - %v19 /\
    eqmod  %v1 (%v12o23*[ %v9[0], %v9[1], %v9[2], %v9[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o23*[%v11[0],%v11[1],%v11[2],%v11[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [precondition];

ghost  %v0o24@int32[4], %v1o24@int32[4],%v28o24@int32[4],%v29o24@int32[4]:
       %v0o24 =  %v0 /\  %v1o24 =  %v1 /\%v28o24 = %v28 /\ %v29o24 = %v29
   &&  %v0o24 =  %v0 /\  %v1o24 =  %v1 /\%v28o24 = %v28 /\ %v29o24 = %v29;

(* mul	v17.4s, v28.4s, v25.4s                      #! PC = 0x4143d0 *)
mull %dc %v17 %v28 %v25; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4143d4 *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v27.4s                      #! PC = 0x4143d8 *)
mull %dc %v19 %v29 %v27; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4143dc *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v24.4s                 #! PC = 0x4143e0 *)
mulj %mm %v28 %v24; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4143e4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.4s                 #! PC = 0x4143e8 *)
mulj %mm %v29 %v26; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4143ec *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4143f0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4143f4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o24*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o24*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [77]] && true;
assume eqmod %v17 (%v28o24*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o24*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 79 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o24 +  %v2 /\ %v12 =  %v0o24 -  %v2 /\
     %v1 =  %v1o24 +  %v3 /\ %v13 =  %v1o24 -  %v3 /\
    eqmod %v17 (%v28o24*[%v25[0],%v25[1],%v25[2],%v25[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o24*[%v27[0],%v27[1],%v27[2],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [77]];

ghost %v16o24@int32[4],%v17o24@int32[4],%v12o24@int32[4],%v13o24@int32[4]:
      %v16o24 = %v16 /\ %v17o24 = %v17 /\%v12o24 = %v12 /\ %v13o24 = %v13
   && %v16o24 = %v16 /\ %v17o24 = %v17 /\%v12o24 = %v12 /\ %v13o24 = %v13;

(* mul	v2.4s, v12.4s, v7.4s                        #! PC = 0x4143f8 *)
mull %dc %v2 %v12 %v7; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4143fc *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v7.4s                        #! PC = 0x414400 *)
mull %dc %v3 %v13 %v7; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x414404 *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v6.4s                  #! PC = 0x414408 *)
mulj %mm %v12 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x41440c *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v6.4s                  #! PC = 0x414410 *)
mulj %mm %v13 %v6; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x414414 *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414418 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x41441c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o24*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o24*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [78]] && true;
assume eqmod  %v2 (%v12o24*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o24*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 80 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o24 + %v18 /\ %v28 = %v16o24 - %v18 /\
    %v17 = %v17o24 + %v19 /\ %v29 = %v17o24 - %v19 /\
    eqmod  %v2 (%v12o24*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o24*[ %v7[0], %v7[1], %v7[2], %v7[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [78]];

ghost %v28o25@int32[4],%v29o25@int32[4]:
      %v28o25 = %v28 /\ %v29o25 = %v29 && %v28o25 = %v28 /\ %v29o25 = %v29;

(* sub	x19, x19, #0x1                              #! PC = 0x414420 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! PC = 0x414424 *)
#cbnz	x19, 0x4141a8 <_intt_bot_loop>            #! 0x414424 = 0x414424;
(* mul	v18.4s, v28.4s, v23.4s                      #! PC = 0x414428 *)
mull %dc %v18 %v28 %v23; cast [] %v18@int32[4] %v18;
(* trn1	v12.4s, v0.4s, v1.4s                       #! PC = 0x41442c *)
mov [t0, _, t2, _] %v0; mov [t1, _, t3, _] %v1; mov %v12 [t0, t1, t2, t3];
(* mul	v19.4s, v29.4s, v23.4s                      #! PC = 0x414430 *)
mull %dc %v19 %v29 %v23; cast [] %v19@int32[4] %v19;
(* trn2	v13.4s, v0.4s, v1.4s                       #! PC = 0x414434 *)
mov [_, t0, _, t2] %v0; mov [_, t1, _, t3] %v1; mov %v13 [t0, t1, t2, t3];
(* sqrdmulh	v28.4s, v28.4s, v22.4s                 #! PC = 0x414438 *)
mulj %mm %v28 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* trn1	v14.4s, v2.4s, v3.4s                       #! PC = 0x41443c *)
mov [t0, _, t2, _] %v2; mov [t1, _, t3, _] %v3; mov %v14 [t0, t1, t2, t3];
(* sqrdmulh	v29.4s, v29.4s, v22.4s                 #! PC = 0x414440 *)
mulj %mm %v29 %v22; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* trn2	v15.4s, v2.4s, v3.4s                       #! PC = 0x414444 *)
mov [_, t0, _, t2] %v2; mov [_, t1, _, t3] %v3; mov %v15 [t0, t1, t2, t3];
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x414448 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* trn1	v0.2d, v12.2d, v14.2d                      #! PC = 0x41444c *)
mov [t0, t1, _, _] %v12; mov [t2, t3, _, _] %v14; mov %v0 [t0, t1, t2, t3];
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x414450 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o25*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o25*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o25*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o25*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 81 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o25*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o25*[%v23[0],%v23[1],%v23[2],%v23[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* trn2	v2.2d, v12.2d, v14.2d                      #! PC = 0x414454 *)
mov [_, _, t0, t1] %v12; mov [_, _, t2, t3] %v14; mov %v2 [t0, t1, t2, t3];
(* trn1	v1.2d, v13.2d, v15.2d                      #! PC = 0x414458 *)
mov [t0, t1, _, _] %v13; mov [t2, t3, _, _] %v15; mov %v1 [t0, t1, t2, t3];
(* trn2	v3.2d, v13.2d, v15.2d                      #! PC = 0x41445c *)
mov [_, _, t0, t1] %v13; mov [_, _, t2, t3] %v15; mov %v3 [t0, t1, t2, t3];
(* trn1	v28.4s, v16.4s, v17.4s                     #! PC = 0x414460 *)
mov [t0, _, t2, _] %v16; mov [t1, _, t3, _] %v17; mov %v28 [t0, t1, t2, t3];
(* trn2	v29.4s, v16.4s, v17.4s                     #! PC = 0x414464 *)
mov [_, t0, _, t2] %v16; mov [_, t1, _, t3] %v17; mov %v29 [t0, t1, t2, t3];
(* trn1	v30.4s, v18.4s, v19.4s                     #! PC = 0x414468 *)
mov [t0, _, t2, _] %v18; mov [t1, _, t3, _] %v19; mov %v30 [t0, t1, t2, t3];
(* trn2	v31.4s, v18.4s, v19.4s                     #! PC = 0x41446c *)
mov [_, t0, _, t2] %v18; mov [_, t1, _, t3] %v19; mov %v31 [t0, t1, t2, t3];
(* trn1	v16.2d, v28.2d, v30.2d                     #! PC = 0x414470 *)
mov [t0, t1, _, _] %v28; mov [t2, t3, _, _] %v30; mov %v16 [t0, t1, t2, t3];
(* trn2	v18.2d, v28.2d, v30.2d                     #! PC = 0x414474 *)
mov [_, _, t0, t1] %v28; mov [_, _, t2, t3] %v30; mov %v18 [t0, t1, t2, t3];
(* trn1	v17.2d, v29.2d, v31.2d                     #! PC = 0x414478 *)
mov [t0, t1, _, _] %v29; mov [t2, t3, _, _] %v31; mov %v17 [t0, t1, t2, t3];
(* trn2	v19.2d, v29.2d, v31.2d                     #! PC = 0x41447c *)
mov [_, _, t0, t1] %v29; mov [_, _, t2, t3] %v31; mov %v19 [t0, t1, t2, t3];

ghost  %v0o25@int32[4], %v2o25@int32[4]:
       %v0o25 =  %v0 /\  %v2o25 =  %v2 &&  %v0o25 =  %v0 /\  %v2o25 =  %v2;

(* sub	v12.4s, v0.4s, v1.4s                        #! PC = 0x414480 *)
sub %v12 %v0 %v1;
(* sub	v13.4s, v2.4s, v3.4s                        #! PC = 0x414484 *)
sub %v13 %v2 %v3;
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x414488 *)
add %v0 %v0 %v1;
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x41448c *)
add %v2 %v2 %v3;

assert [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [79, 80]] && true;
assume [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [8*Q,4*Q,2*Q,2*Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
        %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
       %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
        %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
       %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q];
(* CUT 82 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o25 +  %v1 /\ %v12 =  %v0o25 -  %v1 /\
     %v2 =  %v2o25 +  %v3 /\ %v13 =  %v2o25 -  %v3 /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [8*Q,4*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v0 /\
     %v0 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v12 /\
    %v12 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <  %v2 /\
     %v2 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] < %v13 /\
    %v13 < [8@32*Q,4@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [79, 80]];

ghost %v16o25@int32[4],%v18o25@int32[4],%v12o25@int32[4],%v13o25@int32[4]:
      %v16o25 = %v16 /\ %v18o25 = %v18 /\%v12o25 = %v12 /\ %v13o25 = %v13
   && %v16o25 = %v16 /\ %v18o25 = %v18 /\%v12o25 = %v12 /\ %v13o25 = %v13;

(* mul	v1.4s, v12.4s, v5.s[1]                      #! PC = 0x414490 *)
mov [_, m, _, _] %v5; mov %mm [m, m, m, m];
mull %dc %v1 %v12 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v16.4s, v17.4s                      #! PC = 0x414494 *)
sub %v28 %v16 %v17;
(* mul	v3.4s, v13.4s, v5.s[3]                      #! PC = 0x414498 *)
mov [_, _, _, m] %v5; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v18.4s, v19.4s                      #! PC = 0x41449c *)
sub %v29 %v18 %v19;
(* sqrdmulh	v12.4s, v12.4s, v5.s[0]                #! PC = 0x4144a0 *)
mov [m, _, _, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v17.4s                      #! PC = 0x4144a4 *)
add %v16 %v16 %v17;
(* sqrdmulh	v13.4s, v13.4s, v5.s[2]                #! PC = 0x4144a8 *)
mov [_, _, m, _] %v5; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v18.4s, v18.4s, v19.4s                      #! PC = 0x4144ac *)
add %v18 %v18 %v19;
(* mls	v1.4s, v12.4s, v4.s[0]                      #! PC = 0x4144b0 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x4144b4 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v1 (%v12o25*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o25*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [80, 81]] && true;
assume eqmod  %v1 (%v12o25*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o25*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [8*Q,4*Q,2*Q,2*Q] /\
       [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [8*Q,4*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 83 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o25 + %v17 /\ %v28 = %v16o25 - %v17 /\
    %v18 = %v18o25 + %v19 /\ %v29 = %v18o25 - %v19 /\
    eqmod  %v1 (%v12o25*[ %v5[1], %v5[1], %v5[1], %v5[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o25*[ %v5[3], %v5[3], %v5[3], %v5[3]]) [Q,Q,Q,Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [8*Q,4*Q,2*Q,2*Q] /\
    [8*NQ,4*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [8*Q,4*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [8@32*NQ,4@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,4@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [80, 81]];

ghost  %v0o26@int32[4], %v1o26@int32[4],%v28o26@int32[4],%v29o26@int32[4]:
       %v0o26 =  %v0 /\  %v1o26 =  %v1 /\%v28o26 = %v28 /\ %v29o26 = %v29
   &&  %v0o26 =  %v0 /\  %v1o26 =  %v1 /\%v28o26 = %v28 /\ %v29o26 = %v29;

(* mul	v17.4s, v28.4s, v21.s[1]                    #! PC = 0x4144b8 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v17 %v28 %mm; cast [] %v17@int32[4] %v17;
(* sub	v12.4s, v0.4s, v2.4s                        #! PC = 0x4144bc *)
sub %v12 %v0 %v2;
(* mul	v19.4s, v29.4s, v21.s[3]                    #! PC = 0x4144c0 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sub	v13.4s, v1.4s, v3.4s                        #! PC = 0x4144c4 *)
sub %v13 %v1 %v3;
(* sqrdmulh	v28.4s, v28.4s, v21.s[0]               #! PC = 0x4144c8 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4144cc *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x4144d0 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4144d4 *)
add %v1 %v1 %v3;
(* mls	v17.4s, v28.4s, v4.s[0]                     #! PC = 0x4144d8 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x4144dc *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v17 (%v28o26*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o26*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [82]] && true;
assume eqmod %v17 (%v28o26*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o26*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
        %v1 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
       %v13 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
        %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
       %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 84 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o26 +  %v2 /\ %v12 =  %v0o26 -  %v2 /\
     %v1 =  %v1o26 +  %v3 /\ %v13 =  %v1o26 -  %v3 /\
    eqmod %v17 (%v28o26*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o26*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v1 /\
     %v1 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v13 /\
    %v13 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] < %v17 /\ %v17 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v1 /\
     %v1 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v13 /\
    %v13 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v17 /\ %v17 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q]
    prove with [cuts [82]];

ghost %v16o26@int32[4],%v17o26@int32[4],%v12o26@int32[4],%v13o26@int32[4]:
      %v16o26 = %v16 /\ %v17o26 = %v17 /\%v12o26 = %v12 /\ %v13o26 = %v13
   && %v16o26 = %v16 /\ %v17o26 = %v17 /\%v12o26 = %v12 /\ %v13o26 = %v13;

(* mul	v2.4s, v12.4s, v4.s[3]                      #! PC = 0x4144e0 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v2 %v12 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v16.4s, v18.4s                      #! PC = 0x4144e4 *)
sub %v28 %v16 %v18;
(* mul	v3.4s, v13.4s, v4.s[3]                      #! PC = 0x4144e8 *)
mov [_, _, _, m] %v4; mov %mm [m, m, m, m];
mull %dc %v3 %v13 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v17.4s, v19.4s                      #! PC = 0x4144ec *)
sub %v29 %v17 %v19;
(* sqrdmulh	v12.4s, v12.4s, v4.s[2]                #! PC = 0x4144f0 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* add	v16.4s, v16.4s, v18.4s                      #! PC = 0x4144f4 *)
add %v16 %v16 %v18;
(* sqrdmulh	v13.4s, v13.4s, v4.s[2]                #! PC = 0x4144f8 *)
mov [_, _, m, _] %v4; mov %mm [m, m, m, m];
mulj %mm %v13 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v13 %dc %mm 1;
(* add	v17.4s, v17.4s, v19.4s                      #! PC = 0x4144fc *)
add %v17 %v17 %v19;
(* mls	v2.4s, v12.4s, v4.s[0]                      #! PC = 0x414500 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v13.4s, v4.s[0]                      #! PC = 0x414504 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v13 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;

assert eqmod  %v2 (%v12o26*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o26*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [83]] && true;
assume eqmod  %v2 (%v12o26*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v13o26*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [16*Q,8*Q,4*Q,4*Q] /\
       [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [16*Q,8*Q,4*Q,4*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
    && [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
       %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q];

(* CUT 85 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 = %v16o26 + %v18 /\ %v28 = %v16o26 - %v18 /\
    %v17 = %v17o26 + %v19 /\ %v29 = %v17o26 - %v19 /\
    eqmod  %v2 (%v12o26*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v13o26*[ %v4[3], %v4[3], %v4[3], %v4[3]]) [Q,Q,Q,Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [16*Q,8*Q,4*Q,4*Q] /\
    [16*NQ,8*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [16*Q,8*Q,4*Q,4*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [16@32*NQ,8@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,8@32*Q,4@32*Q,4@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q]
    prove with [cuts [83]];

ghost %v28o27@int32[4],%v29o27@int32[4]:
      %v28o27 = %v28 /\ %v29o27 = %v29 && %v28o27 = %v28 /\ %v29o27 = %v29;

(* mul	v18.4s, v28.4s, v20.s[3]                    #! PC = 0x414508 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v18 %v28 %mm; cast [] %v18@int32[4] %v18;
(* mul	v19.4s, v29.4s, v20.s[3]                    #! PC = 0x41450c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v19 %v29 %mm; cast [] %v19@int32[4] %v19;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x414510 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x414514 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* mls	v18.4s, v28.4s, v4.s[0]                     #! PC = 0x414518 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v18 %v18 %mm;
(* mls	v19.4s, v29.4s, v4.s[0]                     #! PC = 0x41451c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v19 %v19 %mm;

assert eqmod %v18 (%v28o27*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o27*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v18 (%v28o27*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v19 (%v29o27*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

(* CUT 86 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v18 (%v28o27*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v19 (%v29o27*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v18 /\ %v18 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v19 /\ %v19 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v18 /\ %v18 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v19 /\ %v19 <s [Q,Q,Q,Q];

ghost  %v0o27@int32[4], %v1o27@int32[4],%v16o27@int32[4],%v17o27@int32[4]:
       %v0o27 =  %v0 /\  %v1o27 =  %v1 /\%v16o27 = %v16 /\ %v17o27 = %v17
   &&  %v0o27 =  %v0 /\  %v1o27 =  %v1 /\%v16o27 = %v16 /\ %v17o27 = %v17;

(* str	q2, [x0, #32]                               #! EA = L0xffffffff07f0; PC = 0x414520 *)
mov [L0xffffffff07f0, L0xffffffff07f4, L0xffffffff07f8, L0xffffffff07fc] %v2;
(* str	q3, [x0, #48]                               #! EA = L0xffffffff0800; PC = 0x414524 *)
mov [L0xffffffff0800, L0xffffffff0804, L0xffffffff0808, L0xffffffff080c] %v3;
(* str	q18, [x2, #32]                              #! EA = L0xffffffff09f0; PC = 0x414528 *)
mov [L0xffffffff09f0, L0xffffffff09f4, L0xffffffff09f8, L0xffffffff09fc] %v18;
(* str	q19, [x2, #48]                              #! EA = L0xffffffff0a00; PC = 0x41452c *)
mov [L0xffffffff0a00, L0xffffffff0a04, L0xffffffff0a08, L0xffffffff0a0c] %v19;
(* srshr	v14.4s, v0.4s, #23                        #! PC = 0x414530 *)
split %HI %LO %v0 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v14 %HI %LO0;
(* srshr	v15.4s, v1.4s, #23                        #! PC = 0x414534 *)
split %HI %LO %v1 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v15 %HI %LO0;
(* srshr	v30.4s, v16.4s, #23                       #! PC = 0x414538 *)
split %HI %LO %v16 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v30 %HI %LO0;
(* srshr	v31.4s, v17.4s, #23                       #! PC = 0x41453c *)
split %HI %LO %v17 23; split %LO1 %dc %LO (23-1);
cast %LO0@int32[4] %LO1; add %v31 %HI %LO0;
(* mls	v0.4s, v14.4s, v4.s[0]                      #! PC = 0x414540 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* mls	v1.4s, v15.4s, v4.s[0]                      #! PC = 0x414544 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v15 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v16.4s, v30.4s, v4.s[0]                     #! PC = 0x414548 *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v16 %v16 %mm;
(* mls	v17.4s, v31.4s, v4.s[0]                     #! PC = 0x41454c *)
mov [m, _, _, _] %v4; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v17 %v17 %mm;
(* str	q0, [x0]                                    #! EA = L0xffffffff07d0; PC = 0x414550 *)
mov [L0xffffffff07d0, L0xffffffff07d4, L0xffffffff07d8, L0xffffffff07dc] %v0;
(* str	q1, [x0, #16]                               #! EA = L0xffffffff07e0; PC = 0x414554 *)
mov [L0xffffffff07e0, L0xffffffff07e4, L0xffffffff07e8, L0xffffffff07ec] %v1;
(* str	q16, [x2]                                   #! EA = L0xffffffff09d0; PC = 0x414558 *)
mov [L0xffffffff09d0, L0xffffffff09d4, L0xffffffff09d8, L0xffffffff09dc] %v16;
(* str	q17, [x2, #16]                              #! EA = L0xffffffff09e0; PC = 0x41455c *)
mov [L0xffffffff09e0, L0xffffffff09e4, L0xffffffff09e8, L0xffffffff09ec] %v17;

assert eqmod [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]
              %v0o27 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]
              %v1o27 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]
             %v16o27 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]
             %v17o27 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
       [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
       [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
       [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
       [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
       [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
       [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
       [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
       [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<[Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [84, 85]] && true;

assume eqmod [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]
              %v0o27 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]
              %v1o27 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]
             %v16o27 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]
             %v17o27 [Q, Q, Q, Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
       [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
       [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
       [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
       [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
       [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
       [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
       [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
       [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<[Q,Q,Q,Q] &&
       [NQ,NQ,NQ,NQ]<s[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
       [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
       [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
       [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
       [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
       [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
       [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
       [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<s[Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ]<s[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
       [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<s[Q,Q,Q,Q];
(* CUT 87 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod (poly X [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc,
                   L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec,
                   L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc,
                   L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c])
          (16*F**2) [Q, X**16 - 1753**464] /\
    eqmod (poly X [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc,
                   L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec,
                   L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc,
                   L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c])
          (16*F**2) [Q, X**16 - 1753**496] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
    [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
    [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
    [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
    [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
    [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
    [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
    [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
    [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<[Q,Q,Q,Q]
    prove with [all ghosts, precondition, cuts [77, 78, 79, 80, 81, 82, 83, 84, 85, 86]]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
    [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
    [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
    [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
    [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
    [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
    [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
    [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<s[Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ]<s[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
    [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<s[Q,Q,Q,Q];

(* add	x28, x28, #0x80                             #! PC = 0x414560 *)
adds dc x28 x28 (0x80)@uint64;
(* add	x27, x27, #0x80                             #! PC = 0x414564 *)
adds dc x27 x27 (0x80)@uint64;
(* add	x0, x0, #0x40                               #! PC = 0x414568 *)
adds dc x0 x0 (0x40)@uint64;
(* add	x2, x2, #0x40                               #! PC = 0x41456c *)
adds dc x2 x2 (0x40)@uint64;
(* ldp	x19, x20, [sp]                              #! EA = L0xfffffffec440; Value = 0x00000000004159a0; PC = 0x414570 *)
mov x19 L0xfffffffec440; mov x20 L0xfffffffec448;
(* ldp	x21, x22, [sp, #16]                         #! EA = L0xfffffffec450; Value = 0x0000000000416260; PC = 0x414574 *)
mov x21 L0xfffffffec450; mov x22 L0xfffffffec458;
(* ldp	x23, x24, [sp, #32]                         #! EA = L0xfffffffec460; Value = 0x0000ffffffffdac0; PC = 0x414578 *)
mov x23 L0xfffffffec460; mov x24 L0xfffffffec468;
(* ldp	x25, x26, [sp, #48]                         #! EA = L0xfffffffec470; Value = 0x0000000000000000; PC = 0x41457c *)
mov x25 L0xfffffffec470; mov x26 L0xfffffffec478;
(* ldp	x27, x28, [sp, #64]                         #! EA = L0xfffffffec480; Value = 0x0000000000429de0; PC = 0x414580 *)
mov x27 L0xfffffffec480; mov x28 L0xfffffffec488;
(* ldp	d8, d9, [sp, #80]                           #! EA = L0xfffffffec490; Value = 0x0000000000000000; PC = 0x414584 *)
mov d8 L0xfffffffec490; mov d9 L0xfffffffec498;
(* ldp	d10, d11, [sp, #96]                         #! EA = L0xfffffffec4a0; Value = 0x0000000000000000; PC = 0x414588 *)
mov d10 L0xfffffffec4a0; mov d11 L0xfffffffec4a8;
(* ldp	d12, d13, [sp, #112]                        #! EA = L0xfffffffec4b0; Value = 0x0000000000000000; PC = 0x41458c *)
mov d12 L0xfffffffec4b0; mov d13 L0xfffffffec4b8;
(* ldp	d14, d15, [sp, #128]                        #! EA = L0xfffffffec4c0; Value = 0x0000000000000000; PC = 0x414590 *)
mov d14 L0xfffffffec4c0; mov d15 L0xfffffffec4c8;
(* #! <- SP = 0xfffffffec4d0 *)
#! 0xfffffffec4d0 = 0xfffffffec4d0;
(* #ret                                            #! PC = 0x414598 *)
#ret                                            #! 0x414598 = 0x414598;

(* END OF BOT *)

(**************** midcondition ****************)


(* CUT 88 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
eqmod (poly X [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c,
               L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c,
               L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c,
               L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c])
      (16*F**2) [Q, X**16 - 1753**16] /\
eqmod (poly X [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c,
               L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c,
               L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c,
               L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c])
      (16*F**2) [Q, X**16 - 1753**272] /\
eqmod (poly X [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c,
               L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac,
               L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc,
               L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc])
      (16*F**2) [Q, X**16 - 1753**144] /\
eqmod (poly X [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc,
               L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec,
               L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc,
               L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c])
      (16*F**2) [Q, X**16 - 1753**400] /\
eqmod (poly X [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c,
               L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c,
               L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c,
               L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c])
      (16*F**2) [Q, X**16 - 1753**80] /\
eqmod (poly X [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c,
               L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c,
               L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c,
               L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c])
      (16*F**2) [Q, X**16 - 1753**336] /\
eqmod (poly X [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c,
               L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac,
               L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc,
               L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc])
      (16*F**2) [Q, X**16 - 1753**208] /\
eqmod (poly X [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc,
               L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec,
               L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc,
               L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c])
      (16*F**2) [Q, X**16 - 1753**464] /\
eqmod (poly X [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c,
               L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c,
               L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c,
               L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c])
      (16*F**2) [Q, X**16 - 1753**48] /\
eqmod (poly X [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c,
               L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c,
               L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c,
               L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c])
      (16*F**2) [Q, X**16 - 1753**304] /\
eqmod (poly X [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c,
               L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac,
               L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc,
               L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc])
      (16*F**2) [Q, X**16 - 1753**176] /\
eqmod (poly X [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc,
               L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec,
               L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc,
               L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c])
      (16*F**2) [Q, X**16 - 1753**432] /\
eqmod (poly X [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c,
               L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c,
               L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c,
               L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c])
      (16*F**2) [Q, X**16 - 1753**112] /\
eqmod (poly X [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c,
               L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c,
               L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c,
               L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c])
      (16*F**2) [Q, X**16 - 1753**368] /\
eqmod (poly X [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c,
               L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac,
               L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc,
               L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc])
      (16*F**2) [Q, X**16 - 1753**240] /\
eqmod (poly X [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc,
               L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec,
               L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc,
               L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c])
      (16*F**2) [Q, X**16 - 1753**496] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<[Q,Q,Q,Q]
prove with [cuts [10, 21, 32, 43, 54, 65, 76 ,87]] && 
 Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c] /\
[L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c] /\
[L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c] /\
[L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c] /\
[L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c] /\
[L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c] /\
[L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c] /\
[L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c] /\
[L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c] /\
[L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac] /\
[L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc] /\
[L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc] /\
[L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc] /\
[L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec] /\
[L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc] /\
[L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c] /\
[L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c] /\
[L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c] /\
[L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c] /\
[L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c] /\
[L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c] /\
[L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c] /\
[L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c] /\
[L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c] /\
[L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c] /\
[L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac] /\
[L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc] /\
[L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc] /\
[L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc] /\
[L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec] /\
[L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc] /\
[L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c] /\
[L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c] /\
[L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c] /\
[L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c] /\
[L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c] /\
[L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c] /\
[L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c] /\
[L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c] /\
[L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c] /\
[L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c] /\
[L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac] /\
[L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc] /\
[L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc] /\
[L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc] /\
[L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec] /\
[L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc] /\
[L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c] /\
[L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c] /\
[L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c] /\
[L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c] /\
[L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c] /\
[L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c] /\
[L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c] /\
[L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c] /\
[L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c] /\
[L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c] /\
[L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac] /\
[L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc] /\
[L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc] /\
[L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc] /\
[L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec] /\
[L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc] /\
[L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]<s[Q,Q,Q,Q] /\
[NQ,NQ,NQ,NQ]<s[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c] /\
[L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]<s[Q,Q,Q,Q]
prove with [cuts [10, 21, 32, 43, 54, 65, 76 ,87]];

ghost F0@int32:
F0**2=poly X [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c,
              L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c,
              L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c,
              L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]
&& true;

(* mov	x2, x19                                     #! PC = 0x41367c *)
mov x2 x19;
(* mov	x1, x21                                     #! PC = 0x413680 *)
mov x1 x21;
(* ldr	x21, [sp, #32]                              #! EA = L0xfffffffec4f0; Value = 0x0000fffffffec5b0; PC = 0x413684 *)
mov x21 L0xfffffffec4f0;
(* mov	x0, x20                                     #! PC = 0x413688 *)
mov x0 x20;
(* ldp	x19, x20, [sp, #16]                         #! EA = L0xfffffffec4e0; Value = 0x0000ffffffff0a10; PC = 0x41368c *)
mov x19 L0xfffffffec4e0; mov x20 L0xfffffffec4e8;
(* ldp	x29, x30, [sp], #48                         #! EA = L0xfffffffec4d0; Value = 0x0000fffffffec500; PC = 0x413690 *)
mov x29 L0xfffffffec4d0; mov x30 L0xfffffffec4d8;
(* #b	0x413698 <_PQCLEAN_DILITHIUM3_AARCH64__asm_intt_SIMD_top>#! PC = 0x413694 *)
#b	0x413698 <_PQCLEAN_DILITHIUM3_AARCH64__asm_intt_SIMD_top>#! 0x413694 = 0x413694;
(* stp	x19, x20, [sp]                              #! EA = L0xfffffffec470; PC = 0x41369c *)
mov L0xfffffffec470 x19; mov L0xfffffffec478 x20;
(* stp	x21, x22, [sp, #16]                         #! EA = L0xfffffffec480; PC = 0x4136a0 *)
mov L0xfffffffec480 x21; mov L0xfffffffec488 x22;
(* stp	x23, x24, [sp, #32]                         #! EA = L0xfffffffec490; PC = 0x4136a4 *)
mov L0xfffffffec490 x23; mov L0xfffffffec498 x24;
(* stp	x25, x26, [sp, #48]                         #! EA = L0xfffffffec4a0; PC = 0x4136a8 *)
mov L0xfffffffec4a0 x25; mov L0xfffffffec4a8 x26;
(* stp	x27, x28, [sp, #64]                         #! EA = L0xfffffffec4b0; PC = 0x4136ac *)
mov L0xfffffffec4b0 x27; mov L0xfffffffec4b8 x28;
(* stp	d8, d9, [sp, #80]                           #! EA = L0xfffffffec4c0; PC = 0x4136b0 *)
mov L0xfffffffec4c0 d8; mov L0xfffffffec4c8 d9;
(* stp	d10, d11, [sp, #96]                         #! EA = L0xfffffffec4d0; PC = 0x4136b4 *)
mov L0xfffffffec4d0 d10; mov L0xfffffffec4d8 d11;
(* stp	d12, d13, [sp, #112]                        #! EA = L0xfffffffec4e0; PC = 0x4136b8 *)
mov L0xfffffffec4e0 d12; mov L0xfffffffec4e8 d13;
(* stp	d14, d15, [sp, #128]                        #! EA = L0xfffffffec4f0; PC = 0x4136bc *)
mov L0xfffffffec4f0 d14; mov L0xfffffffec4f8 d15;
(* ldr	w20, [x2]                                   #! EA = L0x4159a0; Value = 0xfc7fdfff007fe001; PC = 0x4136c0 *)
mov w20 L0x4159a0;
(* lsr	w21, w20, #1                                #! PC = 0x4136c4 *)
split w21 dc w20 1;
(* neg	w22, w21                                    #! PC = 0x4136c8 *)
sub w22 0@int32 w21;

assert w21 = 4190208 /\ w22 = -4190208 prove with [algebra solver isl]
   && true;
assume w21 = 4190208 /\ w22 = -4190208
    && w21 = 4190208@32 /\ w22 = (-4190208)@32;

(* ldr	w24, [x2, #16]                              #! EA = L0x4159b0; Value = 0x00003ffe00400e03; PC = 0x4136cc *)
mov w24 L0x4159b0;
(* ldr	w25, [x2, #20]                              #! EA = L0x4159b4; Value = 0xfb7f9af000003ffe; PC = 0x4136d0 *)
mov w25 L0x4159b4;
(* ldr	w26, [x2, #24]                              #! EA = L0x4159b8; Value = 0xfffb80bbfb7f9af0; PC = 0x4136d4 *)
mov w26 L0x4159b8;
(* ldr	w27, [x2, #28]                              #! EA = L0x4159bc; Value = 0x00000000fffb80bb; PC = 0x4136d8 *)
mov w27 L0x4159bc;
(* ldr	q20, [x1]                                   #! EA = L0x416260; Value = 0x0000000000000000; PC = 0x4136dc *)
mov %v20 [L0x416260, L0x416264, L0x416268, L0x41626c];
(* ldr	q21, [x1, #16]                              #! EA = L0x416270; Value = 0xffc69a97c68c3a82; PC = 0x4136e0 *)
mov %v21 [L0x416270, L0x416274, L0x416278, L0x41627c];
(* ldr	q22, [x1, #32]                              #! EA = L0x416280; Value = 0x0030d99630e5cf12; PC = 0x4136e4 *)
mov %v22 [L0x416280, L0x416284, L0x416288, L0x41628c];
(* ldr	q23, [x1, #48]                              #! EA = L0x416290; Value = 0x002c008e2c0b908c; PC = 0x4136e8 *)
mov %v23 [L0x416290, L0x416294, L0x416298, L0x41629c];
(* ldr	q24, [x1, #64]                              #! EA = L0x4162a0; Value = 0x0012a23912a6e293; PC = 0x4136ec *)
mov %v24 [L0x4162a0, L0x4162a4, L0x4162a8, L0x4162ac];
(* ldr	q25, [x1, #80]                              #! EA = L0x4162b0; Value = 0x000f56b70f5a8d85; PC = 0x4136f0 *)
mov %v25 [L0x4162b0, L0x4162b4, L0x4162b8, L0x4162bc];
(* ldr	q26, [x1, #96]                              #! EA = L0x4162c0; Value = 0xffdf801cdf77fa40; PC = 0x4136f4 *)
mov %v26 [L0x4162c0, L0x4162c4, L0x4162c8, L0x4162cc];
(* ldr	q27, [x1, #112]                             #! EA = L0x4162d0; Value = 0xffc9f22bc9e4a495; PC = 0x4136f8 *)
mov %v27 [L0x4162d0, L0x4162d4, L0x4162d8, L0x4162dc];
(* mov	v20.s[0], w20                               #! PC = 0x4136fc *)
mov [_, m1, m2, m3] %v20; mov %v20 [w20, m1, m2, m3];
(* ldr	q0, [x0]                                    #! EA = L0xffffffff0610; Value = 0xffe8b462fffe3a4d; PC = 0x413700 *)
mov %v0 [L0xffffffff0610, L0xffffffff0614, L0xffffffff0618, L0xffffffff061c];
(* ldr	q1, [x0, #64]                               #! EA = L0xffffffff0650; Value = 0x002f84940029b9c7; PC = 0x413704 *)
mov %v1 [L0xffffffff0650, L0xffffffff0654, L0xffffffff0658, L0xffffffff065c];
(* ldr	q2, [x0, #128]                              #! EA = L0xffffffff0690; Value = 0x0033b334ffe9eb0d; PC = 0x413708 *)
mov %v2 [L0xffffffff0690, L0xffffffff0694, L0xffffffff0698, L0xffffffff069c];
(* ldr	q3, [x0, #192]                              #! EA = L0xffffffff06d0; Value = 0xffc714caffe727af; PC = 0x41370c *)
mov %v3 [L0xffffffff06d0, L0xffffffff06d4, L0xffffffff06d8, L0xffffffff06dc];
(* ldr	q4, [x0, #256]                              #! EA = L0xffffffff0710; Value = 0x00324da60035b8af; PC = 0x413710 *)
mov %v4 [L0xffffffff0710, L0xffffffff0714, L0xffffffff0718, L0xffffffff071c];
(* ldr	q5, [x0, #320]                              #! EA = L0xffffffff0750; Value = 0xfff015f4ffdb82c4; PC = 0x413714 *)
mov %v5 [L0xffffffff0750, L0xffffffff0754, L0xffffffff0758, L0xffffffff075c];
(* ldr	q6, [x0, #384]                              #! EA = L0xffffffff0790; Value = 0x00127d9b001ffba4; PC = 0x413718 *)
mov %v6 [L0xffffffff0790, L0xffffffff0794, L0xffffffff0798, L0xffffffff079c];
(* ldr	q7, [x0, #448]                              #! EA = L0xffffffff07d0; Value = 0x00228498ffe9d680; PC = 0x41371c *)
mov %v7 [L0xffffffff07d0, L0xffffffff07d4, L0xffffffff07d8, L0xffffffff07dc];

ghost  %v0o28@int32[4], %v2o28@int32[4], %v4o28@int32[4], %v6o28@int32[4],
       %v8o28@int32[4],%v10o28@int32[4],%v12o28@int32[4],%v14o28@int32[4]:
       %v0o28 =  %v0 /\  %v2o28 =  %v2 /\ %v4o28 =  %v4 /\  %v6o28 =  %v6 /\
       %v8o28 =  %v8 /\ %v10o28 = %v10 /\%v12o28 = %v12 /\ %v14o28 = %v14
   &&  %v0o28 =  %v0 /\  %v2o28 =  %v2 /\ %v4o28 =  %v4 /\  %v6o28 =  %v6 /\
       %v8o28 =  %v8 /\ %v10o28 = %v10 /\%v12o28 = %v12 /\ %v14o28 = %v14;

(* sub	v16.4s, v0.4s, v1.4s                        #! PC = 0x413720 *)
sub %v16 %v0 %v1;
(* ldr	q8, [x0, #512]                              #! EA = L0xffffffff0810; Value = 0x0015bdebffd75cd9; PC = 0x413724 *)
mov %v8 [L0xffffffff0810, L0xffffffff0814, L0xffffffff0818, L0xffffffff081c];
(* sub	v17.4s, v2.4s, v3.4s                        #! PC = 0x413728 *)
sub %v17 %v2 %v3;
(* ldr	q9, [x0, #576]                              #! EA = L0xffffffff0850; Value = 0xffcef9d8ffcaa6d0; PC = 0x41372c *)
mov %v9 [L0xffffffff0850, L0xffffffff0854, L0xffffffff0858, L0xffffffff085c];
(* sub	v18.4s, v4.4s, v5.4s                        #! PC = 0x413730 *)
sub %v18 %v4 %v5;
(* ldr	q10, [x0, #640]                             #! EA = L0xffffffff0890; Value = 0x0032f252ffffedeb; PC = 0x413734 *)
mov %v10 [L0xffffffff0890, L0xffffffff0894, L0xffffffff0898, L0xffffffff089c];
(* sub	v19.4s, v6.4s, v7.4s                        #! PC = 0x413738 *)
sub %v19 %v6 %v7;
(* ldr	q11, [x0, #704]                             #! EA = L0xffffffff08d0; Value = 0xffd9750100175e6a; PC = 0x41373c *)
mov %v11 [L0xffffffff08d0, L0xffffffff08d4, L0xffffffff08d8, L0xffffffff08dc];
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x413740 *)
add %v0 %v0 %v1;
(* ldr	q12, [x0, #768]                             #! EA = L0xffffffff0910; Value = 0xffe53ee3ffff51f5; PC = 0x413744 *)
mov %v12 [L0xffffffff0910, L0xffffffff0914, L0xffffffff0918, L0xffffffff091c];
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x413748 *)
add %v2 %v2 %v3;
(* ldr	q13, [x0, #832]                             #! EA = L0xffffffff0950; Value = 0xfff0ffac00353a3d; PC = 0x41374c *)
mov %v13 [L0xffffffff0950, L0xffffffff0954, L0xffffffff0958, L0xffffffff095c];
(* add	v4.4s, v4.4s, v5.4s                         #! PC = 0x413750 *)
add %v4 %v4 %v5;
(* ldr	q14, [x0, #896]                             #! EA = L0xffffffff0990; Value = 0xfffcd5a800290ca1; PC = 0x413754 *)
mov %v14 [L0xffffffff0990, L0xffffffff0994, L0xffffffff0998, L0xffffffff099c];
(* add	v6.4s, v6.4s, v7.4s                         #! PC = 0x413758 *)
add %v6 %v6 %v7;
(* ldr	q15, [x0, #960]                             #! EA = L0xffffffff09d0; Value = 0xffef6765002d2172; PC = 0x41375c *)
mov %v15 [L0xffffffff09d0, L0xffffffff09d4, L0xffffffff09d8, L0xffffffff09dc];

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
        %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
        %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
       %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 89 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     w21 = 4190208 /\ w22 = -4190208 /\
     %v0 =  %v0o28 +  %v1 /\ %v16 =  %v0o28 -  %v1 /\
     %v2 =  %v2o28 +  %v3 /\ %v17 =  %v2o28 -  %v3 /\
     %v4 =  %v4o28 +  %v5 /\ %v18 =  %v4o28 -  %v5 /\
     %v6 =  %v6o28 +  %v7 /\ %v19 =  %v6o28 -  %v7 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
     %v4 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
     %v6 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
    %v19 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    w21 = 4190208@32 /\ w22 = (-4190208)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
     %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
     %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
    %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [88]];

ghost  %v8o29@int32[4],%v10o29@int32[4],%v12o29@int32[4],%v14o29@int32[4],
      %v16o29@int32[4],%v17o29@int32[4],%v18o29@int32[4],%v19o29@int32[4]:
       %v8o29 =  %v8 /\ %v10o29 = %v10 /\%v12o29 = %v12 /\ %v14o29 = %v14 /\
      %v16o29 = %v16 /\ %v17o29 = %v17 /\%v18o29 = %v18 /\ %v19o29 = %v19
   &&  %v8o29 =  %v8 /\ %v10o29 = %v10 /\%v12o29 = %v12 /\ %v14o29 = %v14 /\
      %v16o29 = %v16 /\ %v17o29 = %v17 /\%v18o29 = %v18 /\ %v19o29 = %v19;

(* mul	v1.4s, v16.4s, v24.s[1]                     #! PC = 0x413760 *)
mov [_, m, _, _] %v24; mov %mm [m, m, m, m];
mull %dc %v1 %v16 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v8.4s, v9.4s                        #! PC = 0x413764 *)
sub %v28 %v8 %v9;
(* mul	v3.4s, v17.4s, v24.s[3]                     #! PC = 0x413768 *)
mov [_, _, _, m] %v24; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v10.4s, v11.4s                      #! PC = 0x41376c *)
sub %v29 %v10 %v11;
(* mul	v5.4s, v18.4s, v25.s[1]                     #! PC = 0x413770 *)
mov [_, m, _, _] %v25; mov %mm [m, m, m, m];
mull %dc %v5 %v18 %mm; cast [] %v5@int32[4] %v5;
(* sub	v30.4s, v12.4s, v13.4s                      #! PC = 0x413774 *)
sub %v30 %v12 %v13;
(* mul	v7.4s, v19.4s, v25.s[3]                     #! PC = 0x413778 *)
mov [_, _, _, m] %v25; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v14.4s, v15.4s                      #! PC = 0x41377c *)
sub %v31 %v14 %v15;
(* sqrdmulh	v16.4s, v16.4s, v24.s[0]               #! PC = 0x413780 *)
mov [m, _, _, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v9.4s                         #! PC = 0x413784 *)
add %v8 %v8 %v9;
(* sqrdmulh	v17.4s, v17.4s, v24.s[2]               #! PC = 0x413788 *)
mov [_, _, m, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v10.4s, v10.4s, v11.4s                      #! PC = 0x41378c *)
add %v10 %v10 %v11;
(* sqrdmulh	v18.4s, v18.4s, v25.s[0]               #! PC = 0x413790 *)
mov [m, _, _, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v13.4s                      #! PC = 0x413794 *)
add %v12 %v12 %v13;
(* sqrdmulh	v19.4s, v19.4s, v25.s[2]               #! PC = 0x413798 *)
mov [_, _, m, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v14.4s, v14.4s, v15.4s                      #! PC = 0x41379c *)
add %v14 %v14 %v15;
(* mls	v1.4s, v16.4s, v20.s[0]                     #! PC = 0x4137a0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x4137a4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v18.4s, v20.s[0]                     #! PC = 0x4137a8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x4137ac *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 (%v16o29*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o29*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o29*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o29*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume eqmod  %v1 (%v16o29*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o29*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o29*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o29*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
        %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
       %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
       %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
       %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
       %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 90 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o29 +  %v9 /\ %v28 =  %v8o29 -  %v9 /\
    %v10 = %v10o29 + %v11 /\ %v29 = %v10o29 - %v11 /\
    %v12 = %v12o29 + %v13 /\ %v30 = %v12o29 - %v13 /\
    %v14 = %v14o29 + %v15 /\ %v31 = %v14o29 - %v15 /\
    eqmod  %v1 (%v16o29*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o29*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v18o29*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o29*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
     %v8 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
    %v10 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
    %v30 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
    %v14 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
    %v31 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
     %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
    %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
    %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
    %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
    %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [88]];

ghost  %v0o29@int32[4], %v1o29@int32[4], %v4o29@int32[4], %v5o29@int32[4],
      %v28o29@int32[4],%v29o29@int32[4],%v30o29@int32[4],%v31o29@int32[4]:
       %v0o29 =  %v0 /\  %v1o29 =  %v1 /\ %v4o29 =  %v4 /\  %v5o29 =  %v5 /\
      %v28o29 = %v28 /\ %v29o29 = %v29 /\%v30o29 = %v30 /\ %v31o29 = %v31
   &&  %v0o29 =  %v0 /\  %v1o29 =  %v1 /\ %v4o29 =  %v4 /\  %v5o29 =  %v5 /\
      %v28o29 = %v28 /\ %v29o29 = %v29 /\%v30o29 = %v30 /\ %v31o29 = %v31;

(* mul	v9.4s, v28.4s, v26.s[1]                     #! PC = 0x4137b0 *)
mov [_, m, _, _] %v26; mov %mm [m, m, m, m];
mull %dc %v9 %v28 %mm; cast [] %v9@int32[4] %v9;
(* sub	v16.4s, v0.4s, v2.4s                        #! PC = 0x4137b4 *)
sub %v16 %v0 %v2;
(* mul	v11.4s, v29.4s, v26.s[3]                    #! PC = 0x4137b8 *)
mov [_, _, _, m] %v26; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v3.4s                        #! PC = 0x4137bc *)
sub %v17 %v1 %v3;
(* mul	v13.4s, v30.4s, v27.s[1]                    #! PC = 0x4137c0 *)
mov [_, m, _, _] %v27; mov %mm [m, m, m, m];
mull %dc %v13 %v30 %mm; cast [] %v13@int32[4] %v13;
(* sub	v18.4s, v4.4s, v6.4s                        #! PC = 0x4137c4 *)
sub %v18 %v4 %v6;
(* mul	v15.4s, v31.4s, v27.s[3]                    #! PC = 0x4137c8 *)
mov [_, _, _, m] %v27; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v5.4s, v7.4s                        #! PC = 0x4137cc *)
sub %v19 %v5 %v7;
(* sqrdmulh	v28.4s, v28.4s, v26.s[0]               #! PC = 0x4137d0 *)
mov [m, _, _, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x4137d4 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.s[2]               #! PC = 0x4137d8 *)
mov [_, _, m, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x4137dc *)
add %v1 %v1 %v3;
(* sqrdmulh	v30.4s, v30.4s, v27.s[0]               #! PC = 0x4137e0 *)
mov [m, _, _, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v4.4s, v4.4s, v6.4s                         #! PC = 0x4137e4 *)
add %v4 %v4 %v6;
(* sqrdmulh	v31.4s, v31.4s, v27.s[2]               #! PC = 0x4137e8 *)
mov [_, _, m, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v5.4s, v5.4s, v7.4s                         #! PC = 0x4137ec *)
add %v5 %v5 %v7;
(* mls	v9.4s, v28.4s, v20.s[0]                     #! PC = 0x4137f0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x4137f4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v30.4s, v20.s[0]                    #! PC = 0x4137f8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x4137fc *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 (%v28o29*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o29*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o29*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o29*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [89]] && true;
assume eqmod  %v9 (%v28o29*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o29*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o29*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o29*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
        %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
       %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
        %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
       %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
        %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
       %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 91 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o29 +  %v2 /\ %v16 =  %v0o29 -  %v2 /\
     %v1 =  %v1o29 +  %v3 /\ %v17 =  %v1o29 -  %v3 /\
     %v4 =  %v4o29 +  %v6 /\ %v18 =  %v4o29 -  %v6 /\
     %v5 =  %v5o29 +  %v7 /\ %v19 =  %v5o29 -  %v7 /\
    eqmod  %v9 (%v28o29*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o29*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v30o29*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o29*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
     %v1 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
    %v17 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
     %v4 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
    %v18 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
     %v5 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
    %v19 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
     %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
    %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
     %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
    %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
     %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
    %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [89]];

ghost  %v8o2a@int32[4], %v9o2a@int32[4],%v12o2a@int32[4],%v13o2a@int32[4],
      %v16o2a@int32[4],%v17o2a@int32[4],%v18o2a@int32[4],%v19o2a@int32[4]:
       %v8o2a =  %v8 /\  %v9o2a =  %v9 /\%v12o2a = %v12 /\ %v13o2a = %v13 /\
      %v16o2a = %v16 /\ %v17o2a = %v17 /\%v18o2a = %v18 /\ %v19o2a = %v19
   &&  %v8o2a =  %v8 /\  %v9o2a =  %v9 /\%v12o2a = %v12 /\ %v13o2a = %v13 /\
      %v16o2a = %v16 /\ %v17o2a = %v17 /\%v18o2a = %v18 /\ %v19o2a = %v19;

(* mul	v2.4s, v16.4s, v22.s[1]                     #! PC = 0x413800 *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v2 %v16 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v8.4s, v10.4s                       #! PC = 0x413804 *)
sub %v28 %v8 %v10;
(* mul	v3.4s, v17.4s, v22.s[1]                     #! PC = 0x413808 *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v9.4s, v11.4s                       #! PC = 0x41380c *)
sub %v29 %v9 %v11;
(* mul	v6.4s, v18.4s, v22.s[3]                     #! PC = 0x413810 *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v12.4s, v14.4s                      #! PC = 0x413814 *)
sub %v30 %v12 %v14;
(* mul	v7.4s, v19.4s, v22.s[3]                     #! PC = 0x413818 *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v13.4s, v15.4s                      #! PC = 0x41381c *)
sub %v31 %v13 %v15;
(* sqrdmulh	v16.4s, v16.4s, v22.s[0]               #! PC = 0x413820 *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v10.4s                        #! PC = 0x413824 *)
add %v8 %v8 %v10;
(* sqrdmulh	v17.4s, v17.4s, v22.s[0]               #! PC = 0x413828 *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v11.4s                        #! PC = 0x41382c *)
add %v9 %v9 %v11;
(* sqrdmulh	v18.4s, v18.4s, v22.s[2]               #! PC = 0x413830 *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v14.4s                      #! PC = 0x413834 *)
add %v12 %v12 %v14;
(* sqrdmulh	v19.4s, v19.4s, v22.s[2]               #! PC = 0x413838 *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v13.4s, v13.4s, v15.4s                      #! PC = 0x41383c *)
add %v13 %v13 %v15;
(* mls	v2.4s, v16.4s, v20.s[0]                     #! PC = 0x413840 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x413844 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x413848 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x41384c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v2 (%v16o2a*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o2a*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o2a*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o2a*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [90]] && true;
assume eqmod  %v2 (%v16o2a*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o2a*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o2a*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o2a*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
        %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
        %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
       %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
       %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
       %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
       %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 92 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o2a + %v10 /\ %v28 =  %v8o2a - %v10 /\
     %v9 =  %v9o2a + %v11 /\ %v29 =  %v9o2a - %v11 /\
    %v12 = %v12o2a + %v14 /\ %v30 = %v12o2a - %v14 /\
    %v13 = %v13o2a + %v15 /\ %v31 = %v13o2a - %v15 /\
    eqmod  %v2 (%v16o2a*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o2a*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o2a*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o2a*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
     %v8 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
     %v9 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
    %v29 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
    %v30 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
    %v13 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
    %v31 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
     %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
     %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
    %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
    %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
    %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
    %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [90]];

ghost  %v0o2a@int32[4], %v1o2a@int32[4], %v2o2a@int32[4], %v3o2a@int32[4],
      %v28o2a@int32[4],%v29o2a@int32[4],%v30o2a@int32[4],%v31o2a@int32[4]:
       %v0o2a =  %v0 /\  %v1o2a =  %v1 /\ %v2o2a =  %v2 /\  %v3o2a =  %v3 /\
      %v28o2a = %v28 /\ %v29o2a = %v29 /\%v30o2a = %v30 /\ %v31o2a = %v31
   &&  %v0o2a =  %v0 /\  %v1o2a =  %v1 /\ %v2o2a =  %v2 /\  %v3o2a =  %v3 /\
      %v28o2a = %v28 /\ %v29o2a = %v29 /\%v30o2a = %v30 /\ %v31o2a = %v31;

(* mul	v10.4s, v28.4s, v23.s[1]                    #! PC = 0x413850 *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v10 %v28 %mm; cast [] %v10@int32[4] %v10;
(* sub	v16.4s, v0.4s, v4.4s                        #! PC = 0x413854 *)
sub %v16 %v0 %v4;
(* mul	v11.4s, v29.4s, v23.s[1]                    #! PC = 0x413858 *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v5.4s                        #! PC = 0x41385c *)
sub %v17 %v1 %v5;
(* mul	v14.4s, v30.4s, v23.s[3]                    #! PC = 0x413860 *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* sub	v18.4s, v2.4s, v6.4s                        #! PC = 0x413864 *)
sub %v18 %v2 %v6;
(* mul	v15.4s, v31.4s, v23.s[3]                    #! PC = 0x413868 *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v3.4s, v7.4s                        #! PC = 0x41386c *)
sub %v19 %v3 %v7;
(* sqrdmulh	v28.4s, v28.4s, v23.s[0]               #! PC = 0x413870 *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v4.4s                         #! PC = 0x413874 *)
add %v0 %v0 %v4;
(* sqrdmulh	v29.4s, v29.4s, v23.s[0]               #! PC = 0x413878 *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v5.4s                         #! PC = 0x41387c *)
add %v1 %v1 %v5;
(* sqrdmulh	v30.4s, v30.4s, v23.s[2]               #! PC = 0x413880 *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v2.4s, v2.4s, v6.4s                         #! PC = 0x413884 *)
add %v2 %v2 %v6;
(* sqrdmulh	v31.4s, v31.4s, v23.s[2]               #! PC = 0x413888 *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v3.4s, v3.4s, v7.4s                         #! PC = 0x41388c *)
add %v3 %v3 %v7;
(* mls	v10.4s, v28.4s, v20.s[0]                    #! PC = 0x413890 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x413894 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413898 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x41389c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v10 (%v28o2a*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o2a*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o2a*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o2a*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [91]] && true;
assume eqmod %v10 (%v28o2a*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o2a*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o2a*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o2a*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
        %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
        %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
       %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
        %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
        %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
       %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 93 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o2a +  %v4 /\ %v16 =  %v0o2a -  %v4 /\
     %v1 =  %v1o2a +  %v5 /\ %v17 =  %v1o2a -  %v5 /\
     %v2 =  %v2o2a +  %v6 /\ %v18 =  %v2o2a -  %v6 /\
     %v3 =  %v3o2a +  %v7 /\ %v19 =  %v3o2a -  %v7 /\
    eqmod %v10 (%v28o2a*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o2a*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o2a*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o2a*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
     %v0 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
    %v16 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
     %v1 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
    %v17 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
     %v2 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
    %v18 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
     %v3 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
    %v19 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
     %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
     %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
    %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
     %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
     %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
    %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [91]];

ghost  %v8o2b@int32[4], %v9o2b@int32[4],%v10o2b@int32[4],%v11o2b@int32[4],
      %v16o2b@int32[4],%v17o2b@int32[4],%v18o2b@int32[4],%v19o2b@int32[4]:
       %v8o2b =  %v8 /\  %v9o2b =  %v9 /\%v10o2b = %v10 /\ %v11o2b = %v11 /\
      %v16o2b = %v16 /\ %v17o2b = %v17 /\%v18o2b = %v18 /\ %v19o2b = %v19
   &&  %v8o2b =  %v8 /\  %v9o2b =  %v9 /\%v10o2b = %v10 /\ %v11o2b = %v11 /\
      %v16o2b = %v16 /\ %v17o2b = %v17 /\%v18o2b = %v18 /\ %v19o2b = %v19;

(* mul	v4.4s, v16.4s, v21.s[1]                     #! PC = 0x4138a0 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v4 %v16 %mm; cast [] %v4@int32[4] %v4;
(* sub	v28.4s, v8.4s, v12.4s                       #! PC = 0x4138a4 *)
sub %v28 %v8 %v12;
(* mul	v5.4s, v17.4s, v21.s[1]                     #! PC = 0x4138a8 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v5 %v17 %mm; cast [] %v5@int32[4] %v5;
(* sub	v29.4s, v9.4s, v13.4s                       #! PC = 0x4138ac *)
sub %v29 %v9 %v13;
(* mul	v6.4s, v18.4s, v21.s[1]                     #! PC = 0x4138b0 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v10.4s, v14.4s                      #! PC = 0x4138b4 *)
sub %v30 %v10 %v14;
(* mul	v7.4s, v19.4s, v21.s[1]                     #! PC = 0x4138b8 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v11.4s, v15.4s                      #! PC = 0x4138bc *)
sub %v31 %v11 %v15;
(* sqrdmulh	v16.4s, v16.4s, v21.s[0]               #! PC = 0x4138c0 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v12.4s                        #! PC = 0x4138c4 *)
add %v8 %v8 %v12;
(* sqrdmulh	v17.4s, v17.4s, v21.s[0]               #! PC = 0x4138c8 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v13.4s                        #! PC = 0x4138cc *)
add %v9 %v9 %v13;
(* sqrdmulh	v18.4s, v18.4s, v21.s[0]               #! PC = 0x4138d0 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v10.4s, v10.4s, v14.4s                      #! PC = 0x4138d4 *)
add %v10 %v10 %v14;
(* sqrdmulh	v19.4s, v19.4s, v21.s[0]               #! PC = 0x4138d8 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v11.4s, v11.4s, v15.4s                      #! PC = 0x4138dc *)
add %v11 %v11 %v15;
(* mls	v4.4s, v16.4s, v20.s[0]                     #! PC = 0x4138e0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v5.4s, v17.4s, v20.s[0]                     #! PC = 0x4138e4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x4138e8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x4138ec *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v4 (%v16o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [92]] && true;
assume eqmod  %v4 (%v16o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
        %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
        %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
       %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
       %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
       %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
       %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 94 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o2b + %v12 /\ %v28 =  %v8o2b - %v12 /\
     %v9 =  %v9o2b + %v13 /\ %v29 =  %v9o2b - %v13 /\
    %v10 = %v10o2b + %v14 /\ %v30 = %v10o2b - %v14 /\
    %v11 = %v11o2b + %v15 /\ %v31 = %v11o2b - %v15 /\
    eqmod  %v4 (%v16o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v17o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o2b*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
     %v8 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
    %v28 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
     %v9 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
    %v29 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
    %v10 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
    %v30 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
    %v11 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
    %v31 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
     %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
     %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
    %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
    %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
    %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
    %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [92]];

ghost %v28o2b@int32[4],%v29o2b@int32[4],%v30o2b@int32[4],%v31o2b@int32[4]:
      %v28o2b = %v28 /\ %v29o2b = %v29 /\%v30o2b = %v30 /\ %v31o2b = %v31
   && %v28o2b = %v28 /\ %v29o2b = %v29 /\%v30o2b = %v30 /\ %v31o2b = %v31;

(* mul	v12.4s, v28.4s, v21.s[3]                    #! PC = 0x4138f0 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v12 %v28 %mm; cast [] %v12@int32[4] %v12;
(* mul	v13.4s, v29.4s, v21.s[3]                    #! PC = 0x4138f4 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v13 %v29 %mm; cast [] %v13@int32[4] %v13;
(* mul	v14.4s, v30.4s, v21.s[3]                    #! PC = 0x4138f8 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* mul	v15.4s, v31.4s, v21.s[3]                    #! PC = 0x4138fc *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v28.4s, v28.4s, v21.s[2]               #! PC = 0x413900 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x413904 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v21.s[2]               #! PC = 0x413908 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v21.s[2]               #! PC = 0x41390c *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v12.4s, v28.4s, v20.s[0]                    #! PC = 0x413910 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v13.4s, v29.4s, v20.s[0]                    #! PC = 0x413914 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413918 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x41391c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v12 (%v28o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl] && true;
assume eqmod %v12 (%v28o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 95 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v12 (%v28o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v29o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o2b*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost  %v0o2c@int32[4], %v1o2c@int32[4], %v2o2c@int32[4], %v3o2c@int32[4],
       %v4o2c@int32[4], %v5o2c@int32[4], %v6o2c@int32[4], %v7o2c@int32[4]:
       %v0o2c =  %v0 /\  %v1o2c =  %v1 /\ %v2o2c =  %v2 /\  %v3o2c =  %v3 /\
       %v4o2c =  %v4 /\  %v5o2c =  %v5 /\ %v6o2c =  %v6 /\  %v7o2c =  %v7
   &&  %v0o2c =  %v0 /\  %v1o2c =  %v1 /\ %v2o2c =  %v2 /\  %v3o2c =  %v3 /\
       %v4o2c =  %v4 /\  %v5o2c =  %v5 /\ %v6o2c =  %v6 /\  %v7o2c =  %v7;
ghost  %v8o2c@int32[4], %v9o2c@int32[4],%v10o2c@int32[4],%v11o2c@int32[4],
      %v12o2c@int32[4],%v13o2c@int32[4],%v14o2c@int32[4],%v15o2c@int32[4]:
       %v8o2c =  %v8 /\  %v9o2c =  %v9 /\%v10o2c = %v10 /\ %v11o2c = %v11 /\
      %v12o2c = %v12 /\ %v13o2c = %v13 /\%v14o2c = %v14 /\ %v15o2c = %v15
   &&  %v8o2c =  %v8 /\  %v9o2c =  %v9 /\%v10o2c = %v10 /\ %v11o2c = %v11 /\
      %v12o2c = %v12 /\ %v13o2c = %v13 /\%v14o2c = %v14 /\ %v15o2c = %v15;

(* sub	v28.4s, v0.4s, v8.4s                        #! PC = 0x413920 *)
sub %v28 %v0 %v8;
(* add	v16.4s, v0.4s, v8.4s                        #! PC = 0x413924 *)
add %v16 %v0 %v8;
(* sub	v29.4s, v2.4s, v10.4s                       #! PC = 0x413928 *)
sub %v29 %v2 %v10;
(* add	v17.4s, v2.4s, v10.4s                       #! PC = 0x41392c *)
add %v17 %v2 %v10;
(* sub	v30.4s, v4.4s, v12.4s                       #! PC = 0x413930 *)
sub %v30 %v4 %v12;
(* add	v18.4s, v4.4s, v12.4s                       #! PC = 0x413934 *)
add %v18 %v4 %v12;
(* sub	v31.4s, v6.4s, v14.4s                       #! PC = 0x413938 *)
sub %v31 %v6 %v14;
(* add	v19.4s, v6.4s, v14.4s                       #! PC = 0x41393c *)
add %v19 %v6 %v14;
(* sub	v8.4s, v1.4s, v9.4s                         #! PC = 0x413940 *)
sub %v8 %v1 %v9;
(* add	v0.4s, v1.4s, v9.4s                         #! PC = 0x413944 *)
add %v0 %v1 %v9;
(* sub	v10.4s, v3.4s, v11.4s                       #! PC = 0x413948 *)
sub %v10 %v3 %v11;
(* add	v2.4s, v3.4s, v11.4s                        #! PC = 0x41394c *)
add %v2 %v3 %v11;
(* sub	v12.4s, v5.4s, v13.4s                       #! PC = 0x413950 *)
sub %v12 %v5 %v13;
(* add	v4.4s, v5.4s, v13.4s                        #! PC = 0x413954 *)
add %v4 %v5 %v13;
(* sub	v14.4s, v7.4s, v15.4s                       #! PC = 0x413958 *)
sub %v14 %v7 %v15;
(* add	v6.4s, v7.4s, v15.4s                        #! PC = 0x41395c *)
add %v6 %v7 %v15;

assert [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
       prove with [algebra solver isl, cuts [93, 94]] && true;
assume [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
    && [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
       %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
       %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
       %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
       %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
        %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
        %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
       %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
        %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
        %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
       %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q];
(* CUT 96 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 =  %v0o2c +  %v8o2c /\ %v28 =  %v0o2c -  %v8o2c /\
    %v17 =  %v2o2c + %v10o2c /\ %v29 =  %v2o2c - %v10o2c /\
    %v18 =  %v4o2c + %v12o2c /\ %v30 =  %v4o2c - %v12o2c /\
    %v19 =  %v6o2c + %v14o2c /\ %v31 =  %v6o2c - %v14o2c /\
     %v0 =  %v1o2c +  %v9o2c /\  %v8 =  %v1o2c -  %v9o2c /\
     %v2 =  %v3o2c + %v11o2c /\ %v10 =  %v3o2c - %v11o2c /\
     %v4 =  %v5o2c + %v13o2c /\ %v12 =  %v5o2c - %v13o2c /\
     %v6 =  %v7o2c + %v15o2c /\ %v14 =  %v7o2c - %v15o2c /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
    %v16 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
    %v28 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
    %v17 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
    %v29 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
    %v18 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
    %v30 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
    %v19 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
    %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
    %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v29 /\
    %v29 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
    %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
    %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
    %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
    %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
     %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
     %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
    %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
     %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
     %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
    %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q]
    prove with [cuts [93, 94]];

ghost  %v0o2d@int32[4], %v2o2d@int32[4], %v4o2d@int32[4], %v6o2d@int32[4]:
       %v0o2d =  %v0 /\  %v2o2d =  %v2 /\ %v4o2d =  %v4 /\  %v6o2d =  %v6
   &&  %v0o2d =  %v0 /\  %v2o2d =  %v2 /\ %v4o2d =  %v4 /\  %v6o2d =  %v6;

(* mov	v20.s[2], w24                               #! PC = 0x413960 *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w24, m3];
(* mov	v20.s[3], w25                               #! PC = 0x413964 *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w25];
(* mul	v1.4s, v0.4s, v20.s[3]                      #! PC = 0x413968 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v1 %v0 %mm; cast [] %v1@int32[4] %v1;
(* mul	v3.4s, v2.4s, v20.s[3]                      #! PC = 0x41396c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v3 %v2 %mm; cast [] %v3@int32[4] %v3;
(* mul	v5.4s, v4.4s, v20.s[3]                      #! PC = 0x413970 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v5 %v4 %mm; cast [] %v5@int32[4] %v5;
(* mul	v7.4s, v6.4s, v20.s[3]                      #! PC = 0x413974 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v7 %v6 %mm; cast [] %v7@int32[4] %v7;
(* sqrdmulh	v0.4s, v0.4s, v20.s[2]                 #! PC = 0x413978 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v0 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v0 %dc %mm 1;
(* sqrdmulh	v2.4s, v2.4s, v20.s[2]                 #! PC = 0x41397c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v2 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v2 %dc %mm 1;
(* sqrdmulh	v4.4s, v4.4s, v20.s[2]                 #! PC = 0x413980 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v4 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v4 %dc %mm 1;
(* sqrdmulh	v6.4s, v6.4s, v20.s[2]                 #! PC = 0x413984 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v6 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v6 %dc %mm 1;
(* mls	v1.4s, v0.4s, v20.s[0]                      #! PC = 0x413988 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v0 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v2.4s, v20.s[0]                      #! PC = 0x41398c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v2 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v4.4s, v20.s[0]                      #! PC = 0x413990 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v4 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v6.4s, v20.s[0]                      #! PC = 0x413994 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v6 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 ( %v0o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [96]] && true;
assume eqmod  %v1 ( %v0o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 97 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v1 ( %v0o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 ( %v2o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 ( %v4o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 ( %v6o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

ghost %v16o2d@int32[4],%v17o2d@int32[4],%v18o2d@int32[4],%v19o2d@int32[4]:
      %v16o2d = %v16 /\ %v17o2d = %v17 /\%v18o2d = %v18 /\ %v19o2d = %v19
   && %v16o2d = %v16 /\ %v17o2d = %v17 /\%v18o2d = %v18 /\ %v19o2d = %v19;

(* mul	v0.4s, v16.4s, v20.s[3]                     #! PC = 0x413998 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v0 %v16 %mm; cast [] %v0@int32[4] %v0;
(* mul	v2.4s, v17.4s, v20.s[3]                     #! PC = 0x41399c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v2 %v17 %mm; cast [] %v2@int32[4] %v2;
(* mul	v4.4s, v18.4s, v20.s[3]                     #! PC = 0x4139a0 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v4 %v18 %mm; cast [] %v4@int32[4] %v4;
(* mul	v6.4s, v19.4s, v20.s[3]                     #! PC = 0x4139a4 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v6 %v19 %mm; cast [] %v6@int32[4] %v6;
(* sqrdmulh	v16.4s, v16.4s, v20.s[2]               #! PC = 0x4139a8 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* sqrdmulh	v17.4s, v17.4s, v20.s[2]               #! PC = 0x4139ac *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* sqrdmulh	v18.4s, v18.4s, v20.s[2]               #! PC = 0x4139b0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* sqrdmulh	v19.4s, v19.4s, v20.s[2]               #! PC = 0x4139b4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* mls	v0.4s, v16.4s, v20.s[0]                     #! PC = 0x4139b8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* mls	v2.4s, v17.4s, v20.s[0]                     #! PC = 0x4139bc *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v4.4s, v18.4s, v20.s[0]                     #! PC = 0x4139c0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v6.4s, v19.4s, v20.s[0]                     #! PC = 0x4139c4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;

assert eqmod  %v0 (%v16o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [96]] && true;
assume eqmod  %v0 (%v16o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

(* CUT 98 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v0 (%v16o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v2 (%v17o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v4 (%v18o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v19o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

ghost  %v8o2d@int32[4],%v10o2d@int32[4],%v12o2d@int32[4],%v14o2d@int32[4]:
       %v8o2d =  %v8 /\ %v10o2d = %v10 /\%v12o2d = %v12 /\ %v14o2d = %v14
   &&  %v8o2d =  %v8 /\ %v10o2d = %v10 /\%v12o2d = %v12 /\ %v14o2d = %v14;

(* mov	v20.s[2], w26                               #! PC = 0x4139c8 *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w26, m3];
(* mov	v20.s[3], w27                               #! PC = 0x4139cc *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w27];
(* mul	v9.4s, v8.4s, v20.s[3]                      #! PC = 0x4139d0 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v9 %v8 %mm; cast [] %v9@int32[4] %v9;
(* mul	v11.4s, v10.4s, v20.s[3]                    #! PC = 0x4139d4 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v11 %v10 %mm; cast [] %v11@int32[4] %v11;
(* mul	v13.4s, v12.4s, v20.s[3]                    #! PC = 0x4139d8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v13 %v12 %mm; cast [] %v13@int32[4] %v13;
(* mul	v15.4s, v14.4s, v20.s[3]                    #! PC = 0x4139dc *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v15 %v14 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v8.4s, v8.4s, v20.s[2]                 #! PC = 0x4139e0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v8 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v8 %dc %mm 1;
(* sqrdmulh	v10.4s, v10.4s, v20.s[2]               #! PC = 0x4139e4 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v10 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v10 %dc %mm 1;
(* sqrdmulh	v12.4s, v12.4s, v20.s[2]               #! PC = 0x4139e8 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* sqrdmulh	v14.4s, v14.4s, v20.s[2]               #! PC = 0x4139ec *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v14 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v14 %dc %mm 1;
(* mls	v9.4s, v8.4s, v20.s[0]                      #! PC = 0x4139f0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v8 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v10.4s, v20.s[0]                    #! PC = 0x4139f4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v10 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v12.4s, v20.s[0]                    #! PC = 0x4139f8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v14.4s, v20.s[0]                    #! PC = 0x4139fc *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 ( %v8o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [96]] && true;
assume eqmod  %v9 ( %v8o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 99 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v9 ( %v8o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v10o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v12o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v14o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost %v28o2d@int32[4],%v29o2d@int32[4],%v30o2d@int32[4],%v31o2d@int32[4]:
      %v28o2d = %v28 /\ %v29o2d = %v29 /\%v30o2d = %v30 /\ %v31o2d = %v31
   && %v28o2d = %v28 /\ %v29o2d = %v29 /\%v30o2d = %v30 /\ %v31o2d = %v31;

(* mul	v8.4s, v28.4s, v20.s[3]                     #! PC = 0x413a00 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v8 %v28 %mm; cast [] %v8@int32[4] %v8;
(* mul	v10.4s, v29.4s, v20.s[3]                    #! PC = 0x413a04 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v10 %v29 %mm; cast [] %v10@int32[4] %v10;
(* mul	v12.4s, v30.4s, v20.s[3]                    #! PC = 0x413a08 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v12 %v30 %mm; cast [] %v12@int32[4] %v12;
(* mul	v14.4s, v31.4s, v20.s[3]                    #! PC = 0x413a0c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v14 %v31 %mm; cast [] %v14@int32[4] %v14;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x413a10 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x413a14 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v20.s[2]               #! PC = 0x413a18 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v20.s[2]               #! PC = 0x413a1c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v8.4s, v28.4s, v20.s[0]                     #! PC = 0x413a20 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v8 %v8 %mm;
(* mls	v10.4s, v29.4s, v20.s[0]                    #! PC = 0x413a24 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v12.4s, v30.4s, v20.s[0]                    #! PC = 0x413a28 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v14.4s, v31.4s, v20.s[0]                    #! PC = 0x413a2c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;

assert eqmod  %v8 (%v28o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [96]] && true;
assume eqmod  %v8 (%v28o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

(* CUT 100 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v8 (%v28o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v10 (%v29o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v12 (%v30o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v31o2d*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

ghost  %v0o2e@int32[4], %v1o2e@int32[4], %v2o2e@int32[4], %v3o2e@int32[4],
       %v4o2e@int32[4], %v5o2e@int32[4], %v6o2e@int32[4], %v7o2e@int32[4]:
       %v0o2e =  %v0 /\  %v1o2e =  %v1 /\ %v2o2e =  %v2 /\  %v3o2e =  %v3 /\
       %v4o2e =  %v4 /\  %v5o2e =  %v5 /\ %v6o2e =  %v6 /\  %v7o2e =  %v7
   &&  %v0o2e =  %v0 /\  %v1o2e =  %v1 /\ %v2o2e =  %v2 /\  %v3o2e =  %v3 /\
       %v4o2e =  %v4 /\  %v5o2e =  %v5 /\ %v6o2e =  %v6 /\  %v7o2e =  %v7;
ghost  %v8o2e@int32[4], %v9o2e@int32[4],%v10o2e@int32[4],%v11o2e@int32[4],
      %v12o2e@int32[4],%v13o2e@int32[4],%v14o2e@int32[4],%v15o2e@int32[4]:
       %v8o2e =  %v8 /\  %v9o2e =  %v9 /\%v10o2e = %v10 /\ %v11o2e = %v11 /\
      %v12o2e = %v12 /\ %v13o2e = %v13 /\%v14o2e = %v14 /\ %v15o2e = %v15
   &&  %v8o2e =  %v8 /\  %v9o2e =  %v9 /\%v10o2e = %v10 /\ %v11o2e = %v11 /\
      %v12o2e = %v12 /\ %v13o2e = %v13 /\%v14o2e = %v14 /\ %v15o2e = %v15;

(* mov	x19, #0x3                   	// #3          #! PC = 0x413a30 *)
mov x19 (0x3)@uint64;
(* dup	v29.4s, w20                                 #! PC = 0x413a34 *)
mov %v29 [w20,w20,w20,w20];
(* dup	v30.4s, w21                                 #! PC = 0x413a38 *)
mov %v30 [w21,w21,w21,w21];
(* dup	v31.4s, w22                                 #! PC = 0x413a3c *)
mov %v31 [w22,w22,w22,w22];
(* cmgt	v18.4s, v31.4s, v0.4s                      #! PC = 0x413a40 *)
subs %dc %lt %v0 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v1.4s                      #! PC = 0x413a44 *)
subs %dc %lt %v1 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v0.4s, v30.4s                      #! PC = 0x413a48 *)
subs %dc %lt %v30 %v0; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v1.4s, v30.4s                      #! PC = 0x413a4c *)
subs %dc %lt %v30 %v1; split %v17 %dc %lt 31;
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413a54 *)
sub %v17 %v17 %v19;
(* mla	v0.4s, v16.4s, v29.4s                       #! PC = 0x413a58 *)
mul %mla %v16 %v29; add %v0 %v0 %mla;
(* cmgt	v18.4s, v31.4s, v2.4s                      #! PC = 0x413a5c *)
subs %dc %lt %v2 %v31; split %v18 %dc %lt 31;
(* mla	v1.4s, v17.4s, v29.4s                       #! PC = 0x413a60 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v1 %v1 %mla;
(* cmgt	v19.4s, v31.4s, v3.4s                      #! PC = 0x413a64 *)
subs %dc %lt %v3 %v31; split %v19 %dc %lt 31;
(* str	q0, [x0]                                    #! EA = L0xffffffff0610; PC = 0x413a68 *)
mov [L0xffffffff0610, L0xffffffff0614, L0xffffffff0618, L0xffffffff061c] %v0;
(* cmgt	v16.4s, v2.4s, v30.4s                      #! PC = 0x413a6c *)
subs %dc %lt %v30 %v2; split %v16 %dc %lt 31;
(* ldr	q0, [x0, #16]                               #! EA = L0xffffffff0620; Value = 0x000b1cb7000b77bb; PC = 0x413a70 *)
mov %v0 [L0xffffffff0620, L0xffffffff0624, L0xffffffff0628, L0xffffffff062c];
(* str	q1, [x0, #64]                               #! EA = L0xffffffff0650; PC = 0x413a74 *)
mov [L0xffffffff0650, L0xffffffff0654, L0xffffffff0658, L0xffffffff065c] %v1;
(* cmgt	v17.4s, v3.4s, v30.4s                      #! PC = 0x413a78 *)
subs %dc %lt %v30 %v3; split %v17 %dc %lt 31;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff0660; Value = 0xffcfe684001f7927; PC = 0x413a7c *)
mov %v1 [L0xffffffff0660, L0xffffffff0664, L0xffffffff0668, L0xffffffff066c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413a80 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413a84 *)
sub %v17 %v17 %v19;
(* mla	v2.4s, v16.4s, v29.4s                       #! PC = 0x413a88 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v2 %v2 %mla;
(* cmgt	v18.4s, v31.4s, v4.4s                      #! PC = 0x413a8c *)
subs %dc %lt %v4 %v31; split %v18 %dc %lt 31;
(* mla	v3.4s, v17.4s, v29.4s                       #! PC = 0x413a90 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v3 %v3 %mla;
(* cmgt	v19.4s, v31.4s, v5.4s                      #! PC = 0x413a94 *)
subs %dc %lt %v5 %v31; split %v19 %dc %lt 31;
(* str	q2, [x0, #128]                              #! EA = L0xffffffff0690; PC = 0x413a98 *)
mov [L0xffffffff0690, L0xffffffff0694, L0xffffffff0698, L0xffffffff069c] %v2;
(* cmgt	v16.4s, v4.4s, v30.4s                      #! PC = 0x413a9c *)
subs %dc %lt %v30 %v4; split %v16 %dc %lt 31;
(* ldr	q2, [x0, #144]                              #! EA = L0xffffffff06a0; Value = 0xffc04c120023d9c1; PC = 0x413aa0 *)
mov %v2 [L0xffffffff06a0, L0xffffffff06a4, L0xffffffff06a8, L0xffffffff06ac];
(* str	q3, [x0, #192]                              #! EA = L0xffffffff06d0; PC = 0x413aa4 *)
mov [L0xffffffff06d0, L0xffffffff06d4, L0xffffffff06d8, L0xffffffff06dc] %v3;
(* cmgt	v17.4s, v5.4s, v30.4s                      #! PC = 0x413aa8 *)
subs %dc %lt %v30 %v5; split %v17 %dc %lt 31;
(* ldr	q3, [x0, #208]                              #! EA = L0xffffffff06e0; Value = 0xfffaff78ffe66792; PC = 0x413aac *)
mov %v3 [L0xffffffff06e0, L0xffffffff06e4, L0xffffffff06e8, L0xffffffff06ec];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ab0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413ab4 *)
sub %v17 %v17 %v19;
(* mla	v4.4s, v16.4s, v29.4s                       #! PC = 0x413ab8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v4 %v4 %mla;
(* cmgt	v18.4s, v31.4s, v6.4s                      #! PC = 0x413abc *)
subs %dc %lt %v6 %v31; split %v18 %dc %lt 31;
(* mla	v5.4s, v17.4s, v29.4s                       #! PC = 0x413ac0 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v5 %v5 %mla;
(* cmgt	v19.4s, v31.4s, v7.4s                      #! PC = 0x413ac4 *)
subs %dc %lt %v7 %v31; split %v19 %dc %lt 31;
(* str	q4, [x0, #256]                              #! EA = L0xffffffff0710; PC = 0x413ac8 *)
mov [L0xffffffff0710, L0xffffffff0714, L0xffffffff0718, L0xffffffff071c] %v4;
(* cmgt	v16.4s, v6.4s, v30.4s                      #! PC = 0x413acc *)
subs %dc %lt %v30 %v6; split %v16 %dc %lt 31;
(* ldr	q4, [x0, #272]                              #! EA = L0xffffffff0720; Value = 0xffdd1a55fff9e86c; PC = 0x413ad0 *)
mov %v4 [L0xffffffff0720, L0xffffffff0724, L0xffffffff0728, L0xffffffff072c];
(* str	q5, [x0, #320]                              #! EA = L0xffffffff0750; PC = 0x413ad4 *)
mov [L0xffffffff0750, L0xffffffff0754, L0xffffffff0758, L0xffffffff075c] %v5;
(* cmgt	v17.4s, v7.4s, v30.4s                      #! PC = 0x413ad8 *)
subs %dc %lt %v30 %v7; split %v17 %dc %lt 31;
(* ldr	q5, [x0, #336]                              #! EA = L0xffffffff0760; Value = 0xffe38dc9ffe5158a; PC = 0x413adc *)
mov %v5 [L0xffffffff0760, L0xffffffff0764, L0xffffffff0768, L0xffffffff076c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ae0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413ae4 *)
sub %v17 %v17 %v19;
(* mla	v6.4s, v16.4s, v29.4s                       #! PC = 0x413ae8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v6 %v6 %mla;
(* cmgt	v18.4s, v31.4s, v8.4s                      #! PC = 0x413aec *)
subs %dc %lt %v8 %v31; split %v18 %dc %lt 31;
(* mla	v7.4s, v17.4s, v29.4s                       #! PC = 0x413af0 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v7 %v7 %mla;
(* cmgt	v19.4s, v31.4s, v9.4s                      #! PC = 0x413af4 *)
subs %dc %lt %v9 %v31; split %v19 %dc %lt 31;
(* str	q6, [x0, #384]                              #! EA = L0xffffffff0790; PC = 0x413af8 *)
mov [L0xffffffff0790, L0xffffffff0794, L0xffffffff0798, L0xffffffff079c] %v6;
(* cmgt	v16.4s, v8.4s, v30.4s                      #! PC = 0x413afc *)
subs %dc %lt %v30 %v8; split %v16 %dc %lt 31;
(* ldr	q6, [x0, #400]                              #! EA = L0xffffffff07a0; Value = 0x001e992100205782; PC = 0x413b00 *)
mov %v6 [L0xffffffff07a0, L0xffffffff07a4, L0xffffffff07a8, L0xffffffff07ac];
(* str	q7, [x0, #448]                              #! EA = L0xffffffff07d0; PC = 0x413b04 *)
mov [L0xffffffff07d0, L0xffffffff07d4, L0xffffffff07d8, L0xffffffff07dc] %v7;
(* cmgt	v17.4s, v9.4s, v30.4s                      #! PC = 0x413b08 *)
subs %dc %lt %v30 %v9; split %v17 %dc %lt 31;
(* ldr	q7, [x0, #464]                              #! EA = L0xffffffff07e0; Value = 0x0010f2c7fffe4f09; PC = 0x413b0c *)
mov %v7 [L0xffffffff07e0, L0xffffffff07e4, L0xffffffff07e8, L0xffffffff07ec];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b10 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b14 *)
sub %v17 %v17 %v19;
(* mla	v8.4s, v16.4s, v29.4s                       #! PC = 0x413b18 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v8 %v8 %mla;
(* cmgt	v18.4s, v31.4s, v10.4s                     #! PC = 0x413b1c *)
subs %dc %lt %v10 %v31; split %v18 %dc %lt 31;
(* mla	v9.4s, v17.4s, v29.4s                       #! PC = 0x413b20 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v9 %v9 %mla;
(* cmgt	v19.4s, v31.4s, v11.4s                     #! PC = 0x413b24 *)
subs %dc %lt %v11 %v31; split %v19 %dc %lt 31;
(* str	q8, [x0, #512]                              #! EA = L0xffffffff0810; PC = 0x413b28 *)
mov [L0xffffffff0810, L0xffffffff0814, L0xffffffff0818, L0xffffffff081c] %v8;
(* cmgt	v16.4s, v10.4s, v30.4s                     #! PC = 0x413b2c *)
subs %dc %lt %v30 %v10; split %v16 %dc %lt 31;
(* str	q9, [x0, #576]                              #! EA = L0xffffffff0850; PC = 0x413b30 *)
mov [L0xffffffff0850, L0xffffffff0854, L0xffffffff0858, L0xffffffff085c] %v9;
(* cmgt	v17.4s, v11.4s, v30.4s                     #! PC = 0x413b34 *)
subs %dc %lt %v30 %v11; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b38 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b3c *)
sub %v17 %v17 %v19;
(* mla	v10.4s, v16.4s, v29.4s                      #! PC = 0x413b40 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v10 %v10 %mla;
(* cmgt	v18.4s, v31.4s, v12.4s                     #! PC = 0x413b44 *)
subs %dc %lt %v12 %v31; split %v18 %dc %lt 31;
(* mla	v11.4s, v17.4s, v29.4s                      #! PC = 0x413b48 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v11 %v11 %mla;
(* cmgt	v19.4s, v31.4s, v13.4s                     #! PC = 0x413b4c *)
subs %dc %lt %v13 %v31; split %v19 %dc %lt 31;
(* str	q10, [x0, #640]                             #! EA = L0xffffffff0890; PC = 0x413b50 *)
mov [L0xffffffff0890, L0xffffffff0894, L0xffffffff0898, L0xffffffff089c] %v10;
(* cmgt	v16.4s, v12.4s, v30.4s                     #! PC = 0x413b54 *)
subs %dc %lt %v30 %v12; split %v16 %dc %lt 31;
(* str	q11, [x0, #704]                             #! EA = L0xffffffff08d0; PC = 0x413b58 *)
mov [L0xffffffff08d0, L0xffffffff08d4, L0xffffffff08d8, L0xffffffff08dc] %v11;
(* cmgt	v17.4s, v13.4s, v30.4s                     #! PC = 0x413b5c *)
subs %dc %lt %v30 %v13; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b60 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b64 *)
sub %v17 %v17 %v19;
(* mla	v12.4s, v16.4s, v29.4s                      #! PC = 0x413b68 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v12 %v12 %mla;
(* cmgt	v18.4s, v31.4s, v14.4s                     #! PC = 0x413b6c *)
subs %dc %lt %v14 %v31; split %v18 %dc %lt 31;
(* mla	v13.4s, v17.4s, v29.4s                      #! PC = 0x413b70 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v13 %v13 %mla;
(* cmgt	v19.4s, v31.4s, v15.4s                     #! PC = 0x413b74 *)
subs %dc %lt %v15 %v31; split %v19 %dc %lt 31;
(* str	q12, [x0, #768]                             #! EA = L0xffffffff0910; PC = 0x413b78 *)
mov [L0xffffffff0910, L0xffffffff0914, L0xffffffff0918, L0xffffffff091c] %v12;
(* cmgt	v16.4s, v14.4s, v30.4s                     #! PC = 0x413b7c *)
subs %dc %lt %v30 %v14; split %v16 %dc %lt 31;
(* str	q13, [x0, #832]                             #! EA = L0xffffffff0950; PC = 0x413b80 *)
mov [L0xffffffff0950, L0xffffffff0954, L0xffffffff0958, L0xffffffff095c] %v13;
(* cmgt	v17.4s, v15.4s, v30.4s                     #! PC = 0x413b84 *)
subs %dc %lt %v30 %v15; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b88 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b8c *)
sub %v17 %v17 %v19;
(* mla	v14.4s, v16.4s, v29.4s                      #! PC = 0x413b90 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v14 %v14 %mla;
(* mla	v15.4s, v17.4s, v29.4s                      #! PC = 0x413b94 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v15 %v15 %mla;
(* str	q14, [x0, #896]                             #! EA = L0xffffffff0990; PC = 0x413b98 *)
mov [L0xffffffff0990, L0xffffffff0994, L0xffffffff0998, L0xffffffff099c] %v14;
(* str	q15, [x0, #960]                             #! EA = L0xffffffff09d0; PC = 0x413b9c *)
mov [L0xffffffff09d0, L0xffffffff09d4, L0xffffffff09d8, L0xffffffff09dc] %v15;

assert true &&
       eqsmod [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]
              %v0o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]
              %v1o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]
              %v2o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]
              %v3o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]
              %v4o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]
              %v5o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]
              %v6o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]
              %v7o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]
              %v8o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]
              %v9o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]
              %v10o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]
              %v11o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]
              %v12o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]
              %v13o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]
              %v14o2e [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]
              %v15o2e [Q, Q, Q, Q]
       prove with [cuts [89]];
assume eqmod [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]
             %v0o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]
             %v1o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]
             %v2o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]
             %v3o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]
             %v4o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]
             %v5o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]
             %v6o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]
             %v7o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]
             %v8o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]
             %v9o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]
             %v10o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]
             %v11o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]
             %v12o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]
             %v13o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]
             %v14o2e [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]
             %v15o2e [Q, Q, Q, Q] && true;
(* CUT 101 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c]
          %v0o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c]
          %v1o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c]
          %v2o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc]
          %v3o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c]
          %v4o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c]
          %v5o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c]
          %v6o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc]
          %v7o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c]
          %v8o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c]
          %v9o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c]
          %v10o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc]
          %v11o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c]
          %v12o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c]
          %v13o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c]
          %v14o2e [Q, Q, Q, Q] /\
    eqmod [L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc]
          %v15o2e [Q, Q, Q, Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0610,L0xffffffff0610,L0xffffffff0610,L0xffffffff0610] /\
    [L0xffffffff0610,L0xffffffff0610,L0xffffffff0610,L0xffffffff0610]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0650,L0xffffffff0650,L0xffffffff0650,L0xffffffff0650] /\
    [L0xffffffff0650,L0xffffffff0650,L0xffffffff0650,L0xffffffff0650]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0690,L0xffffffff0690,L0xffffffff0690,L0xffffffff0690] /\
    [L0xffffffff0690,L0xffffffff0690,L0xffffffff0690,L0xffffffff0690]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0] /\
    [L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0710,L0xffffffff0710,L0xffffffff0710,L0xffffffff0710] /\
    [L0xffffffff0710,L0xffffffff0710,L0xffffffff0710,L0xffffffff0710]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0750,L0xffffffff0750,L0xffffffff0750,L0xffffffff0750] /\
    [L0xffffffff0750,L0xffffffff0750,L0xffffffff0750,L0xffffffff0750]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0790,L0xffffffff0790,L0xffffffff0790,L0xffffffff0790] /\
    [L0xffffffff0790,L0xffffffff0790,L0xffffffff0790,L0xffffffff0790]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0] /\
    [L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0810,L0xffffffff0810,L0xffffffff0810,L0xffffffff0810] /\
    [L0xffffffff0810,L0xffffffff0810,L0xffffffff0810,L0xffffffff0810]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0850,L0xffffffff0850,L0xffffffff0850,L0xffffffff0850] /\
    [L0xffffffff0850,L0xffffffff0850,L0xffffffff0850,L0xffffffff0850]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0890,L0xffffffff0890,L0xffffffff0890,L0xffffffff0890] /\
    [L0xffffffff0890,L0xffffffff0890,L0xffffffff0890,L0xffffffff0890]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0] /\
    [L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0910,L0xffffffff0910,L0xffffffff0910,L0xffffffff0910] /\
    [L0xffffffff0910,L0xffffffff0910,L0xffffffff0910,L0xffffffff0910]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0950,L0xffffffff0950,L0xffffffff0950,L0xffffffff0950] /\
    [L0xffffffff0950,L0xffffffff0950,L0xffffffff0950,L0xffffffff0950]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0990,L0xffffffff0990,L0xffffffff0990,L0xffffffff0990] /\
    [L0xffffffff0990,L0xffffffff0990,L0xffffffff0990,L0xffffffff0990]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0] /\
    [L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0]<s[Q2,Q2,Q2,Q2]
    prove with [cuts [89, 97, 98, 99, 100]];

ghost  %v0o2f@int32[4], %v2o2f@int32[4], %v4o2f@int32[4], %v6o2f@int32[4],
       %v8o2f@int32[4],%v10o2f@int32[4],%v12o2f@int32[4],%v14o2f@int32[4]:
       %v0o2f =  %v0 /\  %v2o2f =  %v2 /\ %v4o2f =  %v4 /\  %v6o2f =  %v6 /\
       %v8o2f =  %v8 /\ %v10o2f = %v10 /\%v12o2f = %v12 /\ %v14o2f = %v14
   &&  %v0o2f =  %v0 /\  %v2o2f =  %v2 /\ %v4o2f =  %v4 /\  %v6o2f =  %v6 /\
       %v8o2f =  %v8 /\ %v10o2f = %v10 /\%v12o2f = %v12 /\ %v14o2f = %v14;

(* add	x0, x0, #0x10                               #! PC = 0x413ba0 *)
adds dc x0 x0 (0x10)@uint64;
(* sub	v16.4s, v0.4s, v1.4s                        #! PC = 0x413ba4 *)
sub %v16 %v0 %v1;
(* ldr	q8, [x0, #512]                              #! EA = L0xffffffff0820; Value = 0x000c456100310302; PC = 0x413ba8 *)
mov %v8 [L0xffffffff0820, L0xffffffff0824, L0xffffffff0828, L0xffffffff082c];
(* sub	v17.4s, v2.4s, v3.4s                        #! PC = 0x413bac *)
sub %v17 %v2 %v3;
(* ldr	q9, [x0, #576]                              #! EA = L0xffffffff0860; Value = 0xffc17b44ffee7f02; PC = 0x413bb0 *)
mov %v9 [L0xffffffff0860, L0xffffffff0864, L0xffffffff0868, L0xffffffff086c];
(* sub	v18.4s, v4.4s, v5.4s                        #! PC = 0x413bb4 *)
sub %v18 %v4 %v5;
(* ldr	q10, [x0, #640]                             #! EA = L0xffffffff08a0; Value = 0xfff6ffa4fff47457; PC = 0x413bb8 *)
mov %v10 [L0xffffffff08a0, L0xffffffff08a4, L0xffffffff08a8, L0xffffffff08ac];
(* sub	v19.4s, v6.4s, v7.4s                        #! PC = 0x413bbc *)
sub %v19 %v6 %v7;
(* ldr	q11, [x0, #704]                             #! EA = L0xffffffff08e0; Value = 0x002e2c5e00101ea3; PC = 0x413bc0 *)
mov %v11 [L0xffffffff08e0, L0xffffffff08e4, L0xffffffff08e8, L0xffffffff08ec];
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x413bc4 *)
add %v0 %v0 %v1;
(* ldr	q12, [x0, #768]                             #! EA = L0xffffffff0920; Value = 0xffe1e088ffdf578b; PC = 0x413bc8 *)
mov %v12 [L0xffffffff0920, L0xffffffff0924, L0xffffffff0928, L0xffffffff092c];
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x413bcc *)
add %v2 %v2 %v3;
(* ldr	q13, [x0, #832]                             #! EA = L0xffffffff0960; Value = 0x000165d7ffe0cdb5; PC = 0x413bd0 *)
mov %v13 [L0xffffffff0960, L0xffffffff0964, L0xffffffff0968, L0xffffffff096c];
(* add	v4.4s, v4.4s, v5.4s                         #! PC = 0x413bd4 *)
add %v4 %v4 %v5;
(* ldr	q14, [x0, #896]                             #! EA = L0xffffffff09a0; Value = 0x002b5d1200198097; PC = 0x413bd8 *)
mov %v14 [L0xffffffff09a0, L0xffffffff09a4, L0xffffffff09a8, L0xffffffff09ac];
(* add	v6.4s, v6.4s, v7.4s                         #! PC = 0x413bdc *)
add %v6 %v6 %v7;
(* ldr	q15, [x0, #960]                             #! EA = L0xffffffff09e0; Value = 0xffcbdccd00080386; PC = 0x413be0 *)
mov %v15 [L0xffffffff09e0, L0xffffffff09e4, L0xffffffff09e8, L0xffffffff09ec];

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
        %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
        %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
       %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 102 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o2f +  %v1 /\ %v16 =  %v0o2f -  %v1 /\
     %v2 =  %v2o2f +  %v3 /\ %v17 =  %v2o2f -  %v3 /\
     %v4 =  %v4o2f +  %v5 /\ %v18 =  %v4o2f -  %v5 /\
     %v6 =  %v6o2f +  %v7 /\ %v19 =  %v6o2f -  %v7 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
     %v4 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
     %v6 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
    %v19 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
     %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
     %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
    %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [88]];

ghost  %v8o30@int32[4],%v10o30@int32[4],%v12o30@int32[4],%v14o30@int32[4],
      %v16o30@int32[4],%v17o30@int32[4],%v18o30@int32[4],%v19o30@int32[4]:
       %v8o30 =  %v8 /\ %v10o30 = %v10 /\%v12o30 = %v12 /\ %v14o30 = %v14 /\
      %v16o30 = %v16 /\ %v17o30 = %v17 /\%v18o30 = %v18 /\ %v19o30 = %v19
   &&  %v8o30 =  %v8 /\ %v10o30 = %v10 /\%v12o30 = %v12 /\ %v14o30 = %v14 /\
      %v16o30 = %v16 /\ %v17o30 = %v17 /\%v18o30 = %v18 /\ %v19o30 = %v19;

(* mul	v1.4s, v16.4s, v24.s[1]                     #! PC = 0x413be4 *)
mov [_, m, _, _] %v24; mov %mm [m, m, m, m];
mull %dc %v1 %v16 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v8.4s, v9.4s                        #! PC = 0x413be8 *)
sub %v28 %v8 %v9;
(* mul	v3.4s, v17.4s, v24.s[3]                     #! PC = 0x413bec *)
mov [_, _, _, m] %v24; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v10.4s, v11.4s                      #! PC = 0x413bf0 *)
sub %v29 %v10 %v11;
(* mul	v5.4s, v18.4s, v25.s[1]                     #! PC = 0x413bf4 *)
mov [_, m, _, _] %v25; mov %mm [m, m, m, m];
mull %dc %v5 %v18 %mm; cast [] %v5@int32[4] %v5;
(* sub	v30.4s, v12.4s, v13.4s                      #! PC = 0x413bf8 *)
sub %v30 %v12 %v13;
(* mul	v7.4s, v19.4s, v25.s[3]                     #! PC = 0x413bfc *)
mov [_, _, _, m] %v25; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v14.4s, v15.4s                      #! PC = 0x413c00 *)
sub %v31 %v14 %v15;
(* sqrdmulh	v16.4s, v16.4s, v24.s[0]               #! PC = 0x413c04 *)
mov [m, _, _, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v9.4s                         #! PC = 0x413c08 *)
add %v8 %v8 %v9;
(* sqrdmulh	v17.4s, v17.4s, v24.s[2]               #! PC = 0x413c0c *)
mov [_, _, m, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v10.4s, v10.4s, v11.4s                      #! PC = 0x413c10 *)
add %v10 %v10 %v11;
(* sqrdmulh	v18.4s, v18.4s, v25.s[0]               #! PC = 0x413c14 *)
mov [m, _, _, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v13.4s                      #! PC = 0x413c18 *)
add %v12 %v12 %v13;
(* sqrdmulh	v19.4s, v19.4s, v25.s[2]               #! PC = 0x413c1c *)
mov [_, _, m, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v14.4s, v14.4s, v15.4s                      #! PC = 0x413c20 *)
add %v14 %v14 %v15;
(* mls	v1.4s, v16.4s, v20.s[0]                     #! PC = 0x413c24 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x413c28 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v18.4s, v20.s[0]                     #! PC = 0x413c2c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413c30 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 (%v16o30*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o30*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o30*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o30*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume eqmod  %v1 (%v16o30*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o30*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o30*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o30*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
        %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
       %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
       %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
       %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
       %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 103 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o30 +  %v9 /\ %v28 =  %v8o30 -  %v9 /\
    %v10 = %v10o30 + %v11 /\ %v29 = %v10o30 - %v11 /\
    %v12 = %v12o30 + %v13 /\ %v30 = %v12o30 - %v13 /\
    %v14 = %v14o30 + %v15 /\ %v31 = %v14o30 - %v15 /\
    eqmod  %v1 (%v16o30*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o30*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v18o30*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o30*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
     %v8 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
    %v10 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
    %v30 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
    %v14 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
    %v31 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
     %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
    %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
    %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
    %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
    %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [88]];

ghost  %v0o30@int32[4], %v1o30@int32[4], %v4o30@int32[4], %v5o30@int32[4],
      %v28o30@int32[4],%v29o30@int32[4],%v30o30@int32[4],%v31o30@int32[4]:
       %v0o30 =  %v0 /\  %v1o30 =  %v1 /\ %v4o30 =  %v4 /\  %v5o30 =  %v5 /\
      %v28o30 = %v28 /\ %v29o30 = %v29 /\%v30o30 = %v30 /\ %v31o30 = %v31
   &&  %v0o30 =  %v0 /\  %v1o30 =  %v1 /\ %v4o30 =  %v4 /\  %v5o30 =  %v5 /\
      %v28o30 = %v28 /\ %v29o30 = %v29 /\%v30o30 = %v30 /\ %v31o30 = %v31;

(* mul	v9.4s, v28.4s, v26.s[1]                     #! PC = 0x413c34 *)
mov [_, m, _, _] %v26; mov %mm [m, m, m, m];
mull %dc %v9 %v28 %mm; cast [] %v9@int32[4] %v9;
(* sub	v16.4s, v0.4s, v2.4s                        #! PC = 0x413c38 *)
sub %v16 %v0 %v2;
(* mul	v11.4s, v29.4s, v26.s[3]                    #! PC = 0x413c3c *)
mov [_, _, _, m] %v26; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v3.4s                        #! PC = 0x413c40 *)
sub %v17 %v1 %v3;
(* mul	v13.4s, v30.4s, v27.s[1]                    #! PC = 0x413c44 *)
mov [_, m, _, _] %v27; mov %mm [m, m, m, m];
mull %dc %v13 %v30 %mm; cast [] %v13@int32[4] %v13;
(* sub	v18.4s, v4.4s, v6.4s                        #! PC = 0x413c48 *)
sub %v18 %v4 %v6;
(* mul	v15.4s, v31.4s, v27.s[3]                    #! PC = 0x413c4c *)
mov [_, _, _, m] %v27; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v5.4s, v7.4s                        #! PC = 0x413c50 *)
sub %v19 %v5 %v7;
(* sqrdmulh	v28.4s, v28.4s, v26.s[0]               #! PC = 0x413c54 *)
mov [m, _, _, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x413c58 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.s[2]               #! PC = 0x413c5c *)
mov [_, _, m, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x413c60 *)
add %v1 %v1 %v3;
(* sqrdmulh	v30.4s, v30.4s, v27.s[0]               #! PC = 0x413c64 *)
mov [m, _, _, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v4.4s, v4.4s, v6.4s                         #! PC = 0x413c68 *)
add %v4 %v4 %v6;
(* sqrdmulh	v31.4s, v31.4s, v27.s[2]               #! PC = 0x413c6c *)
mov [_, _, m, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v5.4s, v5.4s, v7.4s                         #! PC = 0x413c70 *)
add %v5 %v5 %v7;
(* mls	v9.4s, v28.4s, v20.s[0]                     #! PC = 0x413c74 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x413c78 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v30.4s, v20.s[0]                    #! PC = 0x413c7c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413c80 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 (%v28o30*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o30*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o30*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o30*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [102]] && true;
assume eqmod  %v9 (%v28o30*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o30*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o30*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o30*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
        %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
       %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
        %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
       %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
        %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
       %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 104 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o30 +  %v2 /\ %v16 =  %v0o30 -  %v2 /\
     %v1 =  %v1o30 +  %v3 /\ %v17 =  %v1o30 -  %v3 /\
     %v4 =  %v4o30 +  %v6 /\ %v18 =  %v4o30 -  %v6 /\
     %v5 =  %v5o30 +  %v7 /\ %v19 =  %v5o30 -  %v7 /\
    eqmod  %v9 (%v28o30*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o30*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v30o30*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o30*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
     %v1 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
    %v17 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
     %v4 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
    %v18 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
     %v5 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
    %v19 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
     %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
    %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
     %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
    %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
     %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
    %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [102]];

ghost  %v8o31@int32[4], %v9o31@int32[4],%v12o31@int32[4],%v13o31@int32[4],
      %v16o31@int32[4],%v17o31@int32[4],%v18o31@int32[4],%v19o31@int32[4]:
       %v8o31 =  %v8 /\  %v9o31 =  %v9 /\%v12o31 = %v12 /\ %v13o31 = %v13 /\
      %v16o31 = %v16 /\ %v17o31 = %v17 /\%v18o31 = %v18 /\ %v19o31 = %v19
   &&  %v8o31 =  %v8 /\  %v9o31 =  %v9 /\%v12o31 = %v12 /\ %v13o31 = %v13 /\
      %v16o31 = %v16 /\ %v17o31 = %v17 /\%v18o31 = %v18 /\ %v19o31 = %v19;

(* mul	v2.4s, v16.4s, v22.s[1]                     #! PC = 0x413c84 *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v2 %v16 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v8.4s, v10.4s                       #! PC = 0x413c88 *)
sub %v28 %v8 %v10;
(* mul	v3.4s, v17.4s, v22.s[1]                     #! PC = 0x413c8c *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v9.4s, v11.4s                       #! PC = 0x413c90 *)
sub %v29 %v9 %v11;
(* mul	v6.4s, v18.4s, v22.s[3]                     #! PC = 0x413c94 *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v12.4s, v14.4s                      #! PC = 0x413c98 *)
sub %v30 %v12 %v14;
(* mul	v7.4s, v19.4s, v22.s[3]                     #! PC = 0x413c9c *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v13.4s, v15.4s                      #! PC = 0x413ca0 *)
sub %v31 %v13 %v15;
(* sqrdmulh	v16.4s, v16.4s, v22.s[0]               #! PC = 0x413ca4 *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v10.4s                        #! PC = 0x413ca8 *)
add %v8 %v8 %v10;
(* sqrdmulh	v17.4s, v17.4s, v22.s[0]               #! PC = 0x413cac *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v11.4s                        #! PC = 0x413cb0 *)
add %v9 %v9 %v11;
(* sqrdmulh	v18.4s, v18.4s, v22.s[2]               #! PC = 0x413cb4 *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v14.4s                      #! PC = 0x413cb8 *)
add %v12 %v12 %v14;
(* sqrdmulh	v19.4s, v19.4s, v22.s[2]               #! PC = 0x413cbc *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v13.4s, v13.4s, v15.4s                      #! PC = 0x413cc0 *)
add %v13 %v13 %v15;
(* mls	v2.4s, v16.4s, v20.s[0]                     #! PC = 0x413cc4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x413cc8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x413ccc *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413cd0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v2 (%v16o31*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o31*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o31*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o31*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [103]] && true;
assume eqmod  %v2 (%v16o31*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o31*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o31*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o31*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
        %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
        %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
       %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
       %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
       %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
       %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 105 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o31 + %v10 /\ %v28 =  %v8o31 - %v10 /\
     %v9 =  %v9o31 + %v11 /\ %v29 =  %v9o31 - %v11 /\
    %v12 = %v12o31 + %v14 /\ %v30 = %v12o31 - %v14 /\
    %v13 = %v13o31 + %v15 /\ %v31 = %v13o31 - %v15 /\
    eqmod  %v2 (%v16o31*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o31*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o31*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o31*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
     %v8 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
     %v9 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
    %v29 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
    %v30 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
    %v13 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
    %v31 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
     %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
     %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
    %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
    %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
    %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
    %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [103]];

ghost  %v0o31@int32[4], %v1o31@int32[4], %v2o31@int32[4], %v3o31@int32[4],
      %v28o31@int32[4],%v29o31@int32[4],%v30o31@int32[4],%v31o31@int32[4]:
       %v0o31 =  %v0 /\  %v1o31 =  %v1 /\ %v2o31 =  %v2 /\  %v3o31 =  %v3 /\
      %v28o31 = %v28 /\ %v29o31 = %v29 /\%v30o31 = %v30 /\ %v31o31 = %v31
   &&  %v0o31 =  %v0 /\  %v1o31 =  %v1 /\ %v2o31 =  %v2 /\  %v3o31 =  %v3 /\
      %v28o31 = %v28 /\ %v29o31 = %v29 /\%v30o31 = %v30 /\ %v31o31 = %v31;

(* mul	v10.4s, v28.4s, v23.s[1]                    #! PC = 0x413cd4 *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v10 %v28 %mm; cast [] %v10@int32[4] %v10;
(* sub	v16.4s, v0.4s, v4.4s                        #! PC = 0x413cd8 *)
sub %v16 %v0 %v4;
(* mul	v11.4s, v29.4s, v23.s[1]                    #! PC = 0x413cdc *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v5.4s                        #! PC = 0x413ce0 *)
sub %v17 %v1 %v5;
(* mul	v14.4s, v30.4s, v23.s[3]                    #! PC = 0x413ce4 *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* sub	v18.4s, v2.4s, v6.4s                        #! PC = 0x413ce8 *)
sub %v18 %v2 %v6;
(* mul	v15.4s, v31.4s, v23.s[3]                    #! PC = 0x413cec *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v3.4s, v7.4s                        #! PC = 0x413cf0 *)
sub %v19 %v3 %v7;
(* sqrdmulh	v28.4s, v28.4s, v23.s[0]               #! PC = 0x413cf4 *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v4.4s                         #! PC = 0x413cf8 *)
add %v0 %v0 %v4;
(* sqrdmulh	v29.4s, v29.4s, v23.s[0]               #! PC = 0x413cfc *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v5.4s                         #! PC = 0x413d00 *)
add %v1 %v1 %v5;
(* sqrdmulh	v30.4s, v30.4s, v23.s[2]               #! PC = 0x413d04 *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v2.4s, v2.4s, v6.4s                         #! PC = 0x413d08 *)
add %v2 %v2 %v6;
(* sqrdmulh	v31.4s, v31.4s, v23.s[2]               #! PC = 0x413d0c *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v3.4s, v3.4s, v7.4s                         #! PC = 0x413d10 *)
add %v3 %v3 %v7;
(* mls	v10.4s, v28.4s, v20.s[0]                    #! PC = 0x413d14 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x413d18 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413d1c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413d20 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v10 (%v28o31*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o31*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o31*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o31*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [104]] && true;
assume eqmod %v10 (%v28o31*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o31*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o31*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o31*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
        %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
        %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
       %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
        %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
        %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
       %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 106 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o31 +  %v4 /\ %v16 =  %v0o31 -  %v4 /\
     %v1 =  %v1o31 +  %v5 /\ %v17 =  %v1o31 -  %v5 /\
     %v2 =  %v2o31 +  %v6 /\ %v18 =  %v2o31 -  %v6 /\
     %v3 =  %v3o31 +  %v7 /\ %v19 =  %v3o31 -  %v7 /\
    eqmod %v10 (%v28o31*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o31*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o31*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o31*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
     %v0 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
    %v16 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
     %v1 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
    %v17 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
     %v2 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
    %v18 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
     %v3 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
    %v19 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
     %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
     %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
    %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
     %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
     %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
    %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [104]];

ghost  %v8o32@int32[4], %v9o32@int32[4],%v10o32@int32[4],%v11o32@int32[4],
      %v16o32@int32[4],%v17o32@int32[4],%v18o32@int32[4],%v19o32@int32[4]:
       %v8o32 =  %v8 /\  %v9o32 =  %v9 /\%v10o32 = %v10 /\ %v11o32 = %v11 /\
      %v16o32 = %v16 /\ %v17o32 = %v17 /\%v18o32 = %v18 /\ %v19o32 = %v19
   &&  %v8o32 =  %v8 /\  %v9o32 =  %v9 /\%v10o32 = %v10 /\ %v11o32 = %v11 /\
      %v16o32 = %v16 /\ %v17o32 = %v17 /\%v18o32 = %v18 /\ %v19o32 = %v19;

(* mul	v4.4s, v16.4s, v21.s[1]                     #! PC = 0x413d24 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v4 %v16 %mm; cast [] %v4@int32[4] %v4;
(* sub	v28.4s, v8.4s, v12.4s                       #! PC = 0x413d28 *)
sub %v28 %v8 %v12;
(* mul	v5.4s, v17.4s, v21.s[1]                     #! PC = 0x413d2c *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v5 %v17 %mm; cast [] %v5@int32[4] %v5;
(* sub	v29.4s, v9.4s, v13.4s                       #! PC = 0x413d30 *)
sub %v29 %v9 %v13;
(* mul	v6.4s, v18.4s, v21.s[1]                     #! PC = 0x413d34 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v10.4s, v14.4s                      #! PC = 0x413d38 *)
sub %v30 %v10 %v14;
(* mul	v7.4s, v19.4s, v21.s[1]                     #! PC = 0x413d3c *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v11.4s, v15.4s                      #! PC = 0x413d40 *)
sub %v31 %v11 %v15;
(* sqrdmulh	v16.4s, v16.4s, v21.s[0]               #! PC = 0x413d44 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v12.4s                        #! PC = 0x413d48 *)
add %v8 %v8 %v12;
(* sqrdmulh	v17.4s, v17.4s, v21.s[0]               #! PC = 0x413d4c *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v13.4s                        #! PC = 0x413d50 *)
add %v9 %v9 %v13;
(* sqrdmulh	v18.4s, v18.4s, v21.s[0]               #! PC = 0x413d54 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v10.4s, v10.4s, v14.4s                      #! PC = 0x413d58 *)
add %v10 %v10 %v14;
(* sqrdmulh	v19.4s, v19.4s, v21.s[0]               #! PC = 0x413d5c *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v11.4s, v11.4s, v15.4s                      #! PC = 0x413d60 *)
add %v11 %v11 %v15;
(* mls	v4.4s, v16.4s, v20.s[0]                     #! PC = 0x413d64 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v5.4s, v17.4s, v20.s[0]                     #! PC = 0x413d68 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x413d6c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413d70 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v4 (%v16o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [105]] && true;
assume eqmod  %v4 (%v16o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
        %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
        %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
       %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
       %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
       %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
       %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 107 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o32 + %v12 /\ %v28 =  %v8o32 - %v12 /\
     %v9 =  %v9o32 + %v13 /\ %v29 =  %v9o32 - %v13 /\
    %v10 = %v10o32 + %v14 /\ %v30 = %v10o32 - %v14 /\
    %v11 = %v11o32 + %v15 /\ %v31 = %v11o32 - %v15 /\
    eqmod  %v4 (%v16o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v17o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o32*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
     %v8 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
    %v28 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
     %v9 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
    %v29 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
    %v10 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
    %v30 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
    %v11 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
    %v31 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
     %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
     %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
    %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
    %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
    %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
    %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [105]];

ghost %v28o32@int32[4],%v29o32@int32[4],%v30o32@int32[4],%v31o32@int32[4]:
      %v28o32 = %v28 /\ %v29o32 = %v29 /\%v30o32 = %v30 /\ %v31o32 = %v31
   && %v28o32 = %v28 /\ %v29o32 = %v29 /\%v30o32 = %v30 /\ %v31o32 = %v31;

(* mul	v12.4s, v28.4s, v21.s[3]                    #! PC = 0x413d74 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v12 %v28 %mm; cast [] %v12@int32[4] %v12;
(* mul	v13.4s, v29.4s, v21.s[3]                    #! PC = 0x413d78 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v13 %v29 %mm; cast [] %v13@int32[4] %v13;
(* mul	v14.4s, v30.4s, v21.s[3]                    #! PC = 0x413d7c *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* mul	v15.4s, v31.4s, v21.s[3]                    #! PC = 0x413d80 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v28.4s, v28.4s, v21.s[2]               #! PC = 0x413d84 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x413d88 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v21.s[2]               #! PC = 0x413d8c *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v21.s[2]               #! PC = 0x413d90 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v12.4s, v28.4s, v20.s[0]                    #! PC = 0x413d94 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v13.4s, v29.4s, v20.s[0]                    #! PC = 0x413d98 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413d9c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413da0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v12 (%v28o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [107]] && true;
assume eqmod %v12 (%v28o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 108 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v12 (%v28o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v29o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o32*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost  %v0o33@int32[4], %v1o33@int32[4], %v2o33@int32[4], %v3o33@int32[4],
       %v4o33@int32[4], %v5o33@int32[4], %v6o33@int32[4], %v7o33@int32[4]:
       %v0o33 =  %v0 /\  %v1o33 =  %v1 /\ %v2o33 =  %v2 /\  %v3o33 =  %v3 /\
       %v4o33 =  %v4 /\  %v5o33 =  %v5 /\ %v6o33 =  %v6 /\  %v7o33 =  %v7
   &&  %v0o33 =  %v0 /\  %v1o33 =  %v1 /\ %v2o33 =  %v2 /\  %v3o33 =  %v3 /\
       %v4o33 =  %v4 /\  %v5o33 =  %v5 /\ %v6o33 =  %v6 /\  %v7o33 =  %v7;
ghost  %v8o33@int32[4], %v9o33@int32[4],%v10o33@int32[4],%v11o33@int32[4],
      %v12o33@int32[4],%v13o33@int32[4],%v14o33@int32[4],%v15o33@int32[4]:
       %v8o33 =  %v8 /\  %v9o33 =  %v9 /\%v10o33 = %v10 /\ %v11o33 = %v11 /\
      %v12o33 = %v12 /\ %v13o33 = %v13 /\%v14o33 = %v14 /\ %v15o33 = %v15
   &&  %v8o33 =  %v8 /\  %v9o33 =  %v9 /\%v10o33 = %v10 /\ %v11o33 = %v11 /\
      %v12o33 = %v12 /\ %v13o33 = %v13 /\%v14o33 = %v14 /\ %v15o33 = %v15;

(* sub	v28.4s, v0.4s, v8.4s                        #! PC = 0x413da4 *)
sub %v28 %v0 %v8;
(* add	v16.4s, v0.4s, v8.4s                        #! PC = 0x413da8 *)
add %v16 %v0 %v8;
(* sub	v29.4s, v2.4s, v10.4s                       #! PC = 0x413dac *)
sub %v29 %v2 %v10;
(* add	v17.4s, v2.4s, v10.4s                       #! PC = 0x413db0 *)
add %v17 %v2 %v10;
(* sub	v30.4s, v4.4s, v12.4s                       #! PC = 0x413db4 *)
sub %v30 %v4 %v12;
(* add	v18.4s, v4.4s, v12.4s                       #! PC = 0x413db8 *)
add %v18 %v4 %v12;
(* sub	v31.4s, v6.4s, v14.4s                       #! PC = 0x413dbc *)
sub %v31 %v6 %v14;
(* add	v19.4s, v6.4s, v14.4s                       #! PC = 0x413dc0 *)
add %v19 %v6 %v14;
(* sub	v8.4s, v1.4s, v9.4s                         #! PC = 0x413dc4 *)
sub %v8 %v1 %v9;
(* add	v0.4s, v1.4s, v9.4s                         #! PC = 0x413dc8 *)
add %v0 %v1 %v9;
(* sub	v10.4s, v3.4s, v11.4s                       #! PC = 0x413dcc *)
sub %v10 %v3 %v11;
(* add	v2.4s, v3.4s, v11.4s                        #! PC = 0x413dd0 *)
add %v2 %v3 %v11;
(* sub	v12.4s, v5.4s, v13.4s                       #! PC = 0x413dd4 *)
sub %v12 %v5 %v13;
(* add	v4.4s, v5.4s, v13.4s                        #! PC = 0x413dd8 *)
add %v4 %v5 %v13;
(* sub	v14.4s, v7.4s, v15.4s                       #! PC = 0x413ddc *)
sub %v14 %v7 %v15;
(* add	v6.4s, v7.4s, v15.4s                        #! PC = 0x413de0 *)
add %v6 %v7 %v15;

assert [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
       prove with [algebra solver isl, cuts [106, 107]] && true;
assume [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
    && [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
       %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
       %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
       %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
       %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
        %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
        %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
       %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
        %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
        %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
       %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q];
(* CUT 109 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 =  %v0o33 +  %v8o33 /\ %v28 =  %v0o33 -  %v8o33 /\
    %v17 =  %v2o33 + %v10o33 /\ %v29 =  %v2o33 - %v10o33 /\
    %v18 =  %v4o33 + %v12o33 /\ %v30 =  %v4o33 - %v12o33 /\
    %v19 =  %v6o33 + %v14o33 /\ %v31 =  %v6o33 - %v14o33 /\
     %v0 =  %v1o33 +  %v9o33 /\  %v8 =  %v1o33 -  %v9o33 /\
     %v2 =  %v3o33 + %v11o33 /\ %v10 =  %v3o33 - %v11o33 /\
     %v4 =  %v5o33 + %v13o33 /\ %v12 =  %v5o33 - %v13o33 /\
     %v6 =  %v7o33 + %v15o33 /\ %v14 =  %v7o33 - %v15o33 /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
    %v16 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
    %v28 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
    %v17 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
    %v29 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
    %v18 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
    %v30 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
    %v19 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
    %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
    %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v29 /\
    %v29 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
    %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
    %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
    %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
    %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
     %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
     %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
    %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
     %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
     %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
    %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q]
    prove with [cuts [106, 107]];

ghost  %v0o34@int32[4], %v2o34@int32[4], %v4o34@int32[4], %v6o34@int32[4]:
       %v0o34 =  %v0 /\  %v2o34 =  %v2 /\ %v4o34 =  %v4 /\  %v6o34 =  %v6
   &&  %v0o34 =  %v0 /\  %v2o34 =  %v2 /\ %v4o34 =  %v4 /\  %v6o34 =  %v6;

(* mov	v20.s[2], w24                               #! PC = 0x413de4 *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w24, m3];
(* mov	v20.s[3], w25                               #! PC = 0x413de8 *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w25];
(* mul	v1.4s, v0.4s, v20.s[3]                      #! PC = 0x413dec *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v1 %v0 %mm; cast [] %v1@int32[4] %v1;
(* mul	v3.4s, v2.4s, v20.s[3]                      #! PC = 0x413df0 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v3 %v2 %mm; cast [] %v3@int32[4] %v3;
(* mul	v5.4s, v4.4s, v20.s[3]                      #! PC = 0x413df4 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v5 %v4 %mm; cast [] %v5@int32[4] %v5;
(* mul	v7.4s, v6.4s, v20.s[3]                      #! PC = 0x413df8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v7 %v6 %mm; cast [] %v7@int32[4] %v7;
(* sqrdmulh	v0.4s, v0.4s, v20.s[2]                 #! PC = 0x413dfc *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v0 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v0 %dc %mm 1;
(* sqrdmulh	v2.4s, v2.4s, v20.s[2]                 #! PC = 0x413e00 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v2 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v2 %dc %mm 1;
(* sqrdmulh	v4.4s, v4.4s, v20.s[2]                 #! PC = 0x413e04 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v4 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v4 %dc %mm 1;
(* sqrdmulh	v6.4s, v6.4s, v20.s[2]                 #! PC = 0x413e08 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v6 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v6 %dc %mm 1;
(* mls	v1.4s, v0.4s, v20.s[0]                      #! PC = 0x413e0c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v0 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v2.4s, v20.s[0]                      #! PC = 0x413e10 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v2 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v4.4s, v20.s[0]                      #! PC = 0x413e14 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v4 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v6.4s, v20.s[0]                      #! PC = 0x413e18 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v6 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 ( %v0o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [109]] && true;
assume eqmod  %v1 ( %v0o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 110 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v1 ( %v0o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 ( %v2o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 ( %v4o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 ( %v6o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

ghost %v16o34@int32[4],%v17o34@int32[4],%v18o34@int32[4],%v19o34@int32[4]:
      %v16o34 = %v16 /\ %v17o34 = %v17 /\%v18o34 = %v18 /\ %v19o34 = %v19
   && %v16o34 = %v16 /\ %v17o34 = %v17 /\%v18o34 = %v18 /\ %v19o34 = %v19;

(* mul	v0.4s, v16.4s, v20.s[3]                     #! PC = 0x413e1c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v0 %v16 %mm; cast [] %v0@int32[4] %v0;
(* mul	v2.4s, v17.4s, v20.s[3]                     #! PC = 0x413e20 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v2 %v17 %mm; cast [] %v2@int32[4] %v2;
(* mul	v4.4s, v18.4s, v20.s[3]                     #! PC = 0x413e24 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v4 %v18 %mm; cast [] %v4@int32[4] %v4;
(* mul	v6.4s, v19.4s, v20.s[3]                     #! PC = 0x413e28 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v6 %v19 %mm; cast [] %v6@int32[4] %v6;
(* sqrdmulh	v16.4s, v16.4s, v20.s[2]               #! PC = 0x413e2c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* sqrdmulh	v17.4s, v17.4s, v20.s[2]               #! PC = 0x413e30 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* sqrdmulh	v18.4s, v18.4s, v20.s[2]               #! PC = 0x413e34 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* sqrdmulh	v19.4s, v19.4s, v20.s[2]               #! PC = 0x413e38 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* mls	v0.4s, v16.4s, v20.s[0]                     #! PC = 0x413e3c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* mls	v2.4s, v17.4s, v20.s[0]                     #! PC = 0x413e40 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v4.4s, v18.4s, v20.s[0]                     #! PC = 0x413e44 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v6.4s, v19.4s, v20.s[0]                     #! PC = 0x413e48 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;

assert eqmod  %v0 (%v16o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [109]] && true;
assume eqmod  %v0 (%v16o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

(* CUT 111 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v0 (%v16o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v2 (%v17o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v4 (%v18o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v19o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

ghost  %v8o34@int32[4],%v10o34@int32[4],%v12o34@int32[4],%v14o34@int32[4]:
       %v8o34 =  %v8 /\ %v10o34 = %v10 /\%v12o34 = %v12 /\ %v14o34 = %v14
   &&  %v8o34 =  %v8 /\ %v10o34 = %v10 /\%v12o34 = %v12 /\ %v14o34 = %v14;

(* mov	v20.s[2], w26                               #! PC = 0x413e4c *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w26, m3];
(* mov	v20.s[3], w27                               #! PC = 0x413e50 *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w27];
(* mul	v9.4s, v8.4s, v20.s[3]                      #! PC = 0x413e54 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v9 %v8 %mm; cast [] %v9@int32[4] %v9;
(* mul	v11.4s, v10.4s, v20.s[3]                    #! PC = 0x413e58 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v11 %v10 %mm; cast [] %v11@int32[4] %v11;
(* mul	v13.4s, v12.4s, v20.s[3]                    #! PC = 0x413e5c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v13 %v12 %mm; cast [] %v13@int32[4] %v13;
(* mul	v15.4s, v14.4s, v20.s[3]                    #! PC = 0x413e60 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v15 %v14 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v8.4s, v8.4s, v20.s[2]                 #! PC = 0x413e64 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v8 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v8 %dc %mm 1;
(* sqrdmulh	v10.4s, v10.4s, v20.s[2]               #! PC = 0x413e68 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v10 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v10 %dc %mm 1;
(* sqrdmulh	v12.4s, v12.4s, v20.s[2]               #! PC = 0x413e6c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* sqrdmulh	v14.4s, v14.4s, v20.s[2]               #! PC = 0x413e70 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v14 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v14 %dc %mm 1;
(* mls	v9.4s, v8.4s, v20.s[0]                      #! PC = 0x413e74 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v8 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v10.4s, v20.s[0]                    #! PC = 0x413e78 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v10 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v12.4s, v20.s[0]                    #! PC = 0x413e7c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v14.4s, v20.s[0]                    #! PC = 0x413e80 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 ( %v8o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [109]] && true;
assume eqmod  %v9 ( %v8o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 112 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v9 ( %v8o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v10o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v12o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v14o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost %v28o34@int32[4],%v29o34@int32[4],%v30o34@int32[4],%v31o34@int32[4]:
      %v28o34 = %v28 /\ %v29o34 = %v29 /\%v30o34 = %v30 /\ %v31o34 = %v31
   && %v28o34 = %v28 /\ %v29o34 = %v29 /\%v30o34 = %v30 /\ %v31o34 = %v31;

(* mul	v8.4s, v28.4s, v20.s[3]                     #! PC = 0x413e84 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v8 %v28 %mm; cast [] %v8@int32[4] %v8;
(* mul	v10.4s, v29.4s, v20.s[3]                    #! PC = 0x413e88 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v10 %v29 %mm; cast [] %v10@int32[4] %v10;
(* mul	v12.4s, v30.4s, v20.s[3]                    #! PC = 0x413e8c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v12 %v30 %mm; cast [] %v12@int32[4] %v12;
(* mul	v14.4s, v31.4s, v20.s[3]                    #! PC = 0x413e90 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v14 %v31 %mm; cast [] %v14@int32[4] %v14;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x413e94 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x413e98 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v20.s[2]               #! PC = 0x413e9c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v20.s[2]               #! PC = 0x413ea0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v8.4s, v28.4s, v20.s[0]                     #! PC = 0x413ea4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v8 %v8 %mm;
(* mls	v10.4s, v29.4s, v20.s[0]                    #! PC = 0x413ea8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v12.4s, v30.4s, v20.s[0]                    #! PC = 0x413eac *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v14.4s, v31.4s, v20.s[0]                    #! PC = 0x413eb0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;

assert eqmod  %v8 (%v28o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [109]] && true;
assume eqmod  %v8 (%v28o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

(* CUT 113 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v8 (%v28o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v10 (%v29o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v12 (%v30o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v31o34*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

ghost  %v0o35@int32[4], %v1o35@int32[4], %v2o35@int32[4], %v3o35@int32[4],
       %v4o35@int32[4], %v5o35@int32[4], %v6o35@int32[4], %v7o35@int32[4]:
       %v0o35 =  %v0 /\  %v1o35 =  %v1 /\ %v2o35 =  %v2 /\  %v3o35 =  %v3 /\
       %v4o35 =  %v4 /\  %v5o35 =  %v5 /\ %v6o35 =  %v6 /\  %v7o35 =  %v7
   &&  %v0o35 =  %v0 /\  %v1o35 =  %v1 /\ %v2o35 =  %v2 /\  %v3o35 =  %v3 /\
       %v4o35 =  %v4 /\  %v5o35 =  %v5 /\ %v6o35 =  %v6 /\  %v7o35 =  %v7;
ghost  %v8o35@int32[4], %v9o35@int32[4],%v10o35@int32[4],%v11o35@int32[4],
      %v12o35@int32[4],%v13o35@int32[4],%v14o35@int32[4],%v15o35@int32[4]:
       %v8o35 =  %v8 /\  %v9o35 =  %v9 /\%v10o35 = %v10 /\ %v11o35 = %v11 /\
      %v12o35 = %v12 /\ %v13o35 = %v13 /\%v14o35 = %v14 /\ %v15o35 = %v15
   &&  %v8o35 =  %v8 /\  %v9o35 =  %v9 /\%v10o35 = %v10 /\ %v11o35 = %v11 /\
      %v12o35 = %v12 /\ %v13o35 = %v13 /\%v14o35 = %v14 /\ %v15o35 = %v15;

(* sub	x19, x19, #0x1                              #! PC = 0x413eb4 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x413a34 <_intt_top_loop>            #! PC = 0x413eb8 *)
#cbnz	x19, 0x413a34 <_intt_top_loop>            #! 0x413eb8 = 0x413eb8;
(* dup	v29.4s, w20                                 #! PC = 0x413a34 *)
mov %v29 [w20,w20,w20,w20];
(* dup	v30.4s, w21                                 #! PC = 0x413a38 *)
mov %v30 [w21,w21,w21,w21];
(* dup	v31.4s, w22                                 #! PC = 0x413a3c *)
mov %v31 [w22,w22,w22,w22];
(* cmgt	v18.4s, v31.4s, v0.4s                      #! PC = 0x413a40 *)
subs %dc %lt %v0 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v1.4s                      #! PC = 0x413a44 *)
subs %dc %lt %v1 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v0.4s, v30.4s                      #! PC = 0x413a48 *)
subs %dc %lt %v30 %v0; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v1.4s, v30.4s                      #! PC = 0x413a4c *)
subs %dc %lt %v30 %v1; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413a50 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413a54 *)
sub %v17 %v17 %v19;
(* mla	v0.4s, v16.4s, v29.4s                       #! PC = 0x413a58 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v0 %v0 %mla;
(* cmgt	v18.4s, v31.4s, v2.4s                      #! PC = 0x413a5c *)
subs %dc %lt %v2 %v31; split %v18 %dc %lt 31;
(* mla	v1.4s, v17.4s, v29.4s                       #! PC = 0x413a60 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v1 %v1 %mla;
(* cmgt	v19.4s, v31.4s, v3.4s                      #! PC = 0x413a64 *)
subs %dc %lt %v3 %v31; split %v19 %dc %lt 31;
(* str	q0, [x0]                                    #! EA = L0xffffffff0620; PC = 0x413a68 *)
mov [L0xffffffff0620, L0xffffffff0624, L0xffffffff0628, L0xffffffff062c] %v0;
(* cmgt	v16.4s, v2.4s, v30.4s                      #! PC = 0x413a6c *)
subs %dc %lt %v30 %v2; split %v16 %dc %lt 31;
(* ldr	q0, [x0, #16]                               #! EA = L0xffffffff0630; Value = 0x000a7050000b1efc; PC = 0x413a70 *)
mov %v0 [L0xffffffff0630, L0xffffffff0634, L0xffffffff0638, L0xffffffff063c];
(* str	q1, [x0, #64]                               #! EA = L0xffffffff0660; PC = 0x413a74 *)
mov [L0xffffffff0660, L0xffffffff0664, L0xffffffff0668, L0xffffffff066c] %v1;
(* cmgt	v17.4s, v3.4s, v30.4s                      #! PC = 0x413a78 *)
subs %dc %lt %v30 %v3; split %v17 %dc %lt 31;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff0670; Value = 0x0018d283001f2192; PC = 0x413a7c *)
mov %v1 [L0xffffffff0670, L0xffffffff0674, L0xffffffff0678, L0xffffffff067c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413a80 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413a84 *)
sub %v17 %v17 %v19;
(* mla	v2.4s, v16.4s, v29.4s                       #! PC = 0x413a88 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v2 %v2 %mla;
(* cmgt	v18.4s, v31.4s, v4.4s                      #! PC = 0x413a8c *)
subs %dc %lt %v4 %v31; split %v18 %dc %lt 31;
(* mla	v3.4s, v17.4s, v29.4s                       #! PC = 0x413a90 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v3 %v3 %mla;
(* cmgt	v19.4s, v31.4s, v5.4s                      #! PC = 0x413a94 *)
subs %dc %lt %v5 %v31; split %v19 %dc %lt 31;
(* str	q2, [x0, #128]                              #! EA = L0xffffffff06a0; PC = 0x413a98 *)
mov [L0xffffffff06a0, L0xffffffff06a4, L0xffffffff06a8, L0xffffffff06ac] %v2;
(* cmgt	v16.4s, v4.4s, v30.4s                      #! PC = 0x413a9c *)
subs %dc %lt %v30 %v4; split %v16 %dc %lt 31;
(* ldr	q2, [x0, #144]                              #! EA = L0xffffffff06b0; Value = 0x001c41e000203589; PC = 0x413aa0 *)
mov %v2 [L0xffffffff06b0, L0xffffffff06b4, L0xffffffff06b8, L0xffffffff06bc];
(* str	q3, [x0, #192]                              #! EA = L0xffffffff06e0; PC = 0x413aa4 *)
mov [L0xffffffff06e0, L0xffffffff06e4, L0xffffffff06e8, L0xffffffff06ec] %v3;
(* cmgt	v17.4s, v5.4s, v30.4s                      #! PC = 0x413aa8 *)
subs %dc %lt %v30 %v5; split %v17 %dc %lt 31;
(* ldr	q3, [x0, #208]                              #! EA = L0xffffffff06f0; Value = 0x0009fafbffc35e9f; PC = 0x413aac *)
mov %v3 [L0xffffffff06f0, L0xffffffff06f4, L0xffffffff06f8, L0xffffffff06fc];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ab0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413ab4 *)
sub %v17 %v17 %v19;
(* mla	v4.4s, v16.4s, v29.4s                       #! PC = 0x413ab8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v4 %v4 %mla;
(* cmgt	v18.4s, v31.4s, v6.4s                      #! PC = 0x413abc *)
subs %dc %lt %v6 %v31; split %v18 %dc %lt 31;
(* mla	v5.4s, v17.4s, v29.4s                       #! PC = 0x413ac0 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v5 %v5 %mla;
(* cmgt	v19.4s, v31.4s, v7.4s                      #! PC = 0x413ac4 *)
subs %dc %lt %v7 %v31; split %v19 %dc %lt 31;
(* str	q4, [x0, #256]                              #! EA = L0xffffffff0720; PC = 0x413ac8 *)
mov [L0xffffffff0720, L0xffffffff0724, L0xffffffff0728, L0xffffffff072c] %v4;
(* cmgt	v16.4s, v6.4s, v30.4s                      #! PC = 0x413acc *)
subs %dc %lt %v30 %v6; split %v16 %dc %lt 31;
(* ldr	q4, [x0, #272]                              #! EA = L0xffffffff0730; Value = 0xffee1e30003c44a2; PC = 0x413ad0 *)
mov %v4 [L0xffffffff0730, L0xffffffff0734, L0xffffffff0738, L0xffffffff073c];
(* str	q5, [x0, #320]                              #! EA = L0xffffffff0760; PC = 0x413ad4 *)
mov [L0xffffffff0760, L0xffffffff0764, L0xffffffff0768, L0xffffffff076c] %v5;
(* cmgt	v17.4s, v7.4s, v30.4s                      #! PC = 0x413ad8 *)
subs %dc %lt %v30 %v7; split %v17 %dc %lt 31;
(* ldr	q5, [x0, #336]                              #! EA = L0xffffffff0770; Value = 0xffec3667003a4a22; PC = 0x413adc *)
mov %v5 [L0xffffffff0770, L0xffffffff0774, L0xffffffff0778, L0xffffffff077c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ae0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413ae4 *)
sub %v17 %v17 %v19;
(* mla	v6.4s, v16.4s, v29.4s                       #! PC = 0x413ae8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v6 %v6 %mla;
(* cmgt	v18.4s, v31.4s, v8.4s                      #! PC = 0x413aec *)
subs %dc %lt %v8 %v31; split %v18 %dc %lt 31;
(* mla	v7.4s, v17.4s, v29.4s                       #! PC = 0x413af0 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v7 %v7 %mla;
(* cmgt	v19.4s, v31.4s, v9.4s                      #! PC = 0x413af4 *)
subs %dc %lt %v9 %v31; split %v19 %dc %lt 31;
(* str	q6, [x0, #384]                              #! EA = L0xffffffff07a0; PC = 0x413af8 *)
mov [L0xffffffff07a0, L0xffffffff07a4, L0xffffffff07a8, L0xffffffff07ac] %v6;
(* cmgt	v16.4s, v8.4s, v30.4s                      #! PC = 0x413afc *)
subs %dc %lt %v30 %v8; split %v16 %dc %lt 31;
(* ldr	q6, [x0, #400]                              #! EA = L0xffffffff07b0; Value = 0xffffcd6dffeb67c0; PC = 0x413b00 *)
mov %v6 [L0xffffffff07b0, L0xffffffff07b4, L0xffffffff07b8, L0xffffffff07bc];
(* str	q7, [x0, #448]                              #! EA = L0xffffffff07e0; PC = 0x413b04 *)
mov [L0xffffffff07e0, L0xffffffff07e4, L0xffffffff07e8, L0xffffffff07ec] %v7;
(* cmgt	v17.4s, v9.4s, v30.4s                      #! PC = 0x413b08 *)
subs %dc %lt %v30 %v9; split %v17 %dc %lt 31;
(* ldr	q7, [x0, #464]                              #! EA = L0xffffffff07f0; Value = 0xfffb0a5c0032b10b; PC = 0x413b0c *)
mov %v7 [L0xffffffff07f0, L0xffffffff07f4, L0xffffffff07f8, L0xffffffff07fc];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b10 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b14 *)
sub %v17 %v17 %v19;
(* mla	v8.4s, v16.4s, v29.4s                       #! PC = 0x413b18 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v8 %v8 %mla;
(* cmgt	v18.4s, v31.4s, v10.4s                     #! PC = 0x413b1c *)
subs %dc %lt %v10 %v31; split %v18 %dc %lt 31;
(* mla	v9.4s, v17.4s, v29.4s                       #! PC = 0x413b20 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v9 %v9 %mla;
(* cmgt	v19.4s, v31.4s, v11.4s                     #! PC = 0x413b24 *)
subs %dc %lt %v11 %v31; split %v19 %dc %lt 31;
(* str	q8, [x0, #512]                              #! EA = L0xffffffff0820; PC = 0x413b28 *)
mov [L0xffffffff0820, L0xffffffff0824, L0xffffffff0828, L0xffffffff082c] %v8;
(* cmgt	v16.4s, v10.4s, v30.4s                     #! PC = 0x413b2c *)
subs %dc %lt %v30 %v10; split %v16 %dc %lt 31;
(* str	q9, [x0, #576]                              #! EA = L0xffffffff0860; PC = 0x413b30 *)
mov [L0xffffffff0860, L0xffffffff0864, L0xffffffff0868, L0xffffffff086c] %v9;
(* cmgt	v17.4s, v11.4s, v30.4s                     #! PC = 0x413b34 *)
subs %dc %lt %v30 %v11; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b38 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b3c *)
sub %v17 %v17 %v19;
(* mla	v10.4s, v16.4s, v29.4s                      #! PC = 0x413b40 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v10 %v10 %mla;
(* cmgt	v18.4s, v31.4s, v12.4s                     #! PC = 0x413b44 *)
subs %dc %lt %v12 %v31; split %v18 %dc %lt 31;
(* mla	v11.4s, v17.4s, v29.4s                      #! PC = 0x413b48 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v11 %v11 %mla;
(* cmgt	v19.4s, v31.4s, v13.4s                     #! PC = 0x413b4c *)
subs %dc %lt %v13 %v31; split %v19 %dc %lt 31;
(* str	q10, [x0, #640]                             #! EA = L0xffffffff08a0; PC = 0x413b50 *)
mov [L0xffffffff08a0, L0xffffffff08a4, L0xffffffff08a8, L0xffffffff08ac] %v10;
(* cmgt	v16.4s, v12.4s, v30.4s                     #! PC = 0x413b54 *)
subs %dc %lt %v30 %v12; split %v16 %dc %lt 31;
(* str	q11, [x0, #704]                             #! EA = L0xffffffff08e0; PC = 0x413b58 *)
mov [L0xffffffff08e0, L0xffffffff08e4, L0xffffffff08e8, L0xffffffff08ec] %v11;
(* cmgt	v17.4s, v13.4s, v30.4s                     #! PC = 0x413b5c *)
subs %dc %lt %v30 %v13; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b60 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b64 *)
sub %v17 %v17 %v19;
(* mla	v12.4s, v16.4s, v29.4s                      #! PC = 0x413b68 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v12 %v12 %mla;
(* cmgt	v18.4s, v31.4s, v14.4s                     #! PC = 0x413b6c *)
subs %dc %lt %v14 %v31; split %v18 %dc %lt 31;
(* mla	v13.4s, v17.4s, v29.4s                      #! PC = 0x413b70 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v13 %v13 %mla;
(* cmgt	v19.4s, v31.4s, v15.4s                     #! PC = 0x413b74 *)
subs %dc %lt %v15 %v31; split %v19 %dc %lt 31;
(* str	q12, [x0, #768]                             #! EA = L0xffffffff0920; PC = 0x413b78 *)
mov [L0xffffffff0920, L0xffffffff0924, L0xffffffff0928, L0xffffffff092c] %v12;
(* cmgt	v16.4s, v14.4s, v30.4s                     #! PC = 0x413b7c *)
subs %dc %lt %v30 %v14; split %v16 %dc %lt 31;
(* str	q13, [x0, #832]                             #! EA = L0xffffffff0960; PC = 0x413b80 *)
mov [L0xffffffff0960, L0xffffffff0964, L0xffffffff0968, L0xffffffff096c] %v13;
(* cmgt	v17.4s, v15.4s, v30.4s                     #! PC = 0x413b84 *)
subs %dc %lt %v30 %v15; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b88 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b8c *)
sub %v17 %v17 %v19;
(* mla	v14.4s, v16.4s, v29.4s                      #! PC = 0x413b90 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v14 %v14 %mla;
(* mla	v15.4s, v17.4s, v29.4s                      #! PC = 0x413b94 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v15 %v15 %mla;
(* str	q14, [x0, #896]                             #! EA = L0xffffffff09a0; PC = 0x413b98 *)
mov [L0xffffffff09a0, L0xffffffff09a4, L0xffffffff09a8, L0xffffffff09ac] %v14;
(* str	q15, [x0, #960]                             #! EA = L0xffffffff09e0; PC = 0x413b9c *)
mov [L0xffffffff09e0, L0xffffffff09e4, L0xffffffff09e8, L0xffffffff09ec] %v15;

assert true &&
       eqsmod [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]
              %v0o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]
              %v1o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]
              %v2o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]
              %v3o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]
              %v4o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]
              %v5o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]
              %v6o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]
              %v7o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]
              %v8o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]
              %v9o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]
              %v10o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]
              %v11o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]
              %v12o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]
              %v13o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]
              %v14o35 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]
              %v15o35 [Q, Q, Q, Q]
       prove with [cuts [89]];
assume eqmod [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]
             %v0o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]
             %v1o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]
             %v2o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]
             %v3o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]
             %v4o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]
             %v5o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]
             %v6o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]
             %v7o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]
             %v8o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]
             %v9o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]
             %v10o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]
             %v11o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]
             %v12o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]
             %v13o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]
             %v14o35 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]
             %v15o35 [Q, Q, Q, Q] && true;
(* CUT 114 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod [L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c]
          %v0o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c]
          %v1o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac]
          %v2o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec]
          %v3o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c]
          %v4o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c]
          %v5o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac]
          %v6o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec]
          %v7o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c]
          %v8o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c]
          %v9o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac]
          %v10o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec]
          %v11o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c]
          %v12o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c]
          %v13o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac]
          %v14o35 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec]
          %v15o35 [Q, Q, Q, Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0620,L0xffffffff0620,L0xffffffff0620,L0xffffffff0620] /\
    [L0xffffffff0620,L0xffffffff0620,L0xffffffff0620,L0xffffffff0620]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0660,L0xffffffff0660,L0xffffffff0660,L0xffffffff0660] /\
    [L0xffffffff0660,L0xffffffff0660,L0xffffffff0660,L0xffffffff0660]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0] /\
    [L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0] /\
    [L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0720,L0xffffffff0720,L0xffffffff0720,L0xffffffff0720] /\
    [L0xffffffff0720,L0xffffffff0720,L0xffffffff0720,L0xffffffff0720]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0760,L0xffffffff0760,L0xffffffff0760,L0xffffffff0760] /\
    [L0xffffffff0760,L0xffffffff0760,L0xffffffff0760,L0xffffffff0760]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0] /\
    [L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0] /\
    [L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0820,L0xffffffff0820,L0xffffffff0820,L0xffffffff0820] /\
    [L0xffffffff0820,L0xffffffff0820,L0xffffffff0820,L0xffffffff0820]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0860,L0xffffffff0860,L0xffffffff0860,L0xffffffff0860] /\
    [L0xffffffff0860,L0xffffffff0860,L0xffffffff0860,L0xffffffff0860]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0] /\
    [L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0] /\
    [L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0920,L0xffffffff0920,L0xffffffff0920,L0xffffffff0920] /\
    [L0xffffffff0920,L0xffffffff0920,L0xffffffff0920,L0xffffffff0920]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0960,L0xffffffff0960,L0xffffffff0960,L0xffffffff0960] /\
    [L0xffffffff0960,L0xffffffff0960,L0xffffffff0960,L0xffffffff0960]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0] /\
    [L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0] /\
    [L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0]<s[Q2,Q2,Q2,Q2]
    prove with [cuts [89, 110, 111, 112, 113]];

ghost  %v0o36@int32[4], %v2o36@int32[4], %v4o36@int32[4], %v6o36@int32[4],
       %v8o36@int32[4],%v10o36@int32[4],%v12o36@int32[4],%v14o36@int32[4]:
       %v0o36 =  %v0 /\  %v2o36 =  %v2 /\ %v4o36 =  %v4 /\  %v6o36 =  %v6 /\
       %v8o36 =  %v8 /\ %v10o36 = %v10 /\%v12o36 = %v12 /\ %v14o36 = %v14
   &&  %v0o36 =  %v0 /\  %v2o36 =  %v2 /\ %v4o36 =  %v4 /\  %v6o36 =  %v6 /\
       %v8o36 =  %v8 /\ %v10o36 = %v10 /\%v12o36 = %v12 /\ %v14o36 = %v14;

(* add	x0, x0, #0x10                               #! PC = 0x413ba0 *)
adds dc x0 x0 (0x10)@uint64;
(* sub	v16.4s, v0.4s, v1.4s                        #! PC = 0x413ba4 *)
sub %v16 %v0 %v1;
(* ldr	q8, [x0, #512]                              #! EA = L0xffffffff0830; Value = 0x003d1332fffb0137; PC = 0x413ba8 *)
mov %v8 [L0xffffffff0830, L0xffffffff0834, L0xffffffff0838, L0xffffffff083c];
(* sub	v17.4s, v2.4s, v3.4s                        #! PC = 0x413bac *)
sub %v17 %v2 %v3;
(* ldr	q9, [x0, #576]                              #! EA = L0xffffffff0870; Value = 0xfff8a73b002dedda; PC = 0x413bb0 *)
mov %v9 [L0xffffffff0870, L0xffffffff0874, L0xffffffff0878, L0xffffffff087c];
(* sub	v18.4s, v4.4s, v5.4s                        #! PC = 0x413bb4 *)
sub %v18 %v4 %v5;
(* ldr	q10, [x0, #640]                             #! EA = L0xffffffff08b0; Value = 0x0038adec003a4694; PC = 0x413bb8 *)
mov %v10 [L0xffffffff08b0, L0xffffffff08b4, L0xffffffff08b8, L0xffffffff08bc];
(* sub	v19.4s, v6.4s, v7.4s                        #! PC = 0x413bbc *)
sub %v19 %v6 %v7;
(* ldr	q11, [x0, #704]                             #! EA = L0xffffffff08f0; Value = 0x0028af55fff66825; PC = 0x413bc0 *)
mov %v11 [L0xffffffff08f0, L0xffffffff08f4, L0xffffffff08f8, L0xffffffff08fc];
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x413bc4 *)
add %v0 %v0 %v1;
(* ldr	q12, [x0, #768]                             #! EA = L0xffffffff0930; Value = 0x000d1e80ffdda0e1; PC = 0x413bc8 *)
mov %v12 [L0xffffffff0930, L0xffffffff0934, L0xffffffff0938, L0xffffffff093c];
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x413bcc *)
add %v2 %v2 %v3;
(* ldr	q13, [x0, #832]                             #! EA = L0xffffffff0970; Value = 0x0004fd7cffe80e3f; PC = 0x413bd0 *)
mov %v13 [L0xffffffff0970, L0xffffffff0974, L0xffffffff0978, L0xffffffff097c];
(* add	v4.4s, v4.4s, v5.4s                         #! PC = 0x413bd4 *)
add %v4 %v4 %v5;
(* ldr	q14, [x0, #896]                             #! EA = L0xffffffff09b0; Value = 0xfff2348e000cd046; PC = 0x413bd8 *)
mov %v14 [L0xffffffff09b0, L0xffffffff09b4, L0xffffffff09b8, L0xffffffff09bc];
(* add	v6.4s, v6.4s, v7.4s                         #! PC = 0x413bdc *)
add %v6 %v6 %v7;
(* ldr	q15, [x0, #960]                             #! EA = L0xffffffff09f0; Value = 0x000510e0ffcea3f7; PC = 0x413be0 *)
mov %v15 [L0xffffffff09f0, L0xffffffff09f4, L0xffffffff09f8, L0xffffffff09fc];

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
        %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
        %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
       %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 115 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o36 +  %v1 /\ %v16 =  %v0o36 -  %v1 /\
     %v2 =  %v2o36 +  %v3 /\ %v17 =  %v2o36 -  %v3 /\
     %v4 =  %v4o36 +  %v5 /\ %v18 =  %v4o36 -  %v5 /\
     %v6 =  %v6o36 +  %v7 /\ %v19 =  %v6o36 -  %v7 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
     %v4 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
     %v6 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
    %v19 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
     %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
     %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
    %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [88]];

ghost  %v8o37@int32[4],%v10o37@int32[4],%v12o37@int32[4],%v14o37@int32[4],
      %v16o37@int32[4],%v17o37@int32[4],%v18o37@int32[4],%v19o37@int32[4]:
       %v8o37 =  %v8 /\ %v10o37 = %v10 /\%v12o37 = %v12 /\ %v14o37 = %v14 /\
      %v16o37 = %v16 /\ %v17o37 = %v17 /\%v18o37 = %v18 /\ %v19o37 = %v19
   &&  %v8o37 =  %v8 /\ %v10o37 = %v10 /\%v12o37 = %v12 /\ %v14o37 = %v14 /\
      %v16o37 = %v16 /\ %v17o37 = %v17 /\%v18o37 = %v18 /\ %v19o37 = %v19;

(* mul	v1.4s, v16.4s, v24.s[1]                     #! PC = 0x413be4 *)
mov [_, m, _, _] %v24; mov %mm [m, m, m, m];
mull %dc %v1 %v16 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v8.4s, v9.4s                        #! PC = 0x413be8 *)
sub %v28 %v8 %v9;
(* mul	v3.4s, v17.4s, v24.s[3]                     #! PC = 0x413bec *)
mov [_, _, _, m] %v24; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v10.4s, v11.4s                      #! PC = 0x413bf0 *)
sub %v29 %v10 %v11;
(* mul	v5.4s, v18.4s, v25.s[1]                     #! PC = 0x413bf4 *)
mov [_, m, _, _] %v25; mov %mm [m, m, m, m];
mull %dc %v5 %v18 %mm; cast [] %v5@int32[4] %v5;
(* sub	v30.4s, v12.4s, v13.4s                      #! PC = 0x413bf8 *)
sub %v30 %v12 %v13;
(* mul	v7.4s, v19.4s, v25.s[3]                     #! PC = 0x413bfc *)
mov [_, _, _, m] %v25; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v14.4s, v15.4s                      #! PC = 0x413c00 *)
sub %v31 %v14 %v15;
(* sqrdmulh	v16.4s, v16.4s, v24.s[0]               #! PC = 0x413c04 *)
mov [m, _, _, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v9.4s                         #! PC = 0x413c08 *)
add %v8 %v8 %v9;
(* sqrdmulh	v17.4s, v17.4s, v24.s[2]               #! PC = 0x413c0c *)
mov [_, _, m, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v10.4s, v10.4s, v11.4s                      #! PC = 0x413c10 *)
add %v10 %v10 %v11;
(* sqrdmulh	v18.4s, v18.4s, v25.s[0]               #! PC = 0x413c14 *)
mov [m, _, _, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v13.4s                      #! PC = 0x413c18 *)
add %v12 %v12 %v13;
(* sqrdmulh	v19.4s, v19.4s, v25.s[2]               #! PC = 0x413c1c *)
mov [_, _, m, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v14.4s, v14.4s, v15.4s                      #! PC = 0x413c20 *)
add %v14 %v14 %v15;
(* mls	v1.4s, v16.4s, v20.s[0]                     #! PC = 0x413c24 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x413c28 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v18.4s, v20.s[0]                     #! PC = 0x413c2c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413c30 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 (%v16o37*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o37*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o37*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o37*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume eqmod  %v1 (%v16o37*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o37*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o37*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o37*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
        %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
       %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
       %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
       %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
       %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 116 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o37 +  %v9 /\ %v28 =  %v8o37 -  %v9 /\
    %v10 = %v10o37 + %v11 /\ %v29 = %v10o37 - %v11 /\
    %v12 = %v12o37 + %v13 /\ %v30 = %v12o37 - %v13 /\
    %v14 = %v14o37 + %v15 /\ %v31 = %v14o37 - %v15 /\
    eqmod  %v1 (%v16o37*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o37*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v18o37*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o37*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
     %v8 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
    %v10 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
    %v30 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
    %v14 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
    %v31 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
     %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
    %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
    %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
    %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
    %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [88]];

ghost  %v0o37@int32[4], %v1o37@int32[4], %v4o37@int32[4], %v5o37@int32[4],
      %v28o37@int32[4],%v29o37@int32[4],%v30o37@int32[4],%v31o37@int32[4]:
       %v0o37 =  %v0 /\  %v1o37 =  %v1 /\ %v4o37 =  %v4 /\  %v5o37 =  %v5 /\
      %v28o37 = %v28 /\ %v29o37 = %v29 /\%v30o37 = %v30 /\ %v31o37 = %v31
   &&  %v0o37 =  %v0 /\  %v1o37 =  %v1 /\ %v4o37 =  %v4 /\  %v5o37 =  %v5 /\
      %v28o37 = %v28 /\ %v29o37 = %v29 /\%v30o37 = %v30 /\ %v31o37 = %v31;

(* mul	v9.4s, v28.4s, v26.s[1]                     #! PC = 0x413c34 *)
mov [_, m, _, _] %v26; mov %mm [m, m, m, m];
mull %dc %v9 %v28 %mm; cast [] %v9@int32[4] %v9;
(* sub	v16.4s, v0.4s, v2.4s                        #! PC = 0x413c38 *)
sub %v16 %v0 %v2;
(* mul	v11.4s, v29.4s, v26.s[3]                    #! PC = 0x413c3c *)
mov [_, _, _, m] %v26; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v3.4s                        #! PC = 0x413c40 *)
sub %v17 %v1 %v3;
(* mul	v13.4s, v30.4s, v27.s[1]                    #! PC = 0x413c44 *)
mov [_, m, _, _] %v27; mov %mm [m, m, m, m];
mull %dc %v13 %v30 %mm; cast [] %v13@int32[4] %v13;
(* sub	v18.4s, v4.4s, v6.4s                        #! PC = 0x413c48 *)
sub %v18 %v4 %v6;
(* mul	v15.4s, v31.4s, v27.s[3]                    #! PC = 0x413c4c *)
mov [_, _, _, m] %v27; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v5.4s, v7.4s                        #! PC = 0x413c50 *)
sub %v19 %v5 %v7;
(* sqrdmulh	v28.4s, v28.4s, v26.s[0]               #! PC = 0x413c54 *)
mov [m, _, _, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x413c58 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.s[2]               #! PC = 0x413c5c *)
mov [_, _, m, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x413c60 *)
add %v1 %v1 %v3;
(* sqrdmulh	v30.4s, v30.4s, v27.s[0]               #! PC = 0x413c64 *)
mov [m, _, _, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v4.4s, v4.4s, v6.4s                         #! PC = 0x413c68 *)
add %v4 %v4 %v6;
(* sqrdmulh	v31.4s, v31.4s, v27.s[2]               #! PC = 0x413c6c *)
mov [_, _, m, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v5.4s, v5.4s, v7.4s                         #! PC = 0x413c70 *)
add %v5 %v5 %v7;
(* mls	v9.4s, v28.4s, v20.s[0]                     #! PC = 0x413c74 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x413c78 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v30.4s, v20.s[0]                    #! PC = 0x413c7c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413c80 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 (%v28o37*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o37*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o37*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o37*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [115]] && true;
assume eqmod  %v9 (%v28o37*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o37*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o37*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o37*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
        %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
       %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
        %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
       %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
        %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
       %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 117 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o37 +  %v2 /\ %v16 =  %v0o37 -  %v2 /\
     %v1 =  %v1o37 +  %v3 /\ %v17 =  %v1o37 -  %v3 /\
     %v4 =  %v4o37 +  %v6 /\ %v18 =  %v4o37 -  %v6 /\
     %v5 =  %v5o37 +  %v7 /\ %v19 =  %v5o37 -  %v7 /\
    eqmod  %v9 (%v28o37*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o37*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v30o37*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o37*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
     %v1 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
    %v17 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
     %v4 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
    %v18 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
     %v5 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
    %v19 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
     %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
    %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
     %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
    %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
     %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
    %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [115]];

ghost  %v8o38@int32[4], %v9o38@int32[4],%v12o38@int32[4],%v13o38@int32[4],
      %v16o38@int32[4],%v17o38@int32[4],%v18o38@int32[4],%v19o38@int32[4]:
       %v8o38 =  %v8 /\  %v9o38 =  %v9 /\%v12o38 = %v12 /\ %v13o38 = %v13 /\
      %v16o38 = %v16 /\ %v17o38 = %v17 /\%v18o38 = %v18 /\ %v19o38 = %v19
   &&  %v8o38 =  %v8 /\  %v9o38 =  %v9 /\%v12o38 = %v12 /\ %v13o38 = %v13 /\
      %v16o38 = %v16 /\ %v17o38 = %v17 /\%v18o38 = %v18 /\ %v19o38 = %v19;

(* mul	v2.4s, v16.4s, v22.s[1]                     #! PC = 0x413c84 *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v2 %v16 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v8.4s, v10.4s                       #! PC = 0x413c88 *)
sub %v28 %v8 %v10;
(* mul	v3.4s, v17.4s, v22.s[1]                     #! PC = 0x413c8c *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v9.4s, v11.4s                       #! PC = 0x413c90 *)
sub %v29 %v9 %v11;
(* mul	v6.4s, v18.4s, v22.s[3]                     #! PC = 0x413c94 *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v12.4s, v14.4s                      #! PC = 0x413c98 *)
sub %v30 %v12 %v14;
(* mul	v7.4s, v19.4s, v22.s[3]                     #! PC = 0x413c9c *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v13.4s, v15.4s                      #! PC = 0x413ca0 *)
sub %v31 %v13 %v15;
(* sqrdmulh	v16.4s, v16.4s, v22.s[0]               #! PC = 0x413ca4 *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v10.4s                        #! PC = 0x413ca8 *)
add %v8 %v8 %v10;
(* sqrdmulh	v17.4s, v17.4s, v22.s[0]               #! PC = 0x413cac *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v11.4s                        #! PC = 0x413cb0 *)
add %v9 %v9 %v11;
(* sqrdmulh	v18.4s, v18.4s, v22.s[2]               #! PC = 0x413cb4 *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v14.4s                      #! PC = 0x413cb8 *)
add %v12 %v12 %v14;
(* sqrdmulh	v19.4s, v19.4s, v22.s[2]               #! PC = 0x413cbc *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v13.4s, v13.4s, v15.4s                      #! PC = 0x413cc0 *)
add %v13 %v13 %v15;
(* mls	v2.4s, v16.4s, v20.s[0]                     #! PC = 0x413cc4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x413cc8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x413ccc *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413cd0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v2 (%v16o38*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o38*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o38*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o38*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [116]] && true;
assume eqmod  %v2 (%v16o38*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o38*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o38*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o38*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
        %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
        %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
       %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
       %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
       %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
       %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 118 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o38 + %v10 /\ %v28 =  %v8o38 - %v10 /\
     %v9 =  %v9o38 + %v11 /\ %v29 =  %v9o38 - %v11 /\
    %v12 = %v12o38 + %v14 /\ %v30 = %v12o38 - %v14 /\
    %v13 = %v13o38 + %v15 /\ %v31 = %v13o38 - %v15 /\
    eqmod  %v2 (%v16o38*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o38*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o38*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o38*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
     %v8 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
     %v9 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
    %v29 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
    %v30 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
    %v13 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
    %v31 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
     %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
     %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
    %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
    %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
    %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
    %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [116]];

ghost  %v0o38@int32[4], %v1o38@int32[4], %v2o38@int32[4], %v3o38@int32[4],
      %v28o38@int32[4],%v29o38@int32[4],%v30o38@int32[4],%v31o38@int32[4]:
       %v0o38 =  %v0 /\  %v1o38 =  %v1 /\ %v2o38 =  %v2 /\  %v3o38 =  %v3 /\
      %v28o38 = %v28 /\ %v29o38 = %v29 /\%v30o38 = %v30 /\ %v31o38 = %v31
   &&  %v0o38 =  %v0 /\  %v1o38 =  %v1 /\ %v2o38 =  %v2 /\  %v3o38 =  %v3 /\
      %v28o38 = %v28 /\ %v29o38 = %v29 /\%v30o38 = %v30 /\ %v31o38 = %v31;

(* mul	v10.4s, v28.4s, v23.s[1]                    #! PC = 0x413cd4 *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v10 %v28 %mm; cast [] %v10@int32[4] %v10;
(* sub	v16.4s, v0.4s, v4.4s                        #! PC = 0x413cd8 *)
sub %v16 %v0 %v4;
(* mul	v11.4s, v29.4s, v23.s[1]                    #! PC = 0x413cdc *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v5.4s                        #! PC = 0x413ce0 *)
sub %v17 %v1 %v5;
(* mul	v14.4s, v30.4s, v23.s[3]                    #! PC = 0x413ce4 *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* sub	v18.4s, v2.4s, v6.4s                        #! PC = 0x413ce8 *)
sub %v18 %v2 %v6;
(* mul	v15.4s, v31.4s, v23.s[3]                    #! PC = 0x413cec *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v3.4s, v7.4s                        #! PC = 0x413cf0 *)
sub %v19 %v3 %v7;
(* sqrdmulh	v28.4s, v28.4s, v23.s[0]               #! PC = 0x413cf4 *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v4.4s                         #! PC = 0x413cf8 *)
add %v0 %v0 %v4;
(* sqrdmulh	v29.4s, v29.4s, v23.s[0]               #! PC = 0x413cfc *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v5.4s                         #! PC = 0x413d00 *)
add %v1 %v1 %v5;
(* sqrdmulh	v30.4s, v30.4s, v23.s[2]               #! PC = 0x413d04 *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v2.4s, v2.4s, v6.4s                         #! PC = 0x413d08 *)
add %v2 %v2 %v6;
(* sqrdmulh	v31.4s, v31.4s, v23.s[2]               #! PC = 0x413d0c *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v3.4s, v3.4s, v7.4s                         #! PC = 0x413d10 *)
add %v3 %v3 %v7;
(* mls	v10.4s, v28.4s, v20.s[0]                    #! PC = 0x413d14 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x413d18 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413d1c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413d20 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v10 (%v28o38*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o38*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o38*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o38*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [117]] && true;
assume eqmod %v10 (%v28o38*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o38*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o38*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o38*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
        %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
        %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
       %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
        %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
        %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
       %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 119 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o38 +  %v4 /\ %v16 =  %v0o38 -  %v4 /\
     %v1 =  %v1o38 +  %v5 /\ %v17 =  %v1o38 -  %v5 /\
     %v2 =  %v2o38 +  %v6 /\ %v18 =  %v2o38 -  %v6 /\
     %v3 =  %v3o38 +  %v7 /\ %v19 =  %v3o38 -  %v7 /\
    eqmod %v10 (%v28o38*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o38*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o38*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o38*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
     %v0 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
    %v16 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
     %v1 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
    %v17 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
     %v2 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
    %v18 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
     %v3 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
    %v19 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
     %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
     %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
    %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
     %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
     %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
    %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [117]];

ghost  %v8o39@int32[4], %v9o39@int32[4],%v10o39@int32[4],%v11o39@int32[4],
      %v16o39@int32[4],%v17o39@int32[4],%v18o39@int32[4],%v19o39@int32[4]:
       %v8o39 =  %v8 /\  %v9o39 =  %v9 /\%v10o39 = %v10 /\ %v11o39 = %v11 /\
      %v16o39 = %v16 /\ %v17o39 = %v17 /\%v18o39 = %v18 /\ %v19o39 = %v19
   &&  %v8o39 =  %v8 /\  %v9o39 =  %v9 /\%v10o39 = %v10 /\ %v11o39 = %v11 /\
      %v16o39 = %v16 /\ %v17o39 = %v17 /\%v18o39 = %v18 /\ %v19o39 = %v19;

(* mul	v4.4s, v16.4s, v21.s[1]                     #! PC = 0x413d24 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v4 %v16 %mm; cast [] %v4@int32[4] %v4;
(* sub	v28.4s, v8.4s, v12.4s                       #! PC = 0x413d28 *)
sub %v28 %v8 %v12;
(* mul	v5.4s, v17.4s, v21.s[1]                     #! PC = 0x413d2c *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v5 %v17 %mm; cast [] %v5@int32[4] %v5;
(* sub	v29.4s, v9.4s, v13.4s                       #! PC = 0x413d30 *)
sub %v29 %v9 %v13;
(* mul	v6.4s, v18.4s, v21.s[1]                     #! PC = 0x413d34 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v10.4s, v14.4s                      #! PC = 0x413d38 *)
sub %v30 %v10 %v14;
(* mul	v7.4s, v19.4s, v21.s[1]                     #! PC = 0x413d3c *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v11.4s, v15.4s                      #! PC = 0x413d40 *)
sub %v31 %v11 %v15;
(* sqrdmulh	v16.4s, v16.4s, v21.s[0]               #! PC = 0x413d44 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v12.4s                        #! PC = 0x413d48 *)
add %v8 %v8 %v12;
(* sqrdmulh	v17.4s, v17.4s, v21.s[0]               #! PC = 0x413d4c *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v13.4s                        #! PC = 0x413d50 *)
add %v9 %v9 %v13;
(* sqrdmulh	v18.4s, v18.4s, v21.s[0]               #! PC = 0x413d54 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v10.4s, v10.4s, v14.4s                      #! PC = 0x413d58 *)
add %v10 %v10 %v14;
(* sqrdmulh	v19.4s, v19.4s, v21.s[0]               #! PC = 0x413d5c *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v11.4s, v11.4s, v15.4s                      #! PC = 0x413d60 *)
add %v11 %v11 %v15;
(* mls	v4.4s, v16.4s, v20.s[0]                     #! PC = 0x413d64 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v5.4s, v17.4s, v20.s[0]                     #! PC = 0x413d68 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x413d6c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413d70 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v4 (%v16o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [118]] && true;
assume eqmod  %v4 (%v16o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
        %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
        %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
       %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
       %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
       %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
       %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 120 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o39 + %v12 /\ %v28 =  %v8o39 - %v12 /\
     %v9 =  %v9o39 + %v13 /\ %v29 =  %v9o39 - %v13 /\
    %v10 = %v10o39 + %v14 /\ %v30 = %v10o39 - %v14 /\
    %v11 = %v11o39 + %v15 /\ %v31 = %v11o39 - %v15 /\
    eqmod  %v4 (%v16o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v17o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o39*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
     %v8 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
    %v28 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
     %v9 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
    %v29 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
    %v10 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
    %v30 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
    %v11 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
    %v31 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
     %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
     %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
    %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
    %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
    %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
    %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [118]];

ghost %v28o39@int32[4],%v29o39@int32[4],%v30o39@int32[4],%v31o39@int32[4]:
      %v28o39 = %v28 /\ %v29o39 = %v29 /\%v30o39 = %v30 /\ %v31o39 = %v31
   && %v28o39 = %v28 /\ %v29o39 = %v29 /\%v30o39 = %v30 /\ %v31o39 = %v31;

(* mul	v12.4s, v28.4s, v21.s[3]                    #! PC = 0x413d74 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v12 %v28 %mm; cast [] %v12@int32[4] %v12;
(* mul	v13.4s, v29.4s, v21.s[3]                    #! PC = 0x413d78 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v13 %v29 %mm; cast [] %v13@int32[4] %v13;
(* mul	v14.4s, v30.4s, v21.s[3]                    #! PC = 0x413d7c *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* mul	v15.4s, v31.4s, v21.s[3]                    #! PC = 0x413d80 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v28.4s, v28.4s, v21.s[2]               #! PC = 0x413d84 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x413d88 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v21.s[2]               #! PC = 0x413d8c *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v21.s[2]               #! PC = 0x413d90 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v12.4s, v28.4s, v20.s[0]                    #! PC = 0x413d94 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v13.4s, v29.4s, v20.s[0]                    #! PC = 0x413d98 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413d9c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413da0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v12 (%v28o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [120]] && true;
assume eqmod %v12 (%v28o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 121 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v12 (%v28o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v29o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o39*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost  %v0o3a@int32[4], %v1o3a@int32[4], %v2o3a@int32[4], %v3o3a@int32[4],
       %v4o3a@int32[4], %v5o3a@int32[4], %v6o3a@int32[4], %v7o3a@int32[4]:
       %v0o3a =  %v0 /\  %v1o3a =  %v1 /\ %v2o3a =  %v2 /\  %v3o3a =  %v3 /\
       %v4o3a =  %v4 /\  %v5o3a =  %v5 /\ %v6o3a =  %v6 /\  %v7o3a =  %v7
   &&  %v0o3a =  %v0 /\  %v1o3a =  %v1 /\ %v2o3a =  %v2 /\  %v3o3a =  %v3 /\
       %v4o3a =  %v4 /\  %v5o3a =  %v5 /\ %v6o3a =  %v6 /\  %v7o3a =  %v7;
ghost  %v8o3a@int32[4], %v9o3a@int32[4],%v10o3a@int32[4],%v11o3a@int32[4],
      %v12o3a@int32[4],%v13o3a@int32[4],%v14o3a@int32[4],%v15o3a@int32[4]:
       %v8o3a =  %v8 /\  %v9o3a =  %v9 /\%v10o3a = %v10 /\ %v11o3a = %v11 /\
      %v12o3a = %v12 /\ %v13o3a = %v13 /\%v14o3a = %v14 /\ %v15o3a = %v15
   &&  %v8o3a =  %v8 /\  %v9o3a =  %v9 /\%v10o3a = %v10 /\ %v11o3a = %v11 /\
      %v12o3a = %v12 /\ %v13o3a = %v13 /\%v14o3a = %v14 /\ %v15o3a = %v15;

(* sub	v28.4s, v0.4s, v8.4s                        #! PC = 0x413da4 *)
sub %v28 %v0 %v8;
(* add	v16.4s, v0.4s, v8.4s                        #! PC = 0x413da8 *)
add %v16 %v0 %v8;
(* sub	v29.4s, v2.4s, v10.4s                       #! PC = 0x413dac *)
sub %v29 %v2 %v10;
(* add	v17.4s, v2.4s, v10.4s                       #! PC = 0x413db0 *)
add %v17 %v2 %v10;
(* sub	v30.4s, v4.4s, v12.4s                       #! PC = 0x413db4 *)
sub %v30 %v4 %v12;
(* add	v18.4s, v4.4s, v12.4s                       #! PC = 0x413db8 *)
add %v18 %v4 %v12;
(* sub	v31.4s, v6.4s, v14.4s                       #! PC = 0x413dbc *)
sub %v31 %v6 %v14;
(* add	v19.4s, v6.4s, v14.4s                       #! PC = 0x413dc0 *)
add %v19 %v6 %v14;
(* sub	v8.4s, v1.4s, v9.4s                         #! PC = 0x413dc4 *)
sub %v8 %v1 %v9;
(* add	v0.4s, v1.4s, v9.4s                         #! PC = 0x413dc8 *)
add %v0 %v1 %v9;
(* sub	v10.4s, v3.4s, v11.4s                       #! PC = 0x413dcc *)
sub %v10 %v3 %v11;
(* add	v2.4s, v3.4s, v11.4s                        #! PC = 0x413dd0 *)
add %v2 %v3 %v11;
(* sub	v12.4s, v5.4s, v13.4s                       #! PC = 0x413dd4 *)
sub %v12 %v5 %v13;
(* add	v4.4s, v5.4s, v13.4s                        #! PC = 0x413dd8 *)
add %v4 %v5 %v13;
(* sub	v14.4s, v7.4s, v15.4s                       #! PC = 0x413ddc *)
sub %v14 %v7 %v15;
(* add	v6.4s, v7.4s, v15.4s                        #! PC = 0x413de0 *)
add %v6 %v7 %v15;

assert [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
       prove with [algebra solver isl, cuts [119, 120]] && true;
assume [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
    && [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
       %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
       %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
       %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
       %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
        %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
        %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
       %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
        %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
        %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
       %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q];
(* CUT 122 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 =  %v0o3a +  %v8o3a /\ %v28 =  %v0o3a -  %v8o3a /\
    %v17 =  %v2o3a + %v10o3a /\ %v29 =  %v2o3a - %v10o3a /\
    %v18 =  %v4o3a + %v12o3a /\ %v30 =  %v4o3a - %v12o3a /\
    %v19 =  %v6o3a + %v14o3a /\ %v31 =  %v6o3a - %v14o3a /\
     %v0 =  %v1o3a +  %v9o3a /\  %v8 =  %v1o3a -  %v9o3a /\
     %v2 =  %v3o3a + %v11o3a /\ %v10 =  %v3o3a - %v11o3a /\
     %v4 =  %v5o3a + %v13o3a /\ %v12 =  %v5o3a - %v13o3a /\
     %v6 =  %v7o3a + %v15o3a /\ %v14 =  %v7o3a - %v15o3a /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
    %v16 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
    %v28 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
    %v17 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
    %v29 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
    %v18 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
    %v30 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
    %v19 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
    %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
    %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v29 /\
    %v29 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
    %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
    %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
    %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
    %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
     %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
     %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
    %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
     %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
     %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
    %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q]
    prove with [cuts [119, 120]];

ghost  %v0o3b@int32[4], %v2o3b@int32[4], %v4o3b@int32[4], %v6o3b@int32[4]:
       %v0o3b =  %v0 /\  %v2o3b =  %v2 /\ %v4o3b =  %v4 /\  %v6o3b =  %v6
   &&  %v0o3b =  %v0 /\  %v2o3b =  %v2 /\ %v4o3b =  %v4 /\  %v6o3b =  %v6;

(* mov	v20.s[2], w24                               #! PC = 0x413de4 *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w24, m3];
(* mov	v20.s[3], w25                               #! PC = 0x413de8 *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w25];
(* mul	v1.4s, v0.4s, v20.s[3]                      #! PC = 0x413dec *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v1 %v0 %mm; cast [] %v1@int32[4] %v1;
(* mul	v3.4s, v2.4s, v20.s[3]                      #! PC = 0x413df0 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v3 %v2 %mm; cast [] %v3@int32[4] %v3;
(* mul	v5.4s, v4.4s, v20.s[3]                      #! PC = 0x413df4 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v5 %v4 %mm; cast [] %v5@int32[4] %v5;
(* mul	v7.4s, v6.4s, v20.s[3]                      #! PC = 0x413df8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v7 %v6 %mm; cast [] %v7@int32[4] %v7;
(* sqrdmulh	v0.4s, v0.4s, v20.s[2]                 #! PC = 0x413dfc *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v0 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v0 %dc %mm 1;
(* sqrdmulh	v2.4s, v2.4s, v20.s[2]                 #! PC = 0x413e00 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v2 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v2 %dc %mm 1;
(* sqrdmulh	v4.4s, v4.4s, v20.s[2]                 #! PC = 0x413e04 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v4 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v4 %dc %mm 1;
(* sqrdmulh	v6.4s, v6.4s, v20.s[2]                 #! PC = 0x413e08 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v6 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v6 %dc %mm 1;
(* mls	v1.4s, v0.4s, v20.s[0]                      #! PC = 0x413e0c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v0 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v2.4s, v20.s[0]                      #! PC = 0x413e10 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v2 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v4.4s, v20.s[0]                      #! PC = 0x413e14 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v4 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v6.4s, v20.s[0]                      #! PC = 0x413e18 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v6 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 ( %v0o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [122]] && true;
assume eqmod  %v1 ( %v0o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 123 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v1 ( %v0o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 ( %v2o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 ( %v4o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 ( %v6o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

ghost %v16o3b@int32[4],%v17o3b@int32[4],%v18o3b@int32[4],%v19o3b@int32[4]:
      %v16o3b = %v16 /\ %v17o3b = %v17 /\%v18o3b = %v18 /\ %v19o3b = %v19
   && %v16o3b = %v16 /\ %v17o3b = %v17 /\%v18o3b = %v18 /\ %v19o3b = %v19;

(* mul	v0.4s, v16.4s, v20.s[3]                     #! PC = 0x413e1c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v0 %v16 %mm; cast [] %v0@int32[4] %v0;
(* mul	v2.4s, v17.4s, v20.s[3]                     #! PC = 0x413e20 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v2 %v17 %mm; cast [] %v2@int32[4] %v2;
(* mul	v4.4s, v18.4s, v20.s[3]                     #! PC = 0x413e24 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v4 %v18 %mm; cast [] %v4@int32[4] %v4;
(* mul	v6.4s, v19.4s, v20.s[3]                     #! PC = 0x413e28 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v6 %v19 %mm; cast [] %v6@int32[4] %v6;
(* sqrdmulh	v16.4s, v16.4s, v20.s[2]               #! PC = 0x413e2c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* sqrdmulh	v17.4s, v17.4s, v20.s[2]               #! PC = 0x413e30 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* sqrdmulh	v18.4s, v18.4s, v20.s[2]               #! PC = 0x413e34 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* sqrdmulh	v19.4s, v19.4s, v20.s[2]               #! PC = 0x413e38 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* mls	v0.4s, v16.4s, v20.s[0]                     #! PC = 0x413e3c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* mls	v2.4s, v17.4s, v20.s[0]                     #! PC = 0x413e40 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v4.4s, v18.4s, v20.s[0]                     #! PC = 0x413e44 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v6.4s, v19.4s, v20.s[0]                     #! PC = 0x413e48 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;

assert eqmod  %v0 (%v16o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [122]] && true;
assume eqmod  %v0 (%v16o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

(* CUT 124 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v0 (%v16o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v2 (%v17o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v4 (%v18o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v19o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

ghost  %v8o3b@int32[4],%v10o3b@int32[4],%v12o3b@int32[4],%v14o3b@int32[4]:
       %v8o3b =  %v8 /\ %v10o3b = %v10 /\%v12o3b = %v12 /\ %v14o3b = %v14
   &&  %v8o3b =  %v8 /\ %v10o3b = %v10 /\%v12o3b = %v12 /\ %v14o3b = %v14;

(* mov	v20.s[2], w26                               #! PC = 0x413e4c *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w26, m3];
(* mov	v20.s[3], w27                               #! PC = 0x413e50 *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w27];
(* mul	v9.4s, v8.4s, v20.s[3]                      #! PC = 0x413e54 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v9 %v8 %mm; cast [] %v9@int32[4] %v9;
(* mul	v11.4s, v10.4s, v20.s[3]                    #! PC = 0x413e58 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v11 %v10 %mm; cast [] %v11@int32[4] %v11;
(* mul	v13.4s, v12.4s, v20.s[3]                    #! PC = 0x413e5c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v13 %v12 %mm; cast [] %v13@int32[4] %v13;
(* mul	v15.4s, v14.4s, v20.s[3]                    #! PC = 0x413e60 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v15 %v14 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v8.4s, v8.4s, v20.s[2]                 #! PC = 0x413e64 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v8 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v8 %dc %mm 1;
(* sqrdmulh	v10.4s, v10.4s, v20.s[2]               #! PC = 0x413e68 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v10 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v10 %dc %mm 1;
(* sqrdmulh	v12.4s, v12.4s, v20.s[2]               #! PC = 0x413e6c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* sqrdmulh	v14.4s, v14.4s, v20.s[2]               #! PC = 0x413e70 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v14 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v14 %dc %mm 1;
(* mls	v9.4s, v8.4s, v20.s[0]                      #! PC = 0x413e74 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v8 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v10.4s, v20.s[0]                    #! PC = 0x413e78 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v10 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v12.4s, v20.s[0]                    #! PC = 0x413e7c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v14.4s, v20.s[0]                    #! PC = 0x413e80 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 ( %v8o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [122]] && true;
assume eqmod  %v9 ( %v8o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 125 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v9 ( %v8o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v10o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v12o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v14o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost %v28o3b@int32[4],%v29o3b@int32[4],%v30o3b@int32[4],%v31o3b@int32[4]:
      %v28o3b = %v28 /\ %v29o3b = %v29 /\%v30o3b = %v30 /\ %v31o3b = %v31
   && %v28o3b = %v28 /\ %v29o3b = %v29 /\%v30o3b = %v30 /\ %v31o3b = %v31;

(* mul	v8.4s, v28.4s, v20.s[3]                     #! PC = 0x413e84 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v8 %v28 %mm; cast [] %v8@int32[4] %v8;
(* mul	v10.4s, v29.4s, v20.s[3]                    #! PC = 0x413e88 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v10 %v29 %mm; cast [] %v10@int32[4] %v10;
(* mul	v12.4s, v30.4s, v20.s[3]                    #! PC = 0x413e8c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v12 %v30 %mm; cast [] %v12@int32[4] %v12;
(* mul	v14.4s, v31.4s, v20.s[3]                    #! PC = 0x413e90 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v14 %v31 %mm; cast [] %v14@int32[4] %v14;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x413e94 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x413e98 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v20.s[2]               #! PC = 0x413e9c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v20.s[2]               #! PC = 0x413ea0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v8.4s, v28.4s, v20.s[0]                     #! PC = 0x413ea4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v8 %v8 %mm;
(* mls	v10.4s, v29.4s, v20.s[0]                    #! PC = 0x413ea8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v12.4s, v30.4s, v20.s[0]                    #! PC = 0x413eac *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v14.4s, v31.4s, v20.s[0]                    #! PC = 0x413eb0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;

assert eqmod  %v8 (%v28o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [122]] && true;
assume eqmod  %v8 (%v28o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

(* CUT 126 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v8 (%v28o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v10 (%v29o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v12 (%v30o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v31o3b*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

ghost  %v0o3c@int32[4], %v1o3c@int32[4], %v2o3c@int32[4], %v3o3c@int32[4],
       %v4o3c@int32[4], %v5o3c@int32[4], %v6o3c@int32[4], %v7o3c@int32[4]:
       %v0o3c =  %v0 /\  %v1o3c =  %v1 /\ %v2o3c =  %v2 /\  %v3o3c =  %v3 /\
       %v4o3c =  %v4 /\  %v5o3c =  %v5 /\ %v6o3c =  %v6 /\  %v7o3c =  %v7
   &&  %v0o3c =  %v0 /\  %v1o3c =  %v1 /\ %v2o3c =  %v2 /\  %v3o3c =  %v3 /\
       %v4o3c =  %v4 /\  %v5o3c =  %v5 /\ %v6o3c =  %v6 /\  %v7o3c =  %v7;
ghost  %v8o3c@int32[4], %v9o3c@int32[4],%v10o3c@int32[4],%v11o3c@int32[4],
      %v12o3c@int32[4],%v13o3c@int32[4],%v14o3c@int32[4],%v15o3c@int32[4]:
       %v8o3c =  %v8 /\  %v9o3c =  %v9 /\%v10o3c = %v10 /\ %v11o3c = %v11 /\
      %v12o3c = %v12 /\ %v13o3c = %v13 /\%v14o3c = %v14 /\ %v15o3c = %v15
   &&  %v8o3c =  %v8 /\  %v9o3c =  %v9 /\%v10o3c = %v10 /\ %v11o3c = %v11 /\
      %v12o3c = %v12 /\ %v13o3c = %v13 /\%v14o3c = %v14 /\ %v15o3c = %v15;

(* sub	x19, x19, #0x1                              #! PC = 0x413eb4 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x413a34 <_intt_top_loop>            #! PC = 0x413eb8 *)
#cbnz	x19, 0x413a34 <_intt_top_loop>            #! 0x413eb8 = 0x413eb8;
(* dup	v29.4s, w20                                 #! PC = 0x413a34 *)
mov %v29 [w20,w20,w20,w20];
(* dup	v30.4s, w21                                 #! PC = 0x413a38 *)
mov %v30 [w21,w21,w21,w21];
(* dup	v31.4s, w22                                 #! PC = 0x413a3c *)
mov %v31 [w22,w22,w22,w22];
(* cmgt	v18.4s, v31.4s, v0.4s                      #! PC = 0x413a40 *)
subs %dc %lt %v0 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v1.4s                      #! PC = 0x413a44 *)
subs %dc %lt %v1 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v0.4s, v30.4s                      #! PC = 0x413a48 *)
subs %dc %lt %v30 %v0; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v1.4s, v30.4s                      #! PC = 0x413a4c *)
subs %dc %lt %v30 %v1; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413a50 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413a54 *)
sub %v17 %v17 %v19;
(* mla	v0.4s, v16.4s, v29.4s                       #! PC = 0x413a58 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v0 %v0 %mla;
(* cmgt	v18.4s, v31.4s, v2.4s                      #! PC = 0x413a5c *)
subs %dc %lt %v2 %v31; split %v18 %dc %lt 31;
(* mla	v1.4s, v17.4s, v29.4s                       #! PC = 0x413a60 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v1 %v1 %mla;
(* cmgt	v19.4s, v31.4s, v3.4s                      #! PC = 0x413a64 *)
subs %dc %lt %v3 %v31; split %v19 %dc %lt 31;
(* str	q0, [x0]                                    #! EA = L0xffffffff0630; PC = 0x413a68 *)
mov [L0xffffffff0630, L0xffffffff0634, L0xffffffff0638, L0xffffffff063c] %v0;
(* cmgt	v16.4s, v2.4s, v30.4s                      #! PC = 0x413a6c *)
subs %dc %lt %v30 %v2; split %v16 %dc %lt 31;
(* ldr	q0, [x0, #16]                               #! EA = L0xffffffff0640; Value = 0x00390984ffce2ab9; PC = 0x413a70 *)
mov %v0 [L0xffffffff0640, L0xffffffff0644, L0xffffffff0648, L0xffffffff064c];
(* str	q1, [x0, #64]                               #! EA = L0xffffffff0670; PC = 0x413a74 *)
mov [L0xffffffff0670, L0xffffffff0674, L0xffffffff0678, L0xffffffff067c] %v1;
(* cmgt	v17.4s, v3.4s, v30.4s                      #! PC = 0x413a78 *)
subs %dc %lt %v30 %v3; split %v17 %dc %lt 31;
(* ldr	q1, [x0, #80]                               #! EA = L0xffffffff0680; Value = 0x0002db09ffde1265; PC = 0x413a7c *)
mov %v1 [L0xffffffff0680, L0xffffffff0684, L0xffffffff0688, L0xffffffff068c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413a80 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413a84 *)
sub %v17 %v17 %v19;
(* mla	v2.4s, v16.4s, v29.4s                       #! PC = 0x413a88 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v2 %v2 %mla;
(* cmgt	v18.4s, v31.4s, v4.4s                      #! PC = 0x413a8c *)
subs %dc %lt %v4 %v31; split %v18 %dc %lt 31;
(* mla	v3.4s, v17.4s, v29.4s                       #! PC = 0x413a90 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v3 %v3 %mla;
(* cmgt	v19.4s, v31.4s, v5.4s                      #! PC = 0x413a94 *)
subs %dc %lt %v5 %v31; split %v19 %dc %lt 31;
(* str	q2, [x0, #128]                              #! EA = L0xffffffff06b0; PC = 0x413a98 *)
mov [L0xffffffff06b0, L0xffffffff06b4, L0xffffffff06b8, L0xffffffff06bc] %v2;
(* cmgt	v16.4s, v4.4s, v30.4s                      #! PC = 0x413a9c *)
subs %dc %lt %v30 %v4; split %v16 %dc %lt 31;
(* ldr	q2, [x0, #144]                              #! EA = L0xffffffff06c0; Value = 0xffcd507dffcf591f; PC = 0x413aa0 *)
mov %v2 [L0xffffffff06c0, L0xffffffff06c4, L0xffffffff06c8, L0xffffffff06cc];
(* str	q3, [x0, #192]                              #! EA = L0xffffffff06f0; PC = 0x413aa4 *)
mov [L0xffffffff06f0, L0xffffffff06f4, L0xffffffff06f8, L0xffffffff06fc] %v3;
(* cmgt	v17.4s, v5.4s, v30.4s                      #! PC = 0x413aa8 *)
subs %dc %lt %v30 %v5; split %v17 %dc %lt 31;
(* ldr	q3, [x0, #208]                              #! EA = L0xffffffff0700; Value = 0xffd4b233001b0d0e; PC = 0x413aac *)
mov %v3 [L0xffffffff0700, L0xffffffff0704, L0xffffffff0708, L0xffffffff070c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ab0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413ab4 *)
sub %v17 %v17 %v19;
(* mla	v4.4s, v16.4s, v29.4s                       #! PC = 0x413ab8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v4 %v4 %mla;
(* cmgt	v18.4s, v31.4s, v6.4s                      #! PC = 0x413abc *)
subs %dc %lt %v6 %v31; split %v18 %dc %lt 31;
(* mla	v5.4s, v17.4s, v29.4s                       #! PC = 0x413ac0 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v5 %v5 %mla;
(* cmgt	v19.4s, v31.4s, v7.4s                      #! PC = 0x413ac4 *)
subs %dc %lt %v7 %v31; split %v19 %dc %lt 31;
(* str	q4, [x0, #256]                              #! EA = L0xffffffff0730; PC = 0x413ac8 *)
mov [L0xffffffff0730, L0xffffffff0734, L0xffffffff0738, L0xffffffff073c] %v4;
(* cmgt	v16.4s, v6.4s, v30.4s                      #! PC = 0x413acc *)
subs %dc %lt %v30 %v6; split %v16 %dc %lt 31;
(* ldr	q4, [x0, #272]                              #! EA = L0xffffffff0740; Value = 0x0032c7f4000d3209; PC = 0x413ad0 *)
mov %v4 [L0xffffffff0740, L0xffffffff0744, L0xffffffff0748, L0xffffffff074c];
(* str	q5, [x0, #320]                              #! EA = L0xffffffff0770; PC = 0x413ad4 *)
mov [L0xffffffff0770, L0xffffffff0774, L0xffffffff0778, L0xffffffff077c] %v5;
(* cmgt	v17.4s, v7.4s, v30.4s                      #! PC = 0x413ad8 *)
subs %dc %lt %v30 %v7; split %v17 %dc %lt 31;
(* ldr	q5, [x0, #336]                              #! EA = L0xffffffff0780; Value = 0x003adf08fff9f2d8; PC = 0x413adc *)
mov %v5 [L0xffffffff0780, L0xffffffff0784, L0xffffffff0788, L0xffffffff078c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ae0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413ae4 *)
sub %v17 %v17 %v19;
(* mla	v6.4s, v16.4s, v29.4s                       #! PC = 0x413ae8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v6 %v6 %mla;
(* cmgt	v18.4s, v31.4s, v8.4s                      #! PC = 0x413aec *)
subs %dc %lt %v8 %v31; split %v18 %dc %lt 31;
(* mla	v7.4s, v17.4s, v29.4s                       #! PC = 0x413af0 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v7 %v7 %mla;
(* cmgt	v19.4s, v31.4s, v9.4s                      #! PC = 0x413af4 *)
subs %dc %lt %v9 %v31; split %v19 %dc %lt 31;
(* str	q6, [x0, #384]                              #! EA = L0xffffffff07b0; PC = 0x413af8 *)
mov [L0xffffffff07b0, L0xffffffff07b4, L0xffffffff07b8, L0xffffffff07bc] %v6;
(* cmgt	v16.4s, v8.4s, v30.4s                      #! PC = 0x413afc *)
subs %dc %lt %v30 %v8; split %v16 %dc %lt 31;
(* ldr	q6, [x0, #400]                              #! EA = L0xffffffff07c0; Value = 0xffd435d60027b2f0; PC = 0x413b00 *)
mov %v6 [L0xffffffff07c0, L0xffffffff07c4, L0xffffffff07c8, L0xffffffff07cc];
(* str	q7, [x0, #448]                              #! EA = L0xffffffff07f0; PC = 0x413b04 *)
mov [L0xffffffff07f0, L0xffffffff07f4, L0xffffffff07f8, L0xffffffff07fc] %v7;
(* cmgt	v17.4s, v9.4s, v30.4s                      #! PC = 0x413b08 *)
subs %dc %lt %v30 %v9; split %v17 %dc %lt 31;
(* ldr	q7, [x0, #464]                              #! EA = L0xffffffff0800; Value = 0xffdac83affe39d52; PC = 0x413b0c *)
mov %v7 [L0xffffffff0800, L0xffffffff0804, L0xffffffff0808, L0xffffffff080c];
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b10 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b14 *)
sub %v17 %v17 %v19;
(* mla	v8.4s, v16.4s, v29.4s                       #! PC = 0x413b18 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v8 %v8 %mla;
(* cmgt	v18.4s, v31.4s, v10.4s                     #! PC = 0x413b1c *)
subs %dc %lt %v10 %v31; split %v18 %dc %lt 31;
(* mla	v9.4s, v17.4s, v29.4s                       #! PC = 0x413b20 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v9 %v9 %mla;
(* cmgt	v19.4s, v31.4s, v11.4s                     #! PC = 0x413b24 *)
subs %dc %lt %v11 %v31; split %v19 %dc %lt 31;
(* str	q8, [x0, #512]                              #! EA = L0xffffffff0830; PC = 0x413b28 *)
mov [L0xffffffff0830, L0xffffffff0834, L0xffffffff0838, L0xffffffff083c] %v8;
(* cmgt	v16.4s, v10.4s, v30.4s                     #! PC = 0x413b2c *)
subs %dc %lt %v30 %v10; split %v16 %dc %lt 31;
(* str	q9, [x0, #576]                              #! EA = L0xffffffff0870; PC = 0x413b30 *)
mov [L0xffffffff0870, L0xffffffff0874, L0xffffffff0878, L0xffffffff087c] %v9;
(* cmgt	v17.4s, v11.4s, v30.4s                     #! PC = 0x413b34 *)
subs %dc %lt %v30 %v11; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b38 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b3c *)
sub %v17 %v17 %v19;
(* mla	v10.4s, v16.4s, v29.4s                      #! PC = 0x413b40 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v10 %v10 %mla;
(* cmgt	v18.4s, v31.4s, v12.4s                     #! PC = 0x413b44 *)
subs %dc %lt %v12 %v31; split %v18 %dc %lt 31;
(* mla	v11.4s, v17.4s, v29.4s                      #! PC = 0x413b48 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v11 %v11 %mla;
(* cmgt	v19.4s, v31.4s, v13.4s                     #! PC = 0x413b4c *)
subs %dc %lt %v13 %v31; split %v19 %dc %lt 31;
(* str	q10, [x0, #640]                             #! EA = L0xffffffff08b0; PC = 0x413b50 *)
mov [L0xffffffff08b0, L0xffffffff08b4, L0xffffffff08b8, L0xffffffff08bc] %v10;
(* cmgt	v16.4s, v12.4s, v30.4s                     #! PC = 0x413b54 *)
subs %dc %lt %v30 %v12; split %v16 %dc %lt 31;
(* str	q11, [x0, #704]                             #! EA = L0xffffffff08f0; PC = 0x413b58 *)
mov [L0xffffffff08f0, L0xffffffff08f4, L0xffffffff08f8, L0xffffffff08fc] %v11;
(* cmgt	v17.4s, v13.4s, v30.4s                     #! PC = 0x413b5c *)
subs %dc %lt %v30 %v13; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b60 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b64 *)
sub %v17 %v17 %v19;
(* mla	v12.4s, v16.4s, v29.4s                      #! PC = 0x413b68 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v12 %v12 %mla;
(* cmgt	v18.4s, v31.4s, v14.4s                     #! PC = 0x413b6c *)
subs %dc %lt %v14 %v31; split %v18 %dc %lt 31;
(* mla	v13.4s, v17.4s, v29.4s                      #! PC = 0x413b70 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v13 %v13 %mla;
(* cmgt	v19.4s, v31.4s, v15.4s                     #! PC = 0x413b74 *)
subs %dc %lt %v15 %v31; split %v19 %dc %lt 31;
(* str	q12, [x0, #768]                             #! EA = L0xffffffff0930; PC = 0x413b78 *)
mov [L0xffffffff0930, L0xffffffff0934, L0xffffffff0938, L0xffffffff093c] %v12;
(* cmgt	v16.4s, v14.4s, v30.4s                     #! PC = 0x413b7c *)
subs %dc %lt %v30 %v14; split %v16 %dc %lt 31;
(* str	q13, [x0, #832]                             #! EA = L0xffffffff0970; PC = 0x413b80 *)
mov [L0xffffffff0970, L0xffffffff0974, L0xffffffff0978, L0xffffffff097c] %v13;
(* cmgt	v17.4s, v15.4s, v30.4s                     #! PC = 0x413b84 *)
subs %dc %lt %v30 %v15; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413b88 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413b8c *)
sub %v17 %v17 %v19;
(* mla	v14.4s, v16.4s, v29.4s                      #! PC = 0x413b90 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v14 %v14 %mla;
(* mla	v15.4s, v17.4s, v29.4s                      #! PC = 0x413b94 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v15 %v15 %mla;
(* str	q14, [x0, #896]                             #! EA = L0xffffffff09b0; PC = 0x413b98 *)
mov [L0xffffffff09b0, L0xffffffff09b4, L0xffffffff09b8, L0xffffffff09bc] %v14;
(* str	q15, [x0, #960]                             #! EA = L0xffffffff09f0; PC = 0x413b9c *)
mov [L0xffffffff09f0, L0xffffffff09f4, L0xffffffff09f8, L0xffffffff09fc] %v15;

assert true &&
       eqsmod [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]
              %v0o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]
              %v1o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]
              %v2o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]
              %v3o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]
              %v4o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]
              %v5o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]
              %v6o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]
              %v7o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]
              %v8o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]
              %v9o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]
              %v10o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]
              %v11o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]
              %v12o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]
              %v13o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]
              %v14o3c [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]
              %v15o3c [Q, Q, Q, Q]
       prove with [cuts [89]];
assume eqmod [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]
             %v0o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]
             %v1o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]
             %v2o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]
             %v3o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]
             %v4o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]
             %v5o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]
             %v6o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]
             %v7o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]
             %v8o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]
             %v9o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]
             %v10o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]
             %v11o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]
             %v12o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]
             %v13o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]
             %v14o3c [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]
             %v15o3c [Q, Q, Q, Q] && true;
(* CUT 127 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod [L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c]
          %v0o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c]
          %v1o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc]
          %v2o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc]
          %v3o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c]
          %v4o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c]
          %v5o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc]
          %v6o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc]
          %v7o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c]
          %v8o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c]
          %v9o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc]
          %v10o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc]
          %v11o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c]
          %v12o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c]
          %v13o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc]
          %v14o3c [Q, Q, Q, Q] /\
    eqmod [L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc]
          %v15o3c [Q, Q, Q, Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0630,L0xffffffff0630,L0xffffffff0630,L0xffffffff0630] /\
    [L0xffffffff0630,L0xffffffff0630,L0xffffffff0630,L0xffffffff0630]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0670,L0xffffffff0670,L0xffffffff0670,L0xffffffff0670] /\
    [L0xffffffff0670,L0xffffffff0670,L0xffffffff0670,L0xffffffff0670]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0] /\
    [L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0] /\
    [L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0730,L0xffffffff0730,L0xffffffff0730,L0xffffffff0730] /\
    [L0xffffffff0730,L0xffffffff0730,L0xffffffff0730,L0xffffffff0730]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0770,L0xffffffff0770,L0xffffffff0770,L0xffffffff0770] /\
    [L0xffffffff0770,L0xffffffff0770,L0xffffffff0770,L0xffffffff0770]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0] /\
    [L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0] /\
    [L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0830,L0xffffffff0830,L0xffffffff0830,L0xffffffff0830] /\
    [L0xffffffff0830,L0xffffffff0830,L0xffffffff0830,L0xffffffff0830]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0870,L0xffffffff0870,L0xffffffff0870,L0xffffffff0870] /\
    [L0xffffffff0870,L0xffffffff0870,L0xffffffff0870,L0xffffffff0870]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0] /\
    [L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0] /\
    [L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0930,L0xffffffff0930,L0xffffffff0930,L0xffffffff0930] /\
    [L0xffffffff0930,L0xffffffff0930,L0xffffffff0930,L0xffffffff0930]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0970,L0xffffffff0970,L0xffffffff0970,L0xffffffff0970] /\
    [L0xffffffff0970,L0xffffffff0970,L0xffffffff0970,L0xffffffff0970]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0] /\
    [L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0] /\
    [L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0]<s[Q2,Q2,Q2,Q2]
    prove with [cuts [89, 123, 124, 125, 126]];

ghost  %v0o3d@int32[4], %v2o3d@int32[4], %v4o3d@int32[4], %v6o3d@int32[4],
       %v8o3d@int32[4],%v10o3d@int32[4],%v12o3d@int32[4],%v14o3d@int32[4]:
       %v0o3d =  %v0 /\  %v2o3d =  %v2 /\ %v4o3d =  %v4 /\  %v6o3d =  %v6 /\
       %v8o3d =  %v8 /\ %v10o3d = %v10 /\%v12o3d = %v12 /\ %v14o3d = %v14
   &&  %v0o3d =  %v0 /\  %v2o3d =  %v2 /\ %v4o3d =  %v4 /\  %v6o3d =  %v6 /\
       %v8o3d =  %v8 /\ %v10o3d = %v10 /\%v12o3d = %v12 /\ %v14o3d = %v14;

(* add	x0, x0, #0x10                               #! PC = 0x413ba0 *)
adds dc x0 x0 (0x10)@uint64;
(* sub	v16.4s, v0.4s, v1.4s                        #! PC = 0x413ba4 *)
sub %v16 %v0 %v1;
(* ldr	q8, [x0, #512]                              #! EA = L0xffffffff0840; Value = 0xffdd657affeaa9ef; PC = 0x413ba8 *)
mov %v8 [L0xffffffff0840, L0xffffffff0844, L0xffffffff0848, L0xffffffff084c];
(* sub	v17.4s, v2.4s, v3.4s                        #! PC = 0x413bac *)
sub %v17 %v2 %v3;
(* ldr	q9, [x0, #576]                              #! EA = L0xffffffff0880; Value = 0xffed89bbffe0757d; PC = 0x413bb0 *)
mov %v9 [L0xffffffff0880, L0xffffffff0884, L0xffffffff0888, L0xffffffff088c];
(* sub	v18.4s, v4.4s, v5.4s                        #! PC = 0x413bb4 *)
sub %v18 %v4 %v5;
(* ldr	q10, [x0, #640]                             #! EA = L0xffffffff08c0; Value = 0x0016256bfffebcb8; PC = 0x413bb8 *)
mov %v10 [L0xffffffff08c0, L0xffffffff08c4, L0xffffffff08c8, L0xffffffff08cc];
(* sub	v19.4s, v6.4s, v7.4s                        #! PC = 0x413bbc *)
sub %v19 %v6 %v7;
(* ldr	q11, [x0, #704]                             #! EA = L0xffffffff0900; Value = 0xffe3d0b70025a7ce; PC = 0x413bc0 *)
mov %v11 [L0xffffffff0900, L0xffffffff0904, L0xffffffff0908, L0xffffffff090c];
(* add	v0.4s, v0.4s, v1.4s                         #! PC = 0x413bc4 *)
add %v0 %v0 %v1;
(* ldr	q12, [x0, #768]                             #! EA = L0xffffffff0940; Value = 0x0018de3c00339b43; PC = 0x413bc8 *)
mov %v12 [L0xffffffff0940, L0xffffffff0944, L0xffffffff0948, L0xffffffff094c];
(* add	v2.4s, v2.4s, v3.4s                         #! PC = 0x413bcc *)
add %v2 %v2 %v3;
(* ldr	q13, [x0, #832]                             #! EA = L0xffffffff0980; Value = 0xffc3bb98ffde48ba; PC = 0x413bd0 *)
mov %v13 [L0xffffffff0980, L0xffffffff0984, L0xffffffff0988, L0xffffffff098c];
(* add	v4.4s, v4.4s, v5.4s                         #! PC = 0x413bd4 *)
add %v4 %v4 %v5;
(* ldr	q14, [x0, #896]                             #! EA = L0xffffffff09c0; Value = 0xffdca1ea00374878; PC = 0x413bd8 *)
mov %v14 [L0xffffffff09c0, L0xffffffff09c4, L0xffffffff09c8, L0xffffffff09cc];
(* add	v6.4s, v6.4s, v7.4s                         #! PC = 0x413bdc *)
add %v6 %v6 %v7;
(* ldr	q15, [x0, #960]                             #! EA = L0xffffffff0a00; Value = 0x000d1b77ffe7eecd; PC = 0x413be0 *)
mov %v15 [L0xffffffff0a00, L0xffffffff0a04, L0xffffffff0a08, L0xffffffff0a0c];

assert [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
        %v0 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
       %v16 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
        %v2 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
       %v17 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
        %v4 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
       %v18 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
        %v6 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
       %v19 < [2*Q,2*Q,2*Q,2*Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
        %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
       %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
        %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
        %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
       %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
        %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
       %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q];
(* CUT 128 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o3d +  %v1 /\ %v16 =  %v0o3d -  %v1 /\
     %v2 =  %v2o3d +  %v3 /\ %v17 =  %v2o3d -  %v3 /\
     %v4 =  %v4o3d +  %v5 /\ %v18 =  %v4o3d -  %v5 /\
     %v6 =  %v6o3d +  %v7 /\ %v19 =  %v6o3d -  %v7 /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v0 /\
     %v0 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v16 /\
    %v16 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v2 /\
     %v2 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v17 /\
    %v17 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v4 /\
     %v4 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v18 /\
    %v18 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v6 /\
     %v6 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v19 /\
    %v19 < [2*Q,2*Q,2*Q,2*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v0 /\
     %v0 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v16 /\
    %v16 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v2 /\
     %v2 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v17 /\
    %v17 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v4 /\
     %v4 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v18 /\
    %v18 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v6 /\
     %v6 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v19 /\
    %v19 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q]
    prove with [cuts [88]];

ghost  %v8o3e@int32[4],%v10o3e@int32[4],%v12o3e@int32[4],%v14o3e@int32[4],
      %v16o3e@int32[4],%v17o3e@int32[4],%v18o3e@int32[4],%v19o3e@int32[4]:
       %v8o3e =  %v8 /\ %v10o3e = %v10 /\%v12o3e = %v12 /\ %v14o3e = %v14 /\
      %v16o3e = %v16 /\ %v17o3e = %v17 /\%v18o3e = %v18 /\ %v19o3e = %v19
   &&  %v8o3e =  %v8 /\ %v10o3e = %v10 /\%v12o3e = %v12 /\ %v14o3e = %v14 /\
      %v16o3e = %v16 /\ %v17o3e = %v17 /\%v18o3e = %v18 /\ %v19o3e = %v19;

(* mul	v1.4s, v16.4s, v24.s[1]                     #! PC = 0x413be4 *)
mov [_, m, _, _] %v24; mov %mm [m, m, m, m];
mull %dc %v1 %v16 %mm; cast [] %v1@int32[4] %v1;
(* sub	v28.4s, v8.4s, v9.4s                        #! PC = 0x413be8 *)
sub %v28 %v8 %v9;
(* mul	v3.4s, v17.4s, v24.s[3]                     #! PC = 0x413bec *)
mov [_, _, _, m] %v24; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v10.4s, v11.4s                      #! PC = 0x413bf0 *)
sub %v29 %v10 %v11;
(* mul	v5.4s, v18.4s, v25.s[1]                     #! PC = 0x413bf4 *)
mov [_, m, _, _] %v25; mov %mm [m, m, m, m];
mull %dc %v5 %v18 %mm; cast [] %v5@int32[4] %v5;
(* sub	v30.4s, v12.4s, v13.4s                      #! PC = 0x413bf8 *)
sub %v30 %v12 %v13;
(* mul	v7.4s, v19.4s, v25.s[3]                     #! PC = 0x413bfc *)
mov [_, _, _, m] %v25; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v14.4s, v15.4s                      #! PC = 0x413c00 *)
sub %v31 %v14 %v15;
(* sqrdmulh	v16.4s, v16.4s, v24.s[0]               #! PC = 0x413c04 *)
mov [m, _, _, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v9.4s                         #! PC = 0x413c08 *)
add %v8 %v8 %v9;
(* sqrdmulh	v17.4s, v17.4s, v24.s[2]               #! PC = 0x413c0c *)
mov [_, _, m, _] %v24; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v10.4s, v10.4s, v11.4s                      #! PC = 0x413c10 *)
add %v10 %v10 %v11;
(* sqrdmulh	v18.4s, v18.4s, v25.s[0]               #! PC = 0x413c14 *)
mov [m, _, _, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v13.4s                      #! PC = 0x413c18 *)
add %v12 %v12 %v13;
(* sqrdmulh	v19.4s, v19.4s, v25.s[2]               #! PC = 0x413c1c *)
mov [_, _, m, _] %v25; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v14.4s, v14.4s, v15.4s                      #! PC = 0x413c20 *)
add %v14 %v14 %v15;
(* mls	v1.4s, v16.4s, v20.s[0]                     #! PC = 0x413c24 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x413c28 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v18.4s, v20.s[0]                     #! PC = 0x413c2c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413c30 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 (%v16o3e*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o3e*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o3e*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o3e*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [88]] && true;
assume eqmod  %v1 (%v16o3e*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o3e*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v18o3e*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o3e*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
        %v8 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
       %v28 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
       %v10 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
       %v29 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
       %v12 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
       %v30 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
       %v14 < [2*Q,2*Q,2*Q,2*Q] /\
       [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
       %v31 < [2*Q,2*Q,2*Q,2*Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
        %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
       %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
       %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
       %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
       %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
       %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
       %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
       %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 129 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o3e +  %v9 /\ %v28 =  %v8o3e -  %v9 /\
    %v10 = %v10o3e + %v11 /\ %v29 = %v10o3e - %v11 /\
    %v12 = %v12o3e + %v13 /\ %v30 = %v12o3e - %v13 /\
    %v14 = %v14o3e + %v15 /\ %v31 = %v14o3e - %v15 /\
    eqmod  %v1 (%v16o3e*[%v24[1],%v24[1],%v24[1],%v24[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o3e*[%v24[3],%v24[3],%v24[3],%v24[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v18o3e*[%v25[1],%v25[1],%v25[1],%v25[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o3e*[%v25[3],%v25[3],%v25[3],%v25[3]]) [Q,Q,Q,Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] <  %v8 /\
     %v8 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v28 /\
    %v28 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v10 /\
    %v10 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v29 /\
    %v29 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v12 /\
    %v12 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v30 /\
    %v30 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v14 /\
    %v14 < [2*Q,2*Q,2*Q,2*Q] /\
    [2*NQ,2*NQ,2*NQ,2*NQ] < %v31 /\
    %v31 < [2*Q,2*Q,2*Q,2*Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s  %v8 /\
     %v8 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v28 /\
    %v28 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v10 /\
    %v10 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v29 /\
    %v29 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v12 /\
    %v12 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v30 /\
    %v30 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v14 /\
    %v14 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [2@32*NQ,2@32*NQ,2@32*NQ,2@32*NQ] <s %v31 /\
    %v31 <s [2@32*Q,2@32*Q,2@32*Q,2@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [88]];

ghost  %v0o3e@int32[4], %v1o3e@int32[4], %v4o3e@int32[4], %v5o3e@int32[4],
      %v28o3e@int32[4],%v29o3e@int32[4],%v30o3e@int32[4],%v31o3e@int32[4]:
       %v0o3e =  %v0 /\  %v1o3e =  %v1 /\ %v4o3e =  %v4 /\  %v5o3e =  %v5 /\
      %v28o3e = %v28 /\ %v29o3e = %v29 /\%v30o3e = %v30 /\ %v31o3e = %v31
   &&  %v0o3e =  %v0 /\  %v1o3e =  %v1 /\ %v4o3e =  %v4 /\  %v5o3e =  %v5 /\
      %v28o3e = %v28 /\ %v29o3e = %v29 /\%v30o3e = %v30 /\ %v31o3e = %v31;

(* mul	v9.4s, v28.4s, v26.s[1]                     #! PC = 0x413c34 *)
mov [_, m, _, _] %v26; mov %mm [m, m, m, m];
mull %dc %v9 %v28 %mm; cast [] %v9@int32[4] %v9;
(* sub	v16.4s, v0.4s, v2.4s                        #! PC = 0x413c38 *)
sub %v16 %v0 %v2;
(* mul	v11.4s, v29.4s, v26.s[3]                    #! PC = 0x413c3c *)
mov [_, _, _, m] %v26; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v3.4s                        #! PC = 0x413c40 *)
sub %v17 %v1 %v3;
(* mul	v13.4s, v30.4s, v27.s[1]                    #! PC = 0x413c44 *)
mov [_, m, _, _] %v27; mov %mm [m, m, m, m];
mull %dc %v13 %v30 %mm; cast [] %v13@int32[4] %v13;
(* sub	v18.4s, v4.4s, v6.4s                        #! PC = 0x413c48 *)
sub %v18 %v4 %v6;
(* mul	v15.4s, v31.4s, v27.s[3]                    #! PC = 0x413c4c *)
mov [_, _, _, m] %v27; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v5.4s, v7.4s                        #! PC = 0x413c50 *)
sub %v19 %v5 %v7;
(* sqrdmulh	v28.4s, v28.4s, v26.s[0]               #! PC = 0x413c54 *)
mov [m, _, _, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v2.4s                         #! PC = 0x413c58 *)
add %v0 %v0 %v2;
(* sqrdmulh	v29.4s, v29.4s, v26.s[2]               #! PC = 0x413c5c *)
mov [_, _, m, _] %v26; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v3.4s                         #! PC = 0x413c60 *)
add %v1 %v1 %v3;
(* sqrdmulh	v30.4s, v30.4s, v27.s[0]               #! PC = 0x413c64 *)
mov [m, _, _, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v4.4s, v4.4s, v6.4s                         #! PC = 0x413c68 *)
add %v4 %v4 %v6;
(* sqrdmulh	v31.4s, v31.4s, v27.s[2]               #! PC = 0x413c6c *)
mov [_, _, m, _] %v27; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v5.4s, v5.4s, v7.4s                         #! PC = 0x413c70 *)
add %v5 %v5 %v7;
(* mls	v9.4s, v28.4s, v20.s[0]                     #! PC = 0x413c74 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x413c78 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v30.4s, v20.s[0]                    #! PC = 0x413c7c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413c80 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 (%v28o3e*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o3e*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o3e*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o3e*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [128]] && true;
assume eqmod  %v9 (%v28o3e*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o3e*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v30o3e*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o3e*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
        %v0 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
       %v16 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
        %v1 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
       %v17 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
        %v4 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
       %v18 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
        %v5 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
       %v19 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
        %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
       %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
        %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
       %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
        %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
       %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
        %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
       %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 130 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o3e +  %v2 /\ %v16 =  %v0o3e -  %v2 /\
     %v1 =  %v1o3e +  %v3 /\ %v17 =  %v1o3e -  %v3 /\
     %v4 =  %v4o3e +  %v6 /\ %v18 =  %v4o3e -  %v6 /\
     %v5 =  %v5o3e +  %v7 /\ %v19 =  %v5o3e -  %v7 /\
    eqmod  %v9 (%v28o3e*[%v26[1],%v26[1],%v26[1],%v26[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o3e*[%v26[3],%v26[3],%v26[3],%v26[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v30o3e*[%v27[1],%v27[1],%v27[1],%v27[1]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o3e*[%v27[3],%v27[3],%v27[3],%v27[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v0 /\
     %v0 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v16 /\
    %v16 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v1 /\
     %v1 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v17 /\
    %v17 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v4 /\
     %v4 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v18 /\
    %v18 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v5 /\
     %v5 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v19 /\
    %v19 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v0 /\
     %v0 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v16 /\
    %v16 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v1 /\
     %v1 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v17 /\
    %v17 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v4 /\
     %v4 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v18 /\
    %v18 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v5 /\
     %v5 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v19 /\
    %v19 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [128]];

ghost  %v8o3f@int32[4], %v9o3f@int32[4],%v12o3f@int32[4],%v13o3f@int32[4],
      %v16o3f@int32[4],%v17o3f@int32[4],%v18o3f@int32[4],%v19o3f@int32[4]:
       %v8o3f =  %v8 /\  %v9o3f =  %v9 /\%v12o3f = %v12 /\ %v13o3f = %v13 /\
      %v16o3f = %v16 /\ %v17o3f = %v17 /\%v18o3f = %v18 /\ %v19o3f = %v19
   &&  %v8o3f =  %v8 /\  %v9o3f =  %v9 /\%v12o3f = %v12 /\ %v13o3f = %v13 /\
      %v16o3f = %v16 /\ %v17o3f = %v17 /\%v18o3f = %v18 /\ %v19o3f = %v19;

(* mul	v2.4s, v16.4s, v22.s[1]                     #! PC = 0x413c84 *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v2 %v16 %mm; cast [] %v2@int32[4] %v2;
(* sub	v28.4s, v8.4s, v10.4s                       #! PC = 0x413c88 *)
sub %v28 %v8 %v10;
(* mul	v3.4s, v17.4s, v22.s[1]                     #! PC = 0x413c8c *)
mov [_, m, _, _] %v22; mov %mm [m, m, m, m];
mull %dc %v3 %v17 %mm; cast [] %v3@int32[4] %v3;
(* sub	v29.4s, v9.4s, v11.4s                       #! PC = 0x413c90 *)
sub %v29 %v9 %v11;
(* mul	v6.4s, v18.4s, v22.s[3]                     #! PC = 0x413c94 *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v12.4s, v14.4s                      #! PC = 0x413c98 *)
sub %v30 %v12 %v14;
(* mul	v7.4s, v19.4s, v22.s[3]                     #! PC = 0x413c9c *)
mov [_, _, _, m] %v22; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v13.4s, v15.4s                      #! PC = 0x413ca0 *)
sub %v31 %v13 %v15;
(* sqrdmulh	v16.4s, v16.4s, v22.s[0]               #! PC = 0x413ca4 *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v10.4s                        #! PC = 0x413ca8 *)
add %v8 %v8 %v10;
(* sqrdmulh	v17.4s, v17.4s, v22.s[0]               #! PC = 0x413cac *)
mov [m, _, _, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v11.4s                        #! PC = 0x413cb0 *)
add %v9 %v9 %v11;
(* sqrdmulh	v18.4s, v18.4s, v22.s[2]               #! PC = 0x413cb4 *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v12.4s, v12.4s, v14.4s                      #! PC = 0x413cb8 *)
add %v12 %v12 %v14;
(* sqrdmulh	v19.4s, v19.4s, v22.s[2]               #! PC = 0x413cbc *)
mov [_, _, m, _] %v22; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v13.4s, v13.4s, v15.4s                      #! PC = 0x413cc0 *)
add %v13 %v13 %v15;
(* mls	v2.4s, v16.4s, v20.s[0]                     #! PC = 0x413cc4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v3.4s, v17.4s, v20.s[0]                     #! PC = 0x413cc8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x413ccc *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413cd0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v2 (%v16o3f*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o3f*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o3f*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o3f*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [129]] && true;
assume eqmod  %v2 (%v16o3f*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v3 (%v17o3f*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o3f*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o3f*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
        %v8 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
       %v28 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
        %v9 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
       %v29 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
       %v12 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
       %v30 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
       %v13 < [4*Q,4*Q,4*Q,4*Q] /\
       [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
       %v31 < [4*Q,4*Q,4*Q,4*Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
        %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
       %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
        %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
       %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
       %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
       %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
       %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
       %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 131 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o3f + %v10 /\ %v28 =  %v8o3f - %v10 /\
     %v9 =  %v9o3f + %v11 /\ %v29 =  %v9o3f - %v11 /\
    %v12 = %v12o3f + %v14 /\ %v30 = %v12o3f - %v14 /\
    %v13 = %v13o3f + %v15 /\ %v31 = %v13o3f - %v15 /\
    eqmod  %v2 (%v16o3f*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v3 (%v17o3f*[%v22[1],%v22[1],%v22[1],%v22[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o3f*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o3f*[%v22[3],%v22[3],%v22[3],%v22[3]]) [Q,Q,Q,Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v8 /\
     %v8 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v28 /\
    %v28 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] <  %v9 /\
     %v9 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v29 /\
    %v29 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v12 /\
    %v12 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v30 /\
    %v30 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v13 /\
    %v13 < [4*Q,4*Q,4*Q,4*Q] /\
    [4*NQ,4*NQ,4*NQ,4*NQ] < %v31 /\
    %v31 < [4*Q,4*Q,4*Q,4*Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v8 /\
     %v8 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v28 /\
    %v28 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s  %v9 /\
     %v9 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v29 /\
    %v29 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v12 /\
    %v12 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v30 /\
    %v30 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v13 /\
    %v13 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [4@32*NQ,4@32*NQ,4@32*NQ,4@32*NQ] <s %v31 /\
    %v31 <s [4@32*Q,4@32*Q,4@32*Q,4@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [129]];

ghost  %v0o3f@int32[4], %v1o3f@int32[4], %v2o3f@int32[4], %v3o3f@int32[4],
      %v28o3f@int32[4],%v29o3f@int32[4],%v30o3f@int32[4],%v31o3f@int32[4]:
       %v0o3f =  %v0 /\  %v1o3f =  %v1 /\ %v2o3f =  %v2 /\  %v3o3f =  %v3 /\
      %v28o3f = %v28 /\ %v29o3f = %v29 /\%v30o3f = %v30 /\ %v31o3f = %v31
   &&  %v0o3f =  %v0 /\  %v1o3f =  %v1 /\ %v2o3f =  %v2 /\  %v3o3f =  %v3 /\
      %v28o3f = %v28 /\ %v29o3f = %v29 /\%v30o3f = %v30 /\ %v31o3f = %v31;

(* mul	v10.4s, v28.4s, v23.s[1]                    #! PC = 0x413cd4 *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v10 %v28 %mm; cast [] %v10@int32[4] %v10;
(* sub	v16.4s, v0.4s, v4.4s                        #! PC = 0x413cd8 *)
sub %v16 %v0 %v4;
(* mul	v11.4s, v29.4s, v23.s[1]                    #! PC = 0x413cdc *)
mov [_, m, _, _] %v23; mov %mm [m, m, m, m];
mull %dc %v11 %v29 %mm; cast [] %v11@int32[4] %v11;
(* sub	v17.4s, v1.4s, v5.4s                        #! PC = 0x413ce0 *)
sub %v17 %v1 %v5;
(* mul	v14.4s, v30.4s, v23.s[3]                    #! PC = 0x413ce4 *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* sub	v18.4s, v2.4s, v6.4s                        #! PC = 0x413ce8 *)
sub %v18 %v2 %v6;
(* mul	v15.4s, v31.4s, v23.s[3]                    #! PC = 0x413cec *)
mov [_, _, _, m] %v23; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sub	v19.4s, v3.4s, v7.4s                        #! PC = 0x413cf0 *)
sub %v19 %v3 %v7;
(* sqrdmulh	v28.4s, v28.4s, v23.s[0]               #! PC = 0x413cf4 *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* add	v0.4s, v0.4s, v4.4s                         #! PC = 0x413cf8 *)
add %v0 %v0 %v4;
(* sqrdmulh	v29.4s, v29.4s, v23.s[0]               #! PC = 0x413cfc *)
mov [m, _, _, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* add	v1.4s, v1.4s, v5.4s                         #! PC = 0x413d00 *)
add %v1 %v1 %v5;
(* sqrdmulh	v30.4s, v30.4s, v23.s[2]               #! PC = 0x413d04 *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* add	v2.4s, v2.4s, v6.4s                         #! PC = 0x413d08 *)
add %v2 %v2 %v6;
(* sqrdmulh	v31.4s, v31.4s, v23.s[2]               #! PC = 0x413d0c *)
mov [_, _, m, _] %v23; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* add	v3.4s, v3.4s, v7.4s                         #! PC = 0x413d10 *)
add %v3 %v3 %v7;
(* mls	v10.4s, v28.4s, v20.s[0]                    #! PC = 0x413d14 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v11.4s, v29.4s, v20.s[0]                    #! PC = 0x413d18 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413d1c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413d20 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v10 (%v28o3f*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o3f*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o3f*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o3f*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [130]] && true;
assume eqmod %v10 (%v28o3f*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v29o3f*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o3f*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o3f*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
        %v0 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
       %v16 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
        %v1 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
       %v17 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
        %v2 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
       %v18 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
        %v3 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
       %v19 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
        %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
       %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
        %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
       %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
        %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
       %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
        %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
       %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 132 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v0 =  %v0o3f +  %v4 /\ %v16 =  %v0o3f -  %v4 /\
     %v1 =  %v1o3f +  %v5 /\ %v17 =  %v1o3f -  %v5 /\
     %v2 =  %v2o3f +  %v6 /\ %v18 =  %v2o3f -  %v6 /\
     %v3 =  %v3o3f +  %v7 /\ %v19 =  %v3o3f -  %v7 /\
    eqmod %v10 (%v28o3f*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v29o3f*[%v23[1],%v23[1],%v23[1],%v23[1]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o3f*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o3f*[%v23[3],%v23[3],%v23[3],%v23[3]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v0 /\
     %v0 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v16 /\
    %v16 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v1 /\
     %v1 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v17 /\
    %v17 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v2 /\
     %v2 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v18 /\
    %v18 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v3 /\
     %v3 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v19 /\
    %v19 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v0 /\
     %v0 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v16 /\
    %v16 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v1 /\
     %v1 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v17 /\
    %v17 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v2 /\
     %v2 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v18 /\
    %v18 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v3 /\
     %v3 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v19 /\
    %v19 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q]
    prove with [cuts [130]];

ghost  %v8o40@int32[4], %v9o40@int32[4],%v10o40@int32[4],%v11o40@int32[4],
      %v16o40@int32[4],%v17o40@int32[4],%v18o40@int32[4],%v19o40@int32[4]:
       %v8o40 =  %v8 /\  %v9o40 =  %v9 /\%v10o40 = %v10 /\ %v11o40 = %v11 /\
      %v16o40 = %v16 /\ %v17o40 = %v17 /\%v18o40 = %v18 /\ %v19o40 = %v19
   &&  %v8o40 =  %v8 /\  %v9o40 =  %v9 /\%v10o40 = %v10 /\ %v11o40 = %v11 /\
      %v16o40 = %v16 /\ %v17o40 = %v17 /\%v18o40 = %v18 /\ %v19o40 = %v19;

(* mul	v4.4s, v16.4s, v21.s[1]                     #! PC = 0x413d24 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v4 %v16 %mm; cast [] %v4@int32[4] %v4;
(* sub	v28.4s, v8.4s, v12.4s                       #! PC = 0x413d28 *)
sub %v28 %v8 %v12;
(* mul	v5.4s, v17.4s, v21.s[1]                     #! PC = 0x413d2c *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v5 %v17 %mm; cast [] %v5@int32[4] %v5;
(* sub	v29.4s, v9.4s, v13.4s                       #! PC = 0x413d30 *)
sub %v29 %v9 %v13;
(* mul	v6.4s, v18.4s, v21.s[1]                     #! PC = 0x413d34 *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v6 %v18 %mm; cast [] %v6@int32[4] %v6;
(* sub	v30.4s, v10.4s, v14.4s                      #! PC = 0x413d38 *)
sub %v30 %v10 %v14;
(* mul	v7.4s, v19.4s, v21.s[1]                     #! PC = 0x413d3c *)
mov [_, m, _, _] %v21; mov %mm [m, m, m, m];
mull %dc %v7 %v19 %mm; cast [] %v7@int32[4] %v7;
(* sub	v31.4s, v11.4s, v15.4s                      #! PC = 0x413d40 *)
sub %v31 %v11 %v15;
(* sqrdmulh	v16.4s, v16.4s, v21.s[0]               #! PC = 0x413d44 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* add	v8.4s, v8.4s, v12.4s                        #! PC = 0x413d48 *)
add %v8 %v8 %v12;
(* sqrdmulh	v17.4s, v17.4s, v21.s[0]               #! PC = 0x413d4c *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* add	v9.4s, v9.4s, v13.4s                        #! PC = 0x413d50 *)
add %v9 %v9 %v13;
(* sqrdmulh	v18.4s, v18.4s, v21.s[0]               #! PC = 0x413d54 *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* add	v10.4s, v10.4s, v14.4s                      #! PC = 0x413d58 *)
add %v10 %v10 %v14;
(* sqrdmulh	v19.4s, v19.4s, v21.s[0]               #! PC = 0x413d5c *)
mov [m, _, _, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* add	v11.4s, v11.4s, v15.4s                      #! PC = 0x413d60 *)
add %v11 %v11 %v15;
(* mls	v4.4s, v16.4s, v20.s[0]                     #! PC = 0x413d64 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v5.4s, v17.4s, v20.s[0]                     #! PC = 0x413d68 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v6.4s, v18.4s, v20.s[0]                     #! PC = 0x413d6c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;
(* mls	v7.4s, v19.4s, v20.s[0]                     #! PC = 0x413d70 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v4 (%v16o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [131]] && true;
assume eqmod  %v4 (%v16o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v5 (%v17o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v18o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       eqmod  %v7 (%v19o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
        %v8 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
       %v28 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
        %v9 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
       %v29 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
       %v10 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
       %v30 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
       %v11 < [8*Q,8*Q,8*Q,8*Q] /\
       [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
       %v31 < [8*Q,8*Q,8*Q,8*Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
        %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
       %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
        %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
       %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
       %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
       %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
       %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
       %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 133 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
     %v8 =  %v8o40 + %v12 /\ %v28 =  %v8o40 - %v12 /\
     %v9 =  %v9o40 + %v13 /\ %v29 =  %v9o40 - %v13 /\
    %v10 = %v10o40 + %v14 /\ %v30 = %v10o40 - %v14 /\
    %v11 = %v11o40 + %v15 /\ %v31 = %v11o40 - %v15 /\
    eqmod  %v4 (%v16o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v5 (%v17o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v18o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    eqmod  %v7 (%v19o40*[%v21[1],%v21[1],%v21[1],%v21[1]]) [Q,Q,Q,Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v8 /\
     %v8 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v28 /\
    %v28 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] <  %v9 /\
     %v9 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v29 /\
    %v29 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v10 /\
    %v10 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v30 /\
    %v30 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v11 /\
    %v11 < [8*Q,8*Q,8*Q,8*Q] /\
    [8*NQ,8*NQ,8*NQ,8*NQ] < %v31 /\
    %v31 < [8*Q,8*Q,8*Q,8*Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v8 /\
     %v8 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v28 /\
    %v28 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s  %v9 /\
     %v9 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v29 /\
    %v29 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v10 /\
    %v10 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v30 /\
    %v30 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v11 /\
    %v11 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [8@32*NQ,8@32*NQ,8@32*NQ,8@32*NQ] <s %v31 /\
    %v31 <s [8@32*Q,8@32*Q,8@32*Q,8@32*Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q]
    prove with [cuts [131]];

ghost %v28o40@int32[4],%v29o40@int32[4],%v30o40@int32[4],%v31o40@int32[4]:
      %v28o40 = %v28 /\ %v29o40 = %v29 /\%v30o40 = %v30 /\ %v31o40 = %v31
   && %v28o40 = %v28 /\ %v29o40 = %v29 /\%v30o40 = %v30 /\ %v31o40 = %v31;

(* mul	v12.4s, v28.4s, v21.s[3]                    #! PC = 0x413d74 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v12 %v28 %mm; cast [] %v12@int32[4] %v12;
(* mul	v13.4s, v29.4s, v21.s[3]                    #! PC = 0x413d78 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v13 %v29 %mm; cast [] %v13@int32[4] %v13;
(* mul	v14.4s, v30.4s, v21.s[3]                    #! PC = 0x413d7c *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v14 %v30 %mm; cast [] %v14@int32[4] %v14;
(* mul	v15.4s, v31.4s, v21.s[3]                    #! PC = 0x413d80 *)
mov [_, _, _, m] %v21; mov %mm [m, m, m, m];
mull %dc %v15 %v31 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v28.4s, v28.4s, v21.s[2]               #! PC = 0x413d84 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v21.s[2]               #! PC = 0x413d88 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v21.s[2]               #! PC = 0x413d8c *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v21.s[2]               #! PC = 0x413d90 *)
mov [_, _, m, _] %v21; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v12.4s, v28.4s, v20.s[0]                    #! PC = 0x413d94 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v13.4s, v29.4s, v20.s[0]                    #! PC = 0x413d98 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v14.4s, v30.4s, v20.s[0]                    #! PC = 0x413d9c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;
(* mls	v15.4s, v31.4s, v20.s[0]                    #! PC = 0x413da0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod %v12 (%v28o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [133]] && true;
assume eqmod %v12 (%v28o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v29o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v30o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v31o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 134 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod %v12 (%v28o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v29o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v30o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v31o40*[%v21[3],%v21[3],%v21[3],%v21[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost  %v0o41@int32[4], %v1o41@int32[4], %v2o41@int32[4], %v3o41@int32[4],
       %v4o41@int32[4], %v5o41@int32[4], %v6o41@int32[4], %v7o41@int32[4]:
       %v0o41 =  %v0 /\  %v1o41 =  %v1 /\ %v2o41 =  %v2 /\  %v3o41 =  %v3 /\
       %v4o41 =  %v4 /\  %v5o41 =  %v5 /\ %v6o41 =  %v6 /\  %v7o41 =  %v7
   &&  %v0o41 =  %v0 /\  %v1o41 =  %v1 /\ %v2o41 =  %v2 /\  %v3o41 =  %v3 /\
       %v4o41 =  %v4 /\  %v5o41 =  %v5 /\ %v6o41 =  %v6 /\  %v7o41 =  %v7;
ghost  %v8o41@int32[4], %v9o41@int32[4],%v10o41@int32[4],%v11o41@int32[4],
      %v12o41@int32[4],%v13o41@int32[4],%v14o41@int32[4],%v15o41@int32[4]:
       %v8o41 =  %v8 /\  %v9o41 =  %v9 /\%v10o41 = %v10 /\ %v11o41 = %v11 /\
      %v12o41 = %v12 /\ %v13o41 = %v13 /\%v14o41 = %v14 /\ %v15o41 = %v15
   &&  %v8o41 =  %v8 /\  %v9o41 =  %v9 /\%v10o41 = %v10 /\ %v11o41 = %v11 /\
      %v12o41 = %v12 /\ %v13o41 = %v13 /\%v14o41 = %v14 /\ %v15o41 = %v15;

(* sub	v28.4s, v0.4s, v8.4s                        #! PC = 0x413da4 *)
sub %v28 %v0 %v8;
(* add	v16.4s, v0.4s, v8.4s                        #! PC = 0x413da8 *)
add %v16 %v0 %v8;
(* sub	v29.4s, v2.4s, v10.4s                       #! PC = 0x413dac *)
sub %v29 %v2 %v10;
(* add	v17.4s, v2.4s, v10.4s                       #! PC = 0x413db0 *)
add %v17 %v2 %v10;
(* sub	v30.4s, v4.4s, v12.4s                       #! PC = 0x413db4 *)
sub %v30 %v4 %v12;
(* add	v18.4s, v4.4s, v12.4s                       #! PC = 0x413db8 *)
add %v18 %v4 %v12;
(* sub	v31.4s, v6.4s, v14.4s                       #! PC = 0x413dbc *)
sub %v31 %v6 %v14;
(* add	v19.4s, v6.4s, v14.4s                       #! PC = 0x413dc0 *)
add %v19 %v6 %v14;
(* sub	v8.4s, v1.4s, v9.4s                         #! PC = 0x413dc4 *)
sub %v8 %v1 %v9;
(* add	v0.4s, v1.4s, v9.4s                         #! PC = 0x413dc8 *)
add %v0 %v1 %v9;
(* sub	v10.4s, v3.4s, v11.4s                       #! PC = 0x413dcc *)
sub %v10 %v3 %v11;
(* add	v2.4s, v3.4s, v11.4s                        #! PC = 0x413dd0 *)
add %v2 %v3 %v11;
(* sub	v12.4s, v5.4s, v13.4s                       #! PC = 0x413dd4 *)
sub %v12 %v5 %v13;
(* add	v4.4s, v5.4s, v13.4s                        #! PC = 0x413dd8 *)
add %v4 %v5 %v13;
(* sub	v14.4s, v7.4s, v15.4s                       #! PC = 0x413ddc *)
sub %v14 %v7 %v15;
(* add	v6.4s, v7.4s, v15.4s                        #! PC = 0x413de0 *)
add %v6 %v7 %v15;

assert [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
       prove with [algebra solver isl, cuts [132, 133]] && true;
assume [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
       %v16 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
       %v28 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
       %v17 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
       %v29 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
       %v18 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
       %v30 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
       %v19 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
       %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
    && [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
       %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
       %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
       %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
       %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
       %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
       %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
       %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
        %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
        %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
        %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
       %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
        %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
       %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
        %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
       [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
       %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q];
(* CUT 135 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    %v16 =  %v0o41 +  %v8o41 /\ %v28 =  %v0o41 -  %v8o41 /\
    %v17 =  %v2o41 + %v10o41 /\ %v29 =  %v2o41 - %v10o41 /\
    %v18 =  %v4o41 + %v12o41 /\ %v30 =  %v4o41 - %v12o41 /\
    %v19 =  %v6o41 + %v14o41 /\ %v31 =  %v6o41 - %v14o41 /\
     %v0 =  %v1o41 +  %v9o41 /\  %v8 =  %v1o41 -  %v9o41 /\
     %v2 =  %v3o41 + %v11o41 /\ %v10 =  %v3o41 - %v11o41 /\
     %v4 =  %v5o41 + %v13o41 /\ %v12 =  %v5o41 - %v13o41 /\
     %v6 =  %v7o41 + %v15o41 /\ %v14 =  %v7o41 - %v15o41 /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v16 /\
    %v16 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v28 /\
    %v28 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v17 /\
    %v17 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v29 /\
    %v29 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v18 /\
    %v18 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v30 /\
    %v30 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v19 /\
    %v19 < [16*Q,16*Q,16*Q,16*Q] /\
    [16*NQ,16*NQ,16*NQ,16*NQ] < %v31 /\
    %v31 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v0 /\
        %v0 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v8 /\
        %v8 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v2 /\
        %v2 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v10 /\
       %v10 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v4 /\
        %v4 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v12 /\
       %v12 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] <  %v6 /\
        %v6 < [16*Q,16*Q,16*Q,16*Q] /\
       [16*NQ,16*NQ,16*NQ,16*NQ] < %v14 /\
       %v14 < [16*Q,16*Q,16*Q,16*Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v16 /\
    %v16 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v28 /\
    %v28 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v17 /\
    %v17 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v29 /\
    %v29 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v18 /\
    %v18 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v30 /\
    %v30 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v19 /\
    %v19 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v31 /\
    %v31 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v0 /\
     %v0 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v8 /\
     %v8 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v2 /\
     %v2 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v10 /\
    %v10 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v4 /\
     %v4 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v12 /\
    %v12 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s  %v6 /\
     %v6 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q] /\
    [16@32*NQ,16@32*NQ,16@32*NQ,16@32*NQ] <s %v14 /\
    %v14 <s [16@32*Q,16@32*Q,16@32*Q,16@32*Q]
    prove with [cuts [132, 133]];

ghost  %v0o42@int32[4], %v2o42@int32[4], %v4o42@int32[4], %v6o42@int32[4]:
       %v0o42 =  %v0 /\  %v2o42 =  %v2 /\ %v4o42 =  %v4 /\  %v6o42 =  %v6
   &&  %v0o42 =  %v0 /\  %v2o42 =  %v2 /\ %v4o42 =  %v4 /\  %v6o42 =  %v6;

(* mov	v20.s[2], w24                               #! PC = 0x413de4 *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w24, m3];
(* mov	v20.s[3], w25                               #! PC = 0x413de8 *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w25];
(* mul	v1.4s, v0.4s, v20.s[3]                      #! PC = 0x413dec *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v1 %v0 %mm; cast [] %v1@int32[4] %v1;
(* mul	v3.4s, v2.4s, v20.s[3]                      #! PC = 0x413df0 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v3 %v2 %mm; cast [] %v3@int32[4] %v3;
(* mul	v5.4s, v4.4s, v20.s[3]                      #! PC = 0x413df4 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v5 %v4 %mm; cast [] %v5@int32[4] %v5;
(* mul	v7.4s, v6.4s, v20.s[3]                      #! PC = 0x413df8 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v7 %v6 %mm; cast [] %v7@int32[4] %v7;
(* sqrdmulh	v0.4s, v0.4s, v20.s[2]                 #! PC = 0x413dfc *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v0 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v0 %dc %mm 1;
(* sqrdmulh	v2.4s, v2.4s, v20.s[2]                 #! PC = 0x413e00 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v2 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v2 %dc %mm 1;
(* sqrdmulh	v4.4s, v4.4s, v20.s[2]                 #! PC = 0x413e04 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v4 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v4 %dc %mm 1;
(* sqrdmulh	v6.4s, v6.4s, v20.s[2]                 #! PC = 0x413e08 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v6 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v6 %dc %mm 1;
(* mls	v1.4s, v0.4s, v20.s[0]                      #! PC = 0x413e0c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v0 %mm; cast [] %mm@int32[4] %mm; subs %dc %v1 %v1 %mm;
(* mls	v3.4s, v2.4s, v20.s[0]                      #! PC = 0x413e10 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v2 %mm; cast [] %mm@int32[4] %mm; subs %dc %v3 %v3 %mm;
(* mls	v5.4s, v4.4s, v20.s[0]                      #! PC = 0x413e14 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v4 %mm; cast [] %mm@int32[4] %mm; subs %dc %v5 %v5 %mm;
(* mls	v7.4s, v6.4s, v20.s[0]                      #! PC = 0x413e18 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v6 %mm; cast [] %mm@int32[4] %mm; subs %dc %v7 %v7 %mm;

assert eqmod  %v1 ( %v0o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [135]] && true;
assume eqmod  %v1 ( %v0o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v3 ( %v2o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v5 ( %v4o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v7 ( %v6o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

(* CUT 136 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v1 ( %v0o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v3 ( %v2o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v5 ( %v4o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v7 ( %v6o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v1 /\  %v1 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v3 /\  %v3 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v5 /\  %v5 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v7 /\  %v7 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v1 /\  %v1 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v3 /\  %v3 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v5 /\  %v5 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v7 /\  %v7 <s [Q,Q,Q,Q];

ghost %v16o42@int32[4],%v17o42@int32[4],%v18o42@int32[4],%v19o42@int32[4]:
      %v16o42 = %v16 /\ %v17o42 = %v17 /\%v18o42 = %v18 /\ %v19o42 = %v19
   && %v16o42 = %v16 /\ %v17o42 = %v17 /\%v18o42 = %v18 /\ %v19o42 = %v19;

(* mul	v0.4s, v16.4s, v20.s[3]                     #! PC = 0x413e1c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v0 %v16 %mm; cast [] %v0@int32[4] %v0;
(* mul	v2.4s, v17.4s, v20.s[3]                     #! PC = 0x413e20 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v2 %v17 %mm; cast [] %v2@int32[4] %v2;
(* mul	v4.4s, v18.4s, v20.s[3]                     #! PC = 0x413e24 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v4 %v18 %mm; cast [] %v4@int32[4] %v4;
(* mul	v6.4s, v19.4s, v20.s[3]                     #! PC = 0x413e28 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v6 %v19 %mm; cast [] %v6@int32[4] %v6;
(* sqrdmulh	v16.4s, v16.4s, v20.s[2]               #! PC = 0x413e2c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v16 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v16 %dc %mm 1;
(* sqrdmulh	v17.4s, v17.4s, v20.s[2]               #! PC = 0x413e30 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v17 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v17 %dc %mm 1;
(* sqrdmulh	v18.4s, v18.4s, v20.s[2]               #! PC = 0x413e34 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v18 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v18 %dc %mm 1;
(* sqrdmulh	v19.4s, v19.4s, v20.s[2]               #! PC = 0x413e38 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v19 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v19 %dc %mm 1;
(* mls	v0.4s, v16.4s, v20.s[0]                     #! PC = 0x413e3c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v16 %mm; cast [] %mm@int32[4] %mm; subs %dc %v0 %v0 %mm;
(* mls	v2.4s, v17.4s, v20.s[0]                     #! PC = 0x413e40 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v17 %mm; cast [] %mm@int32[4] %mm; subs %dc %v2 %v2 %mm;
(* mls	v4.4s, v18.4s, v20.s[0]                     #! PC = 0x413e44 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v18 %mm; cast [] %mm@int32[4] %mm; subs %dc %v4 %v4 %mm;
(* mls	v6.4s, v19.4s, v20.s[0]                     #! PC = 0x413e48 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v19 %mm; cast [] %mm@int32[4] %mm; subs %dc %v6 %v6 %mm;

assert eqmod  %v0 (%v16o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [135]] && true;
assume eqmod  %v0 (%v16o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v2 (%v17o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v4 (%v18o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod  %v6 (%v19o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

(* CUT 137 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v0 (%v16o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v2 (%v17o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v4 (%v18o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod  %v6 (%v19o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v0 /\  %v0 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v2 /\  %v2 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v4 /\  %v4 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v6 /\  %v6 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v0 /\  %v0 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v2 /\  %v2 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v4 /\  %v4 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s  %v6 /\  %v6 <s [Q,Q,Q,Q];

ghost  %v8o42@int32[4],%v10o42@int32[4],%v12o42@int32[4],%v14o42@int32[4]:
       %v8o42 =  %v8 /\ %v10o42 = %v10 /\%v12o42 = %v12 /\ %v14o42 = %v14
   &&  %v8o42 =  %v8 /\ %v10o42 = %v10 /\%v12o42 = %v12 /\ %v14o42 = %v14;

(* mov	v20.s[2], w26                               #! PC = 0x413e4c *)
mov [m0, m1, _, m3] %v20; mov %v20 [m0, m1, w26, m3];
(* mov	v20.s[3], w27                               #! PC = 0x413e50 *)
mov [m0, m1, m2, _] %v20; mov %v20 [m0, m1, m2, w27];
(* mul	v9.4s, v8.4s, v20.s[3]                      #! PC = 0x413e54 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v9 %v8 %mm; cast [] %v9@int32[4] %v9;
(* mul	v11.4s, v10.4s, v20.s[3]                    #! PC = 0x413e58 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v11 %v10 %mm; cast [] %v11@int32[4] %v11;
(* mul	v13.4s, v12.4s, v20.s[3]                    #! PC = 0x413e5c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v13 %v12 %mm; cast [] %v13@int32[4] %v13;
(* mul	v15.4s, v14.4s, v20.s[3]                    #! PC = 0x413e60 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v15 %v14 %mm; cast [] %v15@int32[4] %v15;
(* sqrdmulh	v8.4s, v8.4s, v20.s[2]                 #! PC = 0x413e64 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v8 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v8 %dc %mm 1;
(* sqrdmulh	v10.4s, v10.4s, v20.s[2]               #! PC = 0x413e68 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v10 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v10 %dc %mm 1;
(* sqrdmulh	v12.4s, v12.4s, v20.s[2]               #! PC = 0x413e6c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v12 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v12 %dc %mm 1;
(* sqrdmulh	v14.4s, v14.4s, v20.s[2]               #! PC = 0x413e70 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v14 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v14 %dc %mm 1;
(* mls	v9.4s, v8.4s, v20.s[0]                      #! PC = 0x413e74 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v8 %mm; cast [] %mm@int32[4] %mm; subs %dc %v9 %v9 %mm;
(* mls	v11.4s, v10.4s, v20.s[0]                    #! PC = 0x413e78 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v10 %mm; cast [] %mm@int32[4] %mm; subs %dc %v11 %v11 %mm;
(* mls	v13.4s, v12.4s, v20.s[0]                    #! PC = 0x413e7c *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v12 %mm; cast [] %mm@int32[4] %mm; subs %dc %v13 %v13 %mm;
(* mls	v15.4s, v14.4s, v20.s[0]                    #! PC = 0x413e80 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v14 %mm; cast [] %mm@int32[4] %mm; subs %dc %v15 %v15 %mm;

assert eqmod  %v9 ( %v8o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [135]] && true;
assume eqmod  %v9 ( %v8o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v11 (%v10o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v13 (%v12o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v15 (%v14o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

(* CUT 138 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v9 ( %v8o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v11 (%v10o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v13 (%v12o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v15 (%v14o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v9 /\  %v9 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v11 /\ %v11 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v13 /\ %v13 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v15 /\ %v15 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v9 /\  %v9 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v11 /\ %v11 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v13 /\ %v13 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v15 /\ %v15 <s [Q,Q,Q,Q];

ghost %v28o42@int32[4],%v29o42@int32[4],%v30o42@int32[4],%v31o42@int32[4]:
      %v28o42 = %v28 /\ %v29o42 = %v29 /\%v30o42 = %v30 /\ %v31o42 = %v31
   && %v28o42 = %v28 /\ %v29o42 = %v29 /\%v30o42 = %v30 /\ %v31o42 = %v31;

(* mul	v8.4s, v28.4s, v20.s[3]                     #! PC = 0x413e84 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v8 %v28 %mm; cast [] %v8@int32[4] %v8;
(* mul	v10.4s, v29.4s, v20.s[3]                    #! PC = 0x413e88 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v10 %v29 %mm; cast [] %v10@int32[4] %v10;
(* mul	v12.4s, v30.4s, v20.s[3]                    #! PC = 0x413e8c *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v12 %v30 %mm; cast [] %v12@int32[4] %v12;
(* mul	v14.4s, v31.4s, v20.s[3]                    #! PC = 0x413e90 *)
mov [_, _, _, m] %v20; mov %mm [m, m, m, m];
mull %dc %v14 %v31 %mm; cast [] %v14@int32[4] %v14;
(* sqrdmulh	v28.4s, v28.4s, v20.s[2]               #! PC = 0x413e94 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v28 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v28 %dc %mm 1;
(* sqrdmulh	v29.4s, v29.4s, v20.s[2]               #! PC = 0x413e98 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v29 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v29 %dc %mm 1;
(* sqrdmulh	v30.4s, v30.4s, v20.s[2]               #! PC = 0x413e9c *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v30 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v30 %dc %mm 1;
(* sqrdmulh	v31.4s, v31.4s, v20.s[2]               #! PC = 0x413ea0 *)
mov [_, _, m, _] %v20; mov %mm [m, m, m, m];
mulj %mm %v31 %mm; shl %mm %mm [1@int64, 1@int64, 1@int64, 1@int64];
spl %mm %dc %mm 31; add %mm %mm [1@int33,1@int33,1@int33,1@int33];
spl %v31 %dc %mm 1;
(* mls	v8.4s, v28.4s, v20.s[0]                     #! PC = 0x413ea4 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v28 %mm; cast [] %mm@int32[4] %mm; subs %dc %v8 %v8 %mm;
(* mls	v10.4s, v29.4s, v20.s[0]                    #! PC = 0x413ea8 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v29 %mm; cast [] %mm@int32[4] %mm; subs %dc %v10 %v10 %mm;
(* mls	v12.4s, v30.4s, v20.s[0]                    #! PC = 0x413eac *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v30 %mm; cast [] %mm@int32[4] %mm; subs %dc %v12 %v12 %mm;
(* mls	v14.4s, v31.4s, v20.s[0]                    #! PC = 0x413eb0 *)
mov [m, _, _, _] %v20; mov %mm [m, m, m, m];
mull %dc %mm %v31 %mm; cast [] %mm@int32[4] %mm; subs %dc %v14 %v14 %mm;

assert eqmod  %v8 (%v28o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
       prove with [algebra solver isl, cuts [135]] && true;
assume eqmod  %v8 (%v28o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v10 (%v29o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v12 (%v30o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       eqmod %v14 (%v31o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
    && [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
       [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

(* CUT 139 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod  %v8 (%v28o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v10 (%v29o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v12 (%v30o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    eqmod %v14 (%v31o42*[%v20[3],%v20[3],%v20[3],%v20[3]]) [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <  %v8 /\  %v8 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v10 /\ %v10 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v12 /\ %v12 < [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] < %v14 /\ %v14 < [Q,Q,Q,Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ,NQ,NQ,NQ] <s  %v8 /\  %v8 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v10 /\ %v10 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v12 /\ %v12 <s [Q,Q,Q,Q] /\
    [NQ,NQ,NQ,NQ] <s %v14 /\ %v14 <s [Q,Q,Q,Q];

ghost  %v0o43@int32[4], %v1o43@int32[4], %v2o43@int32[4], %v3o43@int32[4],
       %v4o43@int32[4], %v5o43@int32[4], %v6o43@int32[4], %v7o43@int32[4]:
       %v0o43 =  %v0 /\  %v1o43 =  %v1 /\ %v2o43 =  %v2 /\  %v3o43 =  %v3 /\
       %v4o43 =  %v4 /\  %v5o43 =  %v5 /\ %v6o43 =  %v6 /\  %v7o43 =  %v7
   &&  %v0o43 =  %v0 /\  %v1o43 =  %v1 /\ %v2o43 =  %v2 /\  %v3o43 =  %v3 /\
       %v4o43 =  %v4 /\  %v5o43 =  %v5 /\ %v6o43 =  %v6 /\  %v7o43 =  %v7;
ghost  %v8o43@int32[4], %v9o43@int32[4],%v10o43@int32[4],%v11o43@int32[4],
      %v12o43@int32[4],%v13o43@int32[4],%v14o43@int32[4],%v15o43@int32[4]:
       %v8o43 =  %v8 /\  %v9o43 =  %v9 /\%v10o43 = %v10 /\ %v11o43 = %v11 /\
      %v12o43 = %v12 /\ %v13o43 = %v13 /\%v14o43 = %v14 /\ %v15o43 = %v15
   &&  %v8o43 =  %v8 /\  %v9o43 =  %v9 /\%v10o43 = %v10 /\ %v11o43 = %v11 /\
      %v12o43 = %v12 /\ %v13o43 = %v13 /\%v14o43 = %v14 /\ %v15o43 = %v15;

(* sub	x19, x19, #0x1                              #! PC = 0x413eb4 *)
subs dc x19 x19 (0x1)@uint64;
(* #cbnz	x19, 0x413a34 <_intt_top_loop>            #! PC = 0x413eb8 *)
#cbnz	x19, 0x413a34 <_intt_top_loop>            #! 0x413eb8 = 0x413eb8;
(* dup	v29.4s, w20                                 #! PC = 0x413ebc *)
mov %v29 [w20,w20,w20,w20];
(* dup	v30.4s, w21                                 #! PC = 0x413ec0 *)
mov %v30 [w21,w21,w21,w21];
(* dup	v31.4s, w22                                 #! PC = 0x413ec4 *)
mov %v31 [w22,w22,w22,w22];
(* cmgt	v18.4s, v31.4s, v0.4s                      #! PC = 0x413ec8 *)
subs %dc %lt %v0 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v1.4s                      #! PC = 0x413ecc *)
subs %dc %lt %v1 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v0.4s, v30.4s                      #! PC = 0x413ed0 *)
subs %dc %lt %v30 %v0; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v1.4s, v30.4s                      #! PC = 0x413ed4 *)
subs %dc %lt %v30 %v1; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ed8 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413edc *)
sub %v17 %v17 %v19;
(* mla	v0.4s, v16.4s, v29.4s                       #! PC = 0x413ee0 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v0 %v0 %mla;
(* mla	v1.4s, v17.4s, v29.4s                       #! PC = 0x413ee4 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v1 %v1 %mla;
(* str	q0, [x0]                                    #! EA = L0xffffffff0640; PC = 0x413ee8 *)
mov [L0xffffffff0640, L0xffffffff0644, L0xffffffff0648, L0xffffffff064c] %v0;
(* str	q1, [x0, #64]                               #! EA = L0xffffffff0680; PC = 0x413eec *)
mov [L0xffffffff0680, L0xffffffff0684, L0xffffffff0688, L0xffffffff068c] %v1;
(* cmgt	v18.4s, v31.4s, v2.4s                      #! PC = 0x413ef0 *)
subs %dc %lt %v2 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v3.4s                      #! PC = 0x413ef4 *)
subs %dc %lt %v3 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v2.4s, v30.4s                      #! PC = 0x413ef8 *)
subs %dc %lt %v30 %v2; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v3.4s, v30.4s                      #! PC = 0x413efc *)
subs %dc %lt %v30 %v3; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413f00 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413f04 *)
sub %v17 %v17 %v19;
(* mla	v2.4s, v16.4s, v29.4s                       #! PC = 0x413f08 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v2 %v2 %mla;
(* mla	v3.4s, v17.4s, v29.4s                       #! PC = 0x413f0c *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v3 %v3 %mla;
(* str	q2, [x0, #128]                              #! EA = L0xffffffff06c0; PC = 0x413f10 *)
mov [L0xffffffff06c0, L0xffffffff06c4, L0xffffffff06c8, L0xffffffff06cc] %v2;
(* str	q3, [x0, #192]                              #! EA = L0xffffffff0700; PC = 0x413f14 *)
mov [L0xffffffff0700, L0xffffffff0704, L0xffffffff0708, L0xffffffff070c] %v3;
(* cmgt	v18.4s, v31.4s, v4.4s                      #! PC = 0x413f18 *)
subs %dc %lt %v4 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v5.4s                      #! PC = 0x413f1c *)
subs %dc %lt %v5 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v4.4s, v30.4s                      #! PC = 0x413f20 *)
subs %dc %lt %v30 %v4; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v5.4s, v30.4s                      #! PC = 0x413f24 *)
subs %dc %lt %v30 %v5; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413f28 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413f2c *)
sub %v17 %v17 %v19;
(* mla	v4.4s, v16.4s, v29.4s                       #! PC = 0x413f30 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v4 %v4 %mla;
(* mla	v5.4s, v17.4s, v29.4s                       #! PC = 0x413f34 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v5 %v5 %mla;
(* str	q4, [x0, #256]                              #! EA = L0xffffffff0740; PC = 0x413f38 *)
mov [L0xffffffff0740, L0xffffffff0744, L0xffffffff0748, L0xffffffff074c] %v4;
(* str	q5, [x0, #320]                              #! EA = L0xffffffff0780; PC = 0x413f3c *)
mov [L0xffffffff0780, L0xffffffff0784, L0xffffffff0788, L0xffffffff078c] %v5;
(* cmgt	v18.4s, v31.4s, v6.4s                      #! PC = 0x413f40 *)
subs %dc %lt %v6 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v7.4s                      #! PC = 0x413f44 *)
subs %dc %lt %v7 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v6.4s, v30.4s                      #! PC = 0x413f48 *)
subs %dc %lt %v30 %v6; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v7.4s, v30.4s                      #! PC = 0x413f4c *)
subs %dc %lt %v30 %v7; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413f50 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413f54 *)
sub %v17 %v17 %v19;
(* mla	v6.4s, v16.4s, v29.4s                       #! PC = 0x413f58 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v6 %v6 %mla;
(* mla	v7.4s, v17.4s, v29.4s                       #! PC = 0x413f5c *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v7 %v7 %mla;
(* str	q6, [x0, #384]                              #! EA = L0xffffffff07c0; PC = 0x413f60 *)
mov [L0xffffffff07c0, L0xffffffff07c4, L0xffffffff07c8, L0xffffffff07cc] %v6;
(* str	q7, [x0, #448]                              #! EA = L0xffffffff0800; PC = 0x413f64 *)
mov [L0xffffffff0800, L0xffffffff0804, L0xffffffff0808, L0xffffffff080c] %v7;
(* cmgt	v18.4s, v31.4s, v8.4s                      #! PC = 0x413f68 *)
subs %dc %lt %v8 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v9.4s                      #! PC = 0x413f6c *)
subs %dc %lt %v9 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v8.4s, v30.4s                      #! PC = 0x413f70 *)
subs %dc %lt %v30 %v8; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v9.4s, v30.4s                      #! PC = 0x413f74 *)
subs %dc %lt %v30 %v9; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413f78 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413f7c *)
sub %v17 %v17 %v19;
(* mla	v8.4s, v16.4s, v29.4s                       #! PC = 0x413f80 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v8 %v8 %mla;
(* mla	v9.4s, v17.4s, v29.4s                       #! PC = 0x413f84 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v9 %v9 %mla;
(* str	q8, [x0, #512]                              #! EA = L0xffffffff0840; PC = 0x413f88 *)
mov [L0xffffffff0840, L0xffffffff0844, L0xffffffff0848, L0xffffffff084c] %v8;
(* str	q9, [x0, #576]                              #! EA = L0xffffffff0880; PC = 0x413f8c *)
mov [L0xffffffff0880, L0xffffffff0884, L0xffffffff0888, L0xffffffff088c] %v9;
(* cmgt	v18.4s, v31.4s, v10.4s                     #! PC = 0x413f90 *)
subs %dc %lt %v10 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v11.4s                     #! PC = 0x413f94 *)
subs %dc %lt %v11 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v10.4s, v30.4s                     #! PC = 0x413f98 *)
subs %dc %lt %v30 %v10; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v11.4s, v30.4s                     #! PC = 0x413f9c *)
subs %dc %lt %v30 %v11; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413fa0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413fa4 *)
sub %v17 %v17 %v19;
(* mla	v10.4s, v16.4s, v29.4s                      #! PC = 0x413fa8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v10 %v10 %mla;
(* mla	v11.4s, v17.4s, v29.4s                      #! PC = 0x413fac *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v11 %v11 %mla;
(* str	q10, [x0, #640]                             #! EA = L0xffffffff08c0; PC = 0x413fb0 *)
mov [L0xffffffff08c0, L0xffffffff08c4, L0xffffffff08c8, L0xffffffff08cc] %v10;
(* str	q11, [x0, #704]                             #! EA = L0xffffffff0900; PC = 0x413fb4 *)
mov [L0xffffffff0900, L0xffffffff0904, L0xffffffff0908, L0xffffffff090c] %v11;
(* cmgt	v18.4s, v31.4s, v12.4s                     #! PC = 0x413fb8 *)
subs %dc %lt %v12 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v13.4s                     #! PC = 0x413fbc *)
subs %dc %lt %v13 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v12.4s, v30.4s                     #! PC = 0x413fc0 *)
subs %dc %lt %v30 %v12; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v13.4s, v30.4s                     #! PC = 0x413fc4 *)
subs %dc %lt %v30 %v13; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413fc8 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413fcc *)
sub %v17 %v17 %v19;
(* mla	v12.4s, v16.4s, v29.4s                      #! PC = 0x413fd0 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v12 %v12 %mla;
(* mla	v13.4s, v17.4s, v29.4s                      #! PC = 0x413fd4 *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v13 %v13 %mla;
(* str	q12, [x0, #768]                             #! EA = L0xffffffff0940; PC = 0x413fd8 *)
mov [L0xffffffff0940, L0xffffffff0944, L0xffffffff0948, L0xffffffff094c] %v12;
(* str	q13, [x0, #832]                             #! EA = L0xffffffff0980; PC = 0x413fdc *)
mov [L0xffffffff0980, L0xffffffff0984, L0xffffffff0988, L0xffffffff098c] %v13;
(* cmgt	v18.4s, v31.4s, v14.4s                     #! PC = 0x413fe0 *)
subs %dc %lt %v14 %v31; split %v18 %dc %lt 31;
(* cmgt	v19.4s, v31.4s, v15.4s                     #! PC = 0x413fe4 *)
subs %dc %lt %v15 %v31; split %v19 %dc %lt 31;
(* cmgt	v16.4s, v14.4s, v30.4s                     #! PC = 0x413fe8 *)
subs %dc %lt %v30 %v14; split %v16 %dc %lt 31;
(* cmgt	v17.4s, v15.4s, v30.4s                     #! PC = 0x413fec *)
subs %dc %lt %v30 %v15; split %v17 %dc %lt 31;
(* sub	v16.4s, v16.4s, v18.4s                      #! PC = 0x413ff0 *)
sub %v16 %v16 %v18;
(* sub	v17.4s, v17.4s, v19.4s                      #! PC = 0x413ff4 *)
sub %v17 %v17 %v19;
(* mla	v14.4s, v16.4s, v29.4s                      #! PC = 0x413ff8 *)
mull %dc %mla %v16 %v29; cast %mla@int32[4] %mla; add %v14 %v14 %mla;
(* mla	v15.4s, v17.4s, v29.4s                      #! PC = 0x413ffc *)
mull %dc %mla %v17 %v29; cast %mla@int32[4] %mla; add %v15 %v15 %mla;
(* str	q14, [x0, #896]                             #! EA = L0xffffffff09c0; PC = 0x414000 *)
mov [L0xffffffff09c0, L0xffffffff09c4, L0xffffffff09c8, L0xffffffff09cc] %v14;
(* str	q15, [x0, #960]                             #! EA = L0xffffffff0a00; PC = 0x414004 *)
mov [L0xffffffff0a00, L0xffffffff0a04, L0xffffffff0a08, L0xffffffff0a0c] %v15;

assert true &&
       eqsmod [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]
              %v0o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]
              %v1o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]
              %v2o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]
              %v3o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]
              %v4o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]
              %v5o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]
              %v6o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]
              %v7o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]
              %v8o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]
              %v9o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]
              %v10o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]
              %v11o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]
              %v12o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]
              %v13o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]
              %v14o43 [Q, Q, Q, Q] /\
       eqsmod [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]
              %v15o43 [Q, Q, Q, Q]
       prove with [cuts [89]];
assume eqmod [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]
             %v0o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]
             %v1o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]
             %v2o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]
             %v3o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]
             %v4o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]
             %v5o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]
             %v6o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]
             %v7o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]
             %v8o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]
             %v9o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]
             %v10o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]
             %v11o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]
             %v12o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]
             %v13o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]
             %v14o43 [Q, Q, Q, Q] /\
       eqmod [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]
             %v15o43 [Q, Q, Q, Q] && true;
(* CUT 140 *)
cut  Q = 8380417 /\ Q2 = 4190209 /\ NQ = -8380417 /\ NQ2 = -4190209 /\
    eqmod [L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c]
          %v0o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c]
          %v1o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc]
          %v2o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c]
          %v3o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c]
          %v4o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c]
          %v5o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc]
          %v6o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c]
          %v7o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c]
          %v8o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c]
          %v9o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc]
          %v10o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c]
          %v11o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c]
          %v12o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c]
          %v13o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc]
          %v14o43 [Q, Q, Q, Q] /\
    eqmod [L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c]
          %v15o43 [Q, Q, Q, Q]
 && Q=8380417@32 /\ Q2=4190209@32 /\ NQ=(-8380417)@32 /\ NQ2=(-4190209)@32 /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0640,L0xffffffff0640,L0xffffffff0640,L0xffffffff0640] /\
    [L0xffffffff0640,L0xffffffff0640,L0xffffffff0640,L0xffffffff0640]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0680,L0xffffffff0680,L0xffffffff0680,L0xffffffff0680] /\
    [L0xffffffff0680,L0xffffffff0680,L0xffffffff0680,L0xffffffff0680]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0] /\
    [L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0700,L0xffffffff0700,L0xffffffff0700,L0xffffffff0700] /\
    [L0xffffffff0700,L0xffffffff0700,L0xffffffff0700,L0xffffffff0700]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0740,L0xffffffff0740,L0xffffffff0740,L0xffffffff0740] /\
    [L0xffffffff0740,L0xffffffff0740,L0xffffffff0740,L0xffffffff0740]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0780,L0xffffffff0780,L0xffffffff0780,L0xffffffff0780] /\
    [L0xffffffff0780,L0xffffffff0780,L0xffffffff0780,L0xffffffff0780]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0] /\
    [L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0800,L0xffffffff0800,L0xffffffff0800,L0xffffffff0800] /\
    [L0xffffffff0800,L0xffffffff0800,L0xffffffff0800,L0xffffffff0800]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0840,L0xffffffff0840,L0xffffffff0840,L0xffffffff0840] /\
    [L0xffffffff0840,L0xffffffff0840,L0xffffffff0840,L0xffffffff0840]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0880,L0xffffffff0880,L0xffffffff0880,L0xffffffff0880] /\
    [L0xffffffff0880,L0xffffffff0880,L0xffffffff0880,L0xffffffff0880]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0] /\
    [L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0900,L0xffffffff0900,L0xffffffff0900,L0xffffffff0900] /\
    [L0xffffffff0900,L0xffffffff0900,L0xffffffff0900,L0xffffffff0900]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0940,L0xffffffff0940,L0xffffffff0940,L0xffffffff0940] /\
    [L0xffffffff0940,L0xffffffff0940,L0xffffffff0940,L0xffffffff0940]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0980,L0xffffffff0980,L0xffffffff0980,L0xffffffff0980] /\
    [L0xffffffff0980,L0xffffffff0980,L0xffffffff0980,L0xffffffff0980]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0] /\
    [L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0]<s[Q2,Q2,Q2,Q2] /\
    [NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00] /\
    [L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00]<s[Q2,Q2,Q2,Q2]
    prove with [cuts [89, 136, 137, 138, 139]];

(* add	x0, x0, #0x10                               #! PC = 0x414008 *)
adds dc x0 x0 (0x10)@uint64;
(* ldp	x19, x20, [sp]                              #! EA = L0xfffffffec470; Value = 0x0000ffffffff0a10; PC = 0x41400c *)
mov x19 L0xfffffffec470; mov x20 L0xfffffffec478;
(* ldp	x21, x22, [sp, #16]                         #! EA = L0xfffffffec480; Value = 0x0000fffffffec5b0; PC = 0x414010 *)
mov x21 L0xfffffffec480; mov x22 L0xfffffffec488;
(* ldp	x23, x24, [sp, #32]                         #! EA = L0xfffffffec490; Value = 0x0000ffffffffdac0; PC = 0x414014 *)
mov x23 L0xfffffffec490; mov x24 L0xfffffffec498;
(* ldp	x25, x26, [sp, #48]                         #! EA = L0xfffffffec4a0; Value = 0x0000000000000000; PC = 0x414018 *)
mov x25 L0xfffffffec4a0; mov x26 L0xfffffffec4a8;
(* ldp	x27, x28, [sp, #64]                         #! EA = L0xfffffffec4b0; Value = 0x0000000000429de0; PC = 0x41401c *)
mov x27 L0xfffffffec4b0; mov x28 L0xfffffffec4b8;
(* ldp	d8, d9, [sp, #80]                           #! EA = L0xfffffffec4c0; Value = 0x0000000000000000; PC = 0x414020 *)
mov d8 L0xfffffffec4c0; mov d9 L0xfffffffec4c8;
(* ldp	d10, d11, [sp, #96]                         #! EA = L0xfffffffec4d0; Value = 0x0000000000000000; PC = 0x414024 *)
mov d10 L0xfffffffec4d0; mov d11 L0xfffffffec4d8;
(* ldp	d12, d13, [sp, #112]                        #! EA = L0xfffffffec4e0; Value = 0x0000000000000000; PC = 0x414028 *)
mov d12 L0xfffffffec4e0; mov d13 L0xfffffffec4e8;
(* ldp	d14, d15, [sp, #128]                        #! EA = L0xfffffffec4f0; Value = 0x0000000000000000; PC = 0x41402c *)
mov d14 L0xfffffffec4f0; mov d15 L0xfffffffec4f8;
(* #! <- SP = 0xfffffffec500 *)
#! 0xfffffffec500 = 0xfffffffec500;
(* #ret                                            #! PC = 0x414034 *)
#ret                                            #! 0x414034 = 0x414034;

{
eqmod (poly X [L0xffffffff0610,L0xffffffff0614,L0xffffffff0618,L0xffffffff061c,
               L0xffffffff0620,L0xffffffff0624,L0xffffffff0628,L0xffffffff062c,
               L0xffffffff0630,L0xffffffff0634,L0xffffffff0638,L0xffffffff063c,
               L0xffffffff0640,L0xffffffff0644,L0xffffffff0648,L0xffffffff064c,
               L0xffffffff0650,L0xffffffff0654,L0xffffffff0658,L0xffffffff065c,
               L0xffffffff0660,L0xffffffff0664,L0xffffffff0668,L0xffffffff066c,
               L0xffffffff0670,L0xffffffff0674,L0xffffffff0678,L0xffffffff067c,
               L0xffffffff0680,L0xffffffff0684,L0xffffffff0688,L0xffffffff068c,
               L0xffffffff0690,L0xffffffff0694,L0xffffffff0698,L0xffffffff069c,
               L0xffffffff06a0,L0xffffffff06a4,L0xffffffff06a8,L0xffffffff06ac,
               L0xffffffff06b0,L0xffffffff06b4,L0xffffffff06b8,L0xffffffff06bc,
               L0xffffffff06c0,L0xffffffff06c4,L0xffffffff06c8,L0xffffffff06cc,
               L0xffffffff06d0,L0xffffffff06d4,L0xffffffff06d8,L0xffffffff06dc,
               L0xffffffff06e0,L0xffffffff06e4,L0xffffffff06e8,L0xffffffff06ec,
               L0xffffffff06f0,L0xffffffff06f4,L0xffffffff06f8,L0xffffffff06fc,
               L0xffffffff0700,L0xffffffff0704,L0xffffffff0708,L0xffffffff070c,
               L0xffffffff0710,L0xffffffff0714,L0xffffffff0718,L0xffffffff071c,
               L0xffffffff0720,L0xffffffff0724,L0xffffffff0728,L0xffffffff072c,
               L0xffffffff0730,L0xffffffff0734,L0xffffffff0738,L0xffffffff073c,
               L0xffffffff0740,L0xffffffff0744,L0xffffffff0748,L0xffffffff074c,
               L0xffffffff0750,L0xffffffff0754,L0xffffffff0758,L0xffffffff075c,
               L0xffffffff0760,L0xffffffff0764,L0xffffffff0768,L0xffffffff076c,
               L0xffffffff0770,L0xffffffff0774,L0xffffffff0778,L0xffffffff077c,
               L0xffffffff0780,L0xffffffff0784,L0xffffffff0788,L0xffffffff078c,
               L0xffffffff0790,L0xffffffff0794,L0xffffffff0798,L0xffffffff079c,
               L0xffffffff07a0,L0xffffffff07a4,L0xffffffff07a8,L0xffffffff07ac,
               L0xffffffff07b0,L0xffffffff07b4,L0xffffffff07b8,L0xffffffff07bc,
               L0xffffffff07c0,L0xffffffff07c4,L0xffffffff07c8,L0xffffffff07cc,
               L0xffffffff07d0,L0xffffffff07d4,L0xffffffff07d8,L0xffffffff07dc,
               L0xffffffff07e0,L0xffffffff07e4,L0xffffffff07e8,L0xffffffff07ec,
               L0xffffffff07f0,L0xffffffff07f4,L0xffffffff07f8,L0xffffffff07fc,
               L0xffffffff0800,L0xffffffff0804,L0xffffffff0808,L0xffffffff080c,
               L0xffffffff0810,L0xffffffff0814,L0xffffffff0818,L0xffffffff081c,
               L0xffffffff0820,L0xffffffff0824,L0xffffffff0828,L0xffffffff082c,
               L0xffffffff0830,L0xffffffff0834,L0xffffffff0838,L0xffffffff083c,
               L0xffffffff0840,L0xffffffff0844,L0xffffffff0848,L0xffffffff084c,
               L0xffffffff0850,L0xffffffff0854,L0xffffffff0858,L0xffffffff085c,
               L0xffffffff0860,L0xffffffff0864,L0xffffffff0868,L0xffffffff086c,
               L0xffffffff0870,L0xffffffff0874,L0xffffffff0878,L0xffffffff087c,
               L0xffffffff0880,L0xffffffff0884,L0xffffffff0888,L0xffffffff088c,
               L0xffffffff0890,L0xffffffff0894,L0xffffffff0898,L0xffffffff089c,
               L0xffffffff08a0,L0xffffffff08a4,L0xffffffff08a8,L0xffffffff08ac,
               L0xffffffff08b0,L0xffffffff08b4,L0xffffffff08b8,L0xffffffff08bc,
               L0xffffffff08c0,L0xffffffff08c4,L0xffffffff08c8,L0xffffffff08cc,
               L0xffffffff08d0,L0xffffffff08d4,L0xffffffff08d8,L0xffffffff08dc,
               L0xffffffff08e0,L0xffffffff08e4,L0xffffffff08e8,L0xffffffff08ec,
               L0xffffffff08f0,L0xffffffff08f4,L0xffffffff08f8,L0xffffffff08fc,
               L0xffffffff0900,L0xffffffff0904,L0xffffffff0908,L0xffffffff090c,
               L0xffffffff0910,L0xffffffff0914,L0xffffffff0918,L0xffffffff091c,
               L0xffffffff0920,L0xffffffff0924,L0xffffffff0928,L0xffffffff092c,
               L0xffffffff0930,L0xffffffff0934,L0xffffffff0938,L0xffffffff093c,
               L0xffffffff0940,L0xffffffff0944,L0xffffffff0948,L0xffffffff094c,
               L0xffffffff0950,L0xffffffff0954,L0xffffffff0958,L0xffffffff095c,
               L0xffffffff0960,L0xffffffff0964,L0xffffffff0968,L0xffffffff096c,
               L0xffffffff0970,L0xffffffff0974,L0xffffffff0978,L0xffffffff097c,
               L0xffffffff0980,L0xffffffff0984,L0xffffffff0988,L0xffffffff098c,
               L0xffffffff0990,L0xffffffff0994,L0xffffffff0998,L0xffffffff099c,
               L0xffffffff09a0,L0xffffffff09a4,L0xffffffff09a8,L0xffffffff09ac,
               L0xffffffff09b0,L0xffffffff09b4,L0xffffffff09b8,L0xffffffff09bc,
               L0xffffffff09c0,L0xffffffff09c4,L0xffffffff09c8,L0xffffffff09cc,
               L0xffffffff09d0,L0xffffffff09d4,L0xffffffff09d8,L0xffffffff09dc,
               L0xffffffff09e0,L0xffffffff09e4,L0xffffffff09e8,L0xffffffff09ec,
               L0xffffffff09f0,L0xffffffff09f4,L0xffffffff09f8,L0xffffffff09fc,
               L0xffffffff0a00,L0xffffffff0a04,L0xffffffff0a08,L0xffffffff0a0c])
      (2**32*F**2) [Q, X**256 - 1753**256]
prove with [all ghosts, cuts [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]]
&&
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0610,L0xffffffff0610,L0xffffffff0610,L0xffffffff0610] /\
[L0xffffffff0610,L0xffffffff0610,L0xffffffff0610,L0xffffffff0610]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0620,L0xffffffff0620,L0xffffffff0620,L0xffffffff0620] /\
[L0xffffffff0620,L0xffffffff0620,L0xffffffff0620,L0xffffffff0620]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0630,L0xffffffff0630,L0xffffffff0630,L0xffffffff0630] /\
[L0xffffffff0630,L0xffffffff0630,L0xffffffff0630,L0xffffffff0630]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0640,L0xffffffff0640,L0xffffffff0640,L0xffffffff0640] /\
[L0xffffffff0640,L0xffffffff0640,L0xffffffff0640,L0xffffffff0640]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0650,L0xffffffff0650,L0xffffffff0650,L0xffffffff0650] /\
[L0xffffffff0650,L0xffffffff0650,L0xffffffff0650,L0xffffffff0650]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0660,L0xffffffff0660,L0xffffffff0660,L0xffffffff0660] /\
[L0xffffffff0660,L0xffffffff0660,L0xffffffff0660,L0xffffffff0660]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0670,L0xffffffff0670,L0xffffffff0670,L0xffffffff0670] /\
[L0xffffffff0670,L0xffffffff0670,L0xffffffff0670,L0xffffffff0670]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0680,L0xffffffff0680,L0xffffffff0680,L0xffffffff0680] /\
[L0xffffffff0680,L0xffffffff0680,L0xffffffff0680,L0xffffffff0680]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0690,L0xffffffff0690,L0xffffffff0690,L0xffffffff0690] /\
[L0xffffffff0690,L0xffffffff0690,L0xffffffff0690,L0xffffffff0690]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0] /\
[L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0,L0xffffffff06a0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0] /\
[L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0,L0xffffffff06b0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0] /\
[L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0,L0xffffffff06c0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0] /\
[L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0,L0xffffffff06d0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0] /\
[L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0,L0xffffffff06e0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0] /\
[L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0,L0xffffffff06f0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0700,L0xffffffff0700,L0xffffffff0700,L0xffffffff0700] /\
[L0xffffffff0700,L0xffffffff0700,L0xffffffff0700,L0xffffffff0700]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0710,L0xffffffff0710,L0xffffffff0710,L0xffffffff0710] /\
[L0xffffffff0710,L0xffffffff0710,L0xffffffff0710,L0xffffffff0710]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0720,L0xffffffff0720,L0xffffffff0720,L0xffffffff0720] /\
[L0xffffffff0720,L0xffffffff0720,L0xffffffff0720,L0xffffffff0720]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0730,L0xffffffff0730,L0xffffffff0730,L0xffffffff0730] /\
[L0xffffffff0730,L0xffffffff0730,L0xffffffff0730,L0xffffffff0730]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0740,L0xffffffff0740,L0xffffffff0740,L0xffffffff0740] /\
[L0xffffffff0740,L0xffffffff0740,L0xffffffff0740,L0xffffffff0740]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0750,L0xffffffff0750,L0xffffffff0750,L0xffffffff0750] /\
[L0xffffffff0750,L0xffffffff0750,L0xffffffff0750,L0xffffffff0750]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0760,L0xffffffff0760,L0xffffffff0760,L0xffffffff0760] /\
[L0xffffffff0760,L0xffffffff0760,L0xffffffff0760,L0xffffffff0760]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0770,L0xffffffff0770,L0xffffffff0770,L0xffffffff0770] /\
[L0xffffffff0770,L0xffffffff0770,L0xffffffff0770,L0xffffffff0770]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0780,L0xffffffff0780,L0xffffffff0780,L0xffffffff0780] /\
[L0xffffffff0780,L0xffffffff0780,L0xffffffff0780,L0xffffffff0780]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0790,L0xffffffff0790,L0xffffffff0790,L0xffffffff0790] /\
[L0xffffffff0790,L0xffffffff0790,L0xffffffff0790,L0xffffffff0790]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0] /\
[L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0,L0xffffffff07a0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0] /\
[L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0,L0xffffffff07b0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0] /\
[L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0,L0xffffffff07c0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0] /\
[L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0,L0xffffffff07d0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0] /\
[L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0,L0xffffffff07e0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0] /\
[L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0,L0xffffffff07f0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0800,L0xffffffff0800,L0xffffffff0800,L0xffffffff0800] /\
[L0xffffffff0800,L0xffffffff0800,L0xffffffff0800,L0xffffffff0800]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0810,L0xffffffff0810,L0xffffffff0810,L0xffffffff0810] /\
[L0xffffffff0810,L0xffffffff0810,L0xffffffff0810,L0xffffffff0810]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0820,L0xffffffff0820,L0xffffffff0820,L0xffffffff0820] /\
[L0xffffffff0820,L0xffffffff0820,L0xffffffff0820,L0xffffffff0820]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0830,L0xffffffff0830,L0xffffffff0830,L0xffffffff0830] /\
[L0xffffffff0830,L0xffffffff0830,L0xffffffff0830,L0xffffffff0830]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0840,L0xffffffff0840,L0xffffffff0840,L0xffffffff0840] /\
[L0xffffffff0840,L0xffffffff0840,L0xffffffff0840,L0xffffffff0840]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0850,L0xffffffff0850,L0xffffffff0850,L0xffffffff0850] /\
[L0xffffffff0850,L0xffffffff0850,L0xffffffff0850,L0xffffffff0850]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0860,L0xffffffff0860,L0xffffffff0860,L0xffffffff0860] /\
[L0xffffffff0860,L0xffffffff0860,L0xffffffff0860,L0xffffffff0860]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0870,L0xffffffff0870,L0xffffffff0870,L0xffffffff0870] /\
[L0xffffffff0870,L0xffffffff0870,L0xffffffff0870,L0xffffffff0870]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0880,L0xffffffff0880,L0xffffffff0880,L0xffffffff0880] /\
[L0xffffffff0880,L0xffffffff0880,L0xffffffff0880,L0xffffffff0880]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0890,L0xffffffff0890,L0xffffffff0890,L0xffffffff0890] /\
[L0xffffffff0890,L0xffffffff0890,L0xffffffff0890,L0xffffffff0890]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0] /\
[L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0,L0xffffffff08a0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0] /\
[L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0,L0xffffffff08b0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0] /\
[L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0,L0xffffffff08c0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0] /\
[L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0,L0xffffffff08d0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0] /\
[L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0,L0xffffffff08e0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0] /\
[L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0,L0xffffffff08f0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0900,L0xffffffff0900,L0xffffffff0900,L0xffffffff0900] /\
[L0xffffffff0900,L0xffffffff0900,L0xffffffff0900,L0xffffffff0900]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0910,L0xffffffff0910,L0xffffffff0910,L0xffffffff0910] /\
[L0xffffffff0910,L0xffffffff0910,L0xffffffff0910,L0xffffffff0910]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0920,L0xffffffff0920,L0xffffffff0920,L0xffffffff0920] /\
[L0xffffffff0920,L0xffffffff0920,L0xffffffff0920,L0xffffffff0920]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0930,L0xffffffff0930,L0xffffffff0930,L0xffffffff0930] /\
[L0xffffffff0930,L0xffffffff0930,L0xffffffff0930,L0xffffffff0930]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0940,L0xffffffff0940,L0xffffffff0940,L0xffffffff0940] /\
[L0xffffffff0940,L0xffffffff0940,L0xffffffff0940,L0xffffffff0940]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0950,L0xffffffff0950,L0xffffffff0950,L0xffffffff0950] /\
[L0xffffffff0950,L0xffffffff0950,L0xffffffff0950,L0xffffffff0950]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0960,L0xffffffff0960,L0xffffffff0960,L0xffffffff0960] /\
[L0xffffffff0960,L0xffffffff0960,L0xffffffff0960,L0xffffffff0960]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0970,L0xffffffff0970,L0xffffffff0970,L0xffffffff0970] /\
[L0xffffffff0970,L0xffffffff0970,L0xffffffff0970,L0xffffffff0970]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0980,L0xffffffff0980,L0xffffffff0980,L0xffffffff0980] /\
[L0xffffffff0980,L0xffffffff0980,L0xffffffff0980,L0xffffffff0980]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0990,L0xffffffff0990,L0xffffffff0990,L0xffffffff0990] /\
[L0xffffffff0990,L0xffffffff0990,L0xffffffff0990,L0xffffffff0990]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0] /\
[L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0,L0xffffffff09a0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0] /\
[L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0,L0xffffffff09b0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0] /\
[L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0,L0xffffffff09c0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0] /\
[L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0,L0xffffffff09d0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0] /\
[L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0,L0xffffffff09e0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0] /\
[L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0,L0xffffffff09f0]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00] /\
[L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00,L0xffffffff0a00]<s[Q2,Q2,Q2,Q2]
prove with [cuts [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]]
}

