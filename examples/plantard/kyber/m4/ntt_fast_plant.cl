(* popper: cv.exe -jobs 32 -v -isafety -enable_rewriting:eqmod -slicing ntt_fast_plant.cl
Parsing CryptoLine file:                    [OK]            0.1128 seconds
Checking well-formedness:                   [OK]            0.0382 seconds

Procedure main
==============
Transforming to SSA form:                   [OK]            0.0212 seconds
Normalizing specification:                  [OK]            0.0228 seconds
Rewriting assignments:                      [OK]            0.0248 seconds
Verifying program safety:                   [OK]            257.0894 seconds
Verifying range assertions:                 [OK]            2.8456 seconds
Verifying range specification:              [OK]            0.1489 seconds
Rewriting value-preserved casting:          [OK]            0.0156 seconds
Verifying algebraic assertions:             [OK]            107.9858 seconds
Verifying algebraic specification:          [OK]            22.4484 seconds

Procedure Summary
-----------------
Procedure verification:                     [OK]            390.6153 seconds

Summary
=======
Verification result:                        [OK]            390.7669 seconds
*)

proc main (
int16 L0xbefff1c4,int16 L0xbefff1c6,int16 L0xbefff1c8,int16 L0xbefff1ca,
int16 L0xbefff1cc,int16 L0xbefff1ce,int16 L0xbefff1d0,int16 L0xbefff1d2,
int16 L0xbefff1d4,int16 L0xbefff1d6,int16 L0xbefff1d8,int16 L0xbefff1da,
int16 L0xbefff1dc,int16 L0xbefff1de,int16 L0xbefff1e0,int16 L0xbefff1e2,
int16 L0xbefff1e4,int16 L0xbefff1e6,int16 L0xbefff1e8,int16 L0xbefff1ea,
int16 L0xbefff1ec,int16 L0xbefff1ee,int16 L0xbefff1f0,int16 L0xbefff1f2,
int16 L0xbefff1f4,int16 L0xbefff1f6,int16 L0xbefff1f8,int16 L0xbefff1fa,
int16 L0xbefff1fc,int16 L0xbefff1fe,int16 L0xbefff200,int16 L0xbefff202,
int16 L0xbefff204,int16 L0xbefff206,int16 L0xbefff208,int16 L0xbefff20a,
int16 L0xbefff20c,int16 L0xbefff20e,int16 L0xbefff210,int16 L0xbefff212,
int16 L0xbefff214,int16 L0xbefff216,int16 L0xbefff218,int16 L0xbefff21a,
int16 L0xbefff21c,int16 L0xbefff21e,int16 L0xbefff220,int16 L0xbefff222,
int16 L0xbefff224,int16 L0xbefff226,int16 L0xbefff228,int16 L0xbefff22a,
int16 L0xbefff22c,int16 L0xbefff22e,int16 L0xbefff230,int16 L0xbefff232,
int16 L0xbefff234,int16 L0xbefff236,int16 L0xbefff238,int16 L0xbefff23a,
int16 L0xbefff23c,int16 L0xbefff23e,int16 L0xbefff240,int16 L0xbefff242,
int16 L0xbefff244,int16 L0xbefff246,int16 L0xbefff248,int16 L0xbefff24a,
int16 L0xbefff24c,int16 L0xbefff24e,int16 L0xbefff250,int16 L0xbefff252,
int16 L0xbefff254,int16 L0xbefff256,int16 L0xbefff258,int16 L0xbefff25a,
int16 L0xbefff25c,int16 L0xbefff25e,int16 L0xbefff260,int16 L0xbefff262,
int16 L0xbefff264,int16 L0xbefff266,int16 L0xbefff268,int16 L0xbefff26a,
int16 L0xbefff26c,int16 L0xbefff26e,int16 L0xbefff270,int16 L0xbefff272,
int16 L0xbefff274,int16 L0xbefff276,int16 L0xbefff278,int16 L0xbefff27a,
int16 L0xbefff27c,int16 L0xbefff27e,int16 L0xbefff280,int16 L0xbefff282,
int16 L0xbefff284,int16 L0xbefff286,int16 L0xbefff288,int16 L0xbefff28a,
int16 L0xbefff28c,int16 L0xbefff28e,int16 L0xbefff290,int16 L0xbefff292,
int16 L0xbefff294,int16 L0xbefff296,int16 L0xbefff298,int16 L0xbefff29a,
int16 L0xbefff29c,int16 L0xbefff29e,int16 L0xbefff2a0,int16 L0xbefff2a2,
int16 L0xbefff2a4,int16 L0xbefff2a6,int16 L0xbefff2a8,int16 L0xbefff2aa,
int16 L0xbefff2ac,int16 L0xbefff2ae,int16 L0xbefff2b0,int16 L0xbefff2b2,
int16 L0xbefff2b4,int16 L0xbefff2b6,int16 L0xbefff2b8,int16 L0xbefff2ba,
int16 L0xbefff2bc,int16 L0xbefff2be,int16 L0xbefff2c0,int16 L0xbefff2c2,
int16 L0xbefff2c4,int16 L0xbefff2c6,int16 L0xbefff2c8,int16 L0xbefff2ca,
int16 L0xbefff2cc,int16 L0xbefff2ce,int16 L0xbefff2d0,int16 L0xbefff2d2,
int16 L0xbefff2d4,int16 L0xbefff2d6,int16 L0xbefff2d8,int16 L0xbefff2da,
int16 L0xbefff2dc,int16 L0xbefff2de,int16 L0xbefff2e0,int16 L0xbefff2e2,
int16 L0xbefff2e4,int16 L0xbefff2e6,int16 L0xbefff2e8,int16 L0xbefff2ea,
int16 L0xbefff2ec,int16 L0xbefff2ee,int16 L0xbefff2f0,int16 L0xbefff2f2,
int16 L0xbefff2f4,int16 L0xbefff2f6,int16 L0xbefff2f8,int16 L0xbefff2fa,
int16 L0xbefff2fc,int16 L0xbefff2fe,int16 L0xbefff300,int16 L0xbefff302,
int16 L0xbefff304,int16 L0xbefff306,int16 L0xbefff308,int16 L0xbefff30a,
int16 L0xbefff30c,int16 L0xbefff30e,int16 L0xbefff310,int16 L0xbefff312,
int16 L0xbefff314,int16 L0xbefff316,int16 L0xbefff318,int16 L0xbefff31a,
int16 L0xbefff31c,int16 L0xbefff31e,int16 L0xbefff320,int16 L0xbefff322,
int16 L0xbefff324,int16 L0xbefff326,int16 L0xbefff328,int16 L0xbefff32a,
int16 L0xbefff32c,int16 L0xbefff32e,int16 L0xbefff330,int16 L0xbefff332,
int16 L0xbefff334,int16 L0xbefff336,int16 L0xbefff338,int16 L0xbefff33a,
int16 L0xbefff33c,int16 L0xbefff33e,int16 L0xbefff340,int16 L0xbefff342,
int16 L0xbefff344,int16 L0xbefff346,int16 L0xbefff348,int16 L0xbefff34a,
int16 L0xbefff34c,int16 L0xbefff34e,int16 L0xbefff350,int16 L0xbefff352,
int16 L0xbefff354,int16 L0xbefff356,int16 L0xbefff358,int16 L0xbefff35a,
int16 L0xbefff35c,int16 L0xbefff35e,int16 L0xbefff360,int16 L0xbefff362,
int16 L0xbefff364,int16 L0xbefff366,int16 L0xbefff368,int16 L0xbefff36a,
int16 L0xbefff36c,int16 L0xbefff36e,int16 L0xbefff370,int16 L0xbefff372,
int16 L0xbefff374,int16 L0xbefff376,int16 L0xbefff378,int16 L0xbefff37a,
int16 L0xbefff37c,int16 L0xbefff37e,int16 L0xbefff380,int16 L0xbefff382,
int16 L0xbefff384,int16 L0xbefff386,int16 L0xbefff388,int16 L0xbefff38a,
int16 L0xbefff38c,int16 L0xbefff38e,int16 L0xbefff390,int16 L0xbefff392,
int16 L0xbefff394,int16 L0xbefff396,int16 L0xbefff398,int16 L0xbefff39a,
int16 L0xbefff39c,int16 L0xbefff39e,int16 L0xbefff3a0,int16 L0xbefff3a2,
int16 L0xbefff3a4,int16 L0xbefff3a6,int16 L0xbefff3a8,int16 L0xbefff3aa,
int16 L0xbefff3ac,int16 L0xbefff3ae,int16 L0xbefff3b0,int16 L0xbefff3b2,
int16 L0xbefff3b4,int16 L0xbefff3b6,int16 L0xbefff3b8,int16 L0xbefff3ba,
int16 L0xbefff3bc,int16 L0xbefff3be,int16 L0xbefff3c0,int16 L0xbefff3c2,
int16 Q, int16 Q2, int16 NQ, int16 NQ2
) =
{
Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1c4,L0xbefff1c6,L0xbefff1c8,L0xbefff1ca] /\
[L0xbefff1c4,L0xbefff1c6,L0xbefff1c8,L0xbefff1ca]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1cc,L0xbefff1ce,L0xbefff1d0,L0xbefff1d2] /\
[L0xbefff1cc,L0xbefff1ce,L0xbefff1d0,L0xbefff1d2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1d4,L0xbefff1d6,L0xbefff1d8,L0xbefff1da] /\
[L0xbefff1d4,L0xbefff1d6,L0xbefff1d8,L0xbefff1da]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1dc,L0xbefff1de,L0xbefff1e0,L0xbefff1e2] /\
[L0xbefff1dc,L0xbefff1de,L0xbefff1e0,L0xbefff1e2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1e4,L0xbefff1e6,L0xbefff1e8,L0xbefff1ea] /\
[L0xbefff1e4,L0xbefff1e6,L0xbefff1e8,L0xbefff1ea]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1ec,L0xbefff1ee,L0xbefff1f0,L0xbefff1f2] /\
[L0xbefff1ec,L0xbefff1ee,L0xbefff1f0,L0xbefff1f2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1f4,L0xbefff1f6,L0xbefff1f8,L0xbefff1fa] /\
[L0xbefff1f4,L0xbefff1f6,L0xbefff1f8,L0xbefff1fa]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff1fc,L0xbefff1fe,L0xbefff200,L0xbefff202] /\
[L0xbefff1fc,L0xbefff1fe,L0xbefff200,L0xbefff202]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff204,L0xbefff206,L0xbefff208,L0xbefff20a] /\
[L0xbefff204,L0xbefff206,L0xbefff208,L0xbefff20a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff20c,L0xbefff20e,L0xbefff210,L0xbefff212] /\
[L0xbefff20c,L0xbefff20e,L0xbefff210,L0xbefff212]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff214,L0xbefff216,L0xbefff218,L0xbefff21a] /\
[L0xbefff214,L0xbefff216,L0xbefff218,L0xbefff21a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff21c,L0xbefff21e,L0xbefff220,L0xbefff222] /\
[L0xbefff21c,L0xbefff21e,L0xbefff220,L0xbefff222]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff224,L0xbefff226,L0xbefff228,L0xbefff22a] /\
[L0xbefff224,L0xbefff226,L0xbefff228,L0xbefff22a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff22c,L0xbefff22e,L0xbefff230,L0xbefff232] /\
[L0xbefff22c,L0xbefff22e,L0xbefff230,L0xbefff232]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff234,L0xbefff236,L0xbefff238,L0xbefff23a] /\
[L0xbefff234,L0xbefff236,L0xbefff238,L0xbefff23a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff23c,L0xbefff23e,L0xbefff240,L0xbefff242] /\
[L0xbefff23c,L0xbefff23e,L0xbefff240,L0xbefff242]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff244,L0xbefff246,L0xbefff248,L0xbefff24a] /\
[L0xbefff244,L0xbefff246,L0xbefff248,L0xbefff24a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff24c,L0xbefff24e,L0xbefff250,L0xbefff252] /\
[L0xbefff24c,L0xbefff24e,L0xbefff250,L0xbefff252]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff254,L0xbefff256,L0xbefff258,L0xbefff25a] /\
[L0xbefff254,L0xbefff256,L0xbefff258,L0xbefff25a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff25c,L0xbefff25e,L0xbefff260,L0xbefff262] /\
[L0xbefff25c,L0xbefff25e,L0xbefff260,L0xbefff262]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff264,L0xbefff266,L0xbefff268,L0xbefff26a] /\
[L0xbefff264,L0xbefff266,L0xbefff268,L0xbefff26a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff26c,L0xbefff26e,L0xbefff270,L0xbefff272] /\
[L0xbefff26c,L0xbefff26e,L0xbefff270,L0xbefff272]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff274,L0xbefff276,L0xbefff278,L0xbefff27a] /\
[L0xbefff274,L0xbefff276,L0xbefff278,L0xbefff27a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff27c,L0xbefff27e,L0xbefff280,L0xbefff282] /\
[L0xbefff27c,L0xbefff27e,L0xbefff280,L0xbefff282]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff284,L0xbefff286,L0xbefff288,L0xbefff28a] /\
[L0xbefff284,L0xbefff286,L0xbefff288,L0xbefff28a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff28c,L0xbefff28e,L0xbefff290,L0xbefff292] /\
[L0xbefff28c,L0xbefff28e,L0xbefff290,L0xbefff292]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff294,L0xbefff296,L0xbefff298,L0xbefff29a] /\
[L0xbefff294,L0xbefff296,L0xbefff298,L0xbefff29a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff29c,L0xbefff29e,L0xbefff2a0,L0xbefff2a2] /\
[L0xbefff29c,L0xbefff29e,L0xbefff2a0,L0xbefff2a2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2a4,L0xbefff2a6,L0xbefff2a8,L0xbefff2aa] /\
[L0xbefff2a4,L0xbefff2a6,L0xbefff2a8,L0xbefff2aa]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2ac,L0xbefff2ae,L0xbefff2b0,L0xbefff2b2] /\
[L0xbefff2ac,L0xbefff2ae,L0xbefff2b0,L0xbefff2b2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2b4,L0xbefff2b6,L0xbefff2b8,L0xbefff2ba] /\
[L0xbefff2b4,L0xbefff2b6,L0xbefff2b8,L0xbefff2ba]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2bc,L0xbefff2be,L0xbefff2c0,L0xbefff2c2] /\
[L0xbefff2bc,L0xbefff2be,L0xbefff2c0,L0xbefff2c2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2c4,L0xbefff2c6,L0xbefff2c8,L0xbefff2ca] /\
[L0xbefff2c4,L0xbefff2c6,L0xbefff2c8,L0xbefff2ca]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2cc,L0xbefff2ce,L0xbefff2d0,L0xbefff2d2] /\
[L0xbefff2cc,L0xbefff2ce,L0xbefff2d0,L0xbefff2d2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2d4,L0xbefff2d6,L0xbefff2d8,L0xbefff2da] /\
[L0xbefff2d4,L0xbefff2d6,L0xbefff2d8,L0xbefff2da]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2dc,L0xbefff2de,L0xbefff2e0,L0xbefff2e2] /\
[L0xbefff2dc,L0xbefff2de,L0xbefff2e0,L0xbefff2e2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2e4,L0xbefff2e6,L0xbefff2e8,L0xbefff2ea] /\
[L0xbefff2e4,L0xbefff2e6,L0xbefff2e8,L0xbefff2ea]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2ec,L0xbefff2ee,L0xbefff2f0,L0xbefff2f2] /\
[L0xbefff2ec,L0xbefff2ee,L0xbefff2f0,L0xbefff2f2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2f4,L0xbefff2f6,L0xbefff2f8,L0xbefff2fa] /\
[L0xbefff2f4,L0xbefff2f6,L0xbefff2f8,L0xbefff2fa]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff2fc,L0xbefff2fe,L0xbefff300,L0xbefff302] /\
[L0xbefff2fc,L0xbefff2fe,L0xbefff300,L0xbefff302]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff304,L0xbefff306,L0xbefff308,L0xbefff30a] /\
[L0xbefff304,L0xbefff306,L0xbefff308,L0xbefff30a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff30c,L0xbefff30e,L0xbefff310,L0xbefff312] /\
[L0xbefff30c,L0xbefff30e,L0xbefff310,L0xbefff312]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff314,L0xbefff316,L0xbefff318,L0xbefff31a] /\
[L0xbefff314,L0xbefff316,L0xbefff318,L0xbefff31a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff31c,L0xbefff31e,L0xbefff320,L0xbefff322] /\
[L0xbefff31c,L0xbefff31e,L0xbefff320,L0xbefff322]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff324,L0xbefff326,L0xbefff328,L0xbefff32a] /\
[L0xbefff324,L0xbefff326,L0xbefff328,L0xbefff32a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff32c,L0xbefff32e,L0xbefff330,L0xbefff332] /\
[L0xbefff32c,L0xbefff32e,L0xbefff330,L0xbefff332]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff334,L0xbefff336,L0xbefff338,L0xbefff33a] /\
[L0xbefff334,L0xbefff336,L0xbefff338,L0xbefff33a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff33c,L0xbefff33e,L0xbefff340,L0xbefff342] /\
[L0xbefff33c,L0xbefff33e,L0xbefff340,L0xbefff342]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff344,L0xbefff346,L0xbefff348,L0xbefff34a] /\
[L0xbefff344,L0xbefff346,L0xbefff348,L0xbefff34a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff34c,L0xbefff34e,L0xbefff350,L0xbefff352] /\
[L0xbefff34c,L0xbefff34e,L0xbefff350,L0xbefff352]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff354,L0xbefff356,L0xbefff358,L0xbefff35a] /\
[L0xbefff354,L0xbefff356,L0xbefff358,L0xbefff35a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff35c,L0xbefff35e,L0xbefff360,L0xbefff362] /\
[L0xbefff35c,L0xbefff35e,L0xbefff360,L0xbefff362]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff364,L0xbefff366,L0xbefff368,L0xbefff36a] /\
[L0xbefff364,L0xbefff366,L0xbefff368,L0xbefff36a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff36c,L0xbefff36e,L0xbefff370,L0xbefff372] /\
[L0xbefff36c,L0xbefff36e,L0xbefff370,L0xbefff372]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff374,L0xbefff376,L0xbefff378,L0xbefff37a] /\
[L0xbefff374,L0xbefff376,L0xbefff378,L0xbefff37a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff37c,L0xbefff37e,L0xbefff380,L0xbefff382] /\
[L0xbefff37c,L0xbefff37e,L0xbefff380,L0xbefff382]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff384,L0xbefff386,L0xbefff388,L0xbefff38a] /\
[L0xbefff384,L0xbefff386,L0xbefff388,L0xbefff38a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff38c,L0xbefff38e,L0xbefff390,L0xbefff392] /\
[L0xbefff38c,L0xbefff38e,L0xbefff390,L0xbefff392]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff394,L0xbefff396,L0xbefff398,L0xbefff39a] /\
[L0xbefff394,L0xbefff396,L0xbefff398,L0xbefff39a]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff39c,L0xbefff39e,L0xbefff3a0,L0xbefff3a2] /\
[L0xbefff39c,L0xbefff39e,L0xbefff3a0,L0xbefff3a2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff3a4,L0xbefff3a6,L0xbefff3a8,L0xbefff3aa] /\
[L0xbefff3a4,L0xbefff3a6,L0xbefff3a8,L0xbefff3aa]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff3ac,L0xbefff3ae,L0xbefff3b0,L0xbefff3b2] /\
[L0xbefff3ac,L0xbefff3ae,L0xbefff3b0,L0xbefff3b2]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff3b4,L0xbefff3b6,L0xbefff3b8,L0xbefff3ba] /\
[L0xbefff3b4,L0xbefff3b6,L0xbefff3b8,L0xbefff3ba]<[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<[L0xbefff3bc,L0xbefff3be,L0xbefff3c0,L0xbefff3c2] /\
[L0xbefff3bc,L0xbefff3be,L0xbefff3c0,L0xbefff3c2]<[Q2,Q2,Q2,Q2]
&&
Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1c4,L0xbefff1c6,L0xbefff1c8,L0xbefff1ca] /\
[L0xbefff1c4,L0xbefff1c6,L0xbefff1c8,L0xbefff1ca]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1cc,L0xbefff1ce,L0xbefff1d0,L0xbefff1d2] /\
[L0xbefff1cc,L0xbefff1ce,L0xbefff1d0,L0xbefff1d2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1d4,L0xbefff1d6,L0xbefff1d8,L0xbefff1da] /\
[L0xbefff1d4,L0xbefff1d6,L0xbefff1d8,L0xbefff1da]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1dc,L0xbefff1de,L0xbefff1e0,L0xbefff1e2] /\
[L0xbefff1dc,L0xbefff1de,L0xbefff1e0,L0xbefff1e2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1e4,L0xbefff1e6,L0xbefff1e8,L0xbefff1ea] /\
[L0xbefff1e4,L0xbefff1e6,L0xbefff1e8,L0xbefff1ea]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1ec,L0xbefff1ee,L0xbefff1f0,L0xbefff1f2] /\
[L0xbefff1ec,L0xbefff1ee,L0xbefff1f0,L0xbefff1f2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1f4,L0xbefff1f6,L0xbefff1f8,L0xbefff1fa] /\
[L0xbefff1f4,L0xbefff1f6,L0xbefff1f8,L0xbefff1fa]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff1fc,L0xbefff1fe,L0xbefff200,L0xbefff202] /\
[L0xbefff1fc,L0xbefff1fe,L0xbefff200,L0xbefff202]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff204,L0xbefff206,L0xbefff208,L0xbefff20a] /\
[L0xbefff204,L0xbefff206,L0xbefff208,L0xbefff20a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff20c,L0xbefff20e,L0xbefff210,L0xbefff212] /\
[L0xbefff20c,L0xbefff20e,L0xbefff210,L0xbefff212]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff214,L0xbefff216,L0xbefff218,L0xbefff21a] /\
[L0xbefff214,L0xbefff216,L0xbefff218,L0xbefff21a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff21c,L0xbefff21e,L0xbefff220,L0xbefff222] /\
[L0xbefff21c,L0xbefff21e,L0xbefff220,L0xbefff222]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff224,L0xbefff226,L0xbefff228,L0xbefff22a] /\
[L0xbefff224,L0xbefff226,L0xbefff228,L0xbefff22a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff22c,L0xbefff22e,L0xbefff230,L0xbefff232] /\
[L0xbefff22c,L0xbefff22e,L0xbefff230,L0xbefff232]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff234,L0xbefff236,L0xbefff238,L0xbefff23a] /\
[L0xbefff234,L0xbefff236,L0xbefff238,L0xbefff23a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff23c,L0xbefff23e,L0xbefff240,L0xbefff242] /\
[L0xbefff23c,L0xbefff23e,L0xbefff240,L0xbefff242]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff244,L0xbefff246,L0xbefff248,L0xbefff24a] /\
[L0xbefff244,L0xbefff246,L0xbefff248,L0xbefff24a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff24c,L0xbefff24e,L0xbefff250,L0xbefff252] /\
[L0xbefff24c,L0xbefff24e,L0xbefff250,L0xbefff252]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff254,L0xbefff256,L0xbefff258,L0xbefff25a] /\
[L0xbefff254,L0xbefff256,L0xbefff258,L0xbefff25a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff25c,L0xbefff25e,L0xbefff260,L0xbefff262] /\
[L0xbefff25c,L0xbefff25e,L0xbefff260,L0xbefff262]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff264,L0xbefff266,L0xbefff268,L0xbefff26a] /\
[L0xbefff264,L0xbefff266,L0xbefff268,L0xbefff26a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff26c,L0xbefff26e,L0xbefff270,L0xbefff272] /\
[L0xbefff26c,L0xbefff26e,L0xbefff270,L0xbefff272]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff274,L0xbefff276,L0xbefff278,L0xbefff27a] /\
[L0xbefff274,L0xbefff276,L0xbefff278,L0xbefff27a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff27c,L0xbefff27e,L0xbefff280,L0xbefff282] /\
[L0xbefff27c,L0xbefff27e,L0xbefff280,L0xbefff282]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff284,L0xbefff286,L0xbefff288,L0xbefff28a] /\
[L0xbefff284,L0xbefff286,L0xbefff288,L0xbefff28a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff28c,L0xbefff28e,L0xbefff290,L0xbefff292] /\
[L0xbefff28c,L0xbefff28e,L0xbefff290,L0xbefff292]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff294,L0xbefff296,L0xbefff298,L0xbefff29a] /\
[L0xbefff294,L0xbefff296,L0xbefff298,L0xbefff29a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff29c,L0xbefff29e,L0xbefff2a0,L0xbefff2a2] /\
[L0xbefff29c,L0xbefff29e,L0xbefff2a0,L0xbefff2a2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2a4,L0xbefff2a6,L0xbefff2a8,L0xbefff2aa] /\
[L0xbefff2a4,L0xbefff2a6,L0xbefff2a8,L0xbefff2aa]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2ac,L0xbefff2ae,L0xbefff2b0,L0xbefff2b2] /\
[L0xbefff2ac,L0xbefff2ae,L0xbefff2b0,L0xbefff2b2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2b4,L0xbefff2b6,L0xbefff2b8,L0xbefff2ba] /\
[L0xbefff2b4,L0xbefff2b6,L0xbefff2b8,L0xbefff2ba]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2bc,L0xbefff2be,L0xbefff2c0,L0xbefff2c2] /\
[L0xbefff2bc,L0xbefff2be,L0xbefff2c0,L0xbefff2c2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2c4,L0xbefff2c6,L0xbefff2c8,L0xbefff2ca] /\
[L0xbefff2c4,L0xbefff2c6,L0xbefff2c8,L0xbefff2ca]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2cc,L0xbefff2ce,L0xbefff2d0,L0xbefff2d2] /\
[L0xbefff2cc,L0xbefff2ce,L0xbefff2d0,L0xbefff2d2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2d4,L0xbefff2d6,L0xbefff2d8,L0xbefff2da] /\
[L0xbefff2d4,L0xbefff2d6,L0xbefff2d8,L0xbefff2da]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2dc,L0xbefff2de,L0xbefff2e0,L0xbefff2e2] /\
[L0xbefff2dc,L0xbefff2de,L0xbefff2e0,L0xbefff2e2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2e4,L0xbefff2e6,L0xbefff2e8,L0xbefff2ea] /\
[L0xbefff2e4,L0xbefff2e6,L0xbefff2e8,L0xbefff2ea]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2ec,L0xbefff2ee,L0xbefff2f0,L0xbefff2f2] /\
[L0xbefff2ec,L0xbefff2ee,L0xbefff2f0,L0xbefff2f2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2f4,L0xbefff2f6,L0xbefff2f8,L0xbefff2fa] /\
[L0xbefff2f4,L0xbefff2f6,L0xbefff2f8,L0xbefff2fa]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff2fc,L0xbefff2fe,L0xbefff300,L0xbefff302] /\
[L0xbefff2fc,L0xbefff2fe,L0xbefff300,L0xbefff302]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff304,L0xbefff306,L0xbefff308,L0xbefff30a] /\
[L0xbefff304,L0xbefff306,L0xbefff308,L0xbefff30a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff30c,L0xbefff30e,L0xbefff310,L0xbefff312] /\
[L0xbefff30c,L0xbefff30e,L0xbefff310,L0xbefff312]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff314,L0xbefff316,L0xbefff318,L0xbefff31a] /\
[L0xbefff314,L0xbefff316,L0xbefff318,L0xbefff31a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff31c,L0xbefff31e,L0xbefff320,L0xbefff322] /\
[L0xbefff31c,L0xbefff31e,L0xbefff320,L0xbefff322]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff324,L0xbefff326,L0xbefff328,L0xbefff32a] /\
[L0xbefff324,L0xbefff326,L0xbefff328,L0xbefff32a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff32c,L0xbefff32e,L0xbefff330,L0xbefff332] /\
[L0xbefff32c,L0xbefff32e,L0xbefff330,L0xbefff332]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff334,L0xbefff336,L0xbefff338,L0xbefff33a] /\
[L0xbefff334,L0xbefff336,L0xbefff338,L0xbefff33a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff33c,L0xbefff33e,L0xbefff340,L0xbefff342] /\
[L0xbefff33c,L0xbefff33e,L0xbefff340,L0xbefff342]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff344,L0xbefff346,L0xbefff348,L0xbefff34a] /\
[L0xbefff344,L0xbefff346,L0xbefff348,L0xbefff34a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff34c,L0xbefff34e,L0xbefff350,L0xbefff352] /\
[L0xbefff34c,L0xbefff34e,L0xbefff350,L0xbefff352]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff354,L0xbefff356,L0xbefff358,L0xbefff35a] /\
[L0xbefff354,L0xbefff356,L0xbefff358,L0xbefff35a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff35c,L0xbefff35e,L0xbefff360,L0xbefff362] /\
[L0xbefff35c,L0xbefff35e,L0xbefff360,L0xbefff362]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff364,L0xbefff366,L0xbefff368,L0xbefff36a] /\
[L0xbefff364,L0xbefff366,L0xbefff368,L0xbefff36a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff36c,L0xbefff36e,L0xbefff370,L0xbefff372] /\
[L0xbefff36c,L0xbefff36e,L0xbefff370,L0xbefff372]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff374,L0xbefff376,L0xbefff378,L0xbefff37a] /\
[L0xbefff374,L0xbefff376,L0xbefff378,L0xbefff37a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff37c,L0xbefff37e,L0xbefff380,L0xbefff382] /\
[L0xbefff37c,L0xbefff37e,L0xbefff380,L0xbefff382]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff384,L0xbefff386,L0xbefff388,L0xbefff38a] /\
[L0xbefff384,L0xbefff386,L0xbefff388,L0xbefff38a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff38c,L0xbefff38e,L0xbefff390,L0xbefff392] /\
[L0xbefff38c,L0xbefff38e,L0xbefff390,L0xbefff392]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff394,L0xbefff396,L0xbefff398,L0xbefff39a] /\
[L0xbefff394,L0xbefff396,L0xbefff398,L0xbefff39a]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff39c,L0xbefff39e,L0xbefff3a0,L0xbefff3a2] /\
[L0xbefff39c,L0xbefff39e,L0xbefff3a0,L0xbefff3a2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff3a4,L0xbefff3a6,L0xbefff3a8,L0xbefff3aa] /\
[L0xbefff3a4,L0xbefff3a6,L0xbefff3a8,L0xbefff3aa]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff3ac,L0xbefff3ae,L0xbefff3b0,L0xbefff3b2] /\
[L0xbefff3ac,L0xbefff3ae,L0xbefff3b0,L0xbefff3b2]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff3b4,L0xbefff3b6,L0xbefff3b8,L0xbefff3ba] /\
[L0xbefff3b4,L0xbefff3b6,L0xbefff3b8,L0xbefff3ba]<s[Q2,Q2,Q2,Q2] /\
[NQ2,NQ2,NQ2,NQ2]<s[L0xbefff3bc,L0xbefff3be,L0xbefff3c0,L0xbefff3c2] /\
[L0xbefff3bc,L0xbefff3be,L0xbefff3c0,L0xbefff3c2]<s[Q2,Q2,Q2,Q2]
}

nondet r0@int32;

(**************** initialization ****************)


mov L0x40167c (-2064267850)@int32; (* -1600 *)
mov L0x401680 ( -966335387)@int32; (*  -749 *)
mov L0x401684 (  -51606696)@int32; (*   -40 *)
mov L0x401688 ( -886345008)@int32; (*  -687 *)
mov L0x40168c (  812805467)@int32; (*   630 *)
mov L0x401690 (-1847519726)@int32; (* -1432 *)
mov L0x401694 ( 1094061961)@int32; (*   848 *)
mov L0x401698 ( 1370157786)@int32; (*  1062 *)
mov L0x40169c (-1819136043)@int32; (* -1410 *)
mov L0x4016a0 (  249002310)@int32; (*   193 *)
mov L0x4016a4 ( 1028263423)@int32; (*   797 *)
mov L0x4016a8 ( -700560901)@int32; (*  -543 *)
mov L0x4016ac (  -89021551)@int32; (*   -69 *)
mov L0x4016b0 (  734105255)@int32; (*   569 *)
mov L0x4016b4 (-2042335004)@int32; (* -1583 *)
mov L0x4016b8 (  381889553)@int32; (*   296 *)
mov L0x4016bc (  372858381)@int32; (*   289 *)
mov L0x4016c0 (  427045412)@int32; (*   331 *)
mov L0x4016c4 (   21932846)@int32; (*    17 *)
mov L0x4016c8 ( -732815086)@int32; (*  -568 *)
mov L0x4016cc (  752167598)@int32; (*   583 *)
mov L0x4016d0 ( -877313836)@int32; (*  -680 *)
mov L0x4016d4 (-1137927652)@int32; (*  -882 *)
mov L0x4016d8 (  -98052722)@int32; (*   -76 *)
mov L0x4016dc (-2029433330)@int32; (* -1573 *)
mov L0x4016e0 ( 2112004045)@int32; (*  1637 *)
mov L0x4016e4 (  932791035)@int32; (*   723 *)
mov L0x4016e8 (-1343064270)@int32; (* -1041 *)
mov L0x4016ec ( 1419184148)@int32; (*  1100 *)
mov L0x4016f0 ( 1727534158)@int32; (*  1339 *)
mov L0x4016f4 ( 1544330386)@int32; (*  1197 *)
mov L0x4016f8 (-1322421591)@int32; (* -1025 *)
mov L0x4016fc ( 1817845876)@int32; (*  1409 *)
mov L0x401700 ( -860541660)@int32; (*  -667 *)
mov L0x401704 (  -61928035)@int32; (*   -48 *)
mov L0x401708 (  300609006)@int32; (*   233 *)
mov L0x40170c ( 1904287092)@int32; (*  1476 *)
mov L0x401710 (-1357256111)@int32; (* -1052 *)
mov L0x401714 (-1643673275)@int32; (* -1274 *)
mov L0x401718 (  975366560)@int32; (*   756 *)
mov L0x40171c (-1513366367)@int32; (* -1173 *)
mov L0x401720 ( -405112565)@int32; (*  -314 *)
mov L0x401724 ( -359956706)@int32; (*  -279 *)
mov L0x401728 ( -365117376)@int32; (*  -283 *)
mov L0x40172c (  838608815)@int32; (*   650 *)
mov L0x401730 (-1744306333)@int32; (* -1352 *)
mov L0x401734 (-2097812202)@int32; (* -1626 *)
mov L0x401738 ( 2130066389)@int32; (*  1651 *)
mov L0x40173c ( -696690399)@int32; (*  -540 *)
mov L0x401740 (-1986857805)@int32; (* -1540 *)
mov L0x401744 (   72249375)@int32; (*    56 *)
mov L0x401748 (-1052776603)@int32; (*  -816 *)
mov L0x40174c (  815385801)@int32; (*   632 *)
mov L0x401750 (-1912028096)@int32; (* -1482 *)
mov L0x401754 ( 1228239371)@int32; (*   952 *)
mov L0x401758 ( 1884934581)@int32; (*  1461 *)
mov L0x40175c ( -828287474)@int32; (*  -642 *)
mov L0x401760 (-1404992305)@int32; (* -1089 *)
mov L0x401764 ( -598637676)@int32; (*  -464 *)
mov L0x401768 (   42575525)@int32; (*    33 *)
mov L0x40176c ( 1211467195)@int32; (*   939 *)
mov L0x401770 (-1317260921)@int32; (* -1021 *)
mov L0x401774 (-1150829326)@int32; (*  -892 *)
mov L0x401778 (-1214047529)@int32; (*  -941 *)
mov L0x40177c ( 1719793153)@int32; (*  1333 *)
mov L0x401780 ( 1703020977)@int32; (*  1320 *)
mov L0x401784 (-1824296712)@int32; (* -1414 *)
mov L0x401788 (  945692709)@int32; (*   733 *)
mov L0x40178c (-1279846067)@int32; (*  -992 *)
mov L0x401790 (  345764865)@int32; (*   268 *)
mov L0x401794 (  826997308)@int32; (*   641 *)
mov L0x401798 ( 1839778722)@int32; (*  1426 *)
mov L0x40179c (-1303069080)@int32; (* -1010 *)
mov L0x4017a0 ( 1851390229)@int32; (*  1435 *)
mov L0x4017a4 ( 2043625172)@int32; (*  1584 *)
mov L0x4017a8 (-1330162596)@int32; (* -1031 *)
mov L0x4017ac (-1666896289)@int32; (* -1292 *)
mov L0x4017b0 ( -140628247)@int32; (*  -109 *)
mov L0x4017b4 (-1593356746)@int32; (* -1235 *)
mov L0x4017b8 ( 1041165097)@int32; (*   807 *)
mov L0x4017bc (  583155668)@int32; (*   452 *)
mov L0x4017c0 (  483812778)@int32; (*   375 *)
mov L0x4017c4 (-1006330577)@int32; (*  -780 *)
mov L0x4017c8 (-1598517416)@int32; (* -1239 *)
mov L0x4017cc ( 2122325384)@int32; (*  1645 *)
mov L0x4017d0 (  690239563)@int32; (*   535 *)
mov L0x4017d4 ( 1855260731)@int32; (*  1438 *)
mov L0x4017d8 ( -594767174)@int32; (*  -461 *)
mov L0x4017dc ( 1371447954)@int32; (*  1063 *)
mov L0x4017e0 (  411563403)@int32; (*   319 *)
mov L0x4017e4 ( -717333077)@int32; (*  -556 *)
mov L0x4017e8 (  976656727)@int32; (*   757 *)
mov L0x4017ec ( -576704830)@int32; (*  -447 *)
mov L0x4017f0 ( 1979116802)@int32; (*  1534 *)
mov L0x4017f4 (-1195985185)@int32; (*  -927 *)
mov L0x4017f8 (-1586905909)@int32; (* -1230 *)
mov L0x4017fc (  723783916)@int32; (*   561 *)
mov L0x401800 (-1113414471)@int32; (*  -863 *)
mov L0x401804 ( -948273043)@int32; (*  -735 *)
mov L0x401808 (-1207596692)@int32; (*  -936 *)
mov L0x40180c ( -879894171)@int32; (*  -682 *)
mov L0x401810 ( -918599193)@int32; (*  -712 *)
mov L0x401814 ( -677337888)@int32; (*  -525 *)
mov L0x401818 ( 1408862808)@int32; (*  1092 *)
mov L0x40181c (  519937465)@int32; (*   403 *)
mov L0x401820 ( 1323711759)@int32; (*  1026 *)
mov L0x401824 ( -580575332)@int32; (*  -450 *)
mov L0x401828 ( 1910737929)@int32; (*  1481 *)
mov L0x40182c (  836028480)@int32; (*   648 *)
mov L0x401830 ( 1474661346)@int32; (*  1143 *)
mov L0x401834 (-1521107372)@int32; (* -1179 *)
mov L0x401838 ( -714752743)@int32; (*  -554 *)
mov L0x40183c ( 1143088323)@int32; (*   886 *)
mov L0x401840 (-1748176835)@int32; (* -1355 *)
mov L0x401844 (-1103093132)@int32; (*  -855 *)
mov L0x401848 ( -282546662)@int32; (*  -219 *)
mov L0x40184c (-2073299022)@int32; (* -1607 *)
mov L0x401850 ( 1563682897)@int32; (*  1212 *)
mov L0x401854 (-1877193576)@int32; (* -1455 *)
mov L0x401858 ( 1327582262)@int32; (*  1029 *)
mov L0x40185c ( 1059227441)@int32; (*   821 *)
mov L0x401860 ( 1583035408)@int32; (*  1227 *)
mov L0x401864 ( 1174052340)@int32; (*   910 *)
mov L0x401868 (-1572714068)@int32; (* -1219 *)
mov L0x40186c ( -508325958)@int32; (*  -394 *)
mov L0x401870 ( 1141798155)@int32; (*   885 *)
mov L0x401874 (-1515946702)@int32; (* -1175 *)
mov L0x401878 (          0)@int32; (*     0 *)

(**************** functions ****************)


ghost X@int16, F@int16 : F**2 =
L0xbefff1c4*X**  0+L0xbefff1c6*X**  1+L0xbefff1c8*X**  2+L0xbefff1ca*X**  3+
L0xbefff1cc*X**  4+L0xbefff1ce*X**  5+L0xbefff1d0*X**  6+L0xbefff1d2*X**  7+
L0xbefff1d4*X**  8+L0xbefff1d6*X**  9+L0xbefff1d8*X** 10+L0xbefff1da*X** 11+
L0xbefff1dc*X** 12+L0xbefff1de*X** 13+L0xbefff1e0*X** 14+L0xbefff1e2*X** 15+
L0xbefff1e4*X** 16+L0xbefff1e6*X** 17+L0xbefff1e8*X** 18+L0xbefff1ea*X** 19+
L0xbefff1ec*X** 20+L0xbefff1ee*X** 21+L0xbefff1f0*X** 22+L0xbefff1f2*X** 23+
L0xbefff1f4*X** 24+L0xbefff1f6*X** 25+L0xbefff1f8*X** 26+L0xbefff1fa*X** 27+
L0xbefff1fc*X** 28+L0xbefff1fe*X** 29+L0xbefff200*X** 30+L0xbefff202*X** 31+
L0xbefff204*X** 32+L0xbefff206*X** 33+L0xbefff208*X** 34+L0xbefff20a*X** 35+
L0xbefff20c*X** 36+L0xbefff20e*X** 37+L0xbefff210*X** 38+L0xbefff212*X** 39+
L0xbefff214*X** 40+L0xbefff216*X** 41+L0xbefff218*X** 42+L0xbefff21a*X** 43+
L0xbefff21c*X** 44+L0xbefff21e*X** 45+L0xbefff220*X** 46+L0xbefff222*X** 47+
L0xbefff224*X** 48+L0xbefff226*X** 49+L0xbefff228*X** 50+L0xbefff22a*X** 51+
L0xbefff22c*X** 52+L0xbefff22e*X** 53+L0xbefff230*X** 54+L0xbefff232*X** 55+
L0xbefff234*X** 56+L0xbefff236*X** 57+L0xbefff238*X** 58+L0xbefff23a*X** 59+
L0xbefff23c*X** 60+L0xbefff23e*X** 61+L0xbefff240*X** 62+L0xbefff242*X** 63+
L0xbefff244*X** 64+L0xbefff246*X** 65+L0xbefff248*X** 66+L0xbefff24a*X** 67+
L0xbefff24c*X** 68+L0xbefff24e*X** 69+L0xbefff250*X** 70+L0xbefff252*X** 71+
L0xbefff254*X** 72+L0xbefff256*X** 73+L0xbefff258*X** 74+L0xbefff25a*X** 75+
L0xbefff25c*X** 76+L0xbefff25e*X** 77+L0xbefff260*X** 78+L0xbefff262*X** 79+
L0xbefff264*X** 80+L0xbefff266*X** 81+L0xbefff268*X** 82+L0xbefff26a*X** 83+
L0xbefff26c*X** 84+L0xbefff26e*X** 85+L0xbefff270*X** 86+L0xbefff272*X** 87+
L0xbefff274*X** 88+L0xbefff276*X** 89+L0xbefff278*X** 90+L0xbefff27a*X** 91+
L0xbefff27c*X** 92+L0xbefff27e*X** 93+L0xbefff280*X** 94+L0xbefff282*X** 95+
L0xbefff284*X** 96+L0xbefff286*X** 97+L0xbefff288*X** 98+L0xbefff28a*X** 99+
L0xbefff28c*X**100+L0xbefff28e*X**101+L0xbefff290*X**102+L0xbefff292*X**103+
L0xbefff294*X**104+L0xbefff296*X**105+L0xbefff298*X**106+L0xbefff29a*X**107+
L0xbefff29c*X**108+L0xbefff29e*X**109+L0xbefff2a0*X**110+L0xbefff2a2*X**111+
L0xbefff2a4*X**112+L0xbefff2a6*X**113+L0xbefff2a8*X**114+L0xbefff2aa*X**115+
L0xbefff2ac*X**116+L0xbefff2ae*X**117+L0xbefff2b0*X**118+L0xbefff2b2*X**119+
L0xbefff2b4*X**120+L0xbefff2b6*X**121+L0xbefff2b8*X**122+L0xbefff2ba*X**123+
L0xbefff2bc*X**124+L0xbefff2be*X**125+L0xbefff2c0*X**126+L0xbefff2c2*X**127+
L0xbefff2c4*X**128+L0xbefff2c6*X**129+L0xbefff2c8*X**130+L0xbefff2ca*X**131+
L0xbefff2cc*X**132+L0xbefff2ce*X**133+L0xbefff2d0*X**134+L0xbefff2d2*X**135+
L0xbefff2d4*X**136+L0xbefff2d6*X**137+L0xbefff2d8*X**138+L0xbefff2da*X**139+
L0xbefff2dc*X**140+L0xbefff2de*X**141+L0xbefff2e0*X**142+L0xbefff2e2*X**143+
L0xbefff2e4*X**144+L0xbefff2e6*X**145+L0xbefff2e8*X**146+L0xbefff2ea*X**147+
L0xbefff2ec*X**148+L0xbefff2ee*X**149+L0xbefff2f0*X**150+L0xbefff2f2*X**151+
L0xbefff2f4*X**152+L0xbefff2f6*X**153+L0xbefff2f8*X**154+L0xbefff2fa*X**155+
L0xbefff2fc*X**156+L0xbefff2fe*X**157+L0xbefff300*X**158+L0xbefff302*X**159+
L0xbefff304*X**160+L0xbefff306*X**161+L0xbefff308*X**162+L0xbefff30a*X**163+
L0xbefff30c*X**164+L0xbefff30e*X**165+L0xbefff310*X**166+L0xbefff312*X**167+
L0xbefff314*X**168+L0xbefff316*X**169+L0xbefff318*X**170+L0xbefff31a*X**171+
L0xbefff31c*X**172+L0xbefff31e*X**173+L0xbefff320*X**174+L0xbefff322*X**175+
L0xbefff324*X**176+L0xbefff326*X**177+L0xbefff328*X**178+L0xbefff32a*X**179+
L0xbefff32c*X**180+L0xbefff32e*X**181+L0xbefff330*X**182+L0xbefff332*X**183+
L0xbefff334*X**184+L0xbefff336*X**185+L0xbefff338*X**186+L0xbefff33a*X**187+
L0xbefff33c*X**188+L0xbefff33e*X**189+L0xbefff340*X**190+L0xbefff342*X**191+
L0xbefff344*X**192+L0xbefff346*X**193+L0xbefff348*X**194+L0xbefff34a*X**195+
L0xbefff34c*X**196+L0xbefff34e*X**197+L0xbefff350*X**198+L0xbefff352*X**199+
L0xbefff354*X**200+L0xbefff356*X**201+L0xbefff358*X**202+L0xbefff35a*X**203+
L0xbefff35c*X**204+L0xbefff35e*X**205+L0xbefff360*X**206+L0xbefff362*X**207+
L0xbefff364*X**208+L0xbefff366*X**209+L0xbefff368*X**210+L0xbefff36a*X**211+
L0xbefff36c*X**212+L0xbefff36e*X**213+L0xbefff370*X**214+L0xbefff372*X**215+
L0xbefff374*X**216+L0xbefff376*X**217+L0xbefff378*X**218+L0xbefff37a*X**219+
L0xbefff37c*X**220+L0xbefff37e*X**221+L0xbefff380*X**222+L0xbefff382*X**223+
L0xbefff384*X**224+L0xbefff386*X**225+L0xbefff388*X**226+L0xbefff38a*X**227+
L0xbefff38c*X**228+L0xbefff38e*X**229+L0xbefff390*X**230+L0xbefff392*X**231+
L0xbefff394*X**232+L0xbefff396*X**233+L0xbefff398*X**234+L0xbefff39a*X**235+
L0xbefff39c*X**236+L0xbefff39e*X**237+L0xbefff3a0*X**238+L0xbefff3a2*X**239+
L0xbefff3a4*X**240+L0xbefff3a6*X**241+L0xbefff3a8*X**242+L0xbefff3aa*X**243+
L0xbefff3ac*X**244+L0xbefff3ae*X**245+L0xbefff3b0*X**246+L0xbefff3b2*X**247+
L0xbefff3b4*X**248+L0xbefff3b6*X**249+L0xbefff3b8*X**250+L0xbefff3ba*X**251+
L0xbefff3bc*X**252+L0xbefff3be*X**253+L0xbefff3c0*X**254+L0xbefff3c2*X**255
&& true;
ghost F0@int16 : F0**2 =
L0xbefff1e4*X** 16+L0xbefff1e6*X** 17+L0xbefff224*X** 48+L0xbefff226*X** 49+
L0xbefff264*X** 80+L0xbefff266*X** 81+L0xbefff2a4*X**112+L0xbefff2a6*X**113+
L0xbefff2e4*X**144+L0xbefff2e6*X**145+L0xbefff324*X**176+L0xbefff326*X**177+
L0xbefff364*X**208+L0xbefff366*X**209+L0xbefff3a4*X**240+L0xbefff3a6*X**241
&& true;
ghost F1@int16 : F1**2 =
L0xbefff1c4*X**  0+L0xbefff1c6*X**  1+L0xbefff204*X** 32+L0xbefff206*X** 33+
L0xbefff244*X** 64+L0xbefff246*X** 65+L0xbefff284*X** 96+L0xbefff286*X** 97+
L0xbefff2c4*X**128+L0xbefff2c6*X**129+L0xbefff304*X**160+L0xbefff306*X**161+
L0xbefff344*X**192+L0xbefff346*X**193+L0xbefff384*X**224+L0xbefff386*X**225
&& true;
ghost F2@int16 : F2**2 =
L0xbefff1e8*X** 18+L0xbefff1ea*X** 19+L0xbefff228*X** 50+L0xbefff22a*X** 51+
L0xbefff268*X** 82+L0xbefff26a*X** 83+L0xbefff2a8*X**114+L0xbefff2aa*X**115+
L0xbefff2e8*X**146+L0xbefff2ea*X**147+L0xbefff328*X**178+L0xbefff32a*X**179+
L0xbefff368*X**210+L0xbefff36a*X**211+L0xbefff3a8*X**242+L0xbefff3aa*X**243
&& true;
ghost F3@int16 : F3**2 =
L0xbefff1c8*X**  2+L0xbefff1ca*X**  3+L0xbefff208*X** 34+L0xbefff20a*X** 35+
L0xbefff248*X** 66+L0xbefff24a*X** 67+L0xbefff288*X** 98+L0xbefff28a*X** 99+
L0xbefff2c8*X**130+L0xbefff2ca*X**131+L0xbefff308*X**162+L0xbefff30a*X**163+
L0xbefff348*X**194+L0xbefff34a*X**195+L0xbefff388*X**226+L0xbefff38a*X**227
&& true;
ghost F4@int16 : F4**2 =
L0xbefff1ec*X** 20+L0xbefff1ee*X** 21+L0xbefff22c*X** 52+L0xbefff22e*X** 53+
L0xbefff26c*X** 84+L0xbefff26e*X** 85+L0xbefff2ac*X**116+L0xbefff2ae*X**117+
L0xbefff2ec*X**148+L0xbefff2ee*X**149+L0xbefff32c*X**180+L0xbefff32e*X**181+
L0xbefff36c*X**212+L0xbefff36e*X**213+L0xbefff3ac*X**244+L0xbefff3ae*X**245
&& true;
ghost F5@int16 : F5**2 =
L0xbefff1cc*X**  4+L0xbefff1ce*X**  5+L0xbefff20c*X** 36+L0xbefff20e*X** 37+
L0xbefff24c*X** 68+L0xbefff24e*X** 69+L0xbefff28c*X**100+L0xbefff28e*X**101+
L0xbefff2cc*X**132+L0xbefff2ce*X**133+L0xbefff30c*X**164+L0xbefff30e*X**165+
L0xbefff34c*X**196+L0xbefff34e*X**197+L0xbefff38c*X**228+L0xbefff38e*X**229
&& true;
ghost F6@int16 : F6**2 =
L0xbefff1f0*X** 22+L0xbefff1f2*X** 23+L0xbefff230*X** 54+L0xbefff232*X** 55+
L0xbefff270*X** 86+L0xbefff272*X** 87+L0xbefff2b0*X**118+L0xbefff2b2*X**119+
L0xbefff2f0*X**150+L0xbefff2f2*X**151+L0xbefff330*X**182+L0xbefff332*X**183+
L0xbefff370*X**214+L0xbefff372*X**215+L0xbefff3b0*X**246+L0xbefff3b2*X**247
&& true;
ghost F7@int16 : F7**2 =
L0xbefff1d0*X**  6+L0xbefff1d2*X**  7+L0xbefff210*X** 38+L0xbefff212*X** 39+
L0xbefff250*X** 70+L0xbefff252*X** 71+L0xbefff290*X**102+L0xbefff292*X**103+
L0xbefff2d0*X**134+L0xbefff2d2*X**135+L0xbefff310*X**166+L0xbefff312*X**167+
L0xbefff350*X**198+L0xbefff352*X**199+L0xbefff390*X**230+L0xbefff392*X**231
&& true;
ghost F8@int16 : F8**2 =
L0xbefff1f4*X** 24+L0xbefff1f6*X** 25+L0xbefff234*X** 56+L0xbefff236*X** 57+
L0xbefff274*X** 88+L0xbefff276*X** 89+L0xbefff2b4*X**120+L0xbefff2b6*X**121+
L0xbefff2f4*X**152+L0xbefff2f6*X**153+L0xbefff334*X**184+L0xbefff336*X**185+
L0xbefff374*X**216+L0xbefff376*X**217+L0xbefff3b4*X**248+L0xbefff3b6*X**249
&& true;
ghost F9@int16 : F9**2 =
L0xbefff1d4*X**  8+L0xbefff1d6*X**  9+L0xbefff214*X** 40+L0xbefff216*X** 41+
L0xbefff254*X** 72+L0xbefff256*X** 73+L0xbefff294*X**104+L0xbefff296*X**105+
L0xbefff2d4*X**136+L0xbefff2d6*X**137+L0xbefff314*X**168+L0xbefff316*X**169+
L0xbefff354*X**200+L0xbefff356*X**201+L0xbefff394*X**232+L0xbefff396*X**233
&& true;
ghost Fa@int16 : Fa**2 =
L0xbefff1f8*X** 26+L0xbefff1fa*X** 27+L0xbefff238*X** 58+L0xbefff23a*X** 59+
L0xbefff278*X** 90+L0xbefff27a*X** 91+L0xbefff2b8*X**122+L0xbefff2ba*X**123+
L0xbefff2f8*X**154+L0xbefff2fa*X**155+L0xbefff338*X**186+L0xbefff33a*X**187+
L0xbefff378*X**218+L0xbefff37a*X**219+L0xbefff3b8*X**250+L0xbefff3ba*X**251
&& true;
ghost Fb@int16 : Fb**2 =
L0xbefff1d8*X** 10+L0xbefff1da*X** 11+L0xbefff218*X** 42+L0xbefff21a*X** 43+
L0xbefff258*X** 74+L0xbefff25a*X** 75+L0xbefff298*X**106+L0xbefff29a*X**107+
L0xbefff2d8*X**138+L0xbefff2da*X**139+L0xbefff318*X**170+L0xbefff31a*X**171+
L0xbefff358*X**202+L0xbefff35a*X**203+L0xbefff398*X**234+L0xbefff39a*X**235
&& true;
ghost Fc@int16 : Fc**2 =
L0xbefff1fc*X** 28+L0xbefff1fe*X** 29+L0xbefff23c*X** 60+L0xbefff23e*X** 61+
L0xbefff27c*X** 92+L0xbefff27e*X** 93+L0xbefff2bc*X**124+L0xbefff2be*X**125+
L0xbefff2fc*X**156+L0xbefff2fe*X**157+L0xbefff33c*X**188+L0xbefff33e*X**189+
L0xbefff37c*X**220+L0xbefff37e*X**221+L0xbefff3bc*X**252+L0xbefff3be*X**253
&& true;
ghost Fd@int16 : Fd**2 =
L0xbefff1dc*X** 12+L0xbefff1de*X** 13+L0xbefff21c*X** 44+L0xbefff21e*X** 45+
L0xbefff25c*X** 76+L0xbefff25e*X** 77+L0xbefff29c*X**108+L0xbefff29e*X**109+
L0xbefff2dc*X**140+L0xbefff2de*X**141+L0xbefff31c*X**172+L0xbefff31e*X**173+
L0xbefff35c*X**204+L0xbefff35e*X**205+L0xbefff39c*X**236+L0xbefff39e*X**237
&& true;
ghost Fe@int16 : Fe**2 =
L0xbefff200*X** 30+L0xbefff202*X** 31+L0xbefff240*X** 62+L0xbefff242*X** 63+
L0xbefff280*X** 94+L0xbefff282*X** 95+L0xbefff2c0*X**126+L0xbefff2c2*X**127+
L0xbefff300*X**158+L0xbefff302*X**159+L0xbefff340*X**190+L0xbefff342*X**191+
L0xbefff380*X**222+L0xbefff382*X**223+L0xbefff3c0*X**254+L0xbefff3c2*X**255
&& true;
ghost Ff@int16 : Ff**2 =
L0xbefff1e0*X** 14+L0xbefff1e2*X** 15+L0xbefff220*X** 46+L0xbefff222*X** 47+
L0xbefff260*X** 78+L0xbefff262*X** 79+L0xbefff2a0*X**110+L0xbefff2a2*X**111+
L0xbefff2e0*X**142+L0xbefff2e2*X**143+L0xbefff320*X**174+L0xbefff322*X**175+
L0xbefff360*X**206+L0xbefff362*X**207+L0xbefff3a0*X**238+L0xbefff3a2*X**239
&& true;

(* #! -> SP = 0xbefff1b0 *)
#! 0xbefff1b0 = 0xbefff1b0;
(* movw r0, #0 ; 0 *)
mov r0_b 0@int16; mov r0_t 0@int16; mov r0 0@int32;
(* movt	r12, #3329	; 0xd01                         #! PC = 0x400618 *)
mov r12_t 3329@sint16;
(* vldmia	r1!, {s8-s22}                            #! EA = L0x40167c; PC = 0x40061c *)
mov  s8 L0x40167c; spl  s8_t  s8_b  s8 16; cast  s8_b@int16  s8_b;
mov  s9 L0x401680; spl  s9_t  s9_b  s9 16; cast  s9_b@int16  s9_b;
mov s10 L0x401684; spl s10_t s10_b s10 16; cast s10_b@int16 s10_b;
mov s11 L0x401688; spl s11_t s11_b s11 16; cast s11_b@int16 s11_b;
mov s12 L0x40168c; spl s12_t s12_b s12 16; cast s12_b@int16 s12_b;
mov s13 L0x401690; spl s13_t s13_b s13 16; cast s13_b@int16 s13_b;
mov s14 L0x401694; spl s14_t s14_b s14 16; cast s14_b@int16 s14_b;
mov s15 L0x401698; spl s15_t s15_b s15 16; cast s15_b@int16 s15_b;
mov s16 L0x40169c; spl s16_t s16_b s16 16; cast s16_b@int16 s16_b;
mov s17 L0x4016a0; spl s17_t s17_b s17 16; cast s17_b@int16 s17_b;
mov s18 L0x4016a4; spl s18_t s18_b s18 16; cast s18_b@int16 s18_b;
mov s19 L0x4016a8; spl s19_t s19_b s19 16; cast s19_b@int16 s19_b;
mov s20 L0x4016ac; spl s20_t s20_b s20 16; cast s20_b@int16 s20_b;
mov s21 L0x4016b0; spl s21_t s21_b s21 16; cast s21_b@int16 s21_b;
mov s22 L0x4016b4; spl s22_t s22_b s22 16; cast s22_b@int16 s22_b;
(* add.w	lr, r0, #32                               #! PC = 0x400620 *)
adds dc lr r0 32@int32;
(* vmov	s24, lr                                    #! PC = 0x400624 *)
mov s24 lr;
(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff1e4; Value = 0x00000000; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff1e4, L0xbefff1e6];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff224; Value = 0xb6ffe8f8; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff224, L0xbefff226];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff264; Value = 0xb6fd5000; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff264, L0xbefff266];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2a4; Value = 0xffffffff; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2a4, L0xbefff2a6];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff2e4; Value = 0xb6fff070; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff2e4, L0xbefff2e6];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff324; Value = 0x00000000; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff324, L0xbefff326];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff364; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff364, L0xbefff366];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3a4; Value = 0xb6ee4a4f; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3a4, L0xbefff3a6];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b0@int16, r6_t0@int16:
      r6_b0 = r6_b /\ r6_t0 = r6_t
   && r6_b0 = r6_b /\ r6_t0 = r6_t;
      
(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b0 *  -1600) [Q] /\
       eqmod lr_t (r6_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b0 *  -1600) [Q] /\
       eqmod lr_t (r6_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b0@int16, r7_t0@int16:
      r7_b0 = r7_b /\ r7_t0 = r7_t
   && r7_b0 = r7_b /\ r7_t0 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b0 *  -1600) [Q] /\
       eqmod lr_t (r7_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b0 *  -1600) [Q] /\
       eqmod lr_t (r7_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b0@int16, r8_t0@int16:
      r8_b0 = r8_b /\ r8_t0 = r8_t
   && r8_b0 = r8_b /\ r8_t0 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b0 *  -1600) [Q] /\
       eqmod lr_t (r8_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b0 *  -1600) [Q] /\
       eqmod lr_t (r8_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b0@int16, r9_t0@int16:
      r9_b0 = r9_b /\ r9_t0 = r9_t
   && r9_b0 = r9_b /\ r9_t0 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b0 *  -1600) [Q] /\
       eqmod lr_t (r9_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b0 *  -1600) [Q] /\
       eqmod lr_t (r9_t0 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;

ghost r4_b0@int16, r4_t0@int16:
      r4_b0 = r4_b /\ r4_t0 = r4_t
   && r4_b0 = r4_b /\ r4_t0 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b0 *  -749) [Q] /\
       eqmod lr_t (r4_t0 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b0 *  -749) [Q] /\
       eqmod lr_t (r4_t0 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b0@int16, r5_t0@int16:
      r5_b0 = r5_b /\ r5_t0 = r5_t
   && r5_b0 = r5_b /\ r5_t0 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b0 *  -749) [Q] /\
       eqmod lr_t (r5_t0 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b0 *  -749) [Q] /\
       eqmod lr_t (r5_t0 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b1@int16, r8_t1@int16:
      r8_b1 = r8_b /\ r8_t1 = r8_t
   && r8_b1 = r8_b /\ r8_t1 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b1 *  -40) [Q] /\
       eqmod lr_t (r8_t1 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b1 *  -40) [Q] /\
       eqmod lr_t (r8_t1 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b1@int16, r9_t1@int16:
      r9_b1 = r9_b /\ r9_t1 = r9_t
   && r9_b1 = r9_b /\ r9_t1 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b1 *  -40) [Q] /\
       eqmod lr_t (r9_t1 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b1 *  -40) [Q] /\
       eqmod lr_t (r9_t1 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];
(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;

ghost r3_b0@int16, r3_t0@int16:
      r3_b0 = r3_b /\ r3_t0 = r3_t
   && r3_b0 = r3_b /\ r3_t0 = r3_t;

(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b0 *  -687) [Q] /\
       eqmod lr_t (r3_t0 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b0 *  -687) [Q] /\
       eqmod lr_t (r3_t0 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b1@int16, r5_t1@int16:
      r5_b1 = r5_b /\ r5_t1 = r5_t
   && r5_b1 = r5_b /\ r5_t1 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b1 *   630) [Q] /\
       eqmod lr_t (r5_t1 *   630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b1 *   630) [Q] /\
       eqmod lr_t (r5_t1 *   630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b1@int16, r7_t1@int16:
      r7_b1 = r7_b /\ r7_t1 = r7_t
   && r7_b1 = r7_b /\ r7_t1 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b1 *  -1432) [Q] /\
       eqmod lr_t (r7_t1 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b1 *  -1432) [Q] /\
       eqmod lr_t (r7_t1 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b2@int16, r9_t2@int16:
      r9_b2 = r9_b /\ r9_t2 = r9_t
   && r9_b2 = r9_b /\ r9_t2 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b2 *   848) [Q] /\
       eqmod lr_t (r9_t2 *   848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b2 *   848) [Q] /\
       eqmod lr_t (r9_t2 *   848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 0 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F0**2) (r2_b*X**16 + r2_t*X**17) [Q, X**32 - 17** 16] /\
    eqmod (F0**2) (r3_b*X**16 + r3_t*X**17) [Q, X**32 - 17**144] /\
    eqmod (F0**2) (r4_b*X**16 + r4_t*X**17) [Q, X**32 - 17** 80] /\
    eqmod (F0**2) (r5_b*X**16 + r5_t*X**17) [Q, X**32 - 17**208] /\
    eqmod (F0**2) (r6_b*X**16 + r6_t*X**17) [Q, X**32 - 17** 48] /\
    eqmod (F0**2) (r7_b*X**16 + r7_t*X**17) [Q, X**32 - 17**176] /\
    eqmod (F0**2) (r8_b*X**16 + r8_t*X**17) [Q, X**32 - 17**112] /\
    eqmod (F0**2) (r9_b*X**16 + r9_t*X**17) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

ghost r2_b0@int16, r2_t0@int16:
      r2_b0 = r2_b /\ r2_t0 = r2_t
   && r2_b0 = r2_b /\ r2_t0 = r2_t;

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;
(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b0 *   1062) [Q] /\
       eqmod r2_t (r2_t0 *   1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r2_b (r2_b0 *   1062) [Q] /\
       eqmod r2_t (r2_t0 *   1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];

ghost r3_b1@int16, r3_t1@int16:
      r3_b1 = r3_b /\ r3_t1 = r3_t
   && r3_b1 = r3_b /\ r3_t1 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b1 *  -1410) [Q] /\
       eqmod r3_t (r3_t1 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r3_b (r3_b1 *  -1410) [Q] /\
       eqmod r3_t (r3_t1 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

ghost r4_b1@int16, r4_t1@int16:
      r4_b1 = r4_b /\ r4_t1 = r4_t
   && r4_b1 = r4_b /\ r4_t1 = r4_t;

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;
(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b1 *   193) [Q] /\
       eqmod r4_t (r4_t1 *   193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r4_b (r4_b1 *   193) [Q] /\
       eqmod r4_t (r4_t1 *   193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];

ghost r5_b2@int16, r5_t2@int16:
      r5_b2 = r5_b /\ r5_t2 = r5_t
   && r5_b2 = r5_b /\ r5_t2 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b2 *   797) [Q] /\
       eqmod r5_t (r5_t2 *   797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r5_b (r5_b2 *   797) [Q] /\
       eqmod r5_t (r5_t2 *   797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

ghost r6_b1@int16, r6_t1@int16:
      r6_b1 = r6_b /\ r6_t1 = r6_t
   && r6_b1 = r6_b /\ r6_t1 = r6_t;

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;
(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b1 *  -543) [Q] /\
       eqmod r6_t (r6_t1 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r6_b (r6_b1 *  -543) [Q] /\
       eqmod r6_t (r6_t1 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];

ghost r7_b2@int16, r7_t2@int16:
      r7_b2 = r7_b /\ r7_t2 = r7_t
   && r7_b2 = r7_b /\ r7_t2 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b2 *  -69) [Q] /\
       eqmod r7_t (r7_t2 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r7_b (r7_b2 *  -69) [Q] /\
       eqmod r7_t (r7_t2 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

ghost r8_b2@int16, r8_t2@int16:
      r8_b2 = r8_b /\ r8_t2 = r8_t
   && r8_b2 = r8_b /\ r8_t2 = r8_t;

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;
(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b2 *   569) [Q] /\
       eqmod r8_t (r8_t2 *   569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r8_b (r8_b2 *   569) [Q] /\
       eqmod r8_t (r8_t2 *   569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];

ghost r9_b3@int16, r9_t3@int16:
      r9_b3 = r9_b /\ r9_t3 = r9_t
   && r9_b3 = r9_b /\ r9_t3 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b3 *  -1583) [Q] /\
       eqmod r9_t (r9_t3 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod r9_b (r9_b3 *  -1583) [Q] /\
       eqmod r9_t (r9_t3 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 1 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*F0**2) (r2_b*X**16 + r2_t*X**17) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*F0**2) (r3_b*X**16 + r3_t*X**17) [Q, X**32 - 17**144] /\
    eqmod (17** 40*F0**2) (r4_b*X**16 + r4_t*X**17) [Q, X**32 - 17** 80] /\
    eqmod (17**104*F0**2) (r5_b*X**16 + r5_t*X**17) [Q, X**32 - 17**208] /\
    eqmod (17** 24*F0**2) (r6_b*X**16 + r6_t*X**17) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*F0**2) (r7_b*X**16 + r7_t*X**17) [Q, X**32 - 17**176] /\
    eqmod (17** 56*F0**2) (r8_b*X**16 + r8_t*X**17) [Q, X**32 - 17**112] /\
    eqmod (17**120*F0**2) (r9_b*X**16 + r9_t*X**17) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1c4; Value = 0xb6ec9408; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1c4, L0xbefff1c6];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff204; Value = 0xb6fde14b; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff204, L0xbefff206];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff244; Value = 0x00000000; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff244, L0xbefff246];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff284; Value = 0x00000000; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff284, L0xbefff286];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2c4; Value = 0x00000000; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2c4, L0xbefff2c6];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff304; Value = 0x00000000; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff304, L0xbefff306];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff344; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff344, L0xbefff346];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff384; Value = 0x00000000; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff384, L0xbefff386];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b2@int16, r6_t2@int16:
      r6_b2 = r6_b /\ r6_t2 = r6_t
   && r6_b2 = r6_b /\ r6_t2 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b2 *  -1600) [Q] /\
       eqmod lr_t (r6_t2 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b2 *  -1600) [Q] /\
       eqmod lr_t (r6_t2 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b3@int16, r7_t3@int16:
      r7_b3 = r7_b /\ r7_t3 = r7_t
   && r7_b3 = r7_b /\ r7_t3 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b3 *  -1600) [Q] /\
       eqmod lr_t (r7_t3 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b3 *  -1600) [Q] /\
       eqmod lr_t (r7_t3 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b3@int16, r8_t3@int16:
      r8_b3 = r8_b /\ r8_t3 = r8_t
   && r8_b3 = r8_b /\ r8_t3 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b3 *  -1600) [Q] /\
       eqmod lr_t (r8_t3 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b3 *  -1600) [Q] /\
       eqmod lr_t (r8_t3 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b4@int16, r9_t4@int16:
      r9_b4 = r9_b /\ r9_t4 = r9_t
   && r9_b4 = r9_b /\ r9_t4 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b4 *  -1600) [Q] /\
       eqmod lr_t (r9_t4 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b4 *  -1600) [Q] /\
       eqmod lr_t (r9_t4 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b2@int16, r4_t2@int16:
      r4_b2 = r4_b /\ r4_t2 = r4_t
   && r4_b2 = r4_b /\ r4_t2 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b2 *  -749) [Q] /\
       eqmod lr_t (r4_t2 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b2 *  -749) [Q] /\
       eqmod lr_t (r4_t2 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b3@int16, r5_t3@int16:
      r5_b3 = r5_b /\ r5_t3 = r5_t
   && r5_b3 = r5_b /\ r5_t3 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b3 *  -749) [Q] /\
       eqmod lr_t (r5_t3 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b3 *  -749) [Q] /\
       eqmod lr_t (r5_t3 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b4@int16, r8_t4@int16:
      r8_b4 = r8_b /\ r8_t4 = r8_t
   && r8_b4 = r8_b /\ r8_t4 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b4 *  -40) [Q] /\
       eqmod lr_t (r8_t4 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b4 *  -40) [Q] /\
       eqmod lr_t (r8_t4 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b5@int16, r9_t5@int16:
      r9_b5 = r9_b /\ r9_t5 = r9_t
   && r9_b5 = r9_b /\ r9_t5 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b5 *  -40) [Q] /\
       eqmod lr_t (r9_t5 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b5 *  -40) [Q] /\
       eqmod lr_t (r9_t5 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b2@int16, r3_t2@int16:
      r3_b2 = r3_b /\ r3_t2 = r3_t
   && r3_b2 = r3_b /\ r3_t2 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b2 *  -687) [Q] /\
       eqmod lr_t (r3_t2 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b2 *  -687) [Q] /\
       eqmod lr_t (r3_t2 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b4@int16, r5_t4@int16:
      r5_b4 = r5_b /\ r5_t4 = r5_t
   && r5_b4 = r5_b /\ r5_t4 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b4 *  630) [Q] /\
       eqmod lr_t (r5_t4 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b4 *  630) [Q] /\
       eqmod lr_t (r5_t4 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b4@int16, r7_t4@int16:
      r7_b4 = r7_b /\ r7_t4 = r7_t
   && r7_b4 = r7_b /\ r7_t4 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b4 *  -1432) [Q] /\
       eqmod lr_t (r7_t4 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b4 *  -1432) [Q] /\
       eqmod lr_t (r7_t4 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b6@int16, r9_t6@int16:
      r9_b6 = r9_b /\ r9_t6 = r9_t
   && r9_b6 = r9_b /\ r9_t6 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b6 *  848) [Q] /\
       eqmod lr_t (r9_t6 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b6 *  848) [Q] /\
       eqmod lr_t (r9_t6 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert true
    && [2@16*NQ, 2@16*NQ] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[2@16*Q, 2@16*Q]
       prove with [precondition];
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[2@16*Q, 2@16*Q];

(* CUT 2 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F1**2) (r2_b + r2_t*X) [Q, X**32 - 17** 16] /\
    eqmod (F1**2) (r3_b + r3_t*X) [Q, X**32 - 17**144] /\
    eqmod (F1**2) (r4_b + r4_t*X) [Q, X**32 - 17** 80] /\
    eqmod (F1**2) (r5_b + r5_t*X) [Q, X**32 - 17**208] /\
    eqmod (F1**2) (r6_b + r6_t*X) [Q, X**32 - 17** 48] /\
    eqmod (F1**2) (r7_b + r7_t*X) [Q, X**32 - 17**176] /\
    eqmod (F1**2) (r8_b + r8_t*X) [Q, X**32 - 17**112] /\
    eqmod (F1**2) (r9_b + r9_t*X) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[2@16*Q, 2@16*Q]
    prove with [precondition];

(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff204; PC = 0x400a40 *)
mov [L0xbefff204, L0xbefff206] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff224; PC = 0x400a44 *)
mov [L0xbefff224, L0xbefff226] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff284; PC = 0x400a54 *)
mov [L0xbefff284, L0xbefff286] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2a4; PC = 0x400a58 *)
mov [L0xbefff2a4, L0xbefff2a6] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff304; PC = 0x400a68 *)
mov [L0xbefff304, L0xbefff306] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff324; PC = 0x400a6c *)
mov [L0xbefff324, L0xbefff326] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff384; PC = 0x400a7c *)
mov [L0xbefff384, L0xbefff386] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3a4; PC = 0x400a80 *)
mov [L0xbefff3a4, L0xbefff3a6] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff244; PC = 0x400a90 *)
mov [L0xbefff244, L0xbefff246] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff264; PC = 0x400a94 *)
mov [L0xbefff264, L0xbefff266] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2c4; PC = 0x400aa4 *)
mov [L0xbefff2c4, L0xbefff2c6] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff2e4; PC = 0x400aa8 *)
mov [L0xbefff2e4, L0xbefff2e6] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff344; PC = 0x400ab8 *)
mov [L0xbefff344, L0xbefff346] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff364; PC = 0x400abc *)
mov [L0xbefff364, L0xbefff366] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff1e4; PC = 0x400acc *)
mov [L0xbefff1e4, L0xbefff1e6] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1c4; PC = 0x400ad0 *)
mov [L0xbefff1c4, L0xbefff1c6] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1c4, L0xbefff1c6] /\
                        [L0xbefff1c4, L0xbefff1c6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1e4, L0xbefff1e6] /\
                        [L0xbefff1e4, L0xbefff1e6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff204, L0xbefff206] /\
                        [L0xbefff204, L0xbefff206] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff224, L0xbefff226] /\
                        [L0xbefff224, L0xbefff226] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff244, L0xbefff246] /\
                        [L0xbefff244, L0xbefff246] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff264, L0xbefff266] /\
                        [L0xbefff264, L0xbefff266] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff284, L0xbefff286] /\
                        [L0xbefff284, L0xbefff286] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2a4, L0xbefff2a6] /\
                        [L0xbefff2a4, L0xbefff2a6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2c4, L0xbefff2c6] /\
                        [L0xbefff2c4, L0xbefff2c6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2e4, L0xbefff2e6] /\
                        [L0xbefff2e4, L0xbefff2e6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff304, L0xbefff306] /\
                        [L0xbefff304, L0xbefff306] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff324, L0xbefff326] /\
                        [L0xbefff324, L0xbefff326] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff344, L0xbefff346] /\
                        [L0xbefff344, L0xbefff346] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff364, L0xbefff366] /\
                        [L0xbefff364, L0xbefff366] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff384, L0xbefff386] /\
                        [L0xbefff384, L0xbefff386] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3a4, L0xbefff3a6] /\
                        [L0xbefff3a4, L0xbefff3a6] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [1]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1c4, L0xbefff1c6] /\
                        [L0xbefff1c4, L0xbefff1c6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1e4, L0xbefff1e6] /\
                        [L0xbefff1e4, L0xbefff1e6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff204, L0xbefff206] /\
                        [L0xbefff204, L0xbefff206] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff224, L0xbefff226] /\
                        [L0xbefff224, L0xbefff226] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff244, L0xbefff246] /\
                        [L0xbefff244, L0xbefff246] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff264, L0xbefff266] /\
                        [L0xbefff264, L0xbefff266] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff284, L0xbefff286] /\
                        [L0xbefff284, L0xbefff286] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2a4, L0xbefff2a6] /\
                        [L0xbefff2a4, L0xbefff2a6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2c4, L0xbefff2c6] /\
                        [L0xbefff2c4, L0xbefff2c6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2e4, L0xbefff2e6] /\
                        [L0xbefff2e4, L0xbefff2e6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff304, L0xbefff306] /\
                        [L0xbefff304, L0xbefff306] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff324, L0xbefff326] /\
                        [L0xbefff324, L0xbefff326] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff344, L0xbefff346] /\
                        [L0xbefff344, L0xbefff346] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff364, L0xbefff366] /\
                        [L0xbefff364, L0xbefff366] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff384, L0xbefff386] /\
                        [L0xbefff384, L0xbefff386] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3a4, L0xbefff3a6] /\
                        [L0xbefff3a4, L0xbefff3a6] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1c4,L0xbefff1c6] /\
                            [L0xbefff1c4,L0xbefff1c6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff1e4,L0xbefff1e6] /\
                            [L0xbefff1e4,L0xbefff1e6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff204,L0xbefff206] /\
                            [L0xbefff204,L0xbefff206]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff224,L0xbefff226] /\
                            [L0xbefff224,L0xbefff226]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff244,L0xbefff246] /\
                            [L0xbefff244,L0xbefff246]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff264,L0xbefff266] /\
                            [L0xbefff264,L0xbefff266]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff284,L0xbefff286] /\
                            [L0xbefff284,L0xbefff286]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2a4,L0xbefff2a6] /\
                            [L0xbefff2a4,L0xbefff2a6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2c4,L0xbefff2c6] /\
                            [L0xbefff2c4,L0xbefff2c6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2e4,L0xbefff2e6] /\
                            [L0xbefff2e4,L0xbefff2e6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff304,L0xbefff306] /\
                            [L0xbefff304,L0xbefff306]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff324,L0xbefff326] /\
                            [L0xbefff324,L0xbefff326]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff344,L0xbefff346] /\
                            [L0xbefff344,L0xbefff346]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff364,L0xbefff366] /\
                            [L0xbefff364,L0xbefff366]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff384,L0xbefff386] /\
                            [L0xbefff384,L0xbefff386]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3a4,L0xbefff3a6] /\
                            [L0xbefff3a4,L0xbefff3a6]<s[5@16*Q2,5@16*Q2];

(* CUT 3 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod(F0**2+F1**2)(L0xbefff1c4+L0xbefff1c6*X)[Q,X**16-17**  8] /\
    eqmod(F0**2+F1**2)(L0xbefff1e4+L0xbefff1e6*X)[Q,X**16-17**136] /\
    eqmod(F0**2+F1**2)(L0xbefff204+L0xbefff206*X)[Q,X**16-17** 72] /\
    eqmod(F0**2+F1**2)(L0xbefff224+L0xbefff226*X)[Q,X**16-17**200] /\
    eqmod(F0**2+F1**2)(L0xbefff244+L0xbefff246*X)[Q,X**16-17** 40] /\
    eqmod(F0**2+F1**2)(L0xbefff264+L0xbefff266*X)[Q,X**16-17**168] /\
    eqmod(F0**2+F1**2)(L0xbefff284+L0xbefff286*X)[Q,X**16-17**104] /\
    eqmod(F0**2+F1**2)(L0xbefff2a4+L0xbefff2a6*X)[Q,X**16-17**232] /\
    eqmod(F0**2+F1**2)(L0xbefff2c4+L0xbefff2c6*X)[Q,X**16-17** 24] /\
    eqmod(F0**2+F1**2)(L0xbefff2e4+L0xbefff2e6*X)[Q,X**16-17**152] /\
    eqmod(F0**2+F1**2)(L0xbefff304+L0xbefff306*X)[Q,X**16-17** 88] /\
    eqmod(F0**2+F1**2)(L0xbefff324+L0xbefff326*X)[Q,X**16-17**216] /\
    eqmod(F0**2+F1**2)(L0xbefff344+L0xbefff346*X)[Q,X**16-17** 56] /\
    eqmod(F0**2+F1**2)(L0xbefff364+L0xbefff366*X)[Q,X**16-17**184] /\
    eqmod(F0**2+F1**2)(L0xbefff384+L0xbefff386*X)[Q,X**16-17**120] /\
    eqmod(F0**2+F1**2)(L0xbefff3a4+L0xbefff3a6*X)[Q,X**16-17**248] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1c4, L0xbefff1c6] /\
                     [L0xbefff1c4, L0xbefff1c6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1e4, L0xbefff1e6] /\
                     [L0xbefff1e4, L0xbefff1e6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff204, L0xbefff206] /\
                     [L0xbefff204, L0xbefff206] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff224, L0xbefff226] /\
                     [L0xbefff224, L0xbefff226] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff244, L0xbefff246] /\
                     [L0xbefff244, L0xbefff246] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff264, L0xbefff266] /\
                     [L0xbefff264, L0xbefff266] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff284, L0xbefff286] /\
                     [L0xbefff284, L0xbefff286] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2a4, L0xbefff2a6] /\
                     [L0xbefff2a4, L0xbefff2a6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2c4, L0xbefff2c6] /\
                     [L0xbefff2c4, L0xbefff2c6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2e4, L0xbefff2e6] /\
                     [L0xbefff2e4, L0xbefff2e6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff304, L0xbefff306] /\
                     [L0xbefff304, L0xbefff306] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff324, L0xbefff326] /\
                     [L0xbefff324, L0xbefff326] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff344, L0xbefff346] /\
                     [L0xbefff344, L0xbefff346] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff364, L0xbefff366] /\
                     [L0xbefff364, L0xbefff366] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff384, L0xbefff386] /\
                     [L0xbefff384, L0xbefff386] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3a4, L0xbefff3a6] /\
                     [L0xbefff3a4, L0xbefff3a6] < [5*Q2, 5*Q2]
    prove with [cuts [1], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1c4,L0xbefff1c6] /\
                         [L0xbefff1c4,L0xbefff1c6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1e4,L0xbefff1e6] /\
                         [L0xbefff1e4,L0xbefff1e6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff204,L0xbefff206] /\
                         [L0xbefff204,L0xbefff206]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff224,L0xbefff226] /\
                         [L0xbefff224,L0xbefff226]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff244,L0xbefff246] /\
                         [L0xbefff244,L0xbefff246]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff264,L0xbefff266] /\
                         [L0xbefff264,L0xbefff266]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff284,L0xbefff286] /\
                         [L0xbefff284,L0xbefff286]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2a4,L0xbefff2a6] /\
                         [L0xbefff2a4,L0xbefff2a6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2c4,L0xbefff2c6] /\
                         [L0xbefff2c4,L0xbefff2c6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2e4,L0xbefff2e6] /\
                         [L0xbefff2e4,L0xbefff2e6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff304,L0xbefff306] /\
                         [L0xbefff304,L0xbefff306]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff324,L0xbefff326] /\
                         [L0xbefff324,L0xbefff326]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff344,L0xbefff346] /\
                         [L0xbefff344,L0xbefff346]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff364,L0xbefff366] /\
                         [L0xbefff364,L0xbefff366]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff384,L0xbefff386] /\
                         [L0xbefff384,L0xbefff386]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3a4,L0xbefff3a6] /\
                         [L0xbefff3a4,L0xbefff3a6]<s[5@16*Q2,5@16*Q2]
    prove with [precondition, cuts [1]];

(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff1e8; Value = 0xb6fd53a4; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff1e8, L0xbefff1ea];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff228; Value = 0xb6fff5c8; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff228, L0xbefff22a];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff268; Value = 0x00000000; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff268, L0xbefff26a];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2a8; Value = 0xbefff2d0; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2a8, L0xbefff2aa];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff2e8; Value = 0x00000000; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff2e8, L0xbefff2ea];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff328; Value = 0x00000000; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff328, L0xbefff32a];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff368; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff368, L0xbefff36a];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3a8; Value = 0xb6fb53c4; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3a8, L0xbefff3aa];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b4@int16, r6_t4@int16:
      r6_b4 = r6_b /\ r6_t4 = r6_t
   && r6_b4 = r6_b /\ r6_t4 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b4 *  -1600) [Q] /\
       eqmod lr_t (r6_t4 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b4 *  -1600) [Q] /\
       eqmod lr_t (r6_t4 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b6@int16, r7_t6@int16:
      r7_b6 = r7_b /\ r7_t6 = r7_t
   && r7_b6 = r7_b /\ r7_t6 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b6 *  -1600) [Q] /\
       eqmod lr_t (r7_t6 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b6 *  -1600) [Q] /\
       eqmod lr_t (r7_t6 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b6@int16, r8_t6@int16:
      r8_b6 = r8_b /\ r8_t6 = r8_t
   && r8_b6 = r8_b /\ r8_t6 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b6 *  -1600) [Q] /\
       eqmod lr_t (r8_t6 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b6 *  -1600) [Q] /\
       eqmod lr_t (r8_t6 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b8@int16, r9_t8@int16:
      r9_b8 = r9_b /\ r9_t8 = r9_t
   && r9_b8 = r9_b /\ r9_t8 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b8 *  -1600) [Q] /\
       eqmod lr_t (r9_t8 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b8 *  -1600) [Q] /\
       eqmod lr_t (r9_t8 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b4@int16, r4_t4@int16:
      r4_b4 = r4_b /\ r4_t4 = r4_t
   && r4_b4 = r4_b /\ r4_t4 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b4 *  -749) [Q] /\
       eqmod lr_t (r4_t4 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b4 *  -749) [Q] /\
       eqmod lr_t (r4_t4 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b6@int16, r5_t6@int16:
      r5_b6 = r5_b /\ r5_t6 = r5_t
   && r5_b6 = r5_b /\ r5_t6 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b6 *  -749) [Q] /\
       eqmod lr_t (r5_t6 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b6 *  -749) [Q] /\
       eqmod lr_t (r5_t6 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b7@int16, r8_t7@int16:
      r8_b7 = r8_b /\ r8_t7 = r8_t
   && r8_b7 = r8_b /\ r8_t7 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b7 *  -40) [Q] /\
       eqmod lr_t (r8_t7 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b7 *  -40) [Q] /\
       eqmod lr_t (r8_t7 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b9@int16, r9_t9@int16:
      r9_b9 = r9_b /\ r9_t9 = r9_t
   && r9_b9 = r9_b /\ r9_t9 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b9 *  -40) [Q] /\
       eqmod lr_t (r9_t9 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b9 *  -40) [Q] /\
       eqmod lr_t (r9_t9 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b4@int16, r3_t4@int16:
      r3_b4 = r3_b /\ r3_t4 = r3_t
   && r3_b4 = r3_b /\ r3_t4 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b4 *  -687) [Q] /\
       eqmod lr_t (r3_t4 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b4 *  -687) [Q] /\
       eqmod lr_t (r3_t4 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b7@int16, r5_t7@int16:
      r5_b7 = r5_b /\ r5_t7 = r5_t
   && r5_b7 = r5_b /\ r5_t7 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b7 *  630) [Q] /\
       eqmod lr_t (r5_t7 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b7 *  630) [Q] /\
       eqmod lr_t (r5_t7 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b7@int16, r7_t7@int16:
      r7_b7 = r7_b /\ r7_t7 = r7_t
   && r7_b7 = r7_b /\ r7_t7 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b7 *  -1432) [Q] /\
       eqmod lr_t (r7_t7 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b7 *  -1432) [Q] /\
       eqmod lr_t (r7_t7 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b10@int16, r9_t10@int16:
      r9_b10 = r9_b /\ r9_t10 = r9_t
   && r9_b10 = r9_b /\ r9_t10 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b10 *  848) [Q] /\
       eqmod lr_t (r9_t10 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b10 *  848) [Q] /\
       eqmod lr_t (r9_t10 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 4 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F2**2) (r2_b*X**18 + r2_t*X**19) [Q, X**32 - 17** 16] /\
    eqmod (F2**2) (r3_b*X**18 + r3_t*X**19) [Q, X**32 - 17**144] /\
    eqmod (F2**2) (r4_b*X**18 + r4_t*X**19) [Q, X**32 - 17** 80] /\
    eqmod (F2**2) (r5_b*X**18 + r5_t*X**19) [Q, X**32 - 17**208] /\
    eqmod (F2**2) (r6_b*X**18 + r6_t*X**19) [Q, X**32 - 17** 48] /\
    eqmod (F2**2) (r7_b*X**18 + r7_t*X**19) [Q, X**32 - 17**176] /\
    eqmod (F2**2) (r8_b*X**18 + r8_t*X**19) [Q, X**32 - 17**112] /\
    eqmod (F2**2) (r9_b*X**18 + r9_t*X**19) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q]
    prove with [precondition];
    
ghost r2_b2@int16, r2_t2@int16:
      r2_b2 = r2_b /\ r2_t2 = r2_t
   && r2_b2 = r2_b /\ r2_t2 = r2_t;

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;
(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b2 *  1062) [Q] /\
       eqmod r2_t (r2_t2 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r2_b (r2_b2 *  1062) [Q] /\
       eqmod r2_t (r2_t2 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];

ghost r3_b5@int16, r3_t5@int16:
      r3_b5 = r3_b /\ r3_t5 = r3_t
   && r3_b5 = r3_b /\ r3_t5 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b5 *  -1410) [Q] /\
       eqmod r3_t (r3_t5 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r3_b (r3_b5 *  -1410) [Q] /\
       eqmod r3_t (r3_t5 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;

ghost r4_b5@int16, r4_t5@int16:
      r4_b5 = r4_b /\ r4_t5 = r4_t
   && r4_b5 = r4_b /\ r4_t5 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b5 *  193) [Q] /\
       eqmod r4_t (r4_t5 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r4_b (r4_b5 *  193) [Q] /\
       eqmod r4_t (r4_t5 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];

ghost r5_b8@int16, r5_t8@int16:
      r5_b8 = r5_b /\ r5_t8 = r5_t
   && r5_b8 = r5_b /\ r5_t8 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b8 *  797) [Q] /\
       eqmod r5_t (r5_t8 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r5_b (r5_b8 *  797) [Q] /\
       eqmod r5_t (r5_t8 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;

ghost r6_b5@int16, r6_t5@int16:
      r6_b5 = r6_b /\ r6_t5 = r6_t
   && r6_b5 = r6_b /\ r6_t5 = r6_t;

(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b5 *  -543) [Q] /\
       eqmod r6_t (r6_t5 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r6_b (r6_b5 *  -543) [Q] /\
       eqmod r6_t (r6_t5 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];


ghost r7_b8@int16, r7_t8@int16:
      r7_b8 = r7_b /\ r7_t8 = r7_t
   && r7_b8 = r7_b /\ r7_t8 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b8 *  -69) [Q] /\
       eqmod r7_t (r7_t8 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r7_b (r7_b8 *  -69) [Q] /\
       eqmod r7_t (r7_t8 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;

ghost r8_b8@int16, r8_t8@int16:
      r8_b8 = r8_b /\ r8_t8 = r8_t
   && r8_b8 = r8_b /\ r8_t8 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b8 *  569) [Q] /\
       eqmod r8_t (r8_t8 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r8_b (r8_b8 *  569) [Q] /\
       eqmod r8_t (r8_t8 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];


ghost r9_b11@int16, r9_t11@int16:
      r9_b11 = r9_b /\ r9_t11 = r9_t
   && r9_b11 = r9_b /\ r9_t11 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b11 *  -1583) [Q] /\
       eqmod r9_t (r9_t11 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r9_b (r9_b11 *  -1583) [Q] /\
       eqmod r9_t (r9_t11 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 5 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*F2**2) (r2_b*X**18 + r2_t*X**19) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*F2**2) (r3_b*X**18 + r3_t*X**19) [Q, X**32 - 17**144] /\
    eqmod (17** 40*F2**2) (r4_b*X**18 + r4_t*X**19) [Q, X**32 - 17** 80] /\
    eqmod (17**104*F2**2) (r5_b*X**18 + r5_t*X**19) [Q, X**32 - 17**208] /\
    eqmod (17** 24*F2**2) (r6_b*X**18 + r6_t*X**19) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*F2**2) (r7_b*X**18 + r7_t*X**19) [Q, X**32 - 17**176] /\
    eqmod (17** 56*F2**2) (r8_b*X**18 + r8_t*X**19) [Q, X**32 - 17**112] /\
    eqmod (17**120*F2**2) (r9_b*X**18 + r9_t*X**19) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2]
    prove with [precondition];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1c8; Value = 0xb6ffb000; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1c8, L0xbefff1ca];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff208; Value = 0xb6ffb510; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff208, L0xbefff20a];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff248; Value = 0x00000000; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff248, L0xbefff24a];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff288; Value = 0x00000000; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff288, L0xbefff28a];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2c8; Value = 0x00000000; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2c8, L0xbefff2ca];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff308; Value = 0x00000000; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff308, L0xbefff30a];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff348; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff348, L0xbefff34a];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff388; Value = 0x00000000; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff388, L0xbefff38a];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b6@int16, r6_t6@int16:
      r6_b6 = r6_b /\ r6_t6 = r6_t
   && r6_b6 = r6_b /\ r6_t6 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b6 *  -1600) [Q] /\
       eqmod lr_t (r6_t6 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b6 *  -1600) [Q] /\
       eqmod lr_t (r6_t6 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b9@int16, r7_t9@int16:
      r7_b9 = r7_b /\ r7_t9 = r7_t
   && r7_b9 = r7_b /\ r7_t9 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b9 *  -1600) [Q] /\
       eqmod lr_t (r7_t9 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b9 *  -1600) [Q] /\
       eqmod lr_t (r7_t9 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b9@int16, r8_t9@int16:
      r8_b9 = r8_b /\ r8_t9 = r8_t
   && r8_b9 = r8_b /\ r8_t9 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b9 *  -1600) [Q] /\
       eqmod lr_t (r8_t9 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b9 *  -1600) [Q] /\
       eqmod lr_t (r8_t9 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b12@int16, r9_t12@int16:
      r9_b12 = r9_b /\ r9_t12 = r9_t
   && r9_b12 = r9_b /\ r9_t12 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b12 *  -1600) [Q] /\
       eqmod lr_t (r9_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b12 *  -1600) [Q] /\
       eqmod lr_t (r9_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b6@int16, r4_t6@int16:
      r4_b6 = r4_b /\ r4_t6 = r4_t
   && r4_b6 = r4_b /\ r4_t6 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b6 *  -749) [Q] /\
       eqmod lr_t (r4_t6 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b6 *  -749) [Q] /\
       eqmod lr_t (r4_t6 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b9@int16, r5_t9@int16:
      r5_b9 = r5_b /\ r5_t9 = r5_t
   && r5_b9 = r5_b /\ r5_t9 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b9 *  -749) [Q] /\
       eqmod lr_t (r5_t9 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b9 *  -749) [Q] /\
       eqmod lr_t (r5_t9 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b10@int16, r8_t10@int16:
      r8_b10 = r8_b /\ r8_t10 = r8_t
   && r8_b10 = r8_b /\ r8_t10 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b10 *  -40) [Q] /\
       eqmod lr_t (r8_t10 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b10 *  -40) [Q] /\
       eqmod lr_t (r8_t10 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b13@int16, r9_t13@int16:
      r9_b13 = r9_b /\ r9_t13 = r9_t
   && r9_b13 = r9_b /\ r9_t13 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b13 *  -40) [Q] /\
       eqmod lr_t (r9_t13 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b13 *  -40) [Q] /\
       eqmod lr_t (r9_t13 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b6@int16, r3_t6@int16:
      r3_b6 = r3_b /\ r3_t6 = r3_t
   && r3_b6 = r3_b /\ r3_t6 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b6 *  -687) [Q] /\
       eqmod lr_t (r3_t6 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b6 *  -687) [Q] /\
       eqmod lr_t (r3_t6 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b10@int16, r5_t10@int16:
      r5_b10 = r5_b /\ r5_t10 = r5_t
   && r5_b10 = r5_b /\ r5_t10 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b10 *  630) [Q] /\
       eqmod lr_t (r5_t10 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b10 *  630) [Q] /\
       eqmod lr_t (r5_t10 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b10@int16, r7_t10@int16:
      r7_b10 = r7_b /\ r7_t10 = r7_t
   && r7_b10 = r7_b /\ r7_t10 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b10 *  -1432) [Q] /\
       eqmod lr_t (r7_t10 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b10 *  -1432) [Q] /\
       eqmod lr_t (r7_t10 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b14@int16, r9_t14@int16:
      r9_b14 = r9_b /\ r9_t14 = r9_t
   && r9_b14 = r9_b /\ r9_t14 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b14 *  848) [Q] /\
       eqmod lr_t (r9_t14 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b14 *  848) [Q] /\
       eqmod lr_t (r9_t14 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff208; PC = 0x400a40 *)
mov [L0xbefff208, L0xbefff20a] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff228; PC = 0x400a44 *)
mov [L0xbefff228, L0xbefff22a] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff288; PC = 0x400a54 *)
mov [L0xbefff288, L0xbefff28a] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2a8; PC = 0x400a58 *)
mov [L0xbefff2a8, L0xbefff2aa] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff308; PC = 0x400a68 *)
mov [L0xbefff308, L0xbefff30a] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff328; PC = 0x400a6c *)
mov [L0xbefff328, L0xbefff32a] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff388; PC = 0x400a7c *)
mov [L0xbefff388, L0xbefff38a] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3a8; PC = 0x400a80 *)
mov [L0xbefff3a8, L0xbefff3aa] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff248; PC = 0x400a90 *)
mov [L0xbefff248, L0xbefff24a] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff268; PC = 0x400a94 *)
mov [L0xbefff268, L0xbefff26a] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2c8; PC = 0x400aa4 *)
mov [L0xbefff2c8, L0xbefff2ca] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff2e8; PC = 0x400aa8 *)
mov [L0xbefff2e8, L0xbefff2ea] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff348; PC = 0x400ab8 *)
mov [L0xbefff348, L0xbefff34a] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff368; PC = 0x400abc *)
mov [L0xbefff368, L0xbefff36a] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff1e8; PC = 0x400acc *)
mov [L0xbefff1e8, L0xbefff1ea] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1c8; PC = 0x400ad0 *)
mov [L0xbefff1c8, L0xbefff1ca] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1c8, L0xbefff1ca] /\
                        [L0xbefff1c8, L0xbefff1ca] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1e8, L0xbefff1ea] /\
                        [L0xbefff1e8, L0xbefff1ea] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff208, L0xbefff20a] /\
                        [L0xbefff208, L0xbefff20a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff228, L0xbefff22a] /\
                        [L0xbefff228, L0xbefff22a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff248, L0xbefff24a] /\
                        [L0xbefff248, L0xbefff24a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff268, L0xbefff26a] /\
                        [L0xbefff268, L0xbefff26a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff288, L0xbefff28a] /\
                        [L0xbefff288, L0xbefff28a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2a8, L0xbefff2aa] /\
                        [L0xbefff2a8, L0xbefff2aa] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2c8, L0xbefff2ca] /\
                        [L0xbefff2c8, L0xbefff2ca] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2e8, L0xbefff2ea] /\
                        [L0xbefff2e8, L0xbefff2ea] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff308, L0xbefff30a] /\
                        [L0xbefff308, L0xbefff30a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff328, L0xbefff32a] /\
                        [L0xbefff328, L0xbefff32a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff348, L0xbefff34a] /\
                        [L0xbefff348, L0xbefff34a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff368, L0xbefff36a] /\
                        [L0xbefff368, L0xbefff36a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff388, L0xbefff38a] /\
                        [L0xbefff388, L0xbefff38a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3a8, L0xbefff3aa] /\
                        [L0xbefff3a8, L0xbefff3aa] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [4]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1c8, L0xbefff1ca] /\
                        [L0xbefff1c8, L0xbefff1ca] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1e8, L0xbefff1ea] /\
                        [L0xbefff1e8, L0xbefff1ea] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff208, L0xbefff20a] /\
                        [L0xbefff208, L0xbefff20a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff228, L0xbefff22a] /\
                        [L0xbefff228, L0xbefff22a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff248, L0xbefff24a] /\
                        [L0xbefff248, L0xbefff24a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff268, L0xbefff26a] /\
                        [L0xbefff268, L0xbefff26a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff288, L0xbefff28a] /\
                        [L0xbefff288, L0xbefff28a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2a8, L0xbefff2aa] /\
                        [L0xbefff2a8, L0xbefff2aa] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2c8, L0xbefff2ca] /\
                        [L0xbefff2c8, L0xbefff2ca] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2e8, L0xbefff2ea] /\
                        [L0xbefff2e8, L0xbefff2ea] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff308, L0xbefff30a] /\
                        [L0xbefff308, L0xbefff30a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff328, L0xbefff32a] /\
                        [L0xbefff328, L0xbefff32a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff348, L0xbefff34a] /\
                        [L0xbefff348, L0xbefff34a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff368, L0xbefff36a] /\
                        [L0xbefff368, L0xbefff36a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff388, L0xbefff38a] /\
                        [L0xbefff388, L0xbefff38a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3a8, L0xbefff3aa] /\
                        [L0xbefff3a8, L0xbefff3aa] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1c8,L0xbefff1ca] /\
                            [L0xbefff1c8,L0xbefff1ca]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff1e8,L0xbefff1ea] /\
                            [L0xbefff1e8,L0xbefff1ea]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff208,L0xbefff20a] /\
                            [L0xbefff208,L0xbefff20a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff228,L0xbefff22a] /\
                            [L0xbefff228,L0xbefff22a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff248,L0xbefff24a] /\
                            [L0xbefff248,L0xbefff24a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff268,L0xbefff26a] /\
                            [L0xbefff268,L0xbefff26a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff288,L0xbefff28a] /\
                            [L0xbefff288,L0xbefff28a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2a8,L0xbefff2aa] /\
                            [L0xbefff2a8,L0xbefff2aa]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2c8,L0xbefff2ca] /\
                            [L0xbefff2c8,L0xbefff2ca]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2e8,L0xbefff2ea] /\
                            [L0xbefff2e8,L0xbefff2ea]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff308,L0xbefff30a] /\
                            [L0xbefff308,L0xbefff30a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff328,L0xbefff32a] /\
                            [L0xbefff328,L0xbefff32a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff348,L0xbefff34a] /\
                            [L0xbefff348,L0xbefff34a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff368,L0xbefff36a] /\
                            [L0xbefff368,L0xbefff36a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff388,L0xbefff38a] /\
                            [L0xbefff388,L0xbefff38a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3a8,L0xbefff3aa] /\
                            [L0xbefff3a8,L0xbefff3aa]<s[5@16*Q2,5@16*Q2];

(* CUT 6 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F2**2+F3**2)(L0xbefff1c8*X**2+L0xbefff1ca*X**3)[Q,X**16-17**  8]/\
    eqmod (F2**2+F3**2)(L0xbefff1e8*X**2+L0xbefff1ea*X**3)[Q,X**16-17**136]/\
    eqmod (F2**2+F3**2)(L0xbefff208*X**2+L0xbefff20a*X**3)[Q,X**16-17** 72]/\
    eqmod (F2**2+F3**2)(L0xbefff228*X**2+L0xbefff22a*X**3)[Q,X**16-17**200]/\
    eqmod (F2**2+F3**2)(L0xbefff248*X**2+L0xbefff24a*X**3)[Q,X**16-17** 40]/\
    eqmod (F2**2+F3**2)(L0xbefff268*X**2+L0xbefff26a*X**3)[Q,X**16-17**168]/\
    eqmod (F2**2+F3**2)(L0xbefff288*X**2+L0xbefff28a*X**3)[Q,X**16-17**104]/\
    eqmod (F2**2+F3**2)(L0xbefff2a8*X**2+L0xbefff2aa*X**3)[Q,X**16-17**232]/\
    eqmod (F2**2+F3**2)(L0xbefff2c8*X**2+L0xbefff2ca*X**3)[Q,X**16-17** 24]/\
    eqmod (F2**2+F3**2)(L0xbefff2e8*X**2+L0xbefff2ea*X**3)[Q,X**16-17**152]/\
    eqmod (F2**2+F3**2)(L0xbefff308*X**2+L0xbefff30a*X**3)[Q,X**16-17** 88]/\
    eqmod (F2**2+F3**2)(L0xbefff328*X**2+L0xbefff32a*X**3)[Q,X**16-17**216]/\
    eqmod (F2**2+F3**2)(L0xbefff348*X**2+L0xbefff34a*X**3)[Q,X**16-17** 56]/\
    eqmod (F2**2+F3**2)(L0xbefff368*X**2+L0xbefff36a*X**3)[Q,X**16-17**184]/\
    eqmod (F2**2+F3**2)(L0xbefff388*X**2+L0xbefff38a*X**3)[Q,X**16-17**120]/\
    eqmod (F2**2+F3**2)(L0xbefff3a8*X**2+L0xbefff3aa*X**3)[Q,X**16-17**248]/\
    [5*NQ2, 5*NQ2] < [L0xbefff1c8, L0xbefff1ca] /\
                     [L0xbefff1c8, L0xbefff1ca] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1e8, L0xbefff1ea] /\
                     [L0xbefff1e8, L0xbefff1ea] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff208, L0xbefff20a] /\
                     [L0xbefff208, L0xbefff20a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff228, L0xbefff22a] /\
                     [L0xbefff228, L0xbefff22a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff248, L0xbefff24a] /\
                     [L0xbefff248, L0xbefff24a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff268, L0xbefff26a] /\
                     [L0xbefff268, L0xbefff26a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff288, L0xbefff28a] /\
                     [L0xbefff288, L0xbefff28a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2a8, L0xbefff2aa] /\
                     [L0xbefff2a8, L0xbefff2aa] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2c8, L0xbefff2ca] /\
                     [L0xbefff2c8, L0xbefff2ca] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2e8, L0xbefff2ea] /\
                     [L0xbefff2e8, L0xbefff2ea] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff308, L0xbefff30a] /\
                     [L0xbefff308, L0xbefff30a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff328, L0xbefff32a] /\
                     [L0xbefff328, L0xbefff32a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff348, L0xbefff34a] /\
                     [L0xbefff348, L0xbefff34a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff368, L0xbefff36a] /\
                     [L0xbefff368, L0xbefff36a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff388, L0xbefff38a] /\
                     [L0xbefff388, L0xbefff38a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3a8, L0xbefff3aa] /\
                     [L0xbefff3a8, L0xbefff3aa] < [5*Q2, 5*Q2]
    prove with [cuts [4], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1c8,L0xbefff1ca] /\
                         [L0xbefff1c8,L0xbefff1ca]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1e8,L0xbefff1ea] /\
                         [L0xbefff1e8,L0xbefff1ea]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff208,L0xbefff20a] /\
                         [L0xbefff208,L0xbefff20a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff228,L0xbefff22a] /\
                         [L0xbefff228,L0xbefff22a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff248,L0xbefff24a] /\
                         [L0xbefff248,L0xbefff24a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff268,L0xbefff26a] /\
                         [L0xbefff268,L0xbefff26a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff288,L0xbefff28a] /\
                         [L0xbefff288,L0xbefff28a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2a8,L0xbefff2aa] /\
                         [L0xbefff2a8,L0xbefff2aa]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2c8,L0xbefff2ca] /\
                         [L0xbefff2c8,L0xbefff2ca]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2e8,L0xbefff2ea] /\
                         [L0xbefff2e8,L0xbefff2ea]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff308,L0xbefff30a] /\
                         [L0xbefff308,L0xbefff30a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff328,L0xbefff32a] /\
                         [L0xbefff328,L0xbefff32a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff348,L0xbefff34a] /\
                         [L0xbefff348,L0xbefff34a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff368,L0xbefff36a] /\
                         [L0xbefff368,L0xbefff36a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff388,L0xbefff38a] /\
                         [L0xbefff388,L0xbefff38a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3a8,L0xbefff3aa] /\
                         [L0xbefff3a8,L0xbefff3aa]<s[5@16*Q2,5@16*Q2]
    prove with [precondition];

(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff1ec; Value = 0x0002a02c; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff1ec, L0xbefff1ee];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff22c; Value = 0xb6fff8e8; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff22c, L0xbefff22e];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff26c; Value = 0xb6ec9408; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff26c, L0xbefff26e];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2ac; Value = 0xb6fff8e8; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2ac, L0xbefff2ae];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff2ec; Value = 0x00000001; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff2ec, L0xbefff2ee];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff32c; Value = 0x00000000; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff32c, L0xbefff32e];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff36c; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff36c, L0xbefff36e];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3ac; Value = 0x00401541; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3ac, L0xbefff3ae];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b8@int16, r6_t8@int16:
      r6_b8 = r6_b /\ r6_t8 = r6_t
   && r6_b8 = r6_b /\ r6_t8 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b8 *  -1600) [Q] /\
       eqmod lr_t (r6_t8 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b8 *  -1600) [Q] /\
       eqmod lr_t (r6_t8 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b12@int16, r7_t12@int16:
      r7_b12 = r7_b /\ r7_t12 = r7_t
   && r7_b12 = r7_b /\ r7_t12 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b12 *  -1600) [Q] /\
       eqmod lr_t (r7_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b12 *  -1600) [Q] /\
       eqmod lr_t (r7_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b12@int16, r8_t12@int16:
      r8_b12 = r8_b /\ r8_t12 = r8_t
   && r8_b12 = r8_b /\ r8_t12 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b12 *  -1600) [Q] /\
       eqmod lr_t (r8_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b12 *  -1600) [Q] /\
       eqmod lr_t (r8_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b16@int16, r9_t16@int16:
      r9_b16 = r9_b /\ r9_t16 = r9_t
   && r9_b16 = r9_b /\ r9_t16 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b16 *  -1600) [Q] /\
       eqmod lr_t (r9_t16 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b16 *  -1600) [Q] /\
       eqmod lr_t (r9_t16 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b8@int16, r4_t8@int16:
      r4_b8 = r4_b /\ r4_t8 = r4_t
   && r4_b8 = r4_b /\ r4_t8 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b8 *  -749) [Q] /\
       eqmod lr_t (r4_t8 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b8 *  -749) [Q] /\
       eqmod lr_t (r4_t8 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b12@int16, r5_t12@int16:
      r5_b12 = r5_b /\ r5_t12 = r5_t
   && r5_b12 = r5_b /\ r5_t12 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b12 *  -749) [Q] /\
       eqmod lr_t (r5_t12 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b12 *  -749) [Q] /\
       eqmod lr_t (r5_t12 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b13@int16, r8_t13@int16:
      r8_b13 = r8_b /\ r8_t13 = r8_t
   && r8_b13 = r8_b /\ r8_t13 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b13 *  -40) [Q] /\
       eqmod lr_t (r8_t13 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b13 *  -40) [Q] /\
       eqmod lr_t (r8_t13 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b17@int16, r9_t17@int16:
      r9_b17 = r9_b /\ r9_t17 = r9_t
   && r9_b17 = r9_b /\ r9_t17 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b17 *  -40) [Q] /\
       eqmod lr_t (r9_t17 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b17 *  -40) [Q] /\
       eqmod lr_t (r9_t17 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b8@int16, r3_t8@int16:
      r3_b8 = r3_b /\ r3_t8 = r3_t
   && r3_b8 = r3_b /\ r3_t8 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b8 *  -687) [Q] /\
       eqmod lr_t (r3_t8 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b8 *  -687) [Q] /\
       eqmod lr_t (r3_t8 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b13@int16, r5_t13@int16:
      r5_b13 = r5_b /\ r5_t13 = r5_t
   && r5_b13 = r5_b /\ r5_t13 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b13 *  630) [Q] /\
       eqmod lr_t (r5_t13 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b13 *  630) [Q] /\
       eqmod lr_t (r5_t13 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b13@int16, r7_t13@int16:
      r7_b13 = r7_b /\ r7_t13 = r7_t
   && r7_b13 = r7_b /\ r7_t13 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b13 *  -1432) [Q] /\
       eqmod lr_t (r7_t13 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b13 *  -1432) [Q] /\
       eqmod lr_t (r7_t13 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b18@int16, r9_t18@int16:
      r9_b18 = r9_b /\ r9_t18 = r9_t
   && r9_b18 = r9_b /\ r9_t18 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b18 *  848) [Q] /\
       eqmod lr_t (r9_t18 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b18 *  848) [Q] /\
       eqmod lr_t (r9_t18 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 7 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F4**2) (r2_b*X**20 + r2_t*X**21) [Q, X**32 - 17** 16] /\
    eqmod (F4**2) (r3_b*X**20 + r3_t*X**21) [Q, X**32 - 17**144] /\
    eqmod (F4**2) (r4_b*X**20 + r4_t*X**21) [Q, X**32 - 17** 80] /\
    eqmod (F4**2) (r5_b*X**20 + r5_t*X**21) [Q, X**32 - 17**208] /\
    eqmod (F4**2) (r6_b*X**20 + r6_t*X**21) [Q, X**32 - 17** 48] /\
    eqmod (F4**2) (r7_b*X**20 + r7_t*X**21) [Q, X**32 - 17**176] /\
    eqmod (F4**2) (r8_b*X**20 + r8_t*X**21) [Q, X**32 - 17**112] /\
    eqmod (F4**2) (r9_b*X**20 + r9_t*X**21) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q]
    prove with [precondition];

ghost r2_b4@int16, r2_t4@int16:
      r2_b4 = r2_b /\ r2_t4 = r2_t
   && r2_b4 = r2_b /\ r2_t4 = r2_t;

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;
(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b4 *  1062) [Q] /\
       eqmod r2_t (r2_t4 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r2_b (r2_b4 *  1062) [Q] /\
       eqmod r2_t (r2_t4 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];


ghost r3_b9@int16, r3_t9@int16:
      r3_b9 = r3_b /\ r3_t9 = r3_t
   && r3_b9 = r3_b /\ r3_t9 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b9 *  -1410) [Q] /\
       eqmod r3_t (r3_t9 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r3_b (r3_b9 *  -1410) [Q] /\
       eqmod r3_t (r3_t9 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;

ghost r4_b9@int16, r4_t9@int16:
      r4_b9 = r4_b /\ r4_t9 = r4_t
   && r4_b9 = r4_b /\ r4_t9 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b9 *  193) [Q] /\
       eqmod r4_t (r4_t9 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r4_b (r4_b9 *  193) [Q] /\
       eqmod r4_t (r4_t9 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];


ghost r5_b14@int16, r5_t14@int16:
      r5_b14 = r5_b /\ r5_t14 = r5_t
   && r5_b14 = r5_b /\ r5_t14 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b14 *  797) [Q] /\
       eqmod r5_t (r5_t14 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r5_b (r5_b14 *  797) [Q] /\
       eqmod r5_t (r5_t14 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;

ghost r6_b9@int16, r6_t9@int16:
      r6_b9 = r6_b /\ r6_t9 = r6_t
   && r6_b9 = r6_b /\ r6_t9 = r6_t;

(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b9 *  -543) [Q] /\
       eqmod r6_t (r6_t9 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r6_b (r6_b9 *  -543) [Q] /\
       eqmod r6_t (r6_t9 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];


ghost r7_b14@int16, r7_t14@int16:
      r7_b14 = r7_b /\ r7_t14 = r7_t
   && r7_b14 = r7_b /\ r7_t14 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b14 *  -69) [Q] /\
       eqmod r7_t (r7_t14 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r7_b (r7_b14 *  -69) [Q] /\
       eqmod r7_t (r7_t14 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;

ghost r8_b14@int16, r8_t14@int16:
      r8_b14 = r8_b /\ r8_t14 = r8_t
   && r8_b14 = r8_b /\ r8_t14 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b14 *  569) [Q] /\
       eqmod r8_t (r8_t14 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r8_b (r8_b14 *  569) [Q] /\
       eqmod r8_t (r8_t14 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];


ghost r9_b19@int16, r9_t19@int16:
      r9_b19 = r9_b /\ r9_t19 = r9_t
   && r9_b19 = r9_b /\ r9_t19 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b19 *  -1583) [Q] /\
       eqmod r9_t (r9_t19 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r9_b (r9_b19 *  -1583) [Q] /\
       eqmod r9_t (r9_t19 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 8 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*F4**2) (r2_b*X**20 + r2_t*X**21) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*F4**2) (r3_b*X**20 + r3_t*X**21) [Q, X**32 - 17**144] /\
    eqmod (17** 40*F4**2) (r4_b*X**20 + r4_t*X**21) [Q, X**32 - 17** 80] /\
    eqmod (17**104*F4**2) (r5_b*X**20 + r5_t*X**21) [Q, X**32 - 17**208] /\
    eqmod (17** 24*F4**2) (r6_b*X**20 + r6_t*X**21) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*F4**2) (r7_b*X**20 + r7_t*X**21) [Q, X**32 - 17**176] /\
    eqmod (17** 56*F4**2) (r8_b*X**20 + r8_t*X**21) [Q, X**32 - 17**112] /\
    eqmod (17**120*F4**2) (r9_b*X**20 + r9_t*X**21) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2]
    prove with [precondition];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1cc; Value = 0x0000000d; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1cc, L0xbefff1ce];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff20c; Value = 0x00000001; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff20c, L0xbefff20e];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff24c; Value = 0xb6fd5534; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff24c, L0xbefff24e];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff28c; Value = 0x00000000; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff28c, L0xbefff28e];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2cc; Value = 0x00000000; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2cc, L0xbefff2ce];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff30c; Value = 0x00000000; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff30c, L0xbefff30e];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff34c; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff34c, L0xbefff34e];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff38c; Value = 0x00000000; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff38c, L0xbefff38e];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b10@int16, r6_t10@int16:
      r6_b10 = r6_b /\ r6_t10 = r6_t
   && r6_b10 = r6_b /\ r6_t10 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b10 *  -1600) [Q] /\
       eqmod lr_t (r6_t10 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b10 *  -1600) [Q] /\
       eqmod lr_t (r6_t10 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b15@int16, r7_t15@int16:
      r7_b15 = r7_b /\ r7_t15 = r7_t
   && r7_b15 = r7_b /\ r7_t15 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b15 *  -1600) [Q] /\
       eqmod lr_t (r7_t15 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b15 *  -1600) [Q] /\
       eqmod lr_t (r7_t15 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b15@int16, r8_t15@int16:
      r8_b15 = r8_b /\ r8_t15 = r8_t
   && r8_b15 = r8_b /\ r8_t15 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b15 *  -1600) [Q] /\
       eqmod lr_t (r8_t15 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b15 *  -1600) [Q] /\
       eqmod lr_t (r8_t15 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b20@int16, r9_t20@int16:
      r9_b20 = r9_b /\ r9_t20 = r9_t
   && r9_b20 = r9_b /\ r9_t20 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b20 *  -1600) [Q] /\
       eqmod lr_t (r9_t20 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b20 *  -1600) [Q] /\
       eqmod lr_t (r9_t20 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b10@int16, r4_t10@int16:
      r4_b10 = r4_b /\ r4_t10 = r4_t
   && r4_b10 = r4_b /\ r4_t10 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b10 *  -749) [Q] /\
       eqmod lr_t (r4_t10 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b10 *  -749) [Q] /\
       eqmod lr_t (r4_t10 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b15@int16, r5_t15@int16:
      r5_b15 = r5_b /\ r5_t15 = r5_t
   && r5_b15 = r5_b /\ r5_t15 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b15 *  -749) [Q] /\
       eqmod lr_t (r5_t15 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b15 *  -749) [Q] /\
       eqmod lr_t (r5_t15 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b16@int16, r8_t16@int16:
      r8_b16 = r8_b /\ r8_t16 = r8_t
   && r8_b16 = r8_b /\ r8_t16 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b16 *  -40) [Q] /\
       eqmod lr_t (r8_t16 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b16 *  -40) [Q] /\
       eqmod lr_t (r8_t16 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b21@int16, r9_t21@int16:
      r9_b21 = r9_b /\ r9_t21 = r9_t
   && r9_b21 = r9_b /\ r9_t21 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b21 *  -40) [Q] /\
       eqmod lr_t (r9_t21 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b21 *  -40) [Q] /\
       eqmod lr_t (r9_t21 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b10@int16, r3_t10@int16:
      r3_b10 = r3_b /\ r3_t10 = r3_t
   && r3_b10 = r3_b /\ r3_t10 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b10 *  -687) [Q] /\
       eqmod lr_t (r3_t10 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b10 *  -687) [Q] /\
       eqmod lr_t (r3_t10 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b16@int16, r5_t16@int16:
      r5_b16 = r5_b /\ r5_t16 = r5_t
   && r5_b16 = r5_b /\ r5_t16 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b16 *  630) [Q] /\
       eqmod lr_t (r5_t16 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b16 *  630) [Q] /\
       eqmod lr_t (r5_t16 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b16@int16, r7_t16@int16:
      r7_b16 = r7_b /\ r7_t16 = r7_t
   && r7_b16 = r7_b /\ r7_t16 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b16 *  -1432) [Q] /\
       eqmod lr_t (r7_t16 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b16 *  -1432) [Q] /\
       eqmod lr_t (r7_t16 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b22@int16, r9_t22@int16:
      r9_b22 = r9_b /\ r9_t22 = r9_t
   && r9_b22 = r9_b /\ r9_t22 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b22 *  848) [Q] /\
       eqmod lr_t (r9_t22 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b22 *  848) [Q] /\
       eqmod lr_t (r9_t22 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff20c; PC = 0x400a40 *)
mov [L0xbefff20c, L0xbefff20e] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff22c; PC = 0x400a44 *)
mov [L0xbefff22c, L0xbefff22e] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff28c; PC = 0x400a54 *)
mov [L0xbefff28c, L0xbefff28e] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2ac; PC = 0x400a58 *)
mov [L0xbefff2ac, L0xbefff2ae] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff30c; PC = 0x400a68 *)
mov [L0xbefff30c, L0xbefff30e] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff32c; PC = 0x400a6c *)
mov [L0xbefff32c, L0xbefff32e] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff38c; PC = 0x400a7c *)
mov [L0xbefff38c, L0xbefff38e] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3ac; PC = 0x400a80 *)
mov [L0xbefff3ac, L0xbefff3ae] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff24c; PC = 0x400a90 *)
mov [L0xbefff24c, L0xbefff24e] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff26c; PC = 0x400a94 *)
mov [L0xbefff26c, L0xbefff26e] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2cc; PC = 0x400aa4 *)
mov [L0xbefff2cc, L0xbefff2ce] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff2ec; PC = 0x400aa8 *)
mov [L0xbefff2ec, L0xbefff2ee] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff34c; PC = 0x400ab8 *)
mov [L0xbefff34c, L0xbefff34e] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff36c; PC = 0x400abc *)
mov [L0xbefff36c, L0xbefff36e] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff1ec; PC = 0x400acc *)
mov [L0xbefff1ec, L0xbefff1ee] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1cc; PC = 0x400ad0 *)
mov [L0xbefff1cc, L0xbefff1ce] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1cc, L0xbefff1ce] /\
                        [L0xbefff1cc, L0xbefff1ce] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1ec, L0xbefff1ee] /\
                        [L0xbefff1ec, L0xbefff1ee] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff20c, L0xbefff20e] /\
                        [L0xbefff20c, L0xbefff20e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff22c, L0xbefff22e] /\
                        [L0xbefff22c, L0xbefff22e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff24c, L0xbefff24e] /\
                        [L0xbefff24c, L0xbefff24e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff26c, L0xbefff26e] /\
                        [L0xbefff26c, L0xbefff26e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff28c, L0xbefff28e] /\
                        [L0xbefff28c, L0xbefff28e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2ac, L0xbefff2ae] /\
                        [L0xbefff2ac, L0xbefff2ae] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2cc, L0xbefff2ce] /\
                        [L0xbefff2cc, L0xbefff2ce] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2ec, L0xbefff2ee] /\
                        [L0xbefff2ec, L0xbefff2ee] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff30c, L0xbefff30e] /\
                        [L0xbefff30c, L0xbefff30e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff32c, L0xbefff32e] /\
                        [L0xbefff32c, L0xbefff32e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff34c, L0xbefff34e] /\
                        [L0xbefff34c, L0xbefff34e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff36c, L0xbefff36e] /\
                        [L0xbefff36c, L0xbefff36e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff38c, L0xbefff38e] /\
                        [L0xbefff38c, L0xbefff38e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3ac, L0xbefff3ae] /\
                        [L0xbefff3ac, L0xbefff3ae] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [7]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1cc, L0xbefff1ce] /\
                        [L0xbefff1cc, L0xbefff1ce] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1ec, L0xbefff1ee] /\
                        [L0xbefff1ec, L0xbefff1ee] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff20c, L0xbefff20e] /\
                        [L0xbefff20c, L0xbefff20e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff22c, L0xbefff22e] /\
                        [L0xbefff22c, L0xbefff22e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff24c, L0xbefff24e] /\
                        [L0xbefff24c, L0xbefff24e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff26c, L0xbefff26e] /\
                        [L0xbefff26c, L0xbefff26e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff28c, L0xbefff28e] /\
                        [L0xbefff28c, L0xbefff28e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2ac, L0xbefff2ae] /\
                        [L0xbefff2ac, L0xbefff2ae] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2cc, L0xbefff2ce] /\
                        [L0xbefff2cc, L0xbefff2ce] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2ec, L0xbefff2ee] /\
                        [L0xbefff2ec, L0xbefff2ee] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff30c, L0xbefff30e] /\
                        [L0xbefff30c, L0xbefff30e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff32c, L0xbefff32e] /\
                        [L0xbefff32c, L0xbefff32e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff34c, L0xbefff34e] /\
                        [L0xbefff34c, L0xbefff34e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff36c, L0xbefff36e] /\
                        [L0xbefff36c, L0xbefff36e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff38c, L0xbefff38e] /\
                        [L0xbefff38c, L0xbefff38e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3ac, L0xbefff3ae] /\
                        [L0xbefff3ac, L0xbefff3ae] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1cc,L0xbefff1ce] /\
                            [L0xbefff1cc,L0xbefff1ce]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff1ec,L0xbefff1ee] /\
                            [L0xbefff1ec,L0xbefff1ee]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff20c,L0xbefff20e] /\
                            [L0xbefff20c,L0xbefff20e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff22c,L0xbefff22e] /\
                            [L0xbefff22c,L0xbefff22e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff24c,L0xbefff24e] /\
                            [L0xbefff24c,L0xbefff24e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff26c,L0xbefff26e] /\
                            [L0xbefff26c,L0xbefff26e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff28c,L0xbefff28e] /\
                            [L0xbefff28c,L0xbefff28e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2ac,L0xbefff2ae] /\
                            [L0xbefff2ac,L0xbefff2ae]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2cc,L0xbefff2ce] /\
                            [L0xbefff2cc,L0xbefff2ce]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2ec,L0xbefff2ee] /\
                            [L0xbefff2ec,L0xbefff2ee]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff30c,L0xbefff30e] /\
                            [L0xbefff30c,L0xbefff30e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff32c,L0xbefff32e] /\
                            [L0xbefff32c,L0xbefff32e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff34c,L0xbefff34e] /\
                            [L0xbefff34c,L0xbefff34e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff36c,L0xbefff36e] /\
                            [L0xbefff36c,L0xbefff36e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff38c,L0xbefff38e] /\
                            [L0xbefff38c,L0xbefff38e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3ac,L0xbefff3ae] /\
                            [L0xbefff3ac,L0xbefff3ae]<s[5@16*Q2,5@16*Q2];

(* CUT 9 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F4**2+F5**2)(L0xbefff1cc*X**4+L0xbefff1ce*X**5)[Q,X**16-17**  8]/\
    eqmod (F4**2+F5**2)(L0xbefff1ec*X**4+L0xbefff1ee*X**5)[Q,X**16-17**136]/\
    eqmod (F4**2+F5**2)(L0xbefff20c*X**4+L0xbefff20e*X**5)[Q,X**16-17** 72]/\
    eqmod (F4**2+F5**2)(L0xbefff22c*X**4+L0xbefff22e*X**5)[Q,X**16-17**200]/\
    eqmod (F4**2+F5**2)(L0xbefff24c*X**4+L0xbefff24e*X**5)[Q,X**16-17** 40]/\
    eqmod (F4**2+F5**2)(L0xbefff26c*X**4+L0xbefff26e*X**5)[Q,X**16-17**168]/\
    eqmod (F4**2+F5**2)(L0xbefff28c*X**4+L0xbefff28e*X**5)[Q,X**16-17**104]/\
    eqmod (F4**2+F5**2)(L0xbefff2ac*X**4+L0xbefff2ae*X**5)[Q,X**16-17**232]/\
    eqmod (F4**2+F5**2)(L0xbefff2cc*X**4+L0xbefff2ce*X**5)[Q,X**16-17** 24]/\
    eqmod (F4**2+F5**2)(L0xbefff2ec*X**4+L0xbefff2ee*X**5)[Q,X**16-17**152]/\
    eqmod (F4**2+F5**2)(L0xbefff30c*X**4+L0xbefff30e*X**5)[Q,X**16-17** 88]/\
    eqmod (F4**2+F5**2)(L0xbefff32c*X**4+L0xbefff32e*X**5)[Q,X**16-17**216]/\
    eqmod (F4**2+F5**2)(L0xbefff34c*X**4+L0xbefff34e*X**5)[Q,X**16-17** 56]/\
    eqmod (F4**2+F5**2)(L0xbefff36c*X**4+L0xbefff36e*X**5)[Q,X**16-17**184]/\
    eqmod (F4**2+F5**2)(L0xbefff38c*X**4+L0xbefff38e*X**5)[Q,X**16-17**120]/\
    eqmod (F4**2+F5**2)(L0xbefff3ac*X**4+L0xbefff3ae*X**5)[Q,X**16-17**248]/\
    [5*NQ2, 5*NQ2] < [L0xbefff1cc, L0xbefff1ce] /\
                     [L0xbefff1cc, L0xbefff1ce] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1ec, L0xbefff1ee] /\
                     [L0xbefff1ec, L0xbefff1ee] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff20c, L0xbefff20e] /\
                     [L0xbefff20c, L0xbefff20e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff22c, L0xbefff22e] /\
                     [L0xbefff22c, L0xbefff22e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff24c, L0xbefff24e] /\
                     [L0xbefff24c, L0xbefff24e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff26c, L0xbefff26e] /\
                     [L0xbefff26c, L0xbefff26e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff28c, L0xbefff28e] /\
                     [L0xbefff28c, L0xbefff28e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2ac, L0xbefff2ae] /\
                     [L0xbefff2ac, L0xbefff2ae] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2cc, L0xbefff2ce] /\
                     [L0xbefff2cc, L0xbefff2ce] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2ec, L0xbefff2ee] /\
                     [L0xbefff2ec, L0xbefff2ee] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff30c, L0xbefff30e] /\
                     [L0xbefff30c, L0xbefff30e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff32c, L0xbefff32e] /\
                     [L0xbefff32c, L0xbefff32e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff34c, L0xbefff34e] /\
                     [L0xbefff34c, L0xbefff34e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff36c, L0xbefff36e] /\
                     [L0xbefff36c, L0xbefff36e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff38c, L0xbefff38e] /\
                     [L0xbefff38c, L0xbefff38e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3ac, L0xbefff3ae] /\
                     [L0xbefff3ac, L0xbefff3ae] < [5*Q2, 5*Q2]
    prove with [cuts [7], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1cc,L0xbefff1ce] /\
                         [L0xbefff1cc,L0xbefff1ce]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1ec,L0xbefff1ee] /\
                         [L0xbefff1ec,L0xbefff1ee]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff20c,L0xbefff20e] /\
                         [L0xbefff20c,L0xbefff20e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff22c,L0xbefff22e] /\
                         [L0xbefff22c,L0xbefff22e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff24c,L0xbefff24e] /\
                         [L0xbefff24c,L0xbefff24e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff26c,L0xbefff26e] /\
                         [L0xbefff26c,L0xbefff26e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff28c,L0xbefff28e] /\
                         [L0xbefff28c,L0xbefff28e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2ac,L0xbefff2ae] /\
                         [L0xbefff2ac,L0xbefff2ae]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2cc,L0xbefff2ce] /\
                         [L0xbefff2cc,L0xbefff2ce]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2ec,L0xbefff2ee] /\
                         [L0xbefff2ec,L0xbefff2ee]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff30c,L0xbefff30e] /\
                         [L0xbefff30c,L0xbefff30e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff32c,L0xbefff32e] /\
                         [L0xbefff32c,L0xbefff32e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff34c,L0xbefff34e] /\
                         [L0xbefff34c,L0xbefff34e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff36c,L0xbefff36e] /\
                         [L0xbefff36c,L0xbefff36e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff38c,L0xbefff38e] /\
                         [L0xbefff38c,L0xbefff38e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3ac,L0xbefff3ae] /\
                         [L0xbefff3ac,L0xbefff3ae]<s[5@16*Q2,5@16*Q2]
    prove with [precondition];

(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff1f0; Value = 0xbefff218; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff1f0, L0xbefff1f2];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff230; Value = 0x00000000; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff230, L0xbefff232];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff270; Value = 0x00000000; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff270, L0xbefff272];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2b0; Value = 0xb6ffe8f8; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2b0, L0xbefff2b2];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff2f0; Value = 0x00000000; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff2f0, L0xbefff2f2];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff330; Value = 0x00000001; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff330, L0xbefff332];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff370; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff370, L0xbefff372];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3b0; Value = 0xb6fb53c4; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3b0, L0xbefff3b2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b12@int16, r6_t12@int16:
      r6_b12 = r6_b /\ r6_t12 = r6_t
   && r6_b12 = r6_b /\ r6_t12 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b12 *  -1600) [Q] /\
       eqmod lr_t (r6_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b12 *  -1600) [Q] /\
       eqmod lr_t (r6_t12 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b18@int16, r7_t18@int16:
      r7_b18 = r7_b /\ r7_t18 = r7_t
   && r7_b18 = r7_b /\ r7_t18 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b18 *  -1600) [Q] /\
       eqmod lr_t (r7_t18 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b18 *  -1600) [Q] /\
       eqmod lr_t (r7_t18 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b18@int16, r8_t18@int16:
      r8_b18 = r8_b /\ r8_t18 = r8_t
   && r8_b18 = r8_b /\ r8_t18 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b18 *  -1600) [Q] /\
       eqmod lr_t (r8_t18 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b18 *  -1600) [Q] /\
       eqmod lr_t (r8_t18 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b24@int16, r9_t24@int16:
      r9_b24 = r9_b /\ r9_t24 = r9_t
   && r9_b24 = r9_b /\ r9_t24 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b24 *  -1600) [Q] /\
       eqmod lr_t (r9_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b24 *  -1600) [Q] /\
       eqmod lr_t (r9_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b12@int16, r4_t12@int16:
      r4_b12 = r4_b /\ r4_t12 = r4_t
   && r4_b12 = r4_b /\ r4_t12 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b12 *  -749) [Q] /\
       eqmod lr_t (r4_t12 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b12 *  -749) [Q] /\
       eqmod lr_t (r4_t12 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b18@int16, r5_t18@int16:
      r5_b18 = r5_b /\ r5_t18 = r5_t
   && r5_b18 = r5_b /\ r5_t18 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b18 *  -749) [Q] /\
       eqmod lr_t (r5_t18 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b18 *  -749) [Q] /\
       eqmod lr_t (r5_t18 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b19@int16, r8_t19@int16:
      r8_b19 = r8_b /\ r8_t19 = r8_t
   && r8_b19 = r8_b /\ r8_t19 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b19 *  -40) [Q] /\
       eqmod lr_t (r8_t19 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b19 *  -40) [Q] /\
       eqmod lr_t (r8_t19 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b25@int16, r9_t25@int16:
      r9_b25 = r9_b /\ r9_t25 = r9_t
   && r9_b25 = r9_b /\ r9_t25 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b25 *  -40) [Q] /\
       eqmod lr_t (r9_t25 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b25 *  -40) [Q] /\
       eqmod lr_t (r9_t25 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b12@int16, r3_t12@int16:
      r3_b12 = r3_b /\ r3_t12 = r3_t
   && r3_b12 = r3_b /\ r3_t12 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b12 *  -687) [Q] /\
       eqmod lr_t (r3_t12 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b12 *  -687) [Q] /\
       eqmod lr_t (r3_t12 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b19@int16, r5_t19@int16:
      r5_b19 = r5_b /\ r5_t19 = r5_t
   && r5_b19 = r5_b /\ r5_t19 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b19 *  630) [Q] /\
       eqmod lr_t (r5_t19 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b19 *  630) [Q] /\
       eqmod lr_t (r5_t19 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b19@int16, r7_t19@int16:
      r7_b19 = r7_b /\ r7_t19 = r7_t
   && r7_b19 = r7_b /\ r7_t19 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b19 *  -1432) [Q] /\
       eqmod lr_t (r7_t19 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b19 *  -1432) [Q] /\
       eqmod lr_t (r7_t19 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b26@int16, r9_t26@int16:
      r9_b26 = r9_b /\ r9_t26 = r9_t
   && r9_b26 = r9_b /\ r9_t26 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b26 *  848) [Q] /\
       eqmod lr_t (r9_t26 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b26 *  848) [Q] /\
       eqmod lr_t (r9_t26 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 10 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F6**2) (r2_b*X**22 + r2_t*X**23) [Q, X**32 - 17** 16] /\
    eqmod (F6**2) (r3_b*X**22 + r3_t*X**23) [Q, X**32 - 17**144] /\
    eqmod (F6**2) (r4_b*X**22 + r4_t*X**23) [Q, X**32 - 17** 80] /\
    eqmod (F6**2) (r5_b*X**22 + r5_t*X**23) [Q, X**32 - 17**208] /\
    eqmod (F6**2) (r6_b*X**22 + r6_t*X**23) [Q, X**32 - 17** 48] /\
    eqmod (F6**2) (r7_b*X**22 + r7_t*X**23) [Q, X**32 - 17**176] /\
    eqmod (F6**2) (r8_b*X**22 + r8_t*X**23) [Q, X**32 - 17**112] /\
    eqmod (F6**2) (r9_b*X**22 + r9_t*X**23) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q]
    prove with [precondition];

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;

ghost r2_b6@int16, r2_t6@int16:
      r2_b6 = r2_b /\ r2_t6 = r2_t
   && r2_b6 = r2_b /\ r2_t6 = r2_t;

(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b6 *  1062) [Q] /\
       eqmod r2_t (r2_t6 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r2_b (r2_b6 *  1062) [Q] /\
       eqmod r2_t (r2_t6 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];


ghost r3_b13@int16, r3_t13@int16:
      r3_b13 = r3_b /\ r3_t13 = r3_t
   && r3_b13 = r3_b /\ r3_t13 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b13 *  -1410) [Q] /\
       eqmod r3_t (r3_t13 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r3_b (r3_b13 *  -1410) [Q] /\
       eqmod r3_t (r3_t13 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;

ghost r4_b13@int16, r4_t13@int16:
      r4_b13 = r4_b /\ r4_t13 = r4_t
   && r4_b13 = r4_b /\ r4_t13 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b13 *  193) [Q] /\
       eqmod r4_t (r4_t13 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r4_b (r4_b13 *  193) [Q] /\
       eqmod r4_t (r4_t13 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];


ghost r5_b20@int16, r5_t20@int16:
      r5_b20 = r5_b /\ r5_t20 = r5_t
   && r5_b20 = r5_b /\ r5_t20 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b20 *  797) [Q] /\
       eqmod r5_t (r5_t20 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r5_b (r5_b20 *  797) [Q] /\
       eqmod r5_t (r5_t20 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;

ghost r6_b13@int16, r6_t13@int16:
      r6_b13 = r6_b /\ r6_t13 = r6_t
   && r6_b13 = r6_b /\ r6_t13 = r6_t;

(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b13 *  -543) [Q] /\
       eqmod r6_t (r6_t13 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r6_b (r6_b13 *  -543) [Q] /\
       eqmod r6_t (r6_t13 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];


ghost r7_b20@int16, r7_t20@int16:
      r7_b20 = r7_b /\ r7_t20 = r7_t
   && r7_b20 = r7_b /\ r7_t20 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b20 *  -69) [Q] /\
       eqmod r7_t (r7_t20 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r7_b (r7_b20 *  -69) [Q] /\
       eqmod r7_t (r7_t20 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;

ghost r8_b20@int16, r8_t20@int16:
      r8_b20 = r8_b /\ r8_t20 = r8_t
   && r8_b20 = r8_b /\ r8_t20 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b20 *  569) [Q] /\
       eqmod r8_t (r8_t20 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r8_b (r8_b20 *  569) [Q] /\
       eqmod r8_t (r8_t20 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];


ghost r9_b27@int16, r9_t27@int16:
      r9_b27 = r9_b /\ r9_t27 = r9_t
   && r9_b27 = r9_b /\ r9_t27 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b27 *  -1583) [Q] /\
       eqmod r9_t (r9_t27 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r9_b (r9_b27 *  -1583) [Q] /\
       eqmod r9_t (r9_t27 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 11 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*F6**2) (r2_b*X**22 + r2_t*X**23) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*F6**2) (r3_b*X**22 + r3_t*X**23) [Q, X**32 - 17**144] /\
    eqmod (17** 40*F6**2) (r4_b*X**22 + r4_t*X**23) [Q, X**32 - 17** 80] /\
    eqmod (17**104*F6**2) (r5_b*X**22 + r5_t*X**23) [Q, X**32 - 17**208] /\
    eqmod (17** 24*F6**2) (r6_b*X**22 + r6_t*X**23) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*F6**2) (r7_b*X**22 + r7_t*X**23) [Q, X**32 - 17**176] /\
    eqmod (17** 56*F6**2) (r8_b*X**22 + r8_t*X**23) [Q, X**32 - 17**112] /\
    eqmod (17**120*F6**2) (r9_b*X**22 + r9_t*X**23) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2]
    prove with [precondition];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1d0; Value = 0x00000000; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1d0, L0xbefff1d2];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff210; Value = 0x00000009; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff210, L0xbefff212];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff250; Value = 0xb6fd5754; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff250, L0xbefff252];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff290; Value = 0xb6ffb530; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff290, L0xbefff292];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2d0; Value = 0x00000000; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2d0, L0xbefff2d2];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff310; Value = 0x00000000; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff310, L0xbefff312];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff350; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff350, L0xbefff352];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff390; Value = 0x0040152d; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff390, L0xbefff392];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b14@int16, r6_t14@int16:
      r6_b14 = r6_b /\ r6_t14 = r6_t
   && r6_b14 = r6_b /\ r6_t14 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b14 *  -1600) [Q] /\
       eqmod lr_t (r6_t14 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b14 *  -1600) [Q] /\
       eqmod lr_t (r6_t14 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b21@int16, r7_t21@int16:
      r7_b21 = r7_b /\ r7_t21 = r7_t
   && r7_b21 = r7_b /\ r7_t21 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b21 *  -1600) [Q] /\
       eqmod lr_t (r7_t21 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b21 *  -1600) [Q] /\
       eqmod lr_t (r7_t21 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b21@int16, r8_t21@int16:
      r8_b21 = r8_b /\ r8_t21 = r8_t
   && r8_b21 = r8_b /\ r8_t21 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b21 *  -1600) [Q] /\
       eqmod lr_t (r8_t21 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b21 *  -1600) [Q] /\
       eqmod lr_t (r8_t21 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b28@int16, r9_t28@int16:
      r9_b28 = r9_b /\ r9_t28 = r9_t
   && r9_b28 = r9_b /\ r9_t28 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b28 *  -1600) [Q] /\
       eqmod lr_t (r9_t28 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b28 *  -1600) [Q] /\
       eqmod lr_t (r9_t28 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b14@int16, r4_t14@int16:
      r4_b14 = r4_b /\ r4_t14 = r4_t
   && r4_b14 = r4_b /\ r4_t14 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b14 *  -749) [Q] /\
       eqmod lr_t (r4_t14 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b14 *  -749) [Q] /\
       eqmod lr_t (r4_t14 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b21@int16, r5_t21@int16:
      r5_b21 = r5_b /\ r5_t21 = r5_t
   && r5_b21 = r5_b /\ r5_t21 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b21 *  -749) [Q] /\
       eqmod lr_t (r5_t21 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b21 *  -749) [Q] /\
       eqmod lr_t (r5_t21 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b22@int16, r8_t22@int16:
      r8_b22 = r8_b /\ r8_t22 = r8_t
   && r8_b22 = r8_b /\ r8_t22 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b22 *  -40) [Q] /\
       eqmod lr_t (r8_t22 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b22 *  -40) [Q] /\
       eqmod lr_t (r8_t22 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b29@int16, r9_t29@int16:
      r9_b29 = r9_b /\ r9_t29 = r9_t
   && r9_b29 = r9_b /\ r9_t29 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b29 *  -40) [Q] /\
       eqmod lr_t (r9_t29 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b29 *  -40) [Q] /\
       eqmod lr_t (r9_t29 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b14@int16, r3_t14@int16:
      r3_b14 = r3_b /\ r3_t14 = r3_t
   && r3_b14 = r3_b /\ r3_t14 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b14 *  -687) [Q] /\
       eqmod lr_t (r3_t14 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b14 *  -687) [Q] /\
       eqmod lr_t (r3_t14 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b22@int16, r5_t22@int16:
      r5_b22 = r5_b /\ r5_t22 = r5_t
   && r5_b22 = r5_b /\ r5_t22 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b22 *  630) [Q] /\
       eqmod lr_t (r5_t22 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b22 *  630) [Q] /\
       eqmod lr_t (r5_t22 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b22@int16, r7_t22@int16:
      r7_b22 = r7_b /\ r7_t22 = r7_t
   && r7_b22 = r7_b /\ r7_t22 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b22 *  -1432) [Q] /\
       eqmod lr_t (r7_t22 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b22 *  -1432) [Q] /\
       eqmod lr_t (r7_t22 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b30@int16, r9_t30@int16:
      r9_b30 = r9_b /\ r9_t30 = r9_t
   && r9_b30 = r9_b /\ r9_t30 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b30 *  848) [Q] /\
       eqmod lr_t (r9_t30 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b30 *  848) [Q] /\
       eqmod lr_t (r9_t30 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff210; PC = 0x400a40 *)
mov [L0xbefff210, L0xbefff212] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff230; PC = 0x400a44 *)
mov [L0xbefff230, L0xbefff232] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff290; PC = 0x400a54 *)
mov [L0xbefff290, L0xbefff292] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2b0; PC = 0x400a58 *)
mov [L0xbefff2b0, L0xbefff2b2] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff310; PC = 0x400a68 *)
mov [L0xbefff310, L0xbefff312] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff330; PC = 0x400a6c *)
mov [L0xbefff330, L0xbefff332] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff390; PC = 0x400a7c *)
mov [L0xbefff390, L0xbefff392] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3b0; PC = 0x400a80 *)
mov [L0xbefff3b0, L0xbefff3b2] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff250; PC = 0x400a90 *)
mov [L0xbefff250, L0xbefff252] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff270; PC = 0x400a94 *)
mov [L0xbefff270, L0xbefff272] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2d0; PC = 0x400aa4 *)
mov [L0xbefff2d0, L0xbefff2d2] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff2f0; PC = 0x400aa8 *)
mov [L0xbefff2f0, L0xbefff2f2] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff350; PC = 0x400ab8 *)
mov [L0xbefff350, L0xbefff352] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff370; PC = 0x400abc *)
mov [L0xbefff370, L0xbefff372] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff1f0; PC = 0x400acc *)
mov [L0xbefff1f0, L0xbefff1f2] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1d0; PC = 0x400ad0 *)
mov [L0xbefff1d0, L0xbefff1d2] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1d0, L0xbefff1d2] /\
                        [L0xbefff1d0, L0xbefff1d2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1f0, L0xbefff1f2] /\
                        [L0xbefff1f0, L0xbefff1f2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff210, L0xbefff212] /\
                        [L0xbefff210, L0xbefff212] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff230, L0xbefff232] /\
                        [L0xbefff230, L0xbefff232] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff250, L0xbefff252] /\
                        [L0xbefff250, L0xbefff252] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff270, L0xbefff272] /\
                        [L0xbefff270, L0xbefff272] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff290, L0xbefff292] /\
                        [L0xbefff290, L0xbefff292] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2b0, L0xbefff2b2] /\
                        [L0xbefff2b0, L0xbefff2b2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2d0, L0xbefff2d2] /\
                        [L0xbefff2d0, L0xbefff2d2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2f0, L0xbefff2f2] /\
                        [L0xbefff2f0, L0xbefff2f2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff310, L0xbefff312] /\
                        [L0xbefff310, L0xbefff312] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff330, L0xbefff332] /\
                        [L0xbefff330, L0xbefff332] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff350, L0xbefff352] /\
                        [L0xbefff350, L0xbefff352] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff370, L0xbefff372] /\
                        [L0xbefff370, L0xbefff372] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff390, L0xbefff392] /\
                        [L0xbefff390, L0xbefff392] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3b0, L0xbefff3b2] /\
                        [L0xbefff3b0, L0xbefff3b2] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [10]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1d0, L0xbefff1d2] /\
                        [L0xbefff1d0, L0xbefff1d2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1f0, L0xbefff1f2] /\
                        [L0xbefff1f0, L0xbefff1f2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff210, L0xbefff212] /\
                        [L0xbefff210, L0xbefff212] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff230, L0xbefff232] /\
                        [L0xbefff230, L0xbefff232] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff250, L0xbefff252] /\
                        [L0xbefff250, L0xbefff252] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff270, L0xbefff272] /\
                        [L0xbefff270, L0xbefff272] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff290, L0xbefff292] /\
                        [L0xbefff290, L0xbefff292] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2b0, L0xbefff2b2] /\
                        [L0xbefff2b0, L0xbefff2b2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2d0, L0xbefff2d2] /\
                        [L0xbefff2d0, L0xbefff2d2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2f0, L0xbefff2f2] /\
                        [L0xbefff2f0, L0xbefff2f2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff310, L0xbefff312] /\
                        [L0xbefff310, L0xbefff312] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff330, L0xbefff332] /\
                        [L0xbefff330, L0xbefff332] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff350, L0xbefff352] /\
                        [L0xbefff350, L0xbefff352] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff370, L0xbefff372] /\
                        [L0xbefff370, L0xbefff372] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff390, L0xbefff392] /\
                        [L0xbefff390, L0xbefff392] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3b0, L0xbefff3b2] /\
                        [L0xbefff3b0, L0xbefff3b2] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1d0,L0xbefff1d2] /\
                            [L0xbefff1d0,L0xbefff1d2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff1f0,L0xbefff1f2] /\
                            [L0xbefff1f0,L0xbefff1f2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff210,L0xbefff212] /\
                            [L0xbefff210,L0xbefff212]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff230,L0xbefff232] /\
                            [L0xbefff230,L0xbefff232]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff250,L0xbefff252] /\
                            [L0xbefff250,L0xbefff252]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff270,L0xbefff272] /\
                            [L0xbefff270,L0xbefff272]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff290,L0xbefff292] /\
                            [L0xbefff290,L0xbefff292]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2b0,L0xbefff2b2] /\
                            [L0xbefff2b0,L0xbefff2b2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2d0,L0xbefff2d2] /\
                            [L0xbefff2d0,L0xbefff2d2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2f0,L0xbefff2f2] /\
                            [L0xbefff2f0,L0xbefff2f2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff310,L0xbefff312] /\
                            [L0xbefff310,L0xbefff312]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff330,L0xbefff332] /\
                            [L0xbefff330,L0xbefff332]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff350,L0xbefff352] /\
                            [L0xbefff350,L0xbefff352]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff370,L0xbefff372] /\
                            [L0xbefff370,L0xbefff372]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff390,L0xbefff392] /\
                            [L0xbefff390,L0xbefff392]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3b0,L0xbefff3b2] /\
                            [L0xbefff3b0,L0xbefff3b2]<s[5@16*Q2,5@16*Q2];

(* CUT 12 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F6**2+F7**2)(L0xbefff1d0*X**6+L0xbefff1d2*X**7)[Q,X**16-17**  8]/\
    eqmod (F6**2+F7**2)(L0xbefff1f0*X**6+L0xbefff1f2*X**7)[Q,X**16-17**136]/\
    eqmod (F6**2+F7**2)(L0xbefff210*X**6+L0xbefff212*X**7)[Q,X**16-17** 72]/\
    eqmod (F6**2+F7**2)(L0xbefff230*X**6+L0xbefff232*X**7)[Q,X**16-17**200]/\
    eqmod (F6**2+F7**2)(L0xbefff250*X**6+L0xbefff252*X**7)[Q,X**16-17** 40]/\
    eqmod (F6**2+F7**2)(L0xbefff270*X**6+L0xbefff272*X**7)[Q,X**16-17**168]/\
    eqmod (F6**2+F7**2)(L0xbefff290*X**6+L0xbefff292*X**7)[Q,X**16-17**104]/\
    eqmod (F6**2+F7**2)(L0xbefff2b0*X**6+L0xbefff2b2*X**7)[Q,X**16-17**232]/\
    eqmod (F6**2+F7**2)(L0xbefff2d0*X**6+L0xbefff2d2*X**7)[Q,X**16-17** 24]/\
    eqmod (F6**2+F7**2)(L0xbefff2f0*X**6+L0xbefff2f2*X**7)[Q,X**16-17**152]/\
    eqmod (F6**2+F7**2)(L0xbefff310*X**6+L0xbefff312*X**7)[Q,X**16-17** 88]/\
    eqmod (F6**2+F7**2)(L0xbefff330*X**6+L0xbefff332*X**7)[Q,X**16-17**216]/\
    eqmod (F6**2+F7**2)(L0xbefff350*X**6+L0xbefff352*X**7)[Q,X**16-17** 56]/\
    eqmod (F6**2+F7**2)(L0xbefff370*X**6+L0xbefff372*X**7)[Q,X**16-17**184]/\
    eqmod (F6**2+F7**2)(L0xbefff390*X**6+L0xbefff392*X**7)[Q,X**16-17**120]/\
    eqmod (F6**2+F7**2)(L0xbefff3b0*X**6+L0xbefff3b2*X**7)[Q,X**16-17**248]/\
    [5*NQ2, 5*NQ2] < [L0xbefff1d0, L0xbefff1d2] /\
                     [L0xbefff1d0, L0xbefff1d2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1f0, L0xbefff1f2] /\
                     [L0xbefff1f0, L0xbefff1f2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff210, L0xbefff212] /\
                     [L0xbefff210, L0xbefff212] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff230, L0xbefff232] /\
                     [L0xbefff230, L0xbefff232] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff250, L0xbefff252] /\
                     [L0xbefff250, L0xbefff252] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff270, L0xbefff272] /\
                     [L0xbefff270, L0xbefff272] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff290, L0xbefff292] /\
                     [L0xbefff290, L0xbefff292] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2b0, L0xbefff2b2] /\
                     [L0xbefff2b0, L0xbefff2b2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2d0, L0xbefff2d2] /\
                     [L0xbefff2d0, L0xbefff2d2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2f0, L0xbefff2f2] /\
                     [L0xbefff2f0, L0xbefff2f2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff310, L0xbefff312] /\
                     [L0xbefff310, L0xbefff312] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff330, L0xbefff332] /\
                     [L0xbefff330, L0xbefff332] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff350, L0xbefff352] /\
                     [L0xbefff350, L0xbefff352] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff370, L0xbefff372] /\
                     [L0xbefff370, L0xbefff372] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff390, L0xbefff392] /\
                     [L0xbefff390, L0xbefff392] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3b0, L0xbefff3b2] /\
                     [L0xbefff3b0, L0xbefff3b2] < [5*Q2, 5*Q2]
    prove with [cuts [10], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1d0,L0xbefff1d2] /\
                         [L0xbefff1d0,L0xbefff1d2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1f0,L0xbefff1f2] /\
                         [L0xbefff1f0,L0xbefff1f2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff210,L0xbefff212] /\
                         [L0xbefff210,L0xbefff212]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff230,L0xbefff232] /\
                         [L0xbefff230,L0xbefff232]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff250,L0xbefff252] /\
                         [L0xbefff250,L0xbefff252]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff270,L0xbefff272] /\
                         [L0xbefff270,L0xbefff272]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff290,L0xbefff292] /\
                         [L0xbefff290,L0xbefff292]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2b0,L0xbefff2b2] /\
                         [L0xbefff2b0,L0xbefff2b2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2d0,L0xbefff2d2] /\
                         [L0xbefff2d0,L0xbefff2d2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2f0,L0xbefff2f2] /\
                         [L0xbefff2f0,L0xbefff2f2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff310,L0xbefff312] /\
                         [L0xbefff310,L0xbefff312]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff330,L0xbefff332] /\
                         [L0xbefff330,L0xbefff332]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff350,L0xbefff352] /\
                         [L0xbefff350,L0xbefff352]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff370,L0xbefff372] /\
                         [L0xbefff370,L0xbefff372]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff390,L0xbefff392] /\
                         [L0xbefff390,L0xbefff392]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3b0,L0xbefff3b2] /\
                         [L0xbefff3b0,L0xbefff3b2]<s[5@16*Q2,5@16*Q2]
    prove with [precondition];

(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff1f4; Value = 0xbefff218; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff1f4, L0xbefff1f6];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff234; Value = 0xb6fff5c8; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff234, L0xbefff236];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff274; Value = 0x00000000; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff274, L0xbefff276];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2b4; Value = 0xbefff2d0; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2b4, L0xbefff2b6];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff2f4; Value = 0x00000001; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff2f4, L0xbefff2f6];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff334; Value = 0x00000000; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff334, L0xbefff336];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff374; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff374, L0xbefff376];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3b4; Value = 0x0040152d; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3b4, L0xbefff3b6];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b16@int16, r6_t16@int16:
      r6_b16 = r6_b /\ r6_t16 = r6_t
   && r6_b16 = r6_b /\ r6_t16 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b16 *  -1600) [Q] /\
       eqmod lr_t (r6_t16 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b16 *  -1600) [Q] /\
       eqmod lr_t (r6_t16 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b24@int16, r7_t24@int16:
      r7_b24 = r7_b /\ r7_t24 = r7_t
   && r7_b24 = r7_b /\ r7_t24 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b24 *  -1600) [Q] /\
       eqmod lr_t (r7_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b24 *  -1600) [Q] /\
       eqmod lr_t (r7_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b24@int16, r8_t24@int16:
      r8_b24 = r8_b /\ r8_t24 = r8_t
   && r8_b24 = r8_b /\ r8_t24 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b24 *  -1600) [Q] /\
       eqmod lr_t (r8_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b24 *  -1600) [Q] /\
       eqmod lr_t (r8_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b32@int16, r9_t32@int16:
      r9_b32 = r9_b /\ r9_t32 = r9_t
   && r9_b32 = r9_b /\ r9_t32 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b32 *  -1600) [Q] /\
       eqmod lr_t (r9_t32 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b32 *  -1600) [Q] /\
       eqmod lr_t (r9_t32 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b16@int16, r4_t16@int16:
      r4_b16 = r4_b /\ r4_t16 = r4_t
   && r4_b16 = r4_b /\ r4_t16 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b16 *  -749) [Q] /\
       eqmod lr_t (r4_t16 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b16 *  -749) [Q] /\
       eqmod lr_t (r4_t16 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b24@int16, r5_t24@int16:
      r5_b24 = r5_b /\ r5_t24 = r5_t
   && r5_b24 = r5_b /\ r5_t24 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b24 *  -749) [Q] /\
       eqmod lr_t (r5_t24 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b24 *  -749) [Q] /\
       eqmod lr_t (r5_t24 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b25@int16, r8_t25@int16:
      r8_b25 = r8_b /\ r8_t25 = r8_t
   && r8_b25 = r8_b /\ r8_t25 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b25 *  -40) [Q] /\
       eqmod lr_t (r8_t25 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b25 *  -40) [Q] /\
       eqmod lr_t (r8_t25 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b33@int16, r9_t33@int16:
      r9_b33 = r9_b /\ r9_t33 = r9_t
   && r9_b33 = r9_b /\ r9_t33 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b33 *  -40) [Q] /\
       eqmod lr_t (r9_t33 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b33 *  -40) [Q] /\
       eqmod lr_t (r9_t33 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b16@int16, r3_t16@int16:
      r3_b16 = r3_b /\ r3_t16 = r3_t
   && r3_b16 = r3_b /\ r3_t16 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b16 *  -687) [Q] /\
       eqmod lr_t (r3_t16 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b16 *  -687) [Q] /\
       eqmod lr_t (r3_t16 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b25@int16, r5_t25@int16:
      r5_b25 = r5_b /\ r5_t25 = r5_t
   && r5_b25 = r5_b /\ r5_t25 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b25 *  630) [Q] /\
       eqmod lr_t (r5_t25 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b25 *  630) [Q] /\
       eqmod lr_t (r5_t25 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b25@int16, r7_t25@int16:
      r7_b25 = r7_b /\ r7_t25 = r7_t
   && r7_b25 = r7_b /\ r7_t25 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b25 *  -1432) [Q] /\
       eqmod lr_t (r7_t25 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b25 *  -1432) [Q] /\
       eqmod lr_t (r7_t25 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b34@int16, r9_t34@int16:
      r9_b34 = r9_b /\ r9_t34 = r9_t
   && r9_b34 = r9_b /\ r9_t34 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b34 *  848) [Q] /\
       eqmod lr_t (r9_t34 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b34 *  848) [Q] /\
       eqmod lr_t (r9_t34 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 13 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F8**2) (r2_b*X**24 + r2_t*X**25) [Q, X**32 - 17** 16] /\
    eqmod (F8**2) (r3_b*X**24 + r3_t*X**25) [Q, X**32 - 17**144] /\
    eqmod (F8**2) (r4_b*X**24 + r4_t*X**25) [Q, X**32 - 17** 80] /\
    eqmod (F8**2) (r5_b*X**24 + r5_t*X**25) [Q, X**32 - 17**208] /\
    eqmod (F8**2) (r6_b*X**24 + r6_t*X**25) [Q, X**32 - 17** 48] /\
    eqmod (F8**2) (r7_b*X**24 + r7_t*X**25) [Q, X**32 - 17**176] /\
    eqmod (F8**2) (r8_b*X**24 + r8_t*X**25) [Q, X**32 - 17**112] /\
    eqmod (F8**2) (r9_b*X**24 + r9_t*X**25) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q]
    prove with [precondition];

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;

ghost r2_b8@int16, r2_t8@int16:
      r2_b8 = r2_b /\ r2_t8 = r2_t
   && r2_b8 = r2_b /\ r2_t8 = r2_t;

(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b8 *  1062) [Q] /\
       eqmod r2_t (r2_t8 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r2_b (r2_b8 *  1062) [Q] /\
       eqmod r2_t (r2_t8 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];


ghost r3_b17@int16, r3_t17@int16:
      r3_b17 = r3_b /\ r3_t17 = r3_t
   && r3_b17 = r3_b /\ r3_t17 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b17 *  -1410) [Q] /\
       eqmod r3_t (r3_t17 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r3_b (r3_b17 *  -1410) [Q] /\
       eqmod r3_t (r3_t17 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;

ghost r4_b17@int16, r4_t17@int16:
      r4_b17 = r4_b /\ r4_t17 = r4_t
   && r4_b17 = r4_b /\ r4_t17 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b17 *  193) [Q] /\
       eqmod r4_t (r4_t17 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r4_b (r4_b17 *  193) [Q] /\
       eqmod r4_t (r4_t17 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];


ghost r5_b26@int16, r5_t26@int16:
      r5_b26 = r5_b /\ r5_t26 = r5_t
   && r5_b26 = r5_b /\ r5_t26 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b26 *  797) [Q] /\
       eqmod r5_t (r5_t26 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r5_b (r5_b26 *  797) [Q] /\
       eqmod r5_t (r5_t26 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;

ghost r6_b17@int16, r6_t17@int16:
      r6_b17 = r6_b /\ r6_t17 = r6_t
   && r6_b17 = r6_b /\ r6_t17 = r6_t;

(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b17 *  -543) [Q] /\
       eqmod r6_t (r6_t17 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r6_b (r6_b17 *  -543) [Q] /\
       eqmod r6_t (r6_t17 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];


ghost r7_b26@int16, r7_t26@int16:
      r7_b26 = r7_b /\ r7_t26 = r7_t
   && r7_b26 = r7_b /\ r7_t26 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b26 *  -69) [Q] /\
       eqmod r7_t (r7_t26 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r7_b (r7_b26 *  -69) [Q] /\
       eqmod r7_t (r7_t26 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;

ghost r8_b26@int16, r8_t26@int16:
      r8_b26 = r8_b /\ r8_t26 = r8_t
   && r8_b26 = r8_b /\ r8_t26 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b26 *  569) [Q] /\
       eqmod r8_t (r8_t26 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r8_b (r8_b26 *  569) [Q] /\
       eqmod r8_t (r8_t26 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];


ghost r9_b35@int16, r9_t35@int16:
      r9_b35 = r9_b /\ r9_t35 = r9_t
   && r9_b35 = r9_b /\ r9_t35 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b35 *  -1583) [Q] /\
       eqmod r9_t (r9_t35 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r9_b (r9_b35 *  -1583) [Q] /\
       eqmod r9_t (r9_t35 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 14 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*F8**2) (r2_b*X**24 + r2_t*X**25) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*F8**2) (r3_b*X**24 + r3_t*X**25) [Q, X**32 - 17**144] /\
    eqmod (17** 40*F8**2) (r4_b*X**24 + r4_t*X**25) [Q, X**32 - 17** 80] /\
    eqmod (17**104*F8**2) (r5_b*X**24 + r5_t*X**25) [Q, X**32 - 17**208] /\
    eqmod (17** 24*F8**2) (r6_b*X**24 + r6_t*X**25) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*F8**2) (r7_b*X**24 + r7_t*X**25) [Q, X**32 - 17**176] /\
    eqmod (17** 56*F8**2) (r8_b*X**24 + r8_t*X**25) [Q, X**32 - 17**112] /\
    eqmod (17**120*F8**2) (r9_b*X**24 + r9_t*X**25) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2]
    prove with [precondition];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1d4; Value = 0xb6fe059d; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1d4, L0xbefff1d6];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff214; Value = 0x00000000; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff214, L0xbefff216];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff254; Value = 0xb6fff02c; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff254, L0xbefff256];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff294; Value = 0xb6feab70; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff294, L0xbefff296];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2d4; Value = 0xb6fff908; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2d4, L0xbefff2d6];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff314; Value = 0x00000000; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff314, L0xbefff316];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff354; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff354, L0xbefff356];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff394; Value = 0xb6fe0f91; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff394, L0xbefff396];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b18@int16, r6_t18@int16:
      r6_b18 = r6_b /\ r6_t18 = r6_t
   && r6_b18 = r6_b /\ r6_t18 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b18 *  -1600) [Q] /\
       eqmod lr_t (r6_t18 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b18 *  -1600) [Q] /\
       eqmod lr_t (r6_t18 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b27@int16, r7_t27@int16:
      r7_b27 = r7_b /\ r7_t27 = r7_t
   && r7_b27 = r7_b /\ r7_t27 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b27 *  -1600) [Q] /\
       eqmod lr_t (r7_t27 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b27 *  -1600) [Q] /\
       eqmod lr_t (r7_t27 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b27@int16, r8_t27@int16:
      r8_b27 = r8_b /\ r8_t27 = r8_t
   && r8_b27 = r8_b /\ r8_t27 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b27 *  -1600) [Q] /\
       eqmod lr_t (r8_t27 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b27 *  -1600) [Q] /\
       eqmod lr_t (r8_t27 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b36@int16, r9_t36@int16:
      r9_b36 = r9_b /\ r9_t36 = r9_t
   && r9_b36 = r9_b /\ r9_t36 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b36 *  -1600) [Q] /\
       eqmod lr_t (r9_t36 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b36 *  -1600) [Q] /\
       eqmod lr_t (r9_t36 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b18@int16, r4_t18@int16:
      r4_b18 = r4_b /\ r4_t18 = r4_t
   && r4_b18 = r4_b /\ r4_t18 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b18 *  -749) [Q] /\
       eqmod lr_t (r4_t18 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b18 *  -749) [Q] /\
       eqmod lr_t (r4_t18 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b27@int16, r5_t27@int16:
      r5_b27 = r5_b /\ r5_t27 = r5_t
   && r5_b27 = r5_b /\ r5_t27 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b27 *  -749) [Q] /\
       eqmod lr_t (r5_t27 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b27 *  -749) [Q] /\
       eqmod lr_t (r5_t27 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b28@int16, r8_t28@int16:
      r8_b28 = r8_b /\ r8_t28 = r8_t
   && r8_b28 = r8_b /\ r8_t28 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b28 *  -40) [Q] /\
       eqmod lr_t (r8_t28 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b28 *  -40) [Q] /\
       eqmod lr_t (r8_t28 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b37@int16, r9_t37@int16:
      r9_b37 = r9_b /\ r9_t37 = r9_t
   && r9_b37 = r9_b /\ r9_t37 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b37 *  -40) [Q] /\
       eqmod lr_t (r9_t37 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b37 *  -40) [Q] /\
       eqmod lr_t (r9_t37 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b18@int16, r3_t18@int16:
      r3_b18 = r3_b /\ r3_t18 = r3_t
   && r3_b18 = r3_b /\ r3_t18 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b18 *  -687) [Q] /\
       eqmod lr_t (r3_t18 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b18 *  -687) [Q] /\
       eqmod lr_t (r3_t18 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b28@int16, r5_t28@int16:
      r5_b28 = r5_b /\ r5_t28 = r5_t
   && r5_b28 = r5_b /\ r5_t28 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b28 *  630) [Q] /\
       eqmod lr_t (r5_t28 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b28 *  630) [Q] /\
       eqmod lr_t (r5_t28 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b28@int16, r7_t28@int16:
      r7_b28 = r7_b /\ r7_t28 = r7_t
   && r7_b28 = r7_b /\ r7_t28 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b28 *  -1432) [Q] /\
       eqmod lr_t (r7_t28 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b28 *  -1432) [Q] /\
       eqmod lr_t (r7_t28 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b38@int16, r9_t38@int16:
      r9_b38 = r9_b /\ r9_t38 = r9_t
   && r9_b38 = r9_b /\ r9_t38 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b38 *  848) [Q] /\
       eqmod lr_t (r9_t38 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b38 *  848) [Q] /\
       eqmod lr_t (r9_t38 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff214; PC = 0x400a40 *)
mov [L0xbefff214, L0xbefff216] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff234; PC = 0x400a44 *)
mov [L0xbefff234, L0xbefff236] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff294; PC = 0x400a54 *)
mov [L0xbefff294, L0xbefff296] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2b4; PC = 0x400a58 *)
mov [L0xbefff2b4, L0xbefff2b6] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff314; PC = 0x400a68 *)
mov [L0xbefff314, L0xbefff316] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff334; PC = 0x400a6c *)
mov [L0xbefff334, L0xbefff336] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff394; PC = 0x400a7c *)
mov [L0xbefff394, L0xbefff396] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3b4; PC = 0x400a80 *)
mov [L0xbefff3b4, L0xbefff3b6] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff254; PC = 0x400a90 *)
mov [L0xbefff254, L0xbefff256] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff274; PC = 0x400a94 *)
mov [L0xbefff274, L0xbefff276] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2d4; PC = 0x400aa4 *)
mov [L0xbefff2d4, L0xbefff2d6] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff2f4; PC = 0x400aa8 *)
mov [L0xbefff2f4, L0xbefff2f6] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff354; PC = 0x400ab8 *)
mov [L0xbefff354, L0xbefff356] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff374; PC = 0x400abc *)
mov [L0xbefff374, L0xbefff376] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff1f4; PC = 0x400acc *)
mov [L0xbefff1f4, L0xbefff1f6] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1d4; PC = 0x400ad0 *)
mov [L0xbefff1d4, L0xbefff1d6] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1d4, L0xbefff1d6] /\
                        [L0xbefff1d4, L0xbefff1d6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1f4, L0xbefff1f6] /\
                        [L0xbefff1f4, L0xbefff1f6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff214, L0xbefff216] /\
                        [L0xbefff214, L0xbefff216] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff234, L0xbefff236] /\
                        [L0xbefff234, L0xbefff236] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff254, L0xbefff256] /\
                        [L0xbefff254, L0xbefff256] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff274, L0xbefff276] /\
                        [L0xbefff274, L0xbefff276] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff294, L0xbefff296] /\
                        [L0xbefff294, L0xbefff296] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2b4, L0xbefff2b6] /\
                        [L0xbefff2b4, L0xbefff2b6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2d4, L0xbefff2d6] /\
                        [L0xbefff2d4, L0xbefff2d6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2f4, L0xbefff2f6] /\
                        [L0xbefff2f4, L0xbefff2f6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff314, L0xbefff316] /\
                        [L0xbefff314, L0xbefff316] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff334, L0xbefff336] /\
                        [L0xbefff334, L0xbefff336] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff354, L0xbefff356] /\
                        [L0xbefff354, L0xbefff356] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff374, L0xbefff376] /\
                        [L0xbefff374, L0xbefff376] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff394, L0xbefff396] /\
                        [L0xbefff394, L0xbefff396] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3b4, L0xbefff3b6] /\
                        [L0xbefff3b4, L0xbefff3b6] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [13]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1d4, L0xbefff1d6] /\
                        [L0xbefff1d4, L0xbefff1d6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1f4, L0xbefff1f6] /\
                        [L0xbefff1f4, L0xbefff1f6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff214, L0xbefff216] /\
                        [L0xbefff214, L0xbefff216] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff234, L0xbefff236] /\
                        [L0xbefff234, L0xbefff236] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff254, L0xbefff256] /\
                        [L0xbefff254, L0xbefff256] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff274, L0xbefff276] /\
                        [L0xbefff274, L0xbefff276] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff294, L0xbefff296] /\
                        [L0xbefff294, L0xbefff296] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2b4, L0xbefff2b6] /\
                        [L0xbefff2b4, L0xbefff2b6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2d4, L0xbefff2d6] /\
                        [L0xbefff2d4, L0xbefff2d6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2f4, L0xbefff2f6] /\
                        [L0xbefff2f4, L0xbefff2f6] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff314, L0xbefff316] /\
                        [L0xbefff314, L0xbefff316] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff334, L0xbefff336] /\
                        [L0xbefff334, L0xbefff336] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff354, L0xbefff356] /\
                        [L0xbefff354, L0xbefff356] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff374, L0xbefff376] /\
                        [L0xbefff374, L0xbefff376] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff394, L0xbefff396] /\
                        [L0xbefff394, L0xbefff396] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3b4, L0xbefff3b6] /\
                        [L0xbefff3b4, L0xbefff3b6] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1d4,L0xbefff1d6] /\
                            [L0xbefff1d4,L0xbefff1d6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff1f4,L0xbefff1f6] /\
                            [L0xbefff1f4,L0xbefff1f6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff214,L0xbefff216] /\
                            [L0xbefff214,L0xbefff216]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff234,L0xbefff236] /\
                            [L0xbefff234,L0xbefff236]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff254,L0xbefff256] /\
                            [L0xbefff254,L0xbefff256]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff274,L0xbefff276] /\
                            [L0xbefff274,L0xbefff276]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff294,L0xbefff296] /\
                            [L0xbefff294,L0xbefff296]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2b4,L0xbefff2b6] /\
                            [L0xbefff2b4,L0xbefff2b6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2d4,L0xbefff2d6] /\
                            [L0xbefff2d4,L0xbefff2d6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2f4,L0xbefff2f6] /\
                            [L0xbefff2f4,L0xbefff2f6]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff314,L0xbefff316] /\
                            [L0xbefff314,L0xbefff316]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff334,L0xbefff336] /\
                            [L0xbefff334,L0xbefff336]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff354,L0xbefff356] /\
                            [L0xbefff354,L0xbefff356]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff374,L0xbefff376] /\
                            [L0xbefff374,L0xbefff376]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff394,L0xbefff396] /\
                            [L0xbefff394,L0xbefff396]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3b4,L0xbefff3b6] /\
                            [L0xbefff3b4,L0xbefff3b6]<s[5@16*Q2,5@16*Q2];

(* CUT 15 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F8**2+F9**2)(L0xbefff1d4*X**8+L0xbefff1d6*X**9)[Q,X**16-17**  8]/\
    eqmod (F8**2+F9**2)(L0xbefff1f4*X**8+L0xbefff1f6*X**9)[Q,X**16-17**136]/\
    eqmod (F8**2+F9**2)(L0xbefff214*X**8+L0xbefff216*X**9)[Q,X**16-17** 72]/\
    eqmod (F8**2+F9**2)(L0xbefff234*X**8+L0xbefff236*X**9)[Q,X**16-17**200]/\
    eqmod (F8**2+F9**2)(L0xbefff254*X**8+L0xbefff256*X**9)[Q,X**16-17** 40]/\
    eqmod (F8**2+F9**2)(L0xbefff274*X**8+L0xbefff276*X**9)[Q,X**16-17**168]/\
    eqmod (F8**2+F9**2)(L0xbefff294*X**8+L0xbefff296*X**9)[Q,X**16-17**104]/\
    eqmod (F8**2+F9**2)(L0xbefff2b4*X**8+L0xbefff2b6*X**9)[Q,X**16-17**232]/\
    eqmod (F8**2+F9**2)(L0xbefff2d4*X**8+L0xbefff2d6*X**9)[Q,X**16-17** 24]/\
    eqmod (F8**2+F9**2)(L0xbefff2f4*X**8+L0xbefff2f6*X**9)[Q,X**16-17**152]/\
    eqmod (F8**2+F9**2)(L0xbefff314*X**8+L0xbefff316*X**9)[Q,X**16-17** 88]/\
    eqmod (F8**2+F9**2)(L0xbefff334*X**8+L0xbefff336*X**9)[Q,X**16-17**216]/\
    eqmod (F8**2+F9**2)(L0xbefff354*X**8+L0xbefff356*X**9)[Q,X**16-17** 56]/\
    eqmod (F8**2+F9**2)(L0xbefff374*X**8+L0xbefff376*X**9)[Q,X**16-17**184]/\
    eqmod (F8**2+F9**2)(L0xbefff394*X**8+L0xbefff396*X**9)[Q,X**16-17**120]/\
    eqmod (F8**2+F9**2)(L0xbefff3b4*X**8+L0xbefff3b6*X**9)[Q,X**16-17**248]/\
    [5*NQ2, 5*NQ2] < [L0xbefff1d4, L0xbefff1d6] /\
                     [L0xbefff1d4, L0xbefff1d6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1f4, L0xbefff1f6] /\
                     [L0xbefff1f4, L0xbefff1f6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff214, L0xbefff216] /\
                     [L0xbefff214, L0xbefff216] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff234, L0xbefff236] /\
                     [L0xbefff234, L0xbefff236] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff254, L0xbefff256] /\
                     [L0xbefff254, L0xbefff256] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff274, L0xbefff276] /\
                     [L0xbefff274, L0xbefff276] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff294, L0xbefff296] /\
                     [L0xbefff294, L0xbefff296] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2b4, L0xbefff2b6] /\
                     [L0xbefff2b4, L0xbefff2b6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2d4, L0xbefff2d6] /\
                     [L0xbefff2d4, L0xbefff2d6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2f4, L0xbefff2f6] /\
                     [L0xbefff2f4, L0xbefff2f6] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff314, L0xbefff316] /\
                     [L0xbefff314, L0xbefff316] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff334, L0xbefff336] /\
                     [L0xbefff334, L0xbefff336] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff354, L0xbefff356] /\
                     [L0xbefff354, L0xbefff356] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff374, L0xbefff376] /\
                     [L0xbefff374, L0xbefff376] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff394, L0xbefff396] /\
                     [L0xbefff394, L0xbefff396] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3b4, L0xbefff3b6] /\
                     [L0xbefff3b4, L0xbefff3b6] < [5*Q2, 5*Q2]
    prove with [cuts [13], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1d4,L0xbefff1d6] /\
                         [L0xbefff1d4,L0xbefff1d6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1f4,L0xbefff1f6] /\
                         [L0xbefff1f4,L0xbefff1f6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff214,L0xbefff216] /\
                         [L0xbefff214,L0xbefff216]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff234,L0xbefff236] /\
                         [L0xbefff234,L0xbefff236]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff254,L0xbefff256] /\
                         [L0xbefff254,L0xbefff256]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff274,L0xbefff276] /\
                         [L0xbefff274,L0xbefff276]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff294,L0xbefff296] /\
                         [L0xbefff294,L0xbefff296]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2b4,L0xbefff2b6] /\
                         [L0xbefff2b4,L0xbefff2b6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2d4,L0xbefff2d6] /\
                         [L0xbefff2d4,L0xbefff2d6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2f4,L0xbefff2f6] /\
                         [L0xbefff2f4,L0xbefff2f6]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff314,L0xbefff316] /\
                         [L0xbefff314,L0xbefff316]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff334,L0xbefff336] /\
                         [L0xbefff334,L0xbefff336]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff354,L0xbefff356] /\
                         [L0xbefff354,L0xbefff356]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff374,L0xbefff376] /\
                         [L0xbefff374,L0xbefff376]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff394,L0xbefff396] /\
                         [L0xbefff394,L0xbefff396]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3b4,L0xbefff3b6] /\
                         [L0xbefff3b4,L0xbefff3b6]<s[5@16*Q2,5@16*Q2]
    prove with [precondition];

(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff1f8; Value = 0xb6fd5000; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff1f8, L0xbefff1fa];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff238; Value = 0xb6ffe8f8; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff238, L0xbefff23a];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff278; Value = 0x00000000; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff278, L0xbefff27a];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2b8; Value = 0xb6fff9a8; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2b8, L0xbefff2ba];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff2f8; Value = 0xb6ffbc00; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff2f8, L0xbefff2fa];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff338; Value = 0x00000000; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff338, L0xbefff33a];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff378; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff378, L0xbefff37a];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3b8; Value = 0x00000000; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3b8, L0xbefff3ba];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b20@int16, r6_t20@int16:
      r6_b20 = r6_b /\ r6_t20 = r6_t
   && r6_b20 = r6_b /\ r6_t20 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b20 *  -1600) [Q] /\
       eqmod lr_t (r6_t20 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b20 *  -1600) [Q] /\
       eqmod lr_t (r6_t20 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b30@int16, r7_t30@int16:
      r7_b30 = r7_b /\ r7_t30 = r7_t
   && r7_b30 = r7_b /\ r7_t30 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b30 *  -1600) [Q] /\
       eqmod lr_t (r7_t30 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b30 *  -1600) [Q] /\
       eqmod lr_t (r7_t30 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b30@int16, r8_t30@int16:
      r8_b30 = r8_b /\ r8_t30 = r8_t
   && r8_b30 = r8_b /\ r8_t30 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b30 *  -1600) [Q] /\
       eqmod lr_t (r8_t30 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b30 *  -1600) [Q] /\
       eqmod lr_t (r8_t30 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b40@int16, r9_t40@int16:
      r9_b40 = r9_b /\ r9_t40 = r9_t
   && r9_b40 = r9_b /\ r9_t40 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b40 *  -1600) [Q] /\
       eqmod lr_t (r9_t40 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b40 *  -1600) [Q] /\
       eqmod lr_t (r9_t40 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b20@int16, r4_t20@int16:
      r4_b20 = r4_b /\ r4_t20 = r4_t
   && r4_b20 = r4_b /\ r4_t20 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b20 *  -749) [Q] /\
       eqmod lr_t (r4_t20 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b20 *  -749) [Q] /\
       eqmod lr_t (r4_t20 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b30@int16, r5_t30@int16:
      r5_b30 = r5_b /\ r5_t30 = r5_t
   && r5_b30 = r5_b /\ r5_t30 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b30 *  -749) [Q] /\
       eqmod lr_t (r5_t30 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b30 *  -749) [Q] /\
       eqmod lr_t (r5_t30 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b31@int16, r8_t31@int16:
      r8_b31 = r8_b /\ r8_t31 = r8_t
   && r8_b31 = r8_b /\ r8_t31 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b31 *  -40) [Q] /\
       eqmod lr_t (r8_t31 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b31 *  -40) [Q] /\
       eqmod lr_t (r8_t31 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b41@int16, r9_t41@int16:
      r9_b41 = r9_b /\ r9_t41 = r9_t
   && r9_b41 = r9_b /\ r9_t41 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b41 *  -40) [Q] /\
       eqmod lr_t (r9_t41 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b41 *  -40) [Q] /\
       eqmod lr_t (r9_t41 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b20@int16, r3_t20@int16:
      r3_b20 = r3_b /\ r3_t20 = r3_t
   && r3_b20 = r3_b /\ r3_t20 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b20 *  -687) [Q] /\
       eqmod lr_t (r3_t20 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b20 *  -687) [Q] /\
       eqmod lr_t (r3_t20 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b31@int16, r5_t31@int16:
      r5_b31 = r5_b /\ r5_t31 = r5_t
   && r5_b31 = r5_b /\ r5_t31 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b31 *  630) [Q] /\
       eqmod lr_t (r5_t31 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b31 *  630) [Q] /\
       eqmod lr_t (r5_t31 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b31@int16, r7_t31@int16:
      r7_b31 = r7_b /\ r7_t31 = r7_t
   && r7_b31 = r7_b /\ r7_t31 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b31 *  -1432) [Q] /\
       eqmod lr_t (r7_t31 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b31 *  -1432) [Q] /\
       eqmod lr_t (r7_t31 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b42@int16, r9_t42@int16:
      r9_b42 = r9_b /\ r9_t42 = r9_t
   && r9_b42 = r9_b /\ r9_t42 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b42 *  848) [Q] /\
       eqmod lr_t (r9_t42 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b42 *  848) [Q] /\
       eqmod lr_t (r9_t42 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 16 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (Fa**2) (r2_b*X**26 + r2_t*X**27) [Q, X**32 - 17** 16] /\
    eqmod (Fa**2) (r3_b*X**26 + r3_t*X**27) [Q, X**32 - 17**144] /\
    eqmod (Fa**2) (r4_b*X**26 + r4_t*X**27) [Q, X**32 - 17** 80] /\
    eqmod (Fa**2) (r5_b*X**26 + r5_t*X**27) [Q, X**32 - 17**208] /\
    eqmod (Fa**2) (r6_b*X**26 + r6_t*X**27) [Q, X**32 - 17** 48] /\
    eqmod (Fa**2) (r7_b*X**26 + r7_t*X**27) [Q, X**32 - 17**176] /\
    eqmod (Fa**2) (r8_b*X**26 + r8_t*X**27) [Q, X**32 - 17**112] /\
    eqmod (Fa**2) (r9_b*X**26 + r9_t*X**27) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q]
    prove with [precondition];

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;

ghost r2_b10@int16, r2_t10@int16:
      r2_b10 = r2_b /\ r2_t10 = r2_t
   && r2_b10 = r2_b /\ r2_t10 = r2_t;

(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b10 *  1062) [Q] /\
       eqmod r2_t (r2_t10 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r2_b (r2_b10 *  1062) [Q] /\
       eqmod r2_t (r2_t10 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];


ghost r3_b21@int16, r3_t21@int16:
      r3_b21 = r3_b /\ r3_t21 = r3_t
   && r3_b21 = r3_b /\ r3_t21 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b21 *  -1410) [Q] /\
       eqmod r3_t (r3_t21 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r3_b (r3_b21 *  -1410) [Q] /\
       eqmod r3_t (r3_t21 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;

ghost r4_b21@int16, r4_t21@int16:
      r4_b21 = r4_b /\ r4_t21 = r4_t
   && r4_b21 = r4_b /\ r4_t21 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b21 *  193) [Q] /\
       eqmod r4_t (r4_t21 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r4_b (r4_b21 *  193) [Q] /\
       eqmod r4_t (r4_t21 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];


ghost r5_b32@int16, r5_t32@int16:
      r5_b32 = r5_b /\ r5_t32 = r5_t
   && r5_b32 = r5_b /\ r5_t32 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b32 *  797) [Q] /\
       eqmod r5_t (r5_t32 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r5_b (r5_b32 *  797) [Q] /\
       eqmod r5_t (r5_t32 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;

ghost r6_b21@int16, r6_t21@int16:
      r6_b21 = r6_b /\ r6_t21 = r6_t
   && r6_b21 = r6_b /\ r6_t21 = r6_t;

(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b21 *  -543) [Q] /\
       eqmod r6_t (r6_t21 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r6_b (r6_b21 *  -543) [Q] /\
       eqmod r6_t (r6_t21 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];


ghost r7_b32@int16, r7_t32@int16:
      r7_b32 = r7_b /\ r7_t32 = r7_t
   && r7_b32 = r7_b /\ r7_t32 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b32 *  -69) [Q] /\
       eqmod r7_t (r7_t32 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r7_b (r7_b32 *  -69) [Q] /\
       eqmod r7_t (r7_t32 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;

ghost r8_b32@int16, r8_t32@int16:
      r8_b32 = r8_b /\ r8_t32 = r8_t
   && r8_b32 = r8_b /\ r8_t32 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b32 *  569) [Q] /\
       eqmod r8_t (r8_t32 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r8_b (r8_b32 *  569) [Q] /\
       eqmod r8_t (r8_t32 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];


ghost r9_b43@int16, r9_t43@int16:
      r9_b43 = r9_b /\ r9_t43 = r9_t
   && r9_b43 = r9_b /\ r9_t43 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b43 *  -1583) [Q] /\
       eqmod r9_t (r9_t43 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r9_b (r9_b43 *  -1583) [Q] /\
       eqmod r9_t (r9_t43 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 17 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*Fa**2) (r2_b*X**26 + r2_t*X**27) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*Fa**2) (r3_b*X**26 + r3_t*X**27) [Q, X**32 - 17**144] /\
    eqmod (17** 40*Fa**2) (r4_b*X**26 + r4_t*X**27) [Q, X**32 - 17** 80] /\
    eqmod (17**104*Fa**2) (r5_b*X**26 + r5_t*X**27) [Q, X**32 - 17**208] /\
    eqmod (17** 24*Fa**2) (r6_b*X**26 + r6_t*X**27) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*Fa**2) (r7_b*X**26 + r7_t*X**27) [Q, X**32 - 17**176] /\
    eqmod (17** 56*Fa**2) (r8_b*X**26 + r8_t*X**27) [Q, X**32 - 17**112] /\
    eqmod (17**120*Fa**2) (r9_b*X**26 + r9_t*X**27) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2]
    prove with [precondition];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1d8; Value = 0xb6ffe980; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1d8, L0xbefff1da];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff218; Value = 0xb6ffff18; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff218, L0xbefff21a];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff258; Value = 0x000000a0; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff258, L0xbefff25a];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff298; Value = 0xb6feab5c; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff298, L0xbefff29a];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2d8; Value = 0xb6fff8fc; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2d8, L0xbefff2da];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff318; Value = 0x00000000; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff318, L0xbefff31a];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff358; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff358, L0xbefff35a];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff398; Value = 0xb6fb6630; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff398, L0xbefff39a];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b22@int16, r6_t22@int16:
      r6_b22 = r6_b /\ r6_t22 = r6_t
   && r6_b22 = r6_b /\ r6_t22 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b22 *  -1600) [Q] /\
       eqmod lr_t (r6_t22 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b22 *  -1600) [Q] /\
       eqmod lr_t (r6_t22 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b33@int16, r7_t33@int16:
      r7_b33 = r7_b /\ r7_t33 = r7_t
   && r7_b33 = r7_b /\ r7_t33 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b33 *  -1600) [Q] /\
       eqmod lr_t (r7_t33 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b33 *  -1600) [Q] /\
       eqmod lr_t (r7_t33 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b33@int16, r8_t33@int16:
      r8_b33 = r8_b /\ r8_t33 = r8_t
   && r8_b33 = r8_b /\ r8_t33 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b33 *  -1600) [Q] /\
       eqmod lr_t (r8_t33 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b33 *  -1600) [Q] /\
       eqmod lr_t (r8_t33 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b44@int16, r9_t44@int16:
      r9_b44 = r9_b /\ r9_t44 = r9_t
   && r9_b44 = r9_b /\ r9_t44 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b44 *  -1600) [Q] /\
       eqmod lr_t (r9_t44 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b44 *  -1600) [Q] /\
       eqmod lr_t (r9_t44 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b22@int16, r4_t22@int16:
      r4_b22 = r4_b /\ r4_t22 = r4_t
   && r4_b22 = r4_b /\ r4_t22 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b22 *  -749) [Q] /\
       eqmod lr_t (r4_t22 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b22 *  -749) [Q] /\
       eqmod lr_t (r4_t22 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b33@int16, r5_t33@int16:
      r5_b33 = r5_b /\ r5_t33 = r5_t
   && r5_b33 = r5_b /\ r5_t33 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b33 *  -749) [Q] /\
       eqmod lr_t (r5_t33 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b33 *  -749) [Q] /\
       eqmod lr_t (r5_t33 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b34@int16, r8_t34@int16:
      r8_b34 = r8_b /\ r8_t34 = r8_t
   && r8_b34 = r8_b /\ r8_t34 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b34 *  -40) [Q] /\
       eqmod lr_t (r8_t34 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b34 *  -40) [Q] /\
       eqmod lr_t (r8_t34 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b45@int16, r9_t45@int16:
      r9_b45 = r9_b /\ r9_t45 = r9_t
   && r9_b45 = r9_b /\ r9_t45 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b45 *  -40) [Q] /\
       eqmod lr_t (r9_t45 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b45 *  -40) [Q] /\
       eqmod lr_t (r9_t45 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b22@int16, r3_t22@int16:
      r3_b22 = r3_b /\ r3_t22 = r3_t
   && r3_b22 = r3_b /\ r3_t22 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b22 *  -687) [Q] /\
       eqmod lr_t (r3_t22 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b22 *  -687) [Q] /\
       eqmod lr_t (r3_t22 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b34@int16, r5_t34@int16:
      r5_b34 = r5_b /\ r5_t34 = r5_t
   && r5_b34 = r5_b /\ r5_t34 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b34 *  630) [Q] /\
       eqmod lr_t (r5_t34 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b34 *  630) [Q] /\
       eqmod lr_t (r5_t34 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b34@int16, r7_t34@int16:
      r7_b34 = r7_b /\ r7_t34 = r7_t
   && r7_b34 = r7_b /\ r7_t34 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b34 *  -1432) [Q] /\
       eqmod lr_t (r7_t34 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b34 *  -1432) [Q] /\
       eqmod lr_t (r7_t34 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b46@int16, r9_t46@int16:
      r9_b46 = r9_b /\ r9_t46 = r9_t
   && r9_b46 = r9_b /\ r9_t46 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b46 *  848) [Q] /\
       eqmod lr_t (r9_t46 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b46 *  848) [Q] /\
       eqmod lr_t (r9_t46 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff218; PC = 0x400a40 *)
mov [L0xbefff218, L0xbefff21a] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff238; PC = 0x400a44 *)
mov [L0xbefff238, L0xbefff23a] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff298; PC = 0x400a54 *)
mov [L0xbefff298, L0xbefff29a] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2b8; PC = 0x400a58 *)
mov [L0xbefff2b8, L0xbefff2ba] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff318; PC = 0x400a68 *)
mov [L0xbefff318, L0xbefff31a] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff338; PC = 0x400a6c *)
mov [L0xbefff338, L0xbefff33a] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff398; PC = 0x400a7c *)
mov [L0xbefff398, L0xbefff39a] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3b8; PC = 0x400a80 *)
mov [L0xbefff3b8, L0xbefff3ba] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff258; PC = 0x400a90 *)
mov [L0xbefff258, L0xbefff25a] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff278; PC = 0x400a94 *)
mov [L0xbefff278, L0xbefff27a] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2d8; PC = 0x400aa4 *)
mov [L0xbefff2d8, L0xbefff2da] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff2f8; PC = 0x400aa8 *)
mov [L0xbefff2f8, L0xbefff2fa] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff358; PC = 0x400ab8 *)
mov [L0xbefff358, L0xbefff35a] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff378; PC = 0x400abc *)
mov [L0xbefff378, L0xbefff37a] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff1f8; PC = 0x400acc *)
mov [L0xbefff1f8, L0xbefff1fa] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1d8; PC = 0x400ad0 *)
mov [L0xbefff1d8, L0xbefff1da] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1d8, L0xbefff1da] /\
                        [L0xbefff1d8, L0xbefff1da] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1f8, L0xbefff1fa] /\
                        [L0xbefff1f8, L0xbefff1fa] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff218, L0xbefff21a] /\
                        [L0xbefff218, L0xbefff21a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff238, L0xbefff23a] /\
                        [L0xbefff238, L0xbefff23a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff258, L0xbefff25a] /\
                        [L0xbefff258, L0xbefff25a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff278, L0xbefff27a] /\
                        [L0xbefff278, L0xbefff27a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff298, L0xbefff29a] /\
                        [L0xbefff298, L0xbefff29a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2b8, L0xbefff2ba] /\
                        [L0xbefff2b8, L0xbefff2ba] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2d8, L0xbefff2da] /\
                        [L0xbefff2d8, L0xbefff2da] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2f8, L0xbefff2fa] /\
                        [L0xbefff2f8, L0xbefff2fa] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff318, L0xbefff31a] /\
                        [L0xbefff318, L0xbefff31a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff338, L0xbefff33a] /\
                        [L0xbefff338, L0xbefff33a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff358, L0xbefff35a] /\
                        [L0xbefff358, L0xbefff35a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff378, L0xbefff37a] /\
                        [L0xbefff378, L0xbefff37a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff398, L0xbefff39a] /\
                        [L0xbefff398, L0xbefff39a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3b8, L0xbefff3ba] /\
                        [L0xbefff3b8, L0xbefff3ba] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [16]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1d8, L0xbefff1da] /\
                        [L0xbefff1d8, L0xbefff1da] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1f8, L0xbefff1fa] /\
                        [L0xbefff1f8, L0xbefff1fa] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff218, L0xbefff21a] /\
                        [L0xbefff218, L0xbefff21a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff238, L0xbefff23a] /\
                        [L0xbefff238, L0xbefff23a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff258, L0xbefff25a] /\
                        [L0xbefff258, L0xbefff25a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff278, L0xbefff27a] /\
                        [L0xbefff278, L0xbefff27a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff298, L0xbefff29a] /\
                        [L0xbefff298, L0xbefff29a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2b8, L0xbefff2ba] /\
                        [L0xbefff2b8, L0xbefff2ba] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2d8, L0xbefff2da] /\
                        [L0xbefff2d8, L0xbefff2da] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2f8, L0xbefff2fa] /\
                        [L0xbefff2f8, L0xbefff2fa] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff318, L0xbefff31a] /\
                        [L0xbefff318, L0xbefff31a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff338, L0xbefff33a] /\
                        [L0xbefff338, L0xbefff33a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff358, L0xbefff35a] /\
                        [L0xbefff358, L0xbefff35a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff378, L0xbefff37a] /\
                        [L0xbefff378, L0xbefff37a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff398, L0xbefff39a] /\
                        [L0xbefff398, L0xbefff39a] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3b8, L0xbefff3ba] /\
                        [L0xbefff3b8, L0xbefff3ba] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1d8,L0xbefff1da] /\
                            [L0xbefff1d8,L0xbefff1da]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff1f8,L0xbefff1fa] /\
                            [L0xbefff1f8,L0xbefff1fa]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff218,L0xbefff21a] /\
                            [L0xbefff218,L0xbefff21a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff238,L0xbefff23a] /\
                            [L0xbefff238,L0xbefff23a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff258,L0xbefff25a] /\
                            [L0xbefff258,L0xbefff25a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff278,L0xbefff27a] /\
                            [L0xbefff278,L0xbefff27a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff298,L0xbefff29a] /\
                            [L0xbefff298,L0xbefff29a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2b8,L0xbefff2ba] /\
                            [L0xbefff2b8,L0xbefff2ba]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2d8,L0xbefff2da] /\
                            [L0xbefff2d8,L0xbefff2da]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2f8,L0xbefff2fa] /\
                            [L0xbefff2f8,L0xbefff2fa]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff318,L0xbefff31a] /\
                            [L0xbefff318,L0xbefff31a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff338,L0xbefff33a] /\
                            [L0xbefff338,L0xbefff33a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff358,L0xbefff35a] /\
                            [L0xbefff358,L0xbefff35a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff378,L0xbefff37a] /\
                            [L0xbefff378,L0xbefff37a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff398,L0xbefff39a] /\
                            [L0xbefff398,L0xbefff39a]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3b8,L0xbefff3ba] /\
                            [L0xbefff3b8,L0xbefff3ba]<s[5@16*Q2,5@16*Q2];

(* CUT 18 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (Fa**2+Fb**2)(L0xbefff1d8*X**10+L0xbefff1da*X**11)[Q,X**16-17**  8]/\
    eqmod (Fa**2+Fb**2)(L0xbefff1f8*X**10+L0xbefff1fa*X**11)[Q,X**16-17**136]/\
    eqmod (Fa**2+Fb**2)(L0xbefff218*X**10+L0xbefff21a*X**11)[Q,X**16-17** 72]/\
    eqmod (Fa**2+Fb**2)(L0xbefff238*X**10+L0xbefff23a*X**11)[Q,X**16-17**200]/\
    eqmod (Fa**2+Fb**2)(L0xbefff258*X**10+L0xbefff25a*X**11)[Q,X**16-17** 40]/\
    eqmod (Fa**2+Fb**2)(L0xbefff278*X**10+L0xbefff27a*X**11)[Q,X**16-17**168]/\
    eqmod (Fa**2+Fb**2)(L0xbefff298*X**10+L0xbefff29a*X**11)[Q,X**16-17**104]/\
    eqmod (Fa**2+Fb**2)(L0xbefff2b8*X**10+L0xbefff2ba*X**11)[Q,X**16-17**232]/\
    eqmod (Fa**2+Fb**2)(L0xbefff2d8*X**10+L0xbefff2da*X**11)[Q,X**16-17** 24]/\
    eqmod (Fa**2+Fb**2)(L0xbefff2f8*X**10+L0xbefff2fa*X**11)[Q,X**16-17**152]/\
    eqmod (Fa**2+Fb**2)(L0xbefff318*X**10+L0xbefff31a*X**11)[Q,X**16-17** 88]/\
    eqmod (Fa**2+Fb**2)(L0xbefff338*X**10+L0xbefff33a*X**11)[Q,X**16-17**216]/\
    eqmod (Fa**2+Fb**2)(L0xbefff358*X**10+L0xbefff35a*X**11)[Q,X**16-17** 56]/\
    eqmod (Fa**2+Fb**2)(L0xbefff378*X**10+L0xbefff37a*X**11)[Q,X**16-17**184]/\
    eqmod (Fa**2+Fb**2)(L0xbefff398*X**10+L0xbefff39a*X**11)[Q,X**16-17**120]/\
    eqmod (Fa**2+Fb**2)(L0xbefff3b8*X**10+L0xbefff3ba*X**11)[Q,X**16-17**248]/\
    [5*NQ2, 5*NQ2] < [L0xbefff1d8, L0xbefff1da] /\
                     [L0xbefff1d8, L0xbefff1da] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1f8, L0xbefff1fa] /\
                     [L0xbefff1f8, L0xbefff1fa] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff218, L0xbefff21a] /\
                     [L0xbefff218, L0xbefff21a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff238, L0xbefff23a] /\
                     [L0xbefff238, L0xbefff23a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff258, L0xbefff25a] /\
                     [L0xbefff258, L0xbefff25a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff278, L0xbefff27a] /\
                     [L0xbefff278, L0xbefff27a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff298, L0xbefff29a] /\
                     [L0xbefff298, L0xbefff29a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2b8, L0xbefff2ba] /\
                     [L0xbefff2b8, L0xbefff2ba] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2d8, L0xbefff2da] /\
                     [L0xbefff2d8, L0xbefff2da] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2f8, L0xbefff2fa] /\
                     [L0xbefff2f8, L0xbefff2fa] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff318, L0xbefff31a] /\
                     [L0xbefff318, L0xbefff31a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff338, L0xbefff33a] /\
                     [L0xbefff338, L0xbefff33a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff358, L0xbefff35a] /\
                     [L0xbefff358, L0xbefff35a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff378, L0xbefff37a] /\
                     [L0xbefff378, L0xbefff37a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff398, L0xbefff39a] /\
                     [L0xbefff398, L0xbefff39a] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3b8, L0xbefff3ba] /\
                     [L0xbefff3b8, L0xbefff3ba] < [5*Q2, 5*Q2]
    prove with [cuts [16], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1d8,L0xbefff1da] /\
                         [L0xbefff1d8,L0xbefff1da]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1f8,L0xbefff1fa] /\
                         [L0xbefff1f8,L0xbefff1fa]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff218,L0xbefff21a] /\
                         [L0xbefff218,L0xbefff21a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff238,L0xbefff23a] /\
                         [L0xbefff238,L0xbefff23a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff258,L0xbefff25a] /\
                         [L0xbefff258,L0xbefff25a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff278,L0xbefff27a] /\
                         [L0xbefff278,L0xbefff27a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff298,L0xbefff29a] /\
                         [L0xbefff298,L0xbefff29a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2b8,L0xbefff2ba] /\
                         [L0xbefff2b8,L0xbefff2ba]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2d8,L0xbefff2da] /\
                         [L0xbefff2d8,L0xbefff2da]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2f8,L0xbefff2fa] /\
                         [L0xbefff2f8,L0xbefff2fa]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff318,L0xbefff31a] /\
                         [L0xbefff318,L0xbefff31a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff338,L0xbefff33a] /\
                         [L0xbefff338,L0xbefff33a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff358,L0xbefff35a] /\
                         [L0xbefff358,L0xbefff35a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff378,L0xbefff37a] /\
                         [L0xbefff378,L0xbefff37a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff398,L0xbefff39a] /\
                         [L0xbefff398,L0xbefff39a]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3b8,L0xbefff3ba] /\
                         [L0xbefff3b8,L0xbefff3ba]<s[5@16*Q2,5@16*Q2]
    prove with [precondition];

(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff1fc; Value = 0xb6fff5c8; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff1fc, L0xbefff1fe];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff23c; Value = 0xbefff280; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff23c, L0xbefff23e];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff27c; Value = 0x00000000; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff27c, L0xbefff27e];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2bc; Value = 0xb6fd81f5; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2bc, L0xbefff2be];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff2fc; Value = 0xb6fff000; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff2fc, L0xbefff2fe];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff33c; Value = 0x00000000; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff33c, L0xbefff33e];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff37c; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff37c, L0xbefff37e];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3bc; Value = 0x00400469; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3bc, L0xbefff3be];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b24@int16, r6_t24@int16:
      r6_b24 = r6_b /\ r6_t24 = r6_t
   && r6_b24 = r6_b /\ r6_t24 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b24 *  -1600) [Q] /\
       eqmod lr_t (r6_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b24 *  -1600) [Q] /\
       eqmod lr_t (r6_t24 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b36@int16, r7_t36@int16:
      r7_b36 = r7_b /\ r7_t36 = r7_t
   && r7_b36 = r7_b /\ r7_t36 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b36 *  -1600) [Q] /\
       eqmod lr_t (r7_t36 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b36 *  -1600) [Q] /\
       eqmod lr_t (r7_t36 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b36@int16, r8_t36@int16:
      r8_b36 = r8_b /\ r8_t36 = r8_t
   && r8_b36 = r8_b /\ r8_t36 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b36 *  -1600) [Q] /\
       eqmod lr_t (r8_t36 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b36 *  -1600) [Q] /\
       eqmod lr_t (r8_t36 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b48@int16, r9_t48@int16:
      r9_b48 = r9_b /\ r9_t48 = r9_t
   && r9_b48 = r9_b /\ r9_t48 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b48 *  -1600) [Q] /\
       eqmod lr_t (r9_t48 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b48 *  -1600) [Q] /\
       eqmod lr_t (r9_t48 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b24@int16, r4_t24@int16:
      r4_b24 = r4_b /\ r4_t24 = r4_t
   && r4_b24 = r4_b /\ r4_t24 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b24 *  -749) [Q] /\
       eqmod lr_t (r4_t24 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b24 *  -749) [Q] /\
       eqmod lr_t (r4_t24 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b36@int16, r5_t36@int16:
      r5_b36 = r5_b /\ r5_t36 = r5_t
   && r5_b36 = r5_b /\ r5_t36 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b36 *  -749) [Q] /\
       eqmod lr_t (r5_t36 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b36 *  -749) [Q] /\
       eqmod lr_t (r5_t36 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b37@int16, r8_t37@int16:
      r8_b37 = r8_b /\ r8_t37 = r8_t
   && r8_b37 = r8_b /\ r8_t37 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b37 *  -40) [Q] /\
       eqmod lr_t (r8_t37 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b37 *  -40) [Q] /\
       eqmod lr_t (r8_t37 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b49@int16, r9_t49@int16:
      r9_b49 = r9_b /\ r9_t49 = r9_t
   && r9_b49 = r9_b /\ r9_t49 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b49 *  -40) [Q] /\
       eqmod lr_t (r9_t49 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b49 *  -40) [Q] /\
       eqmod lr_t (r9_t49 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b24@int16, r3_t24@int16:
      r3_b24 = r3_b /\ r3_t24 = r3_t
   && r3_b24 = r3_b /\ r3_t24 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b24 *  -687) [Q] /\
       eqmod lr_t (r3_t24 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b24 *  -687) [Q] /\
       eqmod lr_t (r3_t24 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b37@int16, r5_t37@int16:
      r5_b37 = r5_b /\ r5_t37 = r5_t
   && r5_b37 = r5_b /\ r5_t37 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b37 *  630) [Q] /\
       eqmod lr_t (r5_t37 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b37 *  630) [Q] /\
       eqmod lr_t (r5_t37 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b37@int16, r7_t37@int16:
      r7_b37 = r7_b /\ r7_t37 = r7_t
   && r7_b37 = r7_b /\ r7_t37 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b37 *  -1432) [Q] /\
       eqmod lr_t (r7_t37 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b37 *  -1432) [Q] /\
       eqmod lr_t (r7_t37 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b50@int16, r9_t50@int16:
      r9_b50 = r9_b /\ r9_t50 = r9_t
   && r9_b50 = r9_b /\ r9_t50 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b50 *  848) [Q] /\
       eqmod lr_t (r9_t50 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b50 *  848) [Q] /\
       eqmod lr_t (r9_t50 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 19 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (Fc**2) (r2_b*X**28 + r2_t*X**29) [Q, X**32 - 17** 16] /\
    eqmod (Fc**2) (r3_b*X**28 + r3_t*X**29) [Q, X**32 - 17**144] /\
    eqmod (Fc**2) (r4_b*X**28 + r4_t*X**29) [Q, X**32 - 17** 80] /\
    eqmod (Fc**2) (r5_b*X**28 + r5_t*X**29) [Q, X**32 - 17**208] /\
    eqmod (Fc**2) (r6_b*X**28 + r6_t*X**29) [Q, X**32 - 17** 48] /\
    eqmod (Fc**2) (r7_b*X**28 + r7_t*X**29) [Q, X**32 - 17**176] /\
    eqmod (Fc**2) (r8_b*X**28 + r8_t*X**29) [Q, X**32 - 17**112] /\
    eqmod (Fc**2) (r9_b*X**28 + r9_t*X**29) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q]
    prove with [precondition];

ghost r2_b12@int16, r2_t12@int16:
      r2_b12 = r2_b /\ r2_t12 = r2_t
   && r2_b12 = r2_b /\ r2_t12 = r2_t;

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;
(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b12 *  1062) [Q] /\
       eqmod r2_t (r2_t12 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r2_b (r2_b12 *  1062) [Q] /\
       eqmod r2_t (r2_t12 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];


ghost r3_b25@int16, r3_t25@int16:
      r3_b25 = r3_b /\ r3_t25 = r3_t
   && r3_b25 = r3_b /\ r3_t25 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b25 *  -1410) [Q] /\
       eqmod r3_t (r3_t25 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r3_b (r3_b25 *  -1410) [Q] /\
       eqmod r3_t (r3_t25 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;

ghost r4_b25@int16, r4_t25@int16:
      r4_b25 = r4_b /\ r4_t25 = r4_t
   && r4_b25 = r4_b /\ r4_t25 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b25 *  193) [Q] /\
       eqmod r4_t (r4_t25 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r4_b (r4_b25 *  193) [Q] /\
       eqmod r4_t (r4_t25 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];


ghost r5_b38@int16, r5_t38@int16:
      r5_b38 = r5_b /\ r5_t38 = r5_t
   && r5_b38 = r5_b /\ r5_t38 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b38 *  797) [Q] /\
       eqmod r5_t (r5_t38 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r5_b (r5_b38 *  797) [Q] /\
       eqmod r5_t (r5_t38 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;

ghost r6_b25@int16, r6_t25@int16:
      r6_b25 = r6_b /\ r6_t25 = r6_t
   && r6_b25 = r6_b /\ r6_t25 = r6_t;

(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b25 *  -543) [Q] /\
       eqmod r6_t (r6_t25 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r6_b (r6_b25 *  -543) [Q] /\
       eqmod r6_t (r6_t25 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];


ghost r7_b38@int16, r7_t38@int16:
      r7_b38 = r7_b /\ r7_t38 = r7_t
   && r7_b38 = r7_b /\ r7_t38 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b38 *  -69) [Q] /\
       eqmod r7_t (r7_t38 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r7_b (r7_b38 *  -69) [Q] /\
       eqmod r7_t (r7_t38 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;

ghost r8_b38@int16, r8_t38@int16:
      r8_b38 = r8_b /\ r8_t38 = r8_t
   && r8_b38 = r8_b /\ r8_t38 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b38 *  569) [Q] /\
       eqmod r8_t (r8_t38 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r8_b (r8_b38 *  569) [Q] /\
       eqmod r8_t (r8_t38 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];


ghost r9_b51@int16, r9_t51@int16:
      r9_b51 = r9_b /\ r9_t51 = r9_t
   && r9_b51 = r9_b /\ r9_t51 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b51 *  -1583) [Q] /\
       eqmod r9_t (r9_t51 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r9_b (r9_b51 *  -1583) [Q] /\
       eqmod r9_t (r9_t51 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 20 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*Fc**2) (r2_b*X**28 + r2_t*X**29) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*Fc**2) (r3_b*X**28 + r3_t*X**29) [Q, X**32 - 17**144] /\
    eqmod (17** 40*Fc**2) (r4_b*X**28 + r4_t*X**29) [Q, X**32 - 17** 80] /\
    eqmod (17**104*Fc**2) (r5_b*X**28 + r5_t*X**29) [Q, X**32 - 17**208] /\
    eqmod (17** 24*Fc**2) (r6_b*X**28 + r6_t*X**29) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*Fc**2) (r7_b*X**28 + r7_t*X**29) [Q, X**32 - 17**176] /\
    eqmod (17** 56*Fc**2) (r8_b*X**28 + r8_t*X**29) [Q, X**32 - 17**112] /\
    eqmod (17**120*Fc**2) (r9_b*X**28 + r9_t*X**29) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2]
    prove with [precondition];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1dc; Value = 0x00000003; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1dc, L0xbefff1de];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff21c; Value = 0xb6fff070; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff21c, L0xbefff21e];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff25c; Value = 0x00000000; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff25c, L0xbefff25e];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff29c; Value = 0x00000011; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff29c, L0xbefff29e];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2dc; Value = 0xb6fff070; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2dc, L0xbefff2de];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff31c; Value = 0x00000000; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff31c, L0xbefff31e];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff35c; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff35c, L0xbefff35e];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff39c; Value = 0x00000000; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff39c, L0xbefff39e];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b26@int16, r6_t26@int16:
      r6_b26 = r6_b /\ r6_t26 = r6_t
   && r6_b26 = r6_b /\ r6_t26 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b26 *  -1600) [Q] /\
       eqmod lr_t (r6_t26 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b26 *  -1600) [Q] /\
       eqmod lr_t (r6_t26 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b39@int16, r7_t39@int16:
      r7_b39 = r7_b /\ r7_t39 = r7_t
   && r7_b39 = r7_b /\ r7_t39 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b39 *  -1600) [Q] /\
       eqmod lr_t (r7_t39 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b39 *  -1600) [Q] /\
       eqmod lr_t (r7_t39 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b39@int16, r8_t39@int16:
      r8_b39 = r8_b /\ r8_t39 = r8_t
   && r8_b39 = r8_b /\ r8_t39 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b39 *  -1600) [Q] /\
       eqmod lr_t (r8_t39 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b39 *  -1600) [Q] /\
       eqmod lr_t (r8_t39 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b52@int16, r9_t52@int16:
      r9_b52 = r9_b /\ r9_t52 = r9_t
   && r9_b52 = r9_b /\ r9_t52 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b52 *  -1600) [Q] /\
       eqmod lr_t (r9_t52 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b52 *  -1600) [Q] /\
       eqmod lr_t (r9_t52 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b26@int16, r4_t26@int16:
      r4_b26 = r4_b /\ r4_t26 = r4_t
   && r4_b26 = r4_b /\ r4_t26 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b26 *  -749) [Q] /\
       eqmod lr_t (r4_t26 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b26 *  -749) [Q] /\
       eqmod lr_t (r4_t26 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b39@int16, r5_t39@int16:
      r5_b39 = r5_b /\ r5_t39 = r5_t
   && r5_b39 = r5_b /\ r5_t39 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b39 *  -749) [Q] /\
       eqmod lr_t (r5_t39 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b39 *  -749) [Q] /\
       eqmod lr_t (r5_t39 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b40@int16, r8_t40@int16:
      r8_b40 = r8_b /\ r8_t40 = r8_t
   && r8_b40 = r8_b /\ r8_t40 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b40 *  -40) [Q] /\
       eqmod lr_t (r8_t40 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b40 *  -40) [Q] /\
       eqmod lr_t (r8_t40 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b53@int16, r9_t53@int16:
      r9_b53 = r9_b /\ r9_t53 = r9_t
   && r9_b53 = r9_b /\ r9_t53 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b53 *  -40) [Q] /\
       eqmod lr_t (r9_t53 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b53 *  -40) [Q] /\
       eqmod lr_t (r9_t53 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b26@int16, r3_t26@int16:
      r3_b26 = r3_b /\ r3_t26 = r3_t
   && r3_b26 = r3_b /\ r3_t26 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b26 *  -687) [Q] /\
       eqmod lr_t (r3_t26 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b26 *  -687) [Q] /\
       eqmod lr_t (r3_t26 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b40@int16, r5_t40@int16:
      r5_b40 = r5_b /\ r5_t40 = r5_t
   && r5_b40 = r5_b /\ r5_t40 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b40 *  630) [Q] /\
       eqmod lr_t (r5_t40 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b40 *  630) [Q] /\
       eqmod lr_t (r5_t40 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b40@int16, r7_t40@int16:
      r7_b40 = r7_b /\ r7_t40 = r7_t
   && r7_b40 = r7_b /\ r7_t40 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b40 *  -1432) [Q] /\
       eqmod lr_t (r7_t40 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b40 *  -1432) [Q] /\
       eqmod lr_t (r7_t40 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b54@int16, r9_t54@int16:
      r9_b54 = r9_b /\ r9_t54 = r9_t
   && r9_b54 = r9_b /\ r9_t54 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b54 *  848) [Q] /\
       eqmod lr_t (r9_t54 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b54 *  848) [Q] /\
       eqmod lr_t (r9_t54 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff21c; PC = 0x400a40 *)
mov [L0xbefff21c, L0xbefff21e] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff23c; PC = 0x400a44 *)
mov [L0xbefff23c, L0xbefff23e] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff29c; PC = 0x400a54 *)
mov [L0xbefff29c, L0xbefff29e] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2bc; PC = 0x400a58 *)
mov [L0xbefff2bc, L0xbefff2be] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff31c; PC = 0x400a68 *)
mov [L0xbefff31c, L0xbefff31e] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff33c; PC = 0x400a6c *)
mov [L0xbefff33c, L0xbefff33e] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff39c; PC = 0x400a7c *)
mov [L0xbefff39c, L0xbefff39e] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3bc; PC = 0x400a80 *)
mov [L0xbefff3bc, L0xbefff3be] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff25c; PC = 0x400a90 *)
mov [L0xbefff25c, L0xbefff25e] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff27c; PC = 0x400a94 *)
mov [L0xbefff27c, L0xbefff27e] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2dc; PC = 0x400aa4 *)
mov [L0xbefff2dc, L0xbefff2de] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff2fc; PC = 0x400aa8 *)
mov [L0xbefff2fc, L0xbefff2fe] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff35c; PC = 0x400ab8 *)
mov [L0xbefff35c, L0xbefff35e] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff37c; PC = 0x400abc *)
mov [L0xbefff37c, L0xbefff37e] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff1fc; PC = 0x400acc *)
mov [L0xbefff1fc, L0xbefff1fe] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1dc; PC = 0x400ad0 *)
mov [L0xbefff1dc, L0xbefff1de] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1dc, L0xbefff1de] /\
                        [L0xbefff1dc, L0xbefff1de] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1fc, L0xbefff1fe] /\
                        [L0xbefff1fc, L0xbefff1fe] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff21c, L0xbefff21e] /\
                        [L0xbefff21c, L0xbefff21e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff23c, L0xbefff23e] /\
                        [L0xbefff23c, L0xbefff23e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff25c, L0xbefff25e] /\
                        [L0xbefff25c, L0xbefff25e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff27c, L0xbefff27e] /\
                        [L0xbefff27c, L0xbefff27e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff29c, L0xbefff29e] /\
                        [L0xbefff29c, L0xbefff29e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2bc, L0xbefff2be] /\
                        [L0xbefff2bc, L0xbefff2be] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2dc, L0xbefff2de] /\
                        [L0xbefff2dc, L0xbefff2de] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2fc, L0xbefff2fe] /\
                        [L0xbefff2fc, L0xbefff2fe] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff31c, L0xbefff31e] /\
                        [L0xbefff31c, L0xbefff31e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff33c, L0xbefff33e] /\
                        [L0xbefff33c, L0xbefff33e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff35c, L0xbefff35e] /\
                        [L0xbefff35c, L0xbefff35e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff37c, L0xbefff37e] /\
                        [L0xbefff37c, L0xbefff37e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff39c, L0xbefff39e] /\
                        [L0xbefff39c, L0xbefff39e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3bc, L0xbefff3be] /\
                        [L0xbefff3bc, L0xbefff3be] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [19]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1dc, L0xbefff1de] /\
                        [L0xbefff1dc, L0xbefff1de] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff1fc, L0xbefff1fe] /\
                        [L0xbefff1fc, L0xbefff1fe] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff21c, L0xbefff21e] /\
                        [L0xbefff21c, L0xbefff21e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff23c, L0xbefff23e] /\
                        [L0xbefff23c, L0xbefff23e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff25c, L0xbefff25e] /\
                        [L0xbefff25c, L0xbefff25e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff27c, L0xbefff27e] /\
                        [L0xbefff27c, L0xbefff27e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff29c, L0xbefff29e] /\
                        [L0xbefff29c, L0xbefff29e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2bc, L0xbefff2be] /\
                        [L0xbefff2bc, L0xbefff2be] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2dc, L0xbefff2de] /\
                        [L0xbefff2dc, L0xbefff2de] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2fc, L0xbefff2fe] /\
                        [L0xbefff2fc, L0xbefff2fe] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff31c, L0xbefff31e] /\
                        [L0xbefff31c, L0xbefff31e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff33c, L0xbefff33e] /\
                        [L0xbefff33c, L0xbefff33e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff35c, L0xbefff35e] /\
                        [L0xbefff35c, L0xbefff35e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff37c, L0xbefff37e] /\
                        [L0xbefff37c, L0xbefff37e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff39c, L0xbefff39e] /\
                        [L0xbefff39c, L0xbefff39e] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3bc, L0xbefff3be] /\
                        [L0xbefff3bc, L0xbefff3be] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1dc,L0xbefff1de] /\
                            [L0xbefff1dc,L0xbefff1de]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff1fc,L0xbefff1fe] /\
                            [L0xbefff1fc,L0xbefff1fe]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff21c,L0xbefff21e] /\
                            [L0xbefff21c,L0xbefff21e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff23c,L0xbefff23e] /\
                            [L0xbefff23c,L0xbefff23e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff25c,L0xbefff25e] /\
                            [L0xbefff25c,L0xbefff25e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff27c,L0xbefff27e] /\
                            [L0xbefff27c,L0xbefff27e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff29c,L0xbefff29e] /\
                            [L0xbefff29c,L0xbefff29e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2bc,L0xbefff2be] /\
                            [L0xbefff2bc,L0xbefff2be]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2dc,L0xbefff2de] /\
                            [L0xbefff2dc,L0xbefff2de]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2fc,L0xbefff2fe] /\
                            [L0xbefff2fc,L0xbefff2fe]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff31c,L0xbefff31e] /\
                            [L0xbefff31c,L0xbefff31e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff33c,L0xbefff33e] /\
                            [L0xbefff33c,L0xbefff33e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff35c,L0xbefff35e] /\
                            [L0xbefff35c,L0xbefff35e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff37c,L0xbefff37e] /\
                            [L0xbefff37c,L0xbefff37e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff39c,L0xbefff39e] /\
                            [L0xbefff39c,L0xbefff39e]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3bc,L0xbefff3be] /\
                            [L0xbefff3bc,L0xbefff3be]<s[5@16*Q2,5@16*Q2];

(* CUT 21 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (Fc**2+Fd**2)(L0xbefff1dc*X**12+L0xbefff1de*X**13)[Q,X**16-17**  8]/\
    eqmod (Fc**2+Fd**2)(L0xbefff1fc*X**12+L0xbefff1fe*X**13)[Q,X**16-17**136]/\
    eqmod (Fc**2+Fd**2)(L0xbefff21c*X**12+L0xbefff21e*X**13)[Q,X**16-17** 72]/\
    eqmod (Fc**2+Fd**2)(L0xbefff23c*X**12+L0xbefff23e*X**13)[Q,X**16-17**200]/\
    eqmod (Fc**2+Fd**2)(L0xbefff25c*X**12+L0xbefff25e*X**13)[Q,X**16-17** 40]/\
    eqmod (Fc**2+Fd**2)(L0xbefff27c*X**12+L0xbefff27e*X**13)[Q,X**16-17**168]/\
    eqmod (Fc**2+Fd**2)(L0xbefff29c*X**12+L0xbefff29e*X**13)[Q,X**16-17**104]/\
    eqmod (Fc**2+Fd**2)(L0xbefff2bc*X**12+L0xbefff2be*X**13)[Q,X**16-17**232]/\
    eqmod (Fc**2+Fd**2)(L0xbefff2dc*X**12+L0xbefff2de*X**13)[Q,X**16-17** 24]/\
    eqmod (Fc**2+Fd**2)(L0xbefff2fc*X**12+L0xbefff2fe*X**13)[Q,X**16-17**152]/\
    eqmod (Fc**2+Fd**2)(L0xbefff31c*X**12+L0xbefff31e*X**13)[Q,X**16-17** 88]/\
    eqmod (Fc**2+Fd**2)(L0xbefff33c*X**12+L0xbefff33e*X**13)[Q,X**16-17**216]/\
    eqmod (Fc**2+Fd**2)(L0xbefff35c*X**12+L0xbefff35e*X**13)[Q,X**16-17** 56]/\
    eqmod (Fc**2+Fd**2)(L0xbefff37c*X**12+L0xbefff37e*X**13)[Q,X**16-17**184]/\
    eqmod (Fc**2+Fd**2)(L0xbefff39c*X**12+L0xbefff39e*X**13)[Q,X**16-17**120]/\
    eqmod (Fc**2+Fd**2)(L0xbefff3bc*X**12+L0xbefff3be*X**13)[Q,X**16-17**248]/\
    [5*NQ2, 5*NQ2] < [L0xbefff1dc, L0xbefff1de] /\
                     [L0xbefff1dc, L0xbefff1de] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff1fc, L0xbefff1fe] /\
                     [L0xbefff1fc, L0xbefff1fe] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff21c, L0xbefff21e] /\
                     [L0xbefff21c, L0xbefff21e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff23c, L0xbefff23e] /\
                     [L0xbefff23c, L0xbefff23e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff25c, L0xbefff25e] /\
                     [L0xbefff25c, L0xbefff25e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff27c, L0xbefff27e] /\
                     [L0xbefff27c, L0xbefff27e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff29c, L0xbefff29e] /\
                     [L0xbefff29c, L0xbefff29e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2bc, L0xbefff2be] /\
                     [L0xbefff2bc, L0xbefff2be] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2dc, L0xbefff2de] /\
                     [L0xbefff2dc, L0xbefff2de] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2fc, L0xbefff2fe] /\
                     [L0xbefff2fc, L0xbefff2fe] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff31c, L0xbefff31e] /\
                     [L0xbefff31c, L0xbefff31e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff33c, L0xbefff33e] /\
                     [L0xbefff33c, L0xbefff33e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff35c, L0xbefff35e] /\
                     [L0xbefff35c, L0xbefff35e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff37c, L0xbefff37e] /\
                     [L0xbefff37c, L0xbefff37e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff39c, L0xbefff39e] /\
                     [L0xbefff39c, L0xbefff39e] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3bc, L0xbefff3be] /\
                     [L0xbefff3bc, L0xbefff3be] < [5*Q2, 5*Q2]
    prove with [cuts [19], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1dc,L0xbefff1de] /\
                         [L0xbefff1dc,L0xbefff1de]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1fc,L0xbefff1fe] /\
                         [L0xbefff1fc,L0xbefff1fe]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff21c,L0xbefff21e] /\
                         [L0xbefff21c,L0xbefff21e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff23c,L0xbefff23e] /\
                         [L0xbefff23c,L0xbefff23e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff25c,L0xbefff25e] /\
                         [L0xbefff25c,L0xbefff25e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff27c,L0xbefff27e] /\
                         [L0xbefff27c,L0xbefff27e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff29c,L0xbefff29e] /\
                         [L0xbefff29c,L0xbefff29e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2bc,L0xbefff2be] /\
                         [L0xbefff2bc,L0xbefff2be]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2dc,L0xbefff2de] /\
                         [L0xbefff2dc,L0xbefff2de]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2fc,L0xbefff2fe] /\
                         [L0xbefff2fc,L0xbefff2fe]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff31c,L0xbefff31e] /\
                         [L0xbefff31c,L0xbefff31e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff33c,L0xbefff33e] /\
                         [L0xbefff33c,L0xbefff33e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff35c,L0xbefff35e] /\
                         [L0xbefff35c,L0xbefff35e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff37c,L0xbefff37e] /\
                         [L0xbefff37c,L0xbefff37e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff39c,L0xbefff39e] /\
                         [L0xbefff39c,L0xbefff39e]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3bc,L0xbefff3be] /\
                         [L0xbefff3bc,L0xbefff3be]<s[5@16*Q2,5@16*Q2]
    prove with [precondition];

(* vmov	s23, r0                                    #! PC = 0x400628 *)
mov s23 r0;
(* ldr.w	r2, [r0, #32]                             #! EA = L0xbefff200; Value = 0x000f0002; PC = 0x40062c *)
mov [r2_b, r2_t] [L0xbefff200, L0xbefff202];
(* ldr.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff240; Value = 0xbefff280; PC = 0x400630 *)
mov [r3_b, r3_t] [L0xbefff240, L0xbefff242];
(* ldr.w	r4, [r0, #160]	; 0xa0                     #! EA = L0xbefff280; Value = 0x00000000; PC = 0x400634 *)
mov [r4_b, r4_t] [L0xbefff280, L0xbefff282];
(* ldr.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2c0; Value = 0x00000000; PC = 0x400638 *)
mov [r5_b, r5_t] [L0xbefff2c0, L0xbefff2c2];
(* ldr.w	r6, [r0, #288]	; 0x120                    #! EA = L0xbefff300; Value = 0xbefff330; PC = 0x40063c *)
mov [r6_b, r6_t] [L0xbefff300, L0xbefff302];
(* ldr.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff340; Value = 0x00000000; PC = 0x400640 *)
mov [r7_b, r7_t] [L0xbefff340, L0xbefff342];
(* ldr.w	r8, [r0, #416]	; 0x1a0                    #! EA = L0xbefff380; Value = 0x00000000; PC = 0x400644 *)
mov [r8_b, r8_t] [L0xbefff380, L0xbefff382];
(* ldr.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3c0; Value = 0x00000000; PC = 0x400648 *)
mov [r9_b, r9_t] [L0xbefff3c0, L0xbefff3c2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x40064c *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b28@int16, r6_t28@int16:
      r6_b28 = r6_b /\ r6_t28 = r6_t
   && r6_b28 = r6_b /\ r6_t28 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x400650 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x400654 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400658 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40065c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400660 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400664 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b28 *  -1600) [Q] /\
       eqmod lr_t (r6_t28 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b28 *  -1600) [Q] /\
       eqmod lr_t (r6_t28 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400668 *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40066c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b42@int16, r7_t42@int16:
      r7_b42 = r7_b /\ r7_t42 = r7_t
   && r7_b42 = r7_b /\ r7_t42 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400670 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400674 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400678 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x40067c *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400680 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b42 *  -1600) [Q] /\
       eqmod lr_t (r7_t42 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b42 *  -1600) [Q] /\
       eqmod lr_t (r7_t42 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400684 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400688 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b42@int16, r8_t42@int16:
      r8_b42 = r8_b /\ r8_t42 = r8_t
   && r8_b42 = r8_b /\ r8_t42 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x40068c *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400690 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400694 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400698 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x40069c *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b42 *  -1600) [Q] /\
       eqmod lr_t (r8_t42 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b42 *  -1600) [Q] /\
       eqmod lr_t (r8_t42 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x4006a0 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4006a4 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b56@int16, r9_t56@int16:
      r9_b56 = r9_b /\ r9_t56 = r9_t
   && r9_b56 = r9_b /\ r9_t56 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x4006a8 *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x4006ac *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006b0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4006b4 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4006b8 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b56 *  -1600) [Q] /\
       eqmod lr_t (r9_t56 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b56 *  -1600) [Q] /\
       eqmod lr_t (r9_t56 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x4006bc *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x4006c0 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b28@int16, r4_t28@int16:
      r4_b28 = r4_b /\ r4_t28 = r4_t
   && r4_b28 = r4_b /\ r4_t28 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x4006c4 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x4006c8 *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x4006cc *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4006d0 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006d4 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x4006d8 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x4006dc *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b28 *  -749) [Q] /\
       eqmod lr_t (r4_t28 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b28 *  -749) [Q] /\
       eqmod lr_t (r4_t28 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x4006e0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4006e4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b42@int16, r5_t42@int16:
      r5_b42 = r5_b /\ r5_t42 = r5_t
   && r5_b42 = r5_b /\ r5_t42 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x4006e8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x4006ec *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4006f0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4006f4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4006f8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b42 *  -749) [Q] /\
       eqmod lr_t (r5_t42 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b42 *  -749) [Q] /\
       eqmod lr_t (r5_t42 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x4006fc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400700 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b43@int16, r8_t43@int16:
      r8_b43 = r8_b /\ r8_t43 = r8_t
   && r8_b43 = r8_b /\ r8_t43 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400704 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400708 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40070c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400710 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400714 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b43 *  -40) [Q] /\
       eqmod lr_t (r8_t43 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b43 *  -40) [Q] /\
       eqmod lr_t (r8_t43 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400718 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40071c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b57@int16, r9_t57@int16:
      r9_b57 = r9_b /\ r9_t57 = r9_t
   && r9_b57 = r9_b /\ r9_t57 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400720 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400724 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400728 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x40072c *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400730 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b57 *  -40) [Q] /\
       eqmod lr_t (r9_t57 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b57 *  -40) [Q] /\
       eqmod lr_t (r9_t57 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400734 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400738 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b28@int16, r3_t28@int16:
      r3_b28 = r3_b /\ r3_t28 = r3_t
   && r3_b28 = r3_b /\ r3_t28 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x40073c *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x400740 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x400744 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400748 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40074c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400750 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400754 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b28 *  -687) [Q] /\
       eqmod lr_t (r3_t28 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b28 *  -687) [Q] /\
       eqmod lr_t (r3_t28 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400758 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x40075c *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b43@int16, r5_t43@int16:
      r5_b43 = r5_b /\ r5_t43 = r5_t
   && r5_b43 = r5_b /\ r5_t43 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400760 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400764 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400768 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x40076c *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400770 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b43 *  630) [Q] /\
       eqmod lr_t (r5_t43 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b43 *  630) [Q] /\
       eqmod lr_t (r5_t43 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400774 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400778 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b43@int16, r7_t43@int16:
      r7_b43 = r7_b /\ r7_t43 = r7_t
   && r7_b43 = r7_b /\ r7_t43 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x40077c *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x400780 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x400784 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400788 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40078c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400790 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400794 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b43 *  -1432) [Q] /\
       eqmod lr_t (r7_t43 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b43 *  -1432) [Q] /\
       eqmod lr_t (r7_t43 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400798 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x40079c *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b58@int16, r9_t58@int16:
      r9_b58 = r9_b /\ r9_t58 = r9_t
   && r9_b58 = r9_b /\ r9_t58 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x4007a0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x4007a4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007a8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4007ac *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4007b0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b58 *  848) [Q] /\
       eqmod lr_t (r9_t58 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b58 *  848) [Q] /\
       eqmod lr_t (r9_t58 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x4007b4 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x4007b8 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];

assert [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
       prove with [precondition, algebra solver isl] && true;
assume [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
       [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    && [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
       [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q];

(* CUT 22 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (Fe**2) (r2_b*X**30 + r2_t*X**31) [Q, X**32 - 17** 16] /\
    eqmod (Fe**2) (r3_b*X**30 + r3_t*X**31) [Q, X**32 - 17**144] /\
    eqmod (Fe**2) (r4_b*X**30 + r4_t*X**31) [Q, X**32 - 17** 80] /\
    eqmod (Fe**2) (r5_b*X**30 + r5_t*X**31) [Q, X**32 - 17**208] /\
    eqmod (Fe**2) (r6_b*X**30 + r6_t*X**31) [Q, X**32 - 17** 48] /\
    eqmod (Fe**2) (r7_b*X**30 + r7_t*X**31) [Q, X**32 - 17**176] /\
    eqmod (Fe**2) (r8_b*X**30 + r8_t*X**31) [Q, X**32 - 17**112] /\
    eqmod (Fe**2) (r9_b*X**30 + r9_t*X**31) [Q, X**32 - 17**240] /\
    [2*NQ, 2*NQ] < [r2_b, r2_t] /\ [r2_b, r2_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r3_b, r3_t] /\ [r3_b, r3_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r4_b, r4_t] /\ [r4_b, r4_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r5_b, r5_t] /\ [r5_b, r5_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r6_b, r6_t] /\ [r6_b, r6_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r7_b, r7_t] /\ [r7_b, r7_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r8_b, r8_t] /\ [r8_b, r8_t] < [2*Q, 2*Q] /\
    [2*NQ, 2*NQ] < [r9_b, r9_t] /\ [r9_b, r9_t] < [2*Q, 2*Q]
    prove with [precondition, all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [2@16*NQ, 2@16*NQ]<s[r2_b, r2_t] /\ [r2_b, r2_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r3_b, r3_t] /\ [r3_b, r3_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r4_b, r4_t] /\ [r4_b, r4_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r5_b, r5_t] /\ [r5_b, r5_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r6_b, r6_t] /\ [r6_b, r6_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r7_b, r7_t] /\ [r7_b, r7_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r8_b, r8_t] /\ [r8_b, r8_t]<s[2@16*Q, 2@16*Q] /\
    [2@16*NQ, 2@16*NQ]<s[r9_b, r9_t] /\ [r9_b, r9_t]<s[2@16*Q, 2@16*Q]
    prove with [precondition];

(* vmov	r10, s15                                   #! PC = 0x4007bc *)
mov r10 s15;
(* vmov	r11, s16                                   #! PC = 0x4007c0 *)
mov r11 s16;

ghost r2_b14@int16, r2_t14@int16:
      r2_b14 = r2_b /\ r2_t14 = r2_t
   && r2_b14 = r2_b /\ r2_t14 = r2_t;

(* smulwb	lr, r10, r2                              #! PC = 0x4007c4 *)
vpc r2_bW@int32 r2_b; mulj tmp r10 r2_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r2, r10, r2                              #! PC = 0x4007c8 *)
vpc r2_tW@int32 r2_t; mulj tmp r10 r2_tW; spl r2_w dc tmp 16;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b; vpc r2_t@int16 r2_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007cc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r2, r2, r12, r0                          #! PC = 0x4007d0 *)
mulj prod r2_b r12_t; add r2_w prod r0;
spl r2_t r2_b r2_w 16; cast r2_b@int16 r2_b;
(* pkhtb	r2, r2, lr, asr #16                       #! PC = 0x4007d4 *)
mov tmp_b lr_t; mov tmp_t r2_t;
mov r2_b tmp_b; mov r2_t tmp_t;

assert eqmod r2_b (r2_b14 *  1062) [Q] /\
       eqmod r2_t (r2_t14 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r2_b (r2_b14 *  1062) [Q] /\
       eqmod r2_t (r2_t14 *  1062) [Q] /\
       [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2];


ghost r3_b29@int16, r3_t29@int16:
      r3_b29 = r3_b /\ r3_t29 = r3_t
   && r3_b29 = r3_b /\ r3_t29 = r3_t;

(* smulwb	lr, r11, r3                              #! PC = 0x4007d8 *)
vpc r3_bW@int32 r3_b; mulj tmp r11 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r11, r3                              #! PC = 0x4007dc *)
vpc r3_tW@int32 r3_t; mulj tmp r11 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007e0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4007e4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	r3, r3, lr, asr #16                       #! PC = 0x4007e8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov r3_b tmp_b; mov r3_t tmp_t;

assert eqmod r3_b (r3_b29 *  -1410) [Q] /\
       eqmod r3_t (r3_t29 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r3_b (r3_b29 *  -1410) [Q] /\
       eqmod r3_t (r3_t29 *  -1410) [Q] /\
       [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2];

(* vmov	r10, s17                                   #! PC = 0x4007ec *)
mov r10 s17;
(* vmov	r11, s18                                   #! PC = 0x4007f0 *)
mov r11 s18;

ghost r4_b29@int16, r4_t29@int16:
      r4_b29 = r4_b /\ r4_t29 = r4_t
   && r4_b29 = r4_b /\ r4_t29 = r4_t;

(* smulwb	lr, r10, r4                              #! PC = 0x4007f4 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x4007f8 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4007fc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400800 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	r4, r4, lr, asr #16                       #! PC = 0x400804 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov r4_b tmp_b; mov r4_t tmp_t;

assert eqmod r4_b (r4_b29 *  193) [Q] /\
       eqmod r4_t (r4_t29 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r4_b (r4_b29 *  193) [Q] /\
       eqmod r4_t (r4_t29 *  193) [Q] /\
       [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2];


ghost r5_b44@int16, r5_t44@int16:
      r5_b44 = r5_b /\ r5_t44 = r5_t
   && r5_b44 = r5_b /\ r5_t44 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400808 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x40080c *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400810 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400814 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	r5, r5, lr, asr #16                       #! PC = 0x400818 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov r5_b tmp_b; mov r5_t tmp_t;

assert eqmod r5_b (r5_b44 *  797) [Q] /\
       eqmod r5_t (r5_t44 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r5_b (r5_b44 *  797) [Q] /\
       eqmod r5_t (r5_t44 *  797) [Q] /\
       [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2];

(* vmov	r10, s19                                   #! PC = 0x40081c *)
mov r10 s19;
(* vmov	r11, s20                                   #! PC = 0x400820 *)
mov r11 s20;

ghost r6_b29@int16, r6_t29@int16:
      r6_b29 = r6_b /\ r6_t29 = r6_t
   && r6_b29 = r6_b /\ r6_t29 = r6_t;

(* smulwb	lr, r10, r6                              #! PC = 0x400824 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400828 *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40082c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400830 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	r6, r6, lr, asr #16                       #! PC = 0x400834 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov r6_b tmp_b; mov r6_t tmp_t;

assert eqmod r6_b (r6_b29 *  -543) [Q] /\
       eqmod r6_t (r6_t29 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r6_b (r6_b29 *  -543) [Q] /\
       eqmod r6_t (r6_t29 *  -543) [Q] /\
       [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2];


ghost r7_b44@int16, r7_t44@int16:
      r7_b44 = r7_b /\ r7_t44 = r7_t
   && r7_b44 = r7_b /\ r7_t44 = r7_t;

(* smulwb	lr, r11, r7                              #! PC = 0x400838 *)
vpc r7_bW@int32 r7_b; mulj tmp r11 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r11, r7                              #! PC = 0x40083c *)
vpc r7_tW@int32 r7_t; mulj tmp r11 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400840 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400844 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	r7, r7, lr, asr #16                       #! PC = 0x400848 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov r7_b tmp_b; mov r7_t tmp_t;

assert eqmod r7_b (r7_b44 *  -69) [Q] /\
       eqmod r7_t (r7_t44 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r7_b (r7_b44 *  -69) [Q] /\
       eqmod r7_t (r7_t44 *  -69) [Q] /\
       [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2];

(* vmov	r10, s21                                   #! PC = 0x40084c *)
mov r10 s21;
(* vmov	r11, s22                                   #! PC = 0x400850 *)
mov r11 s22;

ghost r8_b44@int16, r8_t44@int16:
      r8_b44 = r8_b /\ r8_t44 = r8_t
   && r8_b44 = r8_b /\ r8_t44 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400854 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400858 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40085c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400860 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	r8, r8, lr, asr #16                       #! PC = 0x400864 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov r8_b tmp_b; mov r8_t tmp_t;

assert eqmod r8_b (r8_b44 *  569) [Q] /\
       eqmod r8_t (r8_t44 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r8_b (r8_b44 *  569) [Q] /\
       eqmod r8_t (r8_t44 *  569) [Q] /\
       [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2];


ghost r9_b59@int16, r9_t59@int16:
      r9_b59 = r9_b /\ r9_t59 = r9_t
   && r9_b59 = r9_b /\ r9_t59 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400868 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x40086c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400870 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400874 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	r9, r9, lr, asr #16                       #! PC = 0x400878 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov r9_b tmp_b; mov r9_t tmp_t;

assert eqmod r9_b (r9_b59 *  -1583) [Q] /\
       eqmod r9_t (r9_t59 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod r9_b (r9_b59 *  -1583) [Q] /\
       eqmod r9_t (r9_t59 *  -1583) [Q] /\
       [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2];

(* CUT 23 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (17**  8*Fe**2) (r2_b*X**30 + r2_t*X**31) [Q, X**32 - 17** 16] /\
    eqmod (17** 72*Fe**2) (r3_b*X**30 + r3_t*X**31) [Q, X**32 - 17**144] /\
    eqmod (17** 40*Fe**2) (r4_b*X**30 + r4_t*X**31) [Q, X**32 - 17** 80] /\
    eqmod (17**104*Fe**2) (r5_b*X**30 + r5_t*X**31) [Q, X**32 - 17**208] /\
    eqmod (17** 24*Fe**2) (r6_b*X**30 + r6_t*X**31) [Q, X**32 - 17** 48] /\
    eqmod (17** 88*Fe**2) (r7_b*X**30 + r7_t*X**31) [Q, X**32 - 17**176] /\
    eqmod (17** 56*Fe**2) (r8_b*X**30 + r8_t*X**31) [Q, X**32 - 17**112] /\
    eqmod (17**120*Fe**2) (r9_b*X**30 + r9_t*X**31) [Q, X**32 - 17**240] /\
    [NQ2, NQ2] < [r2_b, r2_t] /\ [r2_b, r2_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r3_b, r3_t] /\ [r3_b, r3_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r4_b, r4_t] /\ [r4_b, r4_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r5_b, r5_t] /\ [r5_b, r5_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r6_b, r6_t] /\ [r6_b, r6_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r7_b, r7_t] /\ [r7_b, r7_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r8_b, r8_t] /\ [r8_b, r8_t] < [Q2, Q2] /\
    [NQ2, NQ2] < [r9_b, r9_t] /\ [r9_b, r9_t] < [Q2, Q2]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [NQ2, NQ2] <s[r2_b, r2_t] /\ [r2_b, r2_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r3_b, r3_t] /\ [r3_b, r3_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r4_b, r4_t] /\ [r4_b, r4_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r5_b, r5_t] /\ [r5_b, r5_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r6_b, r6_t] /\ [r6_b, r6_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r7_b, r7_t] /\ [r7_b, r7_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r8_b, r8_t] /\ [r8_b, r8_t] <s[Q2, Q2] /\
    [NQ2, NQ2] <s[r9_b, r9_t] /\ [r9_b, r9_t] <s[Q2, Q2]
    prove with [precondition];

(* vmov	s0, r2                                     #! PC = 0x40087c *)
mov [s0_b, s0_t] [r2_b, r2_t];
(* vmov	s1, r3                                     #! PC = 0x400880 *)
mov [s1_b, s1_t] [r3_b, r3_t];
(* vmov	s2, r4                                     #! PC = 0x400884 *)
mov [s2_b, s2_t] [r4_b, r4_t];
(* vmov	s3, r5                                     #! PC = 0x400888 *)
mov [s3_b, s3_t] [r5_b, r5_t];
(* vmov	s4, r6                                     #! PC = 0x40088c *)
mov [s4_b, s4_t] [r6_b, r6_t];
(* vmov	s5, r7                                     #! PC = 0x400890 *)
mov [s5_b, s5_t] [r7_b, r7_t];
(* vmov	s6, r8                                     #! PC = 0x400894 *)
mov [s6_b, s6_t] [r8_b, r8_t];
(* vmov	s7, r9                                     #! PC = 0x400898 *)
mov [s7_b, s7_t] [r9_b, r9_t];
(* vmov	r0, s23                                    #! PC = 0x40089c *)
mov r0 s23;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1e0; Value = 0xb6fff914; PC = 0x4008a0 *)
mov [r2_b, r2_t] [L0xbefff1e0, L0xbefff1e2];
(* ldr.w	r3, [r0, #64]	; 0x40                      #! EA = L0xbefff220; Value = 0xb6fff070; PC = 0x4008a4 *)
mov [r3_b, r3_t] [L0xbefff220, L0xbefff222];
(* ldr.w	r4, [r0, #128]	; 0x80                     #! EA = L0xbefff260; Value = 0xb6fd5304; PC = 0x4008a8 *)
mov [r4_b, r4_t] [L0xbefff260, L0xbefff262];
(* ldr.w	r5, [r0, #192]	; 0xc0                     #! EA = L0xbefff2a0; Value = 0xb6ffbc00; PC = 0x4008ac *)
mov [r5_b, r5_t] [L0xbefff2a0, L0xbefff2a2];
(* ldr.w	r6, [r0, #256]	; 0x100                    #! EA = L0xbefff2e0; Value = 0xb6fff8e8; PC = 0x4008b0 *)
mov [r6_b, r6_t] [L0xbefff2e0, L0xbefff2e2];
(* ldr.w	r7, [r0, #320]	; 0x140                    #! EA = L0xbefff320; Value = 0xbefff52c; PC = 0x4008b4 *)
mov [r7_b, r7_t] [L0xbefff320, L0xbefff322];
(* ldr.w	r8, [r0, #384]	; 0x180                    #! EA = L0xbefff360; Value = 0x00000000; PC = 0x4008b8 *)
mov [r8_b, r8_t] [L0xbefff360, L0xbefff362];
(* ldr.w	r9, [r0, #448]	; 0x1c0                    #! EA = L0xbefff3a0; Value = 0x00000000; PC = 0x4008bc *)
mov [r9_b, r9_t] [L0xbefff3a0, L0xbefff3a2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x4008c0 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b30@int16, r6_t30@int16:
      r6_b30 = r6_b /\ r6_t30 = r6_t
   && r6_b30 = r6_b /\ r6_t30 = r6_t;

(* vmov	r10, s8                                    #! PC = 0x4008c4 *)
mov r10 s8;
(* smulwb	lr, r10, r6                              #! PC = 0x4008c8 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x4008cc *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008d0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x4008d4 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x4008d8 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b30 *  -1600) [Q] /\
       eqmod lr_t (r6_t30 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r6_b30 *  -1600) [Q] /\
       eqmod lr_t (r6_t30 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x4008dc *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4008e0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b45@int16, r7_t45@int16:
      r7_b45 = r7_b /\ r7_t45 = r7_t
   && r7_b45 = r7_b /\ r7_t45 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x4008e4 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4008e8 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4008ec *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x4008f0 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x4008f4 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b45 *  -1600) [Q] /\
       eqmod lr_t (r7_t45 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b45 *  -1600) [Q] /\
       eqmod lr_t (r7_t45 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x4008f8 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x4008fc *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b45@int16, r8_t45@int16:
      r8_b45 = r8_b /\ r8_t45 = r8_t
   && r8_b45 = r8_b /\ r8_t45 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400900 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400904 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400908 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x40090c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400910 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b45 *  -1600) [Q] /\
       eqmod lr_t (r8_t45 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b45 *  -1600) [Q] /\
       eqmod lr_t (r8_t45 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400914 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400918 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b60@int16, r9_t60@int16:
      r9_b60 = r9_b /\ r9_t60 = r9_t
   && r9_b60 = r9_b /\ r9_t60 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x40091c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400920 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400924 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400928 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x40092c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b60 *  -1600) [Q] /\
       eqmod lr_t (r9_t60 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b60 *  -1600) [Q] /\
       eqmod lr_t (r9_t60 *  -1600) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400930 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400934 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b30@int16, r4_t30@int16:
      r4_b30 = r4_b /\ r4_t30 = r4_t
   && r4_b30 = r4_b /\ r4_t30 = r4_t;

(* vmov	r10, s9                                    #! PC = 0x400938 *)
mov r10 s9;
(* vmov	r11, s10                                   #! PC = 0x40093c *)
mov r11 s10;
(* smulwb	lr, r10, r4                              #! PC = 0x400940 *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400944 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400948 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x40094c *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400950 *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b30 *  -749) [Q] /\
       eqmod lr_t (r4_t30 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r4_b30 *  -749) [Q] /\
       eqmod lr_t (r4_t30 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400954 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400958 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b45@int16, r5_t45@int16:
      r5_b45 = r5_b /\ r5_t45 = r5_t
   && r5_b45 = r5_b /\ r5_t45 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x40095c *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400960 *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400964 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400968 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x40096c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b45 *  -749) [Q] /\
       eqmod lr_t (r5_t45 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b45 *  -749) [Q] /\
       eqmod lr_t (r5_t45 *  -749) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400970 *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400974 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b46@int16, r8_t46@int16:
      r8_b46 = r8_b /\ r8_t46 = r8_t
   && r8_b46 = r8_b /\ r8_t46 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400978 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x40097c *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400980 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400984 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400988 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b46 *  -40) [Q] /\
       eqmod lr_t (r8_t46 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r8_b46 *  -40) [Q] /\
       eqmod lr_t (r8_t46 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x40098c *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400990 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b61@int16, r9_t61@int16:
      r9_b61 = r9_b /\ r9_t61 = r9_t
   && r9_b61 = r9_b /\ r9_t61 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400994 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400998 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x40099c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x4009a0 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x4009a4 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b61 *  -40) [Q] /\
       eqmod lr_t (r9_t61 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b61 *  -40) [Q] /\
       eqmod lr_t (r9_t61 *  -40) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x4009a8 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x4009ac *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b30@int16, r3_t30@int16:
      r3_b30 = r3_b /\ r3_t30 = r3_t
   && r3_b30 = r3_b /\ r3_t30 = r3_t;

(* vmov	r10, s11                                   #! PC = 0x4009b0 *)
mov r10 s11;
(* vmov	r11, s12                                   #! PC = 0x4009b4 *)
mov r11 s12;
(* smulwb	lr, r10, r3                              #! PC = 0x4009b8 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x4009bc *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009c0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x4009c4 *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x4009c8 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b30 *  -687) [Q] /\
       eqmod lr_t (r3_t30 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r3_b30 *  -687) [Q] /\
       eqmod lr_t (r3_t30 *  -687) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x4009cc *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x4009d0 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b46@int16, r5_t46@int16:
      r5_b46 = r5_b /\ r5_t46 = r5_t
   && r5_b46 = r5_b /\ r5_t46 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x4009d4 *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x4009d8 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x4009dc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x4009e0 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x4009e4 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b46 *  630) [Q] /\
       eqmod lr_t (r5_t46 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r5_b46 *  630) [Q] /\
       eqmod lr_t (r5_t46 *  630) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x4009e8 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x4009ec *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b46@int16, r7_t46@int16:
      r7_b46 = r7_b /\ r7_t46 = r7_t
   && r7_b46 = r7_b /\ r7_t46 = r7_t;

(* vmov	r10, s13                                   #! PC = 0x4009f0 *)
mov r10 s13;
(* vmov	r11, s14                                   #! PC = 0x4009f4 *)
mov r11 s14;
(* smulwb	lr, r10, r7                              #! PC = 0x4009f8 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x4009fc *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a00 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400a04 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400a08 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b46 *  -1432) [Q] /\
       eqmod lr_t (r7_t46 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r7_b46 *  -1432) [Q] /\
       eqmod lr_t (r7_t46 *  -1432) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400a0c *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400a10 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b62@int16, r9_t62@int16:
      r9_b62 = r9_b /\ r9_t62 = r9_t
   && r9_b62 = r9_b /\ r9_t62 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400a14 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400a18 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400a1c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400a20 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400a24 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b62 *  848) [Q] /\
       eqmod lr_t (r9_t62 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [precondition, algebra solver isl] && true;
assume eqmod lr_b (r9_b62 *  848) [Q] /\
       eqmod lr_t (r9_t62 *  848) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400a28 *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400a2c *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400a30 *)
mov r0 s23;
(* vmov	r10, s1                                    #! PC = 0x400a34 *)
mov [r10_b, r10_t] [s1_b, s1_t];
(* uadd16	lr, r3, r10                              #! PC = 0x400a38 *)
add [lr_b, lr_t] [r3_b, r3_t] [r10_b, r10_t];
(* usub16	r3, r3, r10                              #! PC = 0x400a3c *)
sub [r3_b, r3_t] [r3_b, r3_t] [r10_b, r10_t];
(* str.w	lr, [r0, #64]	; 0x40                      #! EA = L0xbefff220; PC = 0x400a40 *)
mov [L0xbefff220, L0xbefff222] [lr_b, lr_t];
(* str.w	r3, [r0, #96]	; 0x60                      #! EA = L0xbefff240; PC = 0x400a44 *)
mov [L0xbefff240, L0xbefff242] [r3_b, r3_t];
(* vmov	r10, s3                                    #! PC = 0x400a48 *)
mov [r10_b, r10_t] [s3_b, s3_t];
(* uadd16	lr, r5, r10                              #! PC = 0x400a4c *)
add [lr_b, lr_t] [r5_b, r5_t] [r10_b, r10_t];
(* usub16	r5, r5, r10                              #! PC = 0x400a50 *)
sub [r5_b, r5_t] [r5_b, r5_t] [r10_b, r10_t];
(* str.w	lr, [r0, #192]	; 0xc0                     #! EA = L0xbefff2a0; PC = 0x400a54 *)
mov [L0xbefff2a0, L0xbefff2a2] [lr_b, lr_t];
(* str.w	r5, [r0, #224]	; 0xe0                     #! EA = L0xbefff2c0; PC = 0x400a58 *)
mov [L0xbefff2c0, L0xbefff2c2] [r5_b, r5_t];
(* vmov	r10, s5                                    #! PC = 0x400a5c *)
mov [r10_b, r10_t] [s5_b, s5_t];
(* uadd16	lr, r7, r10                              #! PC = 0x400a60 *)
add [lr_b, lr_t] [r7_b, r7_t] [r10_b, r10_t];
(* usub16	r7, r7, r10                              #! PC = 0x400a64 *)
sub [r7_b, r7_t] [r7_b, r7_t] [r10_b, r10_t];
(* str.w	lr, [r0, #320]	; 0x140                    #! EA = L0xbefff320; PC = 0x400a68 *)
mov [L0xbefff320, L0xbefff322] [lr_b, lr_t];
(* str.w	r7, [r0, #352]	; 0x160                    #! EA = L0xbefff340; PC = 0x400a6c *)
mov [L0xbefff340, L0xbefff342] [r7_b, r7_t];
(* vmov	r10, s7                                    #! PC = 0x400a70 *)
mov [r10_b, r10_t] [s7_b, s7_t];
(* uadd16	lr, r9, r10                              #! PC = 0x400a74 *)
add [lr_b, lr_t] [r9_b, r9_t] [r10_b, r10_t];
(* usub16	r9, r9, r10                              #! PC = 0x400a78 *)
sub [r9_b, r9_t] [r9_b, r9_t] [r10_b, r10_t];
(* str.w	lr, [r0, #448]	; 0x1c0                    #! EA = L0xbefff3a0; PC = 0x400a7c *)
mov [L0xbefff3a0, L0xbefff3a2] [lr_b, lr_t];
(* str.w	r9, [r0, #480]	; 0x1e0                    #! EA = L0xbefff3c0; PC = 0x400a80 *)
mov [L0xbefff3c0, L0xbefff3c2] [r9_b, r9_t];
(* vmov	r5, s2                                     #! PC = 0x400a84 *)
mov [r5_b, r5_t] [s2_b, s2_t];
(* uadd16	lr, r4, r5                               #! PC = 0x400a88 *)
add [lr_b, lr_t] [r4_b, r4_t] [r5_b, r5_t];
(* usub16	r10, r4, r5                              #! PC = 0x400a8c *)
sub [r10_b, r10_t] [r4_b, r4_t] [r5_b, r5_t];
(* str.w	lr, [r0, #128]	; 0x80                     #! EA = L0xbefff260; PC = 0x400a90 *)
mov [L0xbefff260, L0xbefff262] [lr_b, lr_t];
(* str.w	r10, [r0, #160]	; 0xa0                    #! EA = L0xbefff280; PC = 0x400a94 *)
mov [L0xbefff280, L0xbefff282] [r10_b, r10_t];
(* vmov	r7, s4                                     #! PC = 0x400a98 *)
mov [r7_b, r7_t] [s4_b, s4_t];
(* uadd16	lr, r6, r7                               #! PC = 0x400a9c *)
add [lr_b, lr_t] [r6_b, r6_t] [r7_b, r7_t];
(* usub16	r10, r6, r7                              #! PC = 0x400aa0 *)
sub [r10_b, r10_t] [r6_b, r6_t] [r7_b, r7_t];
(* str.w	lr, [r0, #256]	; 0x100                    #! EA = L0xbefff2e0; PC = 0x400aa4 *)
mov [L0xbefff2e0, L0xbefff2e2] [lr_b, lr_t];
(* str.w	r10, [r0, #288]	; 0x120                   #! EA = L0xbefff300; PC = 0x400aa8 *)
mov [L0xbefff300, L0xbefff302] [r10_b, r10_t];
(* vmov	r9, s6                                     #! PC = 0x400aac *)
mov [r9_b, r9_t] [s6_b, s6_t];
(* uadd16	lr, r8, r9                               #! PC = 0x400ab0 *)
add [lr_b, lr_t] [r8_b, r8_t] [r9_b, r9_t];
(* usub16	r10, r8, r9                              #! PC = 0x400ab4 *)
sub [r10_b, r10_t] [r8_b, r8_t] [r9_b, r9_t];
(* str.w	lr, [r0, #384]	; 0x180                    #! EA = L0xbefff360; PC = 0x400ab8 *)
mov [L0xbefff360, L0xbefff362] [lr_b, lr_t];
(* str.w	r10, [r0, #416]	; 0x1a0                   #! EA = L0xbefff380; PC = 0x400abc *)
mov [L0xbefff380, L0xbefff382] [r10_b, r10_t];
(* vmov	r3, s0                                     #! PC = 0x400ac0 *)
mov [r3_b, r3_t] [s0_b, s0_t];
(* uadd16	lr, r2, r3                               #! PC = 0x400ac4 *)
add [lr_b, lr_t] [r2_b, r2_t] [r3_b, r3_t];
(* usub16	r10, r2, r3                              #! PC = 0x400ac8 *)
sub [r10_b, r10_t] [r2_b, r2_t] [r3_b, r3_t];
(* str.w	r10, [r0, #32]                            #! EA = L0xbefff200; PC = 0x400acc *)
mov [L0xbefff200, L0xbefff202] [r10_b, r10_t];
(* str.w	lr, [r0], #4                              #! EA = L0xbefff1e0; PC = 0x400ad0 *)
mov [L0xbefff1e0, L0xbefff1e2] [lr_b, lr_t];
(* vmov	lr, s24                                    #! PC = 0x400ad4 *)
mov lr s24;
(* cmp.w	r0, lr                                    #! PC = 0x400ad8 *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400628 <ntt_fast+24>                   #! PC = 0x400adc *)
#bne.w	0x400628 <ntt_fast+24>                   #! 0x400adc = 0x400adc;

assert [5*NQ2, 5*NQ2] < [L0xbefff1e0, L0xbefff1e2] /\
                        [L0xbefff1e0, L0xbefff1e2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff200, L0xbefff202] /\
                        [L0xbefff200, L0xbefff202] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff220, L0xbefff222] /\
                        [L0xbefff220, L0xbefff222] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff240, L0xbefff242] /\
                        [L0xbefff240, L0xbefff242] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff260, L0xbefff262] /\
                        [L0xbefff260, L0xbefff262] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff280, L0xbefff282] /\
                        [L0xbefff280, L0xbefff282] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2a0, L0xbefff2a2] /\
                        [L0xbefff2a0, L0xbefff2a2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2c0, L0xbefff2c2] /\
                        [L0xbefff2c0, L0xbefff2c2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2e0, L0xbefff2e2] /\
                        [L0xbefff2e0, L0xbefff2e2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff300, L0xbefff302] /\
                        [L0xbefff300, L0xbefff302] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff320, L0xbefff322] /\
                        [L0xbefff320, L0xbefff322] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff340, L0xbefff342] /\
                        [L0xbefff340, L0xbefff342] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff360, L0xbefff362] /\
                        [L0xbefff360, L0xbefff362] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff380, L0xbefff382] /\
                        [L0xbefff380, L0xbefff382] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3a0, L0xbefff3a2] /\
                        [L0xbefff3a0, L0xbefff3a2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3c0, L0xbefff3c2] /\
                        [L0xbefff3c0, L0xbefff3c2] < [5*Q2, 5*Q2]
       prove with [algebra solver isl, precondition, cuts [22]] && true;

assume [5*NQ2, 5*NQ2] < [L0xbefff1e0, L0xbefff1e2] /\
                        [L0xbefff1e0, L0xbefff1e2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff200, L0xbefff202] /\
                        [L0xbefff200, L0xbefff202] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff220, L0xbefff222] /\
                        [L0xbefff220, L0xbefff222] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff240, L0xbefff242] /\
                        [L0xbefff240, L0xbefff242] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff260, L0xbefff262] /\
                        [L0xbefff260, L0xbefff262] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff280, L0xbefff282] /\
                        [L0xbefff280, L0xbefff282] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2a0, L0xbefff2a2] /\
                        [L0xbefff2a0, L0xbefff2a2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2c0, L0xbefff2c2] /\
                        [L0xbefff2c0, L0xbefff2c2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff2e0, L0xbefff2e2] /\
                        [L0xbefff2e0, L0xbefff2e2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff300, L0xbefff302] /\
                        [L0xbefff300, L0xbefff302] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff320, L0xbefff322] /\
                        [L0xbefff320, L0xbefff322] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff340, L0xbefff342] /\
                        [L0xbefff340, L0xbefff342] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff360, L0xbefff362] /\
                        [L0xbefff360, L0xbefff362] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff380, L0xbefff382] /\
                        [L0xbefff380, L0xbefff382] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3a0, L0xbefff3a2] /\
                        [L0xbefff3a0, L0xbefff3a2] < [5*Q2, 5*Q2] /\
       [5*NQ2, 5*NQ2] < [L0xbefff3c0, L0xbefff3c2] /\
                        [L0xbefff3c0, L0xbefff3c2] < [5*Q2, 5*Q2]
    && [5@16*NQ2,5@16*NQ2]<s[L0xbefff1e0,L0xbefff1e2] /\
                            [L0xbefff1e0,L0xbefff1e2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff200,L0xbefff202] /\
                            [L0xbefff200,L0xbefff202]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff220,L0xbefff222] /\
                            [L0xbefff220,L0xbefff222]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff240,L0xbefff242] /\
                            [L0xbefff240,L0xbefff242]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff260,L0xbefff262] /\
                            [L0xbefff260,L0xbefff262]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff280,L0xbefff282] /\
                            [L0xbefff280,L0xbefff282]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2a0,L0xbefff2a2] /\
                            [L0xbefff2a0,L0xbefff2a2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2c0,L0xbefff2c2] /\
                            [L0xbefff2c0,L0xbefff2c2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff2e0,L0xbefff2e2] /\
                            [L0xbefff2e0,L0xbefff2e2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff300,L0xbefff302] /\
                            [L0xbefff300,L0xbefff302]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff320,L0xbefff322] /\
                            [L0xbefff320,L0xbefff322]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff340,L0xbefff342] /\
                            [L0xbefff340,L0xbefff342]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff360,L0xbefff362] /\
                            [L0xbefff360,L0xbefff362]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff380,L0xbefff382] /\
                            [L0xbefff380,L0xbefff382]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3a0,L0xbefff3a2] /\
                            [L0xbefff3a0,L0xbefff3a2]<s[5@16*Q2,5@16*Q2] /\
       [5@16*NQ2,5@16*NQ2]<s[L0xbefff3c0,L0xbefff3c2] /\
                            [L0xbefff3c0,L0xbefff3c2]<s[5@16*Q2,5@16*Q2];

(* CUT 24 *)
cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (Fe**2+Ff**2)(L0xbefff1e0*X**14+L0xbefff1e2*X**15)[Q,X**16-17**  8]/\
    eqmod (Fe**2+Ff**2)(L0xbefff200*X**14+L0xbefff202*X**15)[Q,X**16-17**136]/\
    eqmod (Fe**2+Ff**2)(L0xbefff220*X**14+L0xbefff222*X**15)[Q,X**16-17** 72]/\
    eqmod (Fe**2+Ff**2)(L0xbefff240*X**14+L0xbefff242*X**15)[Q,X**16-17**200]/\
    eqmod (Fe**2+Ff**2)(L0xbefff260*X**14+L0xbefff262*X**15)[Q,X**16-17** 40]/\
    eqmod (Fe**2+Ff**2)(L0xbefff280*X**14+L0xbefff282*X**15)[Q,X**16-17**168]/\
    eqmod (Fe**2+Ff**2)(L0xbefff2a0*X**14+L0xbefff2a2*X**15)[Q,X**16-17**104]/\
    eqmod (Fe**2+Ff**2)(L0xbefff2c0*X**14+L0xbefff2c2*X**15)[Q,X**16-17**232]/\
    eqmod (Fe**2+Ff**2)(L0xbefff2e0*X**14+L0xbefff2e2*X**15)[Q,X**16-17** 24]/\
    eqmod (Fe**2+Ff**2)(L0xbefff300*X**14+L0xbefff302*X**15)[Q,X**16-17**152]/\
    eqmod (Fe**2+Ff**2)(L0xbefff320*X**14+L0xbefff322*X**15)[Q,X**16-17** 88]/\
    eqmod (Fe**2+Ff**2)(L0xbefff340*X**14+L0xbefff342*X**15)[Q,X**16-17**216]/\
    eqmod (Fe**2+Ff**2)(L0xbefff360*X**14+L0xbefff362*X**15)[Q,X**16-17** 56]/\
    eqmod (Fe**2+Ff**2)(L0xbefff380*X**14+L0xbefff382*X**15)[Q,X**16-17**184]/\
    eqmod (Fe**2+Ff**2)(L0xbefff3a0*X**14+L0xbefff3a2*X**15)[Q,X**16-17**120]/\
    eqmod (Fe**2+Ff**2)(L0xbefff3c0*X**14+L0xbefff3c2*X**15)[Q,X**16-17**248]/\
    [5*NQ2, 5*NQ2] < [L0xbefff1e0, L0xbefff1e2] /\
                     [L0xbefff1e0, L0xbefff1e2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff200, L0xbefff202] /\
                     [L0xbefff200, L0xbefff202] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff220, L0xbefff222] /\
                     [L0xbefff220, L0xbefff222] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff240, L0xbefff242] /\
                     [L0xbefff240, L0xbefff242] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff260, L0xbefff262] /\
                     [L0xbefff260, L0xbefff262] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff280, L0xbefff282] /\
                     [L0xbefff280, L0xbefff282] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2a0, L0xbefff2a2] /\
                     [L0xbefff2a0, L0xbefff2a2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2c0, L0xbefff2c2] /\
                     [L0xbefff2c0, L0xbefff2c2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff2e0, L0xbefff2e2] /\
                     [L0xbefff2e0, L0xbefff2e2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff300, L0xbefff302] /\
                     [L0xbefff300, L0xbefff302] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff320, L0xbefff322] /\
                     [L0xbefff320, L0xbefff322] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff340, L0xbefff342] /\
                     [L0xbefff340, L0xbefff342] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff360, L0xbefff362] /\
                     [L0xbefff360, L0xbefff362] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff380, L0xbefff382] /\
                     [L0xbefff380, L0xbefff382] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3a0, L0xbefff3a2] /\
                     [L0xbefff3a0, L0xbefff3a2] < [5*Q2, 5*Q2] /\
    [5*NQ2, 5*NQ2] < [L0xbefff3c0, L0xbefff3c2] /\
                     [L0xbefff3c0, L0xbefff3c2] < [5*Q2, 5*Q2]
    prove with [cuts [22], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff1e0,L0xbefff1e2] /\
                         [L0xbefff1e0,L0xbefff1e2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff200,L0xbefff202] /\
                         [L0xbefff200,L0xbefff202]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff220,L0xbefff222] /\
                         [L0xbefff220,L0xbefff222]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff240,L0xbefff242] /\
                         [L0xbefff240,L0xbefff242]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff260,L0xbefff262] /\
                         [L0xbefff260,L0xbefff262]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff280,L0xbefff282] /\
                         [L0xbefff280,L0xbefff282]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2a0,L0xbefff2a2] /\
                         [L0xbefff2a0,L0xbefff2a2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2c0,L0xbefff2c2] /\
                         [L0xbefff2c0,L0xbefff2c2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff2e0,L0xbefff2e2] /\
                         [L0xbefff2e0,L0xbefff2e2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff300,L0xbefff302] /\
                         [L0xbefff300,L0xbefff302]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff320,L0xbefff322] /\
                         [L0xbefff320,L0xbefff322]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff340,L0xbefff342] /\
                         [L0xbefff340,L0xbefff342]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff360,L0xbefff362] /\
                         [L0xbefff360,L0xbefff362]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff380,L0xbefff382] /\
                         [L0xbefff380,L0xbefff382]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3a0,L0xbefff3a2] /\
                         [L0xbefff3a0,L0xbefff3a2]<s[5@16*Q2,5@16*Q2] /\
    [5@16*NQ2,5@16*NQ2]<s[L0xbefff3c0,L0xbefff3c2] /\
                         [L0xbefff3c0,L0xbefff3c2]<s[5@16*Q2,5@16*Q2]
    prove with [precondition];

(* sub.w	r0, r0, #32                               #! PC = 0x400ae0 *)
subs dc r0 r0 32@int32;
(* add.w	lr, r0, #512	; 0x200                      #! PC = 0x400ae4 *)
adds dc lr r0 512@int32;
(* vmov	s13, lr                                    #! PC = 0x400ae8 *)
mov s13 lr;
(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1c4; Value = 0xbf049124; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff1c4, L0xbefff1c6];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff1c8; Value = 0xb7c2b4ca; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff1c8, L0xbefff1ca];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff1cc; Value = 0xffa4fe13; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff1cc, L0xbefff1ce];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff1d0; Value = 0xfb840075; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff1d0, L0xbefff1d2];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff1d4; Value = 0xb678066c; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff1d4, L0xbefff1d6];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff1d8; Value = 0xba80ecde; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff1d8, L0xbefff1da];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff1dc; Value = 0x0135fc13; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff1dc, L0xbefff1de];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff1e0; Value = 0xc3ddf4bd; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff1e0, L0xbefff1e2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b31@int16, r6_t31@int16:
      r6_b31 = r6_b /\ r6_t31 = r6_t
   && r6_b31 = r6_b /\ r6_t31 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x4016b8; Value = 0x16c32c11; PC = 0x400b14 *)
mov r10 L0x4016b8;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b31 *  296) [Q] /\
       eqmod lr_t (r6_t31 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b31 *  296) [Q] /\
       eqmod lr_t (r6_t31 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b47@int16, r7_t47@int16:
      r7_b47 = r7_b /\ r7_t47 = r7_t
   && r7_b47 = r7_b /\ r7_t47 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b47 *  296) [Q] /\ (* 17**4 *)
       eqmod lr_t (r7_t47 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b47 *  296) [Q] /\
       eqmod lr_t (r7_t47 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b47@int16, r8_t47@int16:
      r8_b47 = r8_b /\ r8_t47 = r8_t
   && r8_b47 = r8_b /\ r8_t47 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b47 *  296) [Q] /\ (* 17**4 *)
       eqmod lr_t (r8_t47 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b47 *  296) [Q] /\
       eqmod lr_t (r8_t47 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b63@int16, r9_t63@int16:
      r9_b63 = r9_b /\ r9_t63 = r9_t
   && r9_b63 = r9_b /\ r9_t63 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b63 *  296) [Q] /\ (* 17**4 *)
       eqmod lr_t (r9_t63 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b63 *  296) [Q] /\
       eqmod lr_t (r9_t63 *  296) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b31@int16, r4_t31@int16:
      r4_b31 = r4_b /\ r4_t31 = r4_t
   && r4_b31 = r4_b /\ r4_t31 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016bc; Value = 0x16395e0d; PC = 0x400b88 *)
mov [r10, r11] [L0x4016bc, L0x4016c0];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b31 *  289) [Q] /\
       eqmod lr_t (r4_t31 *  289) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b31 *  289) [Q] /\
       eqmod lr_t (r4_t31 *  289) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b47@int16, r5_t47@int16:
      r5_b47 = r5_b /\ r5_t47 = r5_t
   && r5_b47 = r5_b /\ r5_t47 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b47 *  289) [Q] /\
       eqmod lr_t (r5_t47 *  289) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b47 *  289) [Q] /\
       eqmod lr_t (r5_t47 *  289) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b48@int16, r8_t48@int16:
      r8_b48 = r8_b /\ r8_t48 = r8_t
   && r8_b48 = r8_b /\ r8_t48 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b48 *  331) [Q] /\
       eqmod lr_t (r8_t48 *  331) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b48 *  331) [Q] /\
       eqmod lr_t (r8_t48 *  331) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b64@int16, r9_t64@int16:
      r9_b64 = r9_b /\ r9_t64 = r9_t
   && r9_b64 = r9_b /\ r9_t64 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b64 *  331) [Q] /\
       eqmod lr_t (r9_t64 *  331) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b64 *  331) [Q] /\
       eqmod lr_t (r9_t64 *  331) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b31@int16, r3_t31@int16:
      r3_b31 = r3_b /\ r3_t31 = r3_t
   && r3_b31 = r3_b /\ r3_t31 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016c4; Value = 0x014eab2e; PC = 0x400bfc *)
mov [r10, r11] [L0x4016c4, L0x4016c8];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b31 *   17) [Q] /\
       eqmod lr_t (r3_t31 *   17) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b31 *   17) [Q] /\
       eqmod lr_t (r3_t31 *   17) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b48@int16, r5_t48@int16:
      r5_b48 = r5_b /\ r5_t48 = r5_t
   && r5_b48 = r5_b /\ r5_t48 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b48 * -568) [Q] /\
       eqmod lr_t (r5_t48 * -568) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b48 * -568) [Q] /\
       eqmod lr_t (r5_t48 * -568) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b48@int16, r7_t48@int16:
      r7_b48 = r7_b /\ r7_t48 = r7_t
   && r7_b48 = r7_b /\ r7_t48 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016cc; Value = 0x2cd52aae; PC = 0x400c38 *)
mov [r10, r11] [L0x4016cc, L0x4016d0];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b48 *  583) [Q] /\
       eqmod lr_t (r7_t48 *  583) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b48 *  583) [Q] /\
       eqmod lr_t (r7_t48 *  583) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b65@int16, r9_t65@int16:
      r9_b65 = r9_b /\ r9_t65 = r9_t
   && r9_b65 = r9_b /\ r9_t65 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b65 * -680) [Q] /\
       eqmod lr_t (r9_t65 * -680) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b65 * -680) [Q] /\
       eqmod lr_t (r9_t65 * -680) [Q] /\
       [NQ2, NQ2] < [lr_b, lr_t] /\ [lr_b, lr_t] < [Q2, Q2]
    && [NQ2, NQ2] <s[lr_b, lr_t] /\ [lr_b, lr_t] <s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff1d4; PC = 0x400c78 *)
mov [L0xbefff1d4, L0xbefff1d6] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff1d8; PC = 0x400c7c *)
mov [L0xbefff1d8, L0xbefff1da] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff1dc; PC = 0x400c80 *)
mov [L0xbefff1dc, L0xbefff1de] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff1e0; PC = 0x400c84 *)
mov [L0xbefff1e0, L0xbefff1e2] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff1c8; PC = 0x400c88 *)
mov [L0xbefff1c8, L0xbefff1ca] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff1cc; PC = 0x400c8c *)
mov [L0xbefff1cc, L0xbefff1ce] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff1d0; PC = 0x400c90 *)
mov [L0xbefff1d0, L0xbefff1d2] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff1c4; PC = 0x400c94 *)
mov [L0xbefff1c4, L0xbefff1c6] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff1c4,L0xbefff1c6] /\
                     [L0xbefff1c4,L0xbefff1c6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1c8,L0xbefff1ca] /\
                     [L0xbefff1c8,L0xbefff1ca]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1cc,L0xbefff1ce] /\
                     [L0xbefff1cc,L0xbefff1ce]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1d0,L0xbefff1d2] /\
                     [L0xbefff1d0,L0xbefff1d2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1d4,L0xbefff1d6] /\
                     [L0xbefff1d4,L0xbefff1d6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1d8,L0xbefff1da] /\
                     [L0xbefff1d8,L0xbefff1da]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1dc,L0xbefff1de] /\
                     [L0xbefff1dc,L0xbefff1de]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1e0,L0xbefff1e2] /\
                     [L0xbefff1e0,L0xbefff1e2]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff1c4,L0xbefff1c6] /\
                     [L0xbefff1c4,L0xbefff1c6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1c8,L0xbefff1ca] /\
                     [L0xbefff1c8,L0xbefff1ca]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1cc,L0xbefff1ce] /\
                     [L0xbefff1cc,L0xbefff1ce]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1d0,L0xbefff1d2] /\
                     [L0xbefff1d0,L0xbefff1d2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1d4,L0xbefff1d6] /\
                     [L0xbefff1d4,L0xbefff1d6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1d8,L0xbefff1da] /\
                     [L0xbefff1d8,L0xbefff1da]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1dc,L0xbefff1de] /\
                     [L0xbefff1dc,L0xbefff1de]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1e0,L0xbefff1e2] /\
                     [L0xbefff1e0,L0xbefff1e2]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff1c4,L0xbefff1c6] /\
                           [L0xbefff1c4,L0xbefff1c6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1c8,L0xbefff1ca] /\
                           [L0xbefff1c8,L0xbefff1ca]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1cc,L0xbefff1ce] /\
                           [L0xbefff1cc,L0xbefff1ce]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d0,L0xbefff1d2] /\
                           [L0xbefff1d0,L0xbefff1d2]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d4,L0xbefff1d6] /\
                           [L0xbefff1d4,L0xbefff1d6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d8,L0xbefff1da] /\
                           [L0xbefff1d8,L0xbefff1da]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1dc,L0xbefff1de] /\
                           [L0xbefff1dc,L0xbefff1de]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e0,L0xbefff1e2] /\
                           [L0xbefff1e0,L0xbefff1e2]<s[8@16*Q2,8@16*Q2];


(* CUT 25 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff1c4+L0xbefff1c6*X) [Q,X**2 - 17**  1] /\
    eqmod (F**2) (L0xbefff1c8+L0xbefff1ca*X) [Q,X**2 - 17**129] /\
    eqmod (F**2) (L0xbefff1cc+L0xbefff1ce*X) [Q,X**2 - 17** 65] /\
    eqmod (F**2) (L0xbefff1d0+L0xbefff1d2*X) [Q,X**2 - 17**193] /\
    eqmod (F**2) (L0xbefff1d4+L0xbefff1d6*X) [Q,X**2 - 17** 33] /\
    eqmod (F**2) (L0xbefff1d8+L0xbefff1da*X) [Q,X**2 - 17**161] /\
    eqmod (F**2) (L0xbefff1dc+L0xbefff1de*X) [Q,X**2 - 17** 97] /\
    eqmod (F**2) (L0xbefff1e0+L0xbefff1e2*X) [Q,X**2 - 17**225] /\
    [8*NQ2,8*NQ2]<[L0xbefff1c4,L0xbefff1c6] /\
                  [L0xbefff1c4,L0xbefff1c6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1c8,L0xbefff1ca] /\
                  [L0xbefff1c8,L0xbefff1ca]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1cc,L0xbefff1ce] /\
                  [L0xbefff1cc,L0xbefff1ce]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1d0,L0xbefff1d2] /\
                  [L0xbefff1d0,L0xbefff1d2]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1d4,L0xbefff1d6] /\
                  [L0xbefff1d4,L0xbefff1d6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1d8,L0xbefff1da] /\
                  [L0xbefff1d8,L0xbefff1da]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1dc,L0xbefff1de] /\
                  [L0xbefff1dc,L0xbefff1de]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1e0,L0xbefff1e2] /\
                  [L0xbefff1e0,L0xbefff1e2]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1c4,L0xbefff1c6] /\
                         [L0xbefff1c4,L0xbefff1c6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1c8,L0xbefff1ca] /\
                         [L0xbefff1c8,L0xbefff1ca]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1cc,L0xbefff1ce] /\
                         [L0xbefff1cc,L0xbefff1ce]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d0,L0xbefff1d2] /\
                         [L0xbefff1d0,L0xbefff1d2]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d4,L0xbefff1d6] /\
                         [L0xbefff1d4,L0xbefff1d6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d8,L0xbefff1da] /\
                         [L0xbefff1d8,L0xbefff1da]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1dc,L0xbefff1de] /\
                         [L0xbefff1dc,L0xbefff1de]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e0,L0xbefff1e2] /\
                         [L0xbefff1e0,L0xbefff1e2]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff1e4; Value = 0xb4cc9db6; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff1e4, L0xbefff1e6];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff1e8; Value = 0xb178aa68; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff1e8, L0xbefff1ea];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff1ec; Value = 0x091008b9; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff1ec, L0xbefff1ee];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff1f0; Value = 0x01700cff; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff1f0, L0xbefff1f2];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff1f4; Value = 0xb85a0c76; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff1f4, L0xbefff1f6];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff1f8; Value = 0xb8b2f41c; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff1f8, L0xbefff1fa];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff1fc; Value = 0x045bfb4f; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff1fc, L0xbefff1fe];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff200; Value = 0xb875ff29; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff200, L0xbefff202];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b32@int16, r6_t32@int16:
      r6_b32 = r6_b /\ r6_t32 = r6_t
   && r6_b32 = r6_b /\ r6_t32 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x4016d4; Value = 0xbc2c9a1c; PC = 0x400b14 *)
mov r10 L0x4016d4;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b32 *  -882) [Q] /\
       eqmod lr_t (r6_t32 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b32 *  -882) [Q] /\
       eqmod lr_t (r6_t32 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b49@int16, r7_t49@int16:
      r7_b49 = r7_b /\ r7_t49 = r7_t
   && r7_b49 = r7_b /\ r7_t49 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b49 *  -882) [Q] /\
       eqmod lr_t (r7_t49 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b49 *  -882) [Q] /\
       eqmod lr_t (r7_t49 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b49@int16, r8_t49@int16:
      r8_b49 = r8_b /\ r8_t49 = r8_t
   && r8_b49 = r8_b /\ r8_t49 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b49 *  -882) [Q] /\
       eqmod lr_t (r8_t49 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b49 *  -882) [Q] /\
       eqmod lr_t (r8_t49 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b66@int16, r9_t66@int16:
      r9_b66 = r9_b /\ r9_t66 = r9_t
   && r9_b66 = r9_b /\ r9_t66 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b66 *  -882) [Q] /\
       eqmod lr_t (r9_t66 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b66 *  -882) [Q] /\
       eqmod lr_t (r9_t66 *  -882) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b32@int16, r4_t32@int16:
      r4_b32 = r4_b /\ r4_t32 = r4_t
   && r4_b32 = r4_b /\ r4_t32 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016d8; Value = 0xfa27d58e; PC = 0x400b88 *)
mov [r10, r11] [L0x4016d8, L0x4016dc];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b32 *   -76) [Q] /\
       eqmod lr_t (r4_t32 *   -76) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b32 *   -76) [Q] /\
       eqmod lr_t (r4_t32 *   -76) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b49@int16, r5_t49@int16:
      r5_b49 = r5_b /\ r5_t49 = r5_t
   && r5_b49 = r5_b /\ r5_t49 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b49 *   -76) [Q] /\
       eqmod lr_t (r5_t49 *   -76) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b49 *   -76) [Q] /\
       eqmod lr_t (r5_t49 *   -76) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b50@int16, r8_t50@int16:
      r8_b50 = r8_b /\ r8_t50 = r8_t
   && r8_b50 = r8_b /\ r8_t50 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b50 * -1573) [Q] /\
       eqmod lr_t (r8_t50 * -1573) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b50 * -1573) [Q] /\
       eqmod lr_t (r8_t50 * -1573) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b67@int16, r9_t67@int16:
      r9_b67 = r9_b /\ r9_t67 = r9_t
   && r9_b67 = r9_b /\ r9_t67 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b67 * -1573) [Q] /\
       eqmod lr_t (r9_t67 * -1573) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b67 * -1573) [Q] /\
       eqmod lr_t (r9_t67 * -1573) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b32@int16, r3_t32@int16:
      r3_b32 = r3_b /\ r3_t32 = r3_t
   && r3_b32 = r3_b /\ r3_t32 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016e0; Value = 0x7de29fcd; PC = 0x400bfc *)
mov [r10, r11] [L0x4016e0, L0x4016e4];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b32 *  1637) [Q] /\
       eqmod lr_t (r3_t32 *  1637) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b32 *  1637) [Q] /\
       eqmod lr_t (r3_t32 *  1637) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b50@int16, r5_t50@int16:
      r5_b50 = r5_b /\ r5_t50 = r5_t
   && r5_b50 = r5_b /\ r5_t50 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b50 *   723) [Q] /\
       eqmod lr_t (r5_t50 *   723) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b50 *   723) [Q] /\
       eqmod lr_t (r5_t50 *   723) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b50@int16, r7_t50@int16:
      r7_b50 = r7_b /\ r7_t50 = r7_t
   && r7_b50 = r7_b /\ r7_t50 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016e8; Value = 0xaff27732; PC = 0x400c38 *)
mov [r10, r11] [L0x4016e8, L0x4016ec];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b50 * -1041) [Q] /\
       eqmod lr_t (r7_t50 * -1041) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b50 * -1041) [Q] /\
       eqmod lr_t (r7_t50 * -1041) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b68@int16, r9_t68@int16:
      r9_b68 = r9_b /\ r9_t68 = r9_t
   && r9_b68 = r9_b /\ r9_t68 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b68 *  1100) [Q] /\
       eqmod lr_t (r9_t68 *  1100) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b68 *  1100) [Q] /\
       eqmod lr_t (r9_t68 *  1100) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff1f4; PC = 0x400c78 *)
mov [L0xbefff1f4, L0xbefff1f6] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff1f8; PC = 0x400c7c *)
mov [L0xbefff1f8, L0xbefff1fa] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff1fc; PC = 0x400c80 *)
mov [L0xbefff1fc, L0xbefff1fe] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff200; PC = 0x400c84 *)
mov [L0xbefff200, L0xbefff202] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff1e8; PC = 0x400c88 *)
mov [L0xbefff1e8, L0xbefff1ea] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff1ec; PC = 0x400c8c *)
mov [L0xbefff1ec, L0xbefff1ee] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff1f0; PC = 0x400c90 *)
mov [L0xbefff1f0, L0xbefff1f2] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff1e4; PC = 0x400c94 *)
mov [L0xbefff1e4, L0xbefff1e6] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff1e4,L0xbefff1e6] /\
                     [L0xbefff1e4,L0xbefff1e6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1e8,L0xbefff1ea] /\
                     [L0xbefff1e8,L0xbefff1ea]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1ec,L0xbefff1ee] /\
                     [L0xbefff1ec,L0xbefff1ee]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1f0,L0xbefff1f2] /\
                     [L0xbefff1f0,L0xbefff1f2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1f4,L0xbefff1f6] /\
                     [L0xbefff1f4,L0xbefff1f6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1f8,L0xbefff1fa] /\
                     [L0xbefff1f8,L0xbefff1fa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1fc,L0xbefff1fe] /\
                     [L0xbefff1fc,L0xbefff1fe]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff200,L0xbefff202] /\
                     [L0xbefff200,L0xbefff202]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff1e4,L0xbefff1e6] /\
                     [L0xbefff1e4,L0xbefff1e6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1e8,L0xbefff1ea] /\
                     [L0xbefff1e8,L0xbefff1ea]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1ec,L0xbefff1ee] /\
                     [L0xbefff1ec,L0xbefff1ee]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1f0,L0xbefff1f2] /\
                     [L0xbefff1f0,L0xbefff1f2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1f4,L0xbefff1f6] /\
                     [L0xbefff1f4,L0xbefff1f6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1f8,L0xbefff1fa] /\
                     [L0xbefff1f8,L0xbefff1fa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff1fc,L0xbefff1fe] /\
                     [L0xbefff1fc,L0xbefff1fe]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff200,L0xbefff202] /\
                     [L0xbefff200,L0xbefff202]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e4,L0xbefff1e6] /\
                           [L0xbefff1e4,L0xbefff1e6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e8,L0xbefff1ea] /\
                           [L0xbefff1e8,L0xbefff1ea]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1ec,L0xbefff1ee] /\
                           [L0xbefff1ec,L0xbefff1ee]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f0,L0xbefff1f2] /\
                           [L0xbefff1f0,L0xbefff1f2]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f4,L0xbefff1f6] /\
                           [L0xbefff1f4,L0xbefff1f6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f8,L0xbefff1fa] /\
                           [L0xbefff1f8,L0xbefff1fa]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff1fc,L0xbefff1fe] /\
                           [L0xbefff1fc,L0xbefff1fe]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff200,L0xbefff202] /\
                           [L0xbefff200,L0xbefff202]<s[8@16*Q2,8@16*Q2];


(* CUT 26 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff1e4+L0xbefff1e6*X) [Q,X**2 - 17** 17] /\
    eqmod (F**2) (L0xbefff1e8+L0xbefff1ea*X) [Q,X**2 - 17**145] /\
    eqmod (F**2) (L0xbefff1ec+L0xbefff1ee*X) [Q,X**2 - 17** 81] /\
    eqmod (F**2) (L0xbefff1f0+L0xbefff1f2*X) [Q,X**2 - 17**209] /\
    eqmod (F**2) (L0xbefff1f4+L0xbefff1f6*X) [Q,X**2 - 17** 49] /\
    eqmod (F**2) (L0xbefff1f8+L0xbefff1fa*X) [Q,X**2 - 17**177] /\
    eqmod (F**2) (L0xbefff1fc+L0xbefff1fe*X) [Q,X**2 - 17**113] /\
    eqmod (F**2) (L0xbefff200+L0xbefff202*X) [Q,X**2 - 17**241] /\
    [8*NQ2,8*NQ2]<[L0xbefff1e4,L0xbefff1e6] /\
                  [L0xbefff1e4,L0xbefff1e6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1e8,L0xbefff1ea] /\
                  [L0xbefff1e8,L0xbefff1ea]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1ec,L0xbefff1ee] /\
                  [L0xbefff1ec,L0xbefff1ee]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1f0,L0xbefff1f2] /\
                  [L0xbefff1f0,L0xbefff1f2]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1f4,L0xbefff1f6] /\
                  [L0xbefff1f4,L0xbefff1f6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1f8,L0xbefff1fa] /\
                  [L0xbefff1f8,L0xbefff1fa]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff1fc,L0xbefff1fe] /\
                  [L0xbefff1fc,L0xbefff1fe]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff200,L0xbefff202] /\
                  [L0xbefff200,L0xbefff202]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e4,L0xbefff1e6] /\
                         [L0xbefff1e4,L0xbefff1e6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e8,L0xbefff1ea] /\
                         [L0xbefff1e8,L0xbefff1ea]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1ec,L0xbefff1ee] /\
                         [L0xbefff1ec,L0xbefff1ee]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f0,L0xbefff1f2] /\
                         [L0xbefff1f0,L0xbefff1f2]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f4,L0xbefff1f6] /\
                         [L0xbefff1f4,L0xbefff1f6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f8,L0xbefff1fa] /\
                         [L0xbefff1f8,L0xbefff1fa]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff1fc,L0xbefff1fe] /\
                         [L0xbefff1fc,L0xbefff1fe]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff200,L0xbefff202] /\
                         [L0xbefff200,L0xbefff202]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff204; Value = 0xb57b8eec; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff204, L0xbefff206];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff208; Value = 0xba51ab72; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff208, L0xbefff20a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff20c; Value = 0x028d04ed; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff20c, L0xbefff20e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff210; Value = 0x0e1afea6; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff210, L0xbefff212];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff214; Value = 0xbb0efe3f; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff214, L0xbefff216];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff218; Value = 0xc2f5e32c; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff218, L0xbefff21a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff21c; Value = 0x067205b3; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff21c, L0xbefff21e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff220; Value = 0xc8c3fde5; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff220, L0xbefff222];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b33@int16, r6_t33@int16:
      r6_b33 = r6_b /\ r6_t33 = r6_t
   && r6_b33 = r6_b /\ r6_t33 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x4016f0; Value = 0x66f8144e; PC = 0x400b14 *)
mov r10 L0x4016f0;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b33 *  1339) [Q] /\
       eqmod lr_t (r6_t33 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b33 *  1339) [Q] /\
       eqmod lr_t (r6_t33 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b51@int16, r7_t51@int16:
      r7_b51 = r7_b /\ r7_t51 = r7_t
   && r7_b51 = r7_b /\ r7_t51 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b51 *  1339) [Q] /\
       eqmod lr_t (r7_t51 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b51 *  1339) [Q] /\
       eqmod lr_t (r7_t51 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b51@int16, r8_t51@int16:
      r8_b51 = r8_b /\ r8_t51 = r8_t
   && r8_b51 = r8_b /\ r8_t51 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b51 *  1339) [Q] /\
       eqmod lr_t (r8_t51 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b51 *  1339) [Q] /\
       eqmod lr_t (r8_t51 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b69@int16, r9_t69@int16:
      r9_b69 = r9_b /\ r9_t69 = r9_t
   && r9_b69 = r9_b /\ r9_t69 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b69 *  1339) [Q] /\
       eqmod lr_t (r9_t69 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b69 *  1339) [Q] /\
       eqmod lr_t (r9_t69 *  1339) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b33@int16, r4_t33@int16:
      r4_b33 = r4_b /\ r4_t33 = r4_t
   && r4_b33 = r4_b /\ r4_t33 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016f4; Value = 0x5c0c9c92; PC = 0x400b88 *)
mov [r10, r11] [L0x4016f4, L0x4016f8];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b33 *  1197) [Q] /\
       eqmod lr_t (r4_t33 *  1197) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b33 *  1197) [Q] /\
       eqmod lr_t (r4_t33 *  1197) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b51@int16, r5_t51@int16:
      r5_b51 = r5_b /\ r5_t51 = r5_t
   && r5_b51 = r5_b /\ r5_t51 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b51 *  1197) [Q] /\
       eqmod lr_t (r5_t51 *  1197) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b51 *  1197) [Q] /\
       eqmod lr_t (r5_t51 *  1197) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b52@int16, r8_t52@int16:
      r8_b52 = r8_b /\ r8_t52 = r8_t
   && r8_b52 = r8_b /\ r8_t52 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b52 * -1025) [Q] /\
       eqmod lr_t (r8_t52 * -1025) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b52 * -1025) [Q] /\
       eqmod lr_t (r8_t52 * -1025) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b70@int16, r9_t70@int16:
      r9_b70 = r9_b /\ r9_t70 = r9_t
   && r9_b70 = r9_b /\ r9_t70 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b70 * -1025) [Q] /\
       eqmod lr_t (r9_t70 * -1025) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b70 * -1025) [Q] /\
       eqmod lr_t (r9_t70 * -1025) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b33@int16, r3_t33@int16:
      r3_b33 = r3_b /\ r3_t33 = r3_t
   && r3_b33 = r3_b /\ r3_t33 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4016fc; Value = 0x6c5a2074; PC = 0x400bfc *)
mov [r10, r11] [L0x4016fc, L0x401700];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b33 *  1409) [Q] /\
       eqmod lr_t (r3_t33 *  1409) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b33 *  1409) [Q] /\
       eqmod lr_t (r3_t33 *  1409) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b52@int16, r5_t52@int16:
      r5_b52 = r5_b /\ r5_t52 = r5_t
   && r5_b52 = r5_b /\ r5_t52 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b52 *  -667) [Q] /\
       eqmod lr_t (r5_t52 *  -667) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b52 *  -667) [Q] /\
       eqmod lr_t (r5_t52 *  -667) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b52@int16, r7_t52@int16:
      r7_b52 = r7_b /\ r7_t52 = r7_t
   && r7_b52 = r7_b /\ r7_t52 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401704; Value = 0xfc4f0d9d; PC = 0x400c38 *)
mov [r10, r11] [L0x401704, L0x401708];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b52 *   -48) [Q] /\
       eqmod lr_t (r7_t52 *   -48) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b52 *   -48) [Q] /\
       eqmod lr_t (r7_t52 *   -48) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b71@int16, r9_t71@int16:
      r9_b71 = r9_b /\ r9_t71 = r9_t
   && r9_b71 = r9_b /\ r9_t71 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b71 *   233) [Q] /\
       eqmod lr_t (r9_t71 *   233) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b71 *   233) [Q] /\
       eqmod lr_t (r9_t71 *   233) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff214; PC = 0x400c78 *)
mov [L0xbefff214, L0xbefff216] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff218; PC = 0x400c7c *)
mov [L0xbefff218, L0xbefff21a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff21c; PC = 0x400c80 *)
mov [L0xbefff21c, L0xbefff21e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff220; PC = 0x400c84 *)
mov [L0xbefff220, L0xbefff222] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff208; PC = 0x400c88 *)
mov [L0xbefff208, L0xbefff20a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff20c; PC = 0x400c8c *)
mov [L0xbefff20c, L0xbefff20e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff210; PC = 0x400c90 *)
mov [L0xbefff210, L0xbefff212] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff204; PC = 0x400c94 *)
mov [L0xbefff204, L0xbefff206] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff204,L0xbefff206] /\
                     [L0xbefff204,L0xbefff206]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff208,L0xbefff20a] /\
                     [L0xbefff208,L0xbefff20a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff20c,L0xbefff20e] /\
                     [L0xbefff20c,L0xbefff20e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff210,L0xbefff212] /\
                     [L0xbefff210,L0xbefff212]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff214,L0xbefff216] /\
                     [L0xbefff214,L0xbefff216]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff218,L0xbefff21a] /\
                     [L0xbefff218,L0xbefff21a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff21c,L0xbefff21e] /\
                     [L0xbefff21c,L0xbefff21e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff220,L0xbefff222] /\
                     [L0xbefff220,L0xbefff222]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff204,L0xbefff206] /\
                     [L0xbefff204,L0xbefff206]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff208,L0xbefff20a] /\
                     [L0xbefff208,L0xbefff20a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff20c,L0xbefff20e] /\
                     [L0xbefff20c,L0xbefff20e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff210,L0xbefff212] /\
                     [L0xbefff210,L0xbefff212]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff214,L0xbefff216] /\
                     [L0xbefff214,L0xbefff216]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff218,L0xbefff21a] /\
                     [L0xbefff218,L0xbefff21a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff21c,L0xbefff21e] /\
                     [L0xbefff21c,L0xbefff21e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff220,L0xbefff222] /\
                     [L0xbefff220,L0xbefff222]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff204,L0xbefff206] /\
                           [L0xbefff204,L0xbefff206]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff208,L0xbefff20a] /\
                           [L0xbefff208,L0xbefff20a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff20c,L0xbefff20e] /\
                           [L0xbefff20c,L0xbefff20e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff210,L0xbefff212] /\
                           [L0xbefff210,L0xbefff212]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff214,L0xbefff216] /\
                           [L0xbefff214,L0xbefff216]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff218,L0xbefff21a] /\
                           [L0xbefff218,L0xbefff21a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff21c,L0xbefff21e] /\
                           [L0xbefff21c,L0xbefff21e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff220,L0xbefff222] /\
                           [L0xbefff220,L0xbefff222]<s[8@16*Q2,8@16*Q2];


(* CUT 27 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff204+L0xbefff206*X) [Q,X**2 - 17**  9] /\
    eqmod (F**2) (L0xbefff208+L0xbefff20a*X) [Q,X**2 - 17**137] /\
    eqmod (F**2) (L0xbefff20c+L0xbefff20e*X) [Q,X**2 - 17** 73] /\
    eqmod (F**2) (L0xbefff210+L0xbefff212*X) [Q,X**2 - 17**201] /\
    eqmod (F**2) (L0xbefff214+L0xbefff216*X) [Q,X**2 - 17** 41] /\
    eqmod (F**2) (L0xbefff218+L0xbefff21a*X) [Q,X**2 - 17**169] /\
    eqmod (F**2) (L0xbefff21c+L0xbefff21e*X) [Q,X**2 - 17**105] /\
    eqmod (F**2) (L0xbefff220+L0xbefff222*X) [Q,X**2 - 17**233] /\
    [8*NQ2,8*NQ2]<[L0xbefff204,L0xbefff206] /\
                  [L0xbefff204,L0xbefff206]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff208,L0xbefff20a] /\
                  [L0xbefff208,L0xbefff20a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff20c,L0xbefff20e] /\
                  [L0xbefff20c,L0xbefff20e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff210,L0xbefff212] /\
                  [L0xbefff210,L0xbefff212]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff214,L0xbefff216] /\
                  [L0xbefff214,L0xbefff216]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff218,L0xbefff21a] /\
                  [L0xbefff218,L0xbefff21a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff21c,L0xbefff21e] /\
                  [L0xbefff21c,L0xbefff21e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff220,L0xbefff222] /\
                  [L0xbefff220,L0xbefff222]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff204,L0xbefff206] /\
                         [L0xbefff204,L0xbefff206]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff208,L0xbefff20a] /\
                         [L0xbefff208,L0xbefff20a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff20c,L0xbefff20e] /\
                         [L0xbefff20c,L0xbefff20e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff210,L0xbefff212] /\
                         [L0xbefff210,L0xbefff212]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff214,L0xbefff216] /\
                         [L0xbefff214,L0xbefff216]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff218,L0xbefff21a] /\
                         [L0xbefff218,L0xbefff21a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff21c,L0xbefff21e] /\
                         [L0xbefff21c,L0xbefff21e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff220,L0xbefff222] /\
                         [L0xbefff220,L0xbefff222]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff224; Value = 0xb265925a; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff224, L0xbefff226];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff228; Value = 0xb871b55c; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff228, L0xbefff22a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff22c; Value = 0x06270c9b; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff22c, L0xbefff22e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff230; Value = 0x065af76e; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff230, L0xbefff232];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff234; Value = 0xc0c00abf; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff234, L0xbefff236];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff238; Value = 0xba7dec6e; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff238, L0xbefff23a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff23c; Value = 0x08a6f90b; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff23c, L0xbefff23e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff240; Value = 0xbcf700c9; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff240, L0xbefff242];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b34@int16, r6_t34@int16:
      r6_b34 = r6_b /\ r6_t34 = r6_t
   && r6_b34 = r6_b /\ r6_t34 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x40170c; Value = 0x71811d74; PC = 0x400b14 *)
mov r10 L0x40170c;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b34 *  1476) [Q] /\
       eqmod lr_t (r6_t34 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b34 *  1476) [Q] /\
       eqmod lr_t (r6_t34 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b53@int16, r7_t53@int16:
      r7_b53 = r7_b /\ r7_t53 = r7_t
   && r7_b53 = r7_b /\ r7_t53 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b53 *  1476) [Q] /\
       eqmod lr_t (r7_t53 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b53 *  1476) [Q] /\
       eqmod lr_t (r7_t53 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b53@int16, r8_t53@int16:
      r8_b53 = r8_b /\ r8_t53 = r8_t
   && r8_b53 = r8_b /\ r8_t53 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b53 *  1476) [Q] /\
       eqmod lr_t (r8_t53 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b53 *  1476) [Q] /\
       eqmod lr_t (r8_t53 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b72@int16, r9_t72@int16:
      r9_b72 = r9_b /\ r9_t72 = r9_t
   && r9_b72 = r9_b /\ r9_t72 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b72 *  1476) [Q] /\
       eqmod lr_t (r9_t72 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b72 *  1476) [Q] /\
       eqmod lr_t (r9_t72 *  1476) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b34@int16, r4_t34@int16:
      r4_b34 = r4_b /\ r4_t34 = r4_t
   && r4_b34 = r4_b /\ r4_t34 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401710; Value = 0xaf19ea51; PC = 0x400b88 *)
mov [r10, r11] [L0x401710, L0x401714];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b34 * -1052) [Q] /\
       eqmod lr_t (r4_t34 * -1052) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b34 * -1052) [Q] /\
       eqmod lr_t (r4_t34 * -1052) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b53@int16, r5_t53@int16:
      r5_b53 = r5_b /\ r5_t53 = r5_t
   && r5_b53 = r5_b /\ r5_t53 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b53 * -1052) [Q] /\
       eqmod lr_t (r5_t53 * -1052) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b53 * -1052) [Q] /\
       eqmod lr_t (r5_t53 * -1052) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b54@int16, r8_t54@int16:
      r8_b54 = r8_b /\ r8_t54 = r8_t
   && r8_b54 = r8_b /\ r8_t54 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b54 * -1274) [Q] /\
       eqmod lr_t (r8_t54 * -1274) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b54 * -1274) [Q] /\
       eqmod lr_t (r8_t54 * -1274) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b73@int16, r9_t73@int16:
      r9_b73 = r9_b /\ r9_t73 = r9_t
   && r9_b73 = r9_b /\ r9_t73 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b73 * -1274) [Q] /\
       eqmod lr_t (r9_t73 * -1274) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b73 * -1274) [Q] /\
       eqmod lr_t (r9_t73 * -1274) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b34@int16, r3_t34@int16:
      r3_b34 = r3_b /\ r3_t34 = r3_t
   && r3_b34 = r3_b /\ r3_t34 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401718; Value = 0x3a22e9a0; PC = 0x400bfc *)
mov [r10, r11] [L0x401718, L0x40171c];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b34 *   756) [Q] /\
       eqmod lr_t (r3_t34 *   756) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b34 *   756) [Q] /\
       eqmod lr_t (r3_t34 *   756) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b54@int16, r5_t54@int16:
      r5_b54 = r5_b /\ r5_t54 = r5_t
   && r5_b54 = r5_b /\ r5_t54 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b54 * -1173) [Q] /\
       eqmod lr_t (r5_t54 * -1173) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b54 * -1173) [Q] /\
       eqmod lr_t (r5_t54 * -1173) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b54@int16, r7_t54@int16:
      r7_b54 = r7_b /\ r7_t54 = r7_t
   && r7_b54 = r7_b /\ r7_t54 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401720; Value = 0xe7da790b; PC = 0x400c38 *)
mov [r10, r11] [L0x401720, L0x401724];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b54 *  -314) [Q] /\
       eqmod lr_t (r7_t54 *  -314) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b54 *  -314) [Q] /\
       eqmod lr_t (r7_t54 *  -314) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b74@int16, r9_t74@int16:
      r9_b74 = r9_b /\ r9_t74 = r9_t
   && r9_b74 = r9_b /\ r9_t74 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b74 *  -279) [Q] /\
       eqmod lr_t (r9_t74 *  -279) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b74 *  -279) [Q] /\
       eqmod lr_t (r9_t74 *  -279) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff234; PC = 0x400c78 *)
mov [L0xbefff234, L0xbefff236] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff238; PC = 0x400c7c *)
mov [L0xbefff238, L0xbefff23a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff23c; PC = 0x400c80 *)
mov [L0xbefff23c, L0xbefff23e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff240; PC = 0x400c84 *)
mov [L0xbefff240, L0xbefff242] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff228; PC = 0x400c88 *)
mov [L0xbefff228, L0xbefff22a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff22c; PC = 0x400c8c *)
mov [L0xbefff22c, L0xbefff22e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff230; PC = 0x400c90 *)
mov [L0xbefff230, L0xbefff232] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff224; PC = 0x400c94 *)
mov [L0xbefff224, L0xbefff226] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff224,L0xbefff226] /\
                     [L0xbefff224,L0xbefff226]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff228,L0xbefff22a] /\
                     [L0xbefff228,L0xbefff22a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff22c,L0xbefff22e] /\
                     [L0xbefff22c,L0xbefff22e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff230,L0xbefff232] /\
                     [L0xbefff230,L0xbefff232]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff234,L0xbefff236] /\
                     [L0xbefff234,L0xbefff236]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff238,L0xbefff23a] /\
                     [L0xbefff238,L0xbefff23a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff23c,L0xbefff23e] /\
                     [L0xbefff23c,L0xbefff23e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff240,L0xbefff242] /\
                     [L0xbefff240,L0xbefff242]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff224,L0xbefff226] /\
                     [L0xbefff224,L0xbefff226]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff228,L0xbefff22a] /\
                     [L0xbefff228,L0xbefff22a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff22c,L0xbefff22e] /\
                     [L0xbefff22c,L0xbefff22e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff230,L0xbefff232] /\
                     [L0xbefff230,L0xbefff232]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff234,L0xbefff236] /\
                     [L0xbefff234,L0xbefff236]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff238,L0xbefff23a] /\
                     [L0xbefff238,L0xbefff23a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff23c,L0xbefff23e] /\
                     [L0xbefff23c,L0xbefff23e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff240,L0xbefff242] /\
                     [L0xbefff240,L0xbefff242]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff224,L0xbefff226] /\
                           [L0xbefff224,L0xbefff226]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff228,L0xbefff22a] /\
                           [L0xbefff228,L0xbefff22a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff22c,L0xbefff22e] /\
                           [L0xbefff22c,L0xbefff22e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff230,L0xbefff232] /\
                           [L0xbefff230,L0xbefff232]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff234,L0xbefff236] /\
                           [L0xbefff234,L0xbefff236]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff238,L0xbefff23a] /\
                           [L0xbefff238,L0xbefff23a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff23c,L0xbefff23e] /\
                           [L0xbefff23c,L0xbefff23e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff240,L0xbefff242] /\
                           [L0xbefff240,L0xbefff242]<s[8@16*Q2,8@16*Q2];


(* CUT 28 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff224+L0xbefff226*X) [Q,X**2 - 17** 25] /\
    eqmod (F**2) (L0xbefff228+L0xbefff22a*X) [Q,X**2 - 17**153] /\
    eqmod (F**2) (L0xbefff22c+L0xbefff22e*X) [Q,X**2 - 17** 89] /\
    eqmod (F**2) (L0xbefff230+L0xbefff232*X) [Q,X**2 - 17**217] /\
    eqmod (F**2) (L0xbefff234+L0xbefff236*X) [Q,X**2 - 17** 57] /\
    eqmod (F**2) (L0xbefff238+L0xbefff23a*X) [Q,X**2 - 17**185] /\
    eqmod (F**2) (L0xbefff23c+L0xbefff23e*X) [Q,X**2 - 17**121] /\
    eqmod (F**2) (L0xbefff240+L0xbefff242*X) [Q,X**2 - 17**249] /\
    [8*NQ2,8*NQ2]<[L0xbefff224,L0xbefff226] /\
                  [L0xbefff224,L0xbefff226]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff228,L0xbefff22a] /\
                  [L0xbefff228,L0xbefff22a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff22c,L0xbefff22e] /\
                  [L0xbefff22c,L0xbefff22e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff230,L0xbefff232] /\
                  [L0xbefff230,L0xbefff232]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff234,L0xbefff236] /\
                  [L0xbefff234,L0xbefff236]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff238,L0xbefff23a] /\
                  [L0xbefff238,L0xbefff23a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff23c,L0xbefff23e] /\
                  [L0xbefff23c,L0xbefff23e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff240,L0xbefff242] /\
                  [L0xbefff240,L0xbefff242]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff224,L0xbefff226] /\
                         [L0xbefff224,L0xbefff226]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff228,L0xbefff22a] /\
                         [L0xbefff228,L0xbefff22a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff22c,L0xbefff22e] /\
                         [L0xbefff22c,L0xbefff22e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff230,L0xbefff232] /\
                         [L0xbefff230,L0xbefff232]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff234,L0xbefff236] /\
                         [L0xbefff234,L0xbefff236]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff238,L0xbefff23a] /\
                         [L0xbefff238,L0xbefff23a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff23c,L0xbefff23e] /\
                         [L0xbefff23c,L0xbefff23e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff240,L0xbefff242] /\
                         [L0xbefff240,L0xbefff242]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff244; Value = 0xb30c98d4; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff244, L0xbefff246];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff248; Value = 0xbb25a356; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff248, L0xbefff24a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff24c; Value = 0x0064fcd1; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff24c, L0xbefff24e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff250; Value = 0xfe890064; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff250, L0xbefff252];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff254; Value = 0xbb391408; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff254, L0xbefff256];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff258; Value = 0xc21fea46; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff258, L0xbefff25a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff25c; Value = 0x02d8f7a7; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff25c, L0xbefff25e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff260; Value = 0xb2a3f859; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff260, L0xbefff262];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b35@int16, r6_t35@int16:
      r6_b35 = r6_b /\ r6_t35 = r6_t
   && r6_b35 = r6_b /\ r6_t35 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x401728; Value = 0xea3cc040; PC = 0x400b14 *)
mov r10 L0x401728;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b35 *  -283) [Q] /\
       eqmod lr_t (r6_t35 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b35 *  -283) [Q] /\
       eqmod lr_t (r6_t35 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b55@int16, r7_t55@int16:
      r7_b55 = r7_b /\ r7_t55 = r7_t
   && r7_b55 = r7_b /\ r7_t55 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b55 *  -283) [Q] /\
       eqmod lr_t (r7_t55 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b55 *  -283) [Q] /\
       eqmod lr_t (r7_t55 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b55@int16, r8_t55@int16:
      r8_b55 = r8_b /\ r8_t55 = r8_t
   && r8_b55 = r8_b /\ r8_t55 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b55 *  -283) [Q] /\
       eqmod lr_t (r8_t55 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b55 *  -283) [Q] /\
       eqmod lr_t (r8_t55 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b75@int16, r9_t75@int16:
      r9_b75 = r9_b /\ r9_t75 = r9_t
   && r9_b75 = r9_b /\ r9_t75 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b75 *  -283) [Q] /\
       eqmod lr_t (r9_t75 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b75 *  -283) [Q] /\
       eqmod lr_t (r9_t75 *  -283) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b35@int16, r4_t35@int16:
      r4_b35 = r4_b /\ r4_t35 = r4_t
   && r4_b35 = r4_b /\ r4_t35 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x40172c; Value = 0x31fc27af; PC = 0x400b88 *)
mov [r10, r11] [L0x40172c, L0x401730];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b35 *   650) [Q] /\
       eqmod lr_t (r4_t35 *   650) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b35 *   650) [Q] /\
       eqmod lr_t (r4_t35 *   650) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b55@int16, r5_t55@int16:
      r5_b55 = r5_b /\ r5_t55 = r5_t
   && r5_b55 = r5_b /\ r5_t55 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b55 *   650) [Q] /\
       eqmod lr_t (r5_t55 *   650) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b55 *   650) [Q] /\
       eqmod lr_t (r5_t55 *   650) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b56@int16, r8_t56@int16:
      r8_b56 = r8_b /\ r8_t56 = r8_t
   && r8_b56 = r8_b /\ r8_t56 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b56 * -1352) [Q] /\
       eqmod lr_t (r8_t56 * -1352) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b56 * -1352) [Q] /\
       eqmod lr_t (r8_t56 * -1352) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b76@int16, r9_t76@int16:
      r9_b76 = r9_b /\ r9_t76 = r9_t
   && r9_b76 = r9_b /\ r9_t76 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b76 * -1352) [Q] /\
       eqmod lr_t (r9_t76 * -1352) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b76 * -1352) [Q] /\
       eqmod lr_t (r9_t76 * -1352) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b35@int16, r3_t35@int16:
      r3_b35 = r3_b /\ r3_t35 = r3_t
   && r3_b35 = r3_b /\ r3_t35 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401734; Value = 0x82f5ed16; PC = 0x400bfc *)
mov [r10, r11] [L0x401734, L0x401738];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b35 * -1626) [Q] /\
       eqmod lr_t (r3_t35 * -1626) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b35 * -1626) [Q] /\
       eqmod lr_t (r3_t35 * -1626) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b56@int16, r5_t56@int16:
      r5_b56 = r5_b /\ r5_t56 = r5_t
   && r5_b56 = r5_b /\ r5_t56 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b56 *  1651) [Q] /\
       eqmod lr_t (r5_t56 *  1651) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b56 *  1651) [Q] /\
       eqmod lr_t (r5_t56 *  1651) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b56@int16, r7_t56@int16:
      r7_b56 = r7_b /\ r7_t56 = r7_t
   && r7_b56 = r7_b /\ r7_t56 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x40173c; Value = 0xd6795921; PC = 0x400c38 *)
mov [r10, r11] [L0x40173c, L0x401740];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b56 *  -540) [Q] /\
       eqmod lr_t (r7_t56 *  -540) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b56 *  -540) [Q] /\
       eqmod lr_t (r7_t56 *  -540) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b77@int16, r9_t77@int16:
      r9_b77 = r9_b /\ r9_t77 = r9_t
   && r9_b77 = r9_b /\ r9_t77 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b77 * -1540) [Q] /\
       eqmod lr_t (r9_t77 * -1540) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b77 * -1540) [Q] /\
       eqmod lr_t (r9_t77 * -1540) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff254; PC = 0x400c78 *)
mov [L0xbefff254, L0xbefff256] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff258; PC = 0x400c7c *)
mov [L0xbefff258, L0xbefff25a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff25c; PC = 0x400c80 *)
mov [L0xbefff25c, L0xbefff25e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff260; PC = 0x400c84 *)
mov [L0xbefff260, L0xbefff262] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff248; PC = 0x400c88 *)
mov [L0xbefff248, L0xbefff24a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff24c; PC = 0x400c8c *)
mov [L0xbefff24c, L0xbefff24e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff250; PC = 0x400c90 *)
mov [L0xbefff250, L0xbefff252] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff244; PC = 0x400c94 *)
mov [L0xbefff244, L0xbefff246] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff244,L0xbefff246] /\
                     [L0xbefff244,L0xbefff246]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff248,L0xbefff24a] /\
                     [L0xbefff248,L0xbefff24a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff24c,L0xbefff24e] /\
                     [L0xbefff24c,L0xbefff24e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff250,L0xbefff252] /\
                     [L0xbefff250,L0xbefff252]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff254,L0xbefff256] /\
                     [L0xbefff254,L0xbefff256]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff258,L0xbefff25a] /\
                     [L0xbefff258,L0xbefff25a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff25c,L0xbefff25e] /\
                     [L0xbefff25c,L0xbefff25e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff260,L0xbefff262] /\
                     [L0xbefff260,L0xbefff262]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff244,L0xbefff246] /\
                     [L0xbefff244,L0xbefff246]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff248,L0xbefff24a] /\
                     [L0xbefff248,L0xbefff24a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff24c,L0xbefff24e] /\
                     [L0xbefff24c,L0xbefff24e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff250,L0xbefff252] /\
                     [L0xbefff250,L0xbefff252]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff254,L0xbefff256] /\
                     [L0xbefff254,L0xbefff256]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff258,L0xbefff25a] /\
                     [L0xbefff258,L0xbefff25a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff25c,L0xbefff25e] /\
                     [L0xbefff25c,L0xbefff25e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff260,L0xbefff262] /\
                     [L0xbefff260,L0xbefff262]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff244,L0xbefff246] /\
                           [L0xbefff244,L0xbefff246]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff248,L0xbefff24a] /\
                           [L0xbefff248,L0xbefff24a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff24c,L0xbefff24e] /\
                           [L0xbefff24c,L0xbefff24e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff250,L0xbefff252] /\
                           [L0xbefff250,L0xbefff252]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff254,L0xbefff256] /\
                           [L0xbefff254,L0xbefff256]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff258,L0xbefff25a] /\
                           [L0xbefff258,L0xbefff25a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff25c,L0xbefff25e] /\
                           [L0xbefff25c,L0xbefff25e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff260,L0xbefff262] /\
                           [L0xbefff260,L0xbefff262]<s[8@16*Q2,8@16*Q2];


(* CUT 29 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff244+L0xbefff246*X) [Q,X**2 - 17**  5] /\
    eqmod (F**2) (L0xbefff248+L0xbefff24a*X) [Q,X**2 - 17**133] /\
    eqmod (F**2) (L0xbefff24c+L0xbefff24e*X) [Q,X**2 - 17** 69] /\
    eqmod (F**2) (L0xbefff250+L0xbefff252*X) [Q,X**2 - 17**197] /\
    eqmod (F**2) (L0xbefff254+L0xbefff256*X) [Q,X**2 - 17** 37] /\
    eqmod (F**2) (L0xbefff258+L0xbefff25a*X) [Q,X**2 - 17**165] /\
    eqmod (F**2) (L0xbefff25c+L0xbefff25e*X) [Q,X**2 - 17**101] /\
    eqmod (F**2) (L0xbefff260+L0xbefff262*X) [Q,X**2 - 17**229] /\
    [8*NQ2,8*NQ2]<[L0xbefff244,L0xbefff246] /\
                  [L0xbefff244,L0xbefff246]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff248,L0xbefff24a] /\
                  [L0xbefff248,L0xbefff24a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff24c,L0xbefff24e] /\
                  [L0xbefff24c,L0xbefff24e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff250,L0xbefff252] /\
                  [L0xbefff250,L0xbefff252]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff254,L0xbefff256] /\
                  [L0xbefff254,L0xbefff256]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff258,L0xbefff25a] /\
                  [L0xbefff258,L0xbefff25a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff25c,L0xbefff25e] /\
                  [L0xbefff25c,L0xbefff25e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff260,L0xbefff262] /\
                  [L0xbefff260,L0xbefff262]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff244,L0xbefff246] /\
                         [L0xbefff244,L0xbefff246]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff248,L0xbefff24a] /\
                         [L0xbefff248,L0xbefff24a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff24c,L0xbefff24e] /\
                         [L0xbefff24c,L0xbefff24e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff250,L0xbefff252] /\
                         [L0xbefff250,L0xbefff252]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff254,L0xbefff256] /\
                         [L0xbefff254,L0xbefff256]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff258,L0xbefff25a] /\
                         [L0xbefff258,L0xbefff25a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff25c,L0xbefff25e] /\
                         [L0xbefff25c,L0xbefff25e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff260,L0xbefff262] /\
                         [L0xbefff260,L0xbefff262]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff264; Value = 0xb5aa9800; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff264, L0xbefff266];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff268; Value = 0xb78fafc6; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff268, L0xbefff26a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff26c; Value = 0xf6e8fc25; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff26c, L0xbefff26e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff270; Value = 0xfc6908cc; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff270, L0xbefff272];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff274; Value = 0xb5b51138; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff274, L0xbefff276];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff278; Value = 0xb815e4b6; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff278, L0xbefff27a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff27c; Value = 0x0c32fbf5; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff27c, L0xbefff27e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff280; Value = 0xb495f229; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff280, L0xbefff282];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b36@int16, r6_t36@int16:
      r6_b36 = r6_b /\ r6_t36 = r6_t
   && r6_b36 = r6_b /\ r6_t36 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x401744; Value = 0x044e701f; PC = 0x400b14 *)
mov r10 L0x401744;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b36 *    56) [Q] /\
       eqmod lr_t (r6_t36 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b36 *    56) [Q] /\
       eqmod lr_t (r6_t36 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b57@int16, r7_t57@int16:
      r7_b57 = r7_b /\ r7_t57 = r7_t
   && r7_b57 = r7_b /\ r7_t57 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b57 *    56) [Q] /\
       eqmod lr_t (r7_t57 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b57 *    56) [Q] /\
       eqmod lr_t (r7_t57 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b57@int16, r8_t57@int16:
      r8_b57 = r8_b /\ r8_t57 = r8_t
   && r8_b57 = r8_b /\ r8_t57 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b57 *    56) [Q] /\
       eqmod lr_t (r8_t57 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b57 *    56) [Q] /\
       eqmod lr_t (r8_t57 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b78@int16, r9_t78@int16:
      r9_b78 = r9_b /\ r9_t78 = r9_t
   && r9_b78 = r9_b /\ r9_t78 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b78 *    56) [Q] /\
       eqmod lr_t (r9_t78 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b78 *    56) [Q] /\
       eqmod lr_t (r9_t78 *    56) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b36@int16, r4_t36@int16:
      r4_b36 = r4_b /\ r4_t36 = r4_t
   && r4_b36 = r4_b /\ r4_t36 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401748; Value = 0xc13fe765; PC = 0x400b88 *)
mov [r10, r11] [L0x401748, L0x40174c];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b36 *  -816) [Q] /\
       eqmod lr_t (r4_t36 *  -816) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b36 *  -816) [Q] /\
       eqmod lr_t (r4_t36 *  -816) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b57@int16, r5_t57@int16:
      r5_b57 = r5_b /\ r5_t57 = r5_t
   && r5_b57 = r5_b /\ r5_t57 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b57 *  -816) [Q] /\
       eqmod lr_t (r5_t57 *  -816) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b57 *  -816) [Q] /\
       eqmod lr_t (r5_t57 *  -816) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b58@int16, r8_t58@int16:
      r8_b58 = r8_b /\ r8_t58 = r8_t
   && r8_b58 = r8_b /\ r8_t58 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b58 *   632) [Q] /\
       eqmod lr_t (r8_t58 *   632) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b58 *   632) [Q] /\
       eqmod lr_t (r8_t58 *   632) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b79@int16, r9_t79@int16:
      r9_b79 = r9_b /\ r9_t79 = r9_t
   && r9_b79 = r9_b /\ r9_t79 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b79 *   632) [Q] /\
       eqmod lr_t (r9_t79 *   632) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b79 *   632) [Q] /\
       eqmod lr_t (r9_t79 *   632) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b36@int16, r3_t36@int16:
      r3_b36 = r3_b /\ r3_t36 = r3_t
   && r3_b36 = r3_b /\ r3_t36 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401750; Value = 0x8e08c440; PC = 0x400bfc *)
mov [r10, r11] [L0x401750, L0x401754];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b36 * -1482) [Q] /\
       eqmod lr_t (r3_t36 * -1482) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b36 * -1482) [Q] /\
       eqmod lr_t (r3_t36 * -1482) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b58@int16, r5_t58@int16:
      r5_b58 = r5_b /\ r5_t58 = r5_t
   && r5_b58 = r5_b /\ r5_t58 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b58 *   952) [Q] /\
       eqmod lr_t (r5_t58 *   952) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b58 *   952) [Q] /\
       eqmod lr_t (r5_t58 *   952) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b58@int16, r7_t58@int16:
      r7_b58 = r7_b /\ r7_t58 = r7_t
   && r7_b58 = r7_b /\ r7_t58 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401758; Value = 0x7059d1b5; PC = 0x400c38 *)
mov [r10, r11] [L0x401758, L0x40175c];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b58 *  1461) [Q] /\
       eqmod lr_t (r7_t58 *  1461) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b58 *  1461) [Q] /\
       eqmod lr_t (r7_t58 *  1461) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b80@int16, r9_t80@int16:
      r9_b80 = r9_b /\ r9_t80 = r9_t
   && r9_b80 = r9_b /\ r9_t80 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b80 *  -642) [Q] /\
       eqmod lr_t (r9_t80 *  -642) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b80 *  -642) [Q] /\
       eqmod lr_t (r9_t80 *  -642) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff274; PC = 0x400c78 *)
mov [L0xbefff274, L0xbefff276] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff278; PC = 0x400c7c *)
mov [L0xbefff278, L0xbefff27a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff27c; PC = 0x400c80 *)
mov [L0xbefff27c, L0xbefff27e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff280; PC = 0x400c84 *)
mov [L0xbefff280, L0xbefff282] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff268; PC = 0x400c88 *)
mov [L0xbefff268, L0xbefff26a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff26c; PC = 0x400c8c *)
mov [L0xbefff26c, L0xbefff26e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff270; PC = 0x400c90 *)
mov [L0xbefff270, L0xbefff272] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff264; PC = 0x400c94 *)
mov [L0xbefff264, L0xbefff266] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff264,L0xbefff266] /\
                     [L0xbefff264,L0xbefff266]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff268,L0xbefff26a] /\
                     [L0xbefff268,L0xbefff26a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff26c,L0xbefff26e] /\
                     [L0xbefff26c,L0xbefff26e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff270,L0xbefff272] /\
                     [L0xbefff270,L0xbefff272]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff274,L0xbefff276] /\
                     [L0xbefff274,L0xbefff276]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff278,L0xbefff27a] /\
                     [L0xbefff278,L0xbefff27a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff27c,L0xbefff27e] /\
                     [L0xbefff27c,L0xbefff27e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff280,L0xbefff282] /\
                     [L0xbefff280,L0xbefff282]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff264,L0xbefff266] /\
                     [L0xbefff264,L0xbefff266]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff268,L0xbefff26a] /\
                     [L0xbefff268,L0xbefff26a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff26c,L0xbefff26e] /\
                     [L0xbefff26c,L0xbefff26e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff270,L0xbefff272] /\
                     [L0xbefff270,L0xbefff272]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff274,L0xbefff276] /\
                     [L0xbefff274,L0xbefff276]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff278,L0xbefff27a] /\
                     [L0xbefff278,L0xbefff27a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff27c,L0xbefff27e] /\
                     [L0xbefff27c,L0xbefff27e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff280,L0xbefff282] /\
                     [L0xbefff280,L0xbefff282]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff264,L0xbefff266] /\
                           [L0xbefff264,L0xbefff266]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff268,L0xbefff26a] /\
                           [L0xbefff268,L0xbefff26a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff26c,L0xbefff26e] /\
                           [L0xbefff26c,L0xbefff26e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff270,L0xbefff272] /\
                           [L0xbefff270,L0xbefff272]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff274,L0xbefff276] /\
                           [L0xbefff274,L0xbefff276]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff278,L0xbefff27a] /\
                           [L0xbefff278,L0xbefff27a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff27c,L0xbefff27e] /\
                           [L0xbefff27c,L0xbefff27e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff280,L0xbefff282] /\
                           [L0xbefff280,L0xbefff282]<s[8@16*Q2,8@16*Q2];


(* CUT 30 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff264+L0xbefff266*X) [Q,X**2 - 17** 21] /\
    eqmod (F**2) (L0xbefff268+L0xbefff26a*X) [Q,X**2 - 17**149] /\
    eqmod (F**2) (L0xbefff26c+L0xbefff26e*X) [Q,X**2 - 17** 85] /\
    eqmod (F**2) (L0xbefff270+L0xbefff272*X) [Q,X**2 - 17**213] /\
    eqmod (F**2) (L0xbefff274+L0xbefff276*X) [Q,X**2 - 17** 53] /\
    eqmod (F**2) (L0xbefff278+L0xbefff27a*X) [Q,X**2 - 17**181] /\
    eqmod (F**2) (L0xbefff27c+L0xbefff27e*X) [Q,X**2 - 17**117] /\
    eqmod (F**2) (L0xbefff280+L0xbefff282*X) [Q,X**2 - 17**245] /\
    [8*NQ2,8*NQ2]<[L0xbefff264,L0xbefff266] /\
                  [L0xbefff264,L0xbefff266]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff268,L0xbefff26a] /\
                  [L0xbefff268,L0xbefff26a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff26c,L0xbefff26e] /\
                  [L0xbefff26c,L0xbefff26e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff270,L0xbefff272] /\
                  [L0xbefff270,L0xbefff272]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff274,L0xbefff276] /\
                  [L0xbefff274,L0xbefff276]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff278,L0xbefff27a] /\
                  [L0xbefff278,L0xbefff27a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff27c,L0xbefff27e] /\
                  [L0xbefff27c,L0xbefff27e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff280,L0xbefff282] /\
                  [L0xbefff280,L0xbefff282]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff264,L0xbefff266] /\
                         [L0xbefff264,L0xbefff266]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff268,L0xbefff26a] /\
                         [L0xbefff268,L0xbefff26a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff26c,L0xbefff26e] /\
                         [L0xbefff26c,L0xbefff26e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff270,L0xbefff272] /\
                         [L0xbefff270,L0xbefff272]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff274,L0xbefff276] /\
                         [L0xbefff274,L0xbefff276]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff278,L0xbefff27a] /\
                         [L0xbefff278,L0xbefff27a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff27c,L0xbefff27e] /\
                         [L0xbefff27c,L0xbefff27e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff280,L0xbefff282] /\
                         [L0xbefff280,L0xbefff282]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff284; Value = 0xb41a8c3a; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff284, L0xbefff286];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff288; Value = 0xb3cfbb8b; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff288, L0xbefff28a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff28c; Value = 0xfe02f281; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff28c, L0xbefff28e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff290; Value = 0xf536fcc2; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff290, L0xbefff292];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff294; Value = 0xc5ec106a; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff294, L0xbefff296];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff298; Value = 0xba61f035; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff298, L0xbefff29a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff29c; Value = 0x0294fae4; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff29c, L0xbefff29e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff2a0; Value = 0xbc91eb3b; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff2a0, L0xbefff2a2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b37@int16, r6_t37@int16:
      r6_b37 = r6_b /\ r6_t37 = r6_t
   && r6_b37 = r6_b /\ r6_t37 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x401760; Value = 0xac4184cf; PC = 0x400b14 *)
mov r10 L0x401760;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b37 * -1089) [Q] /\
       eqmod lr_t (r6_t37 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b37 * -1089) [Q] /\
       eqmod lr_t (r6_t37 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b59@int16, r7_t59@int16:
      r7_b59 = r7_b /\ r7_t59 = r7_t
   && r7_b59 = r7_b /\ r7_t59 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b59 * -1089) [Q] /\
       eqmod lr_t (r7_t59 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b59 * -1089) [Q] /\
       eqmod lr_t (r7_t59 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b59@int16, r8_t59@int16:
      r8_b59 = r8_b /\ r8_t59 = r8_t
   && r8_b59 = r8_b /\ r8_t59 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b59 * -1089) [Q] /\
       eqmod lr_t (r8_t59 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b59 * -1089) [Q] /\
       eqmod lr_t (r8_t59 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b81@int16, r9_t81@int16:
      r9_b81 = r9_b /\ r9_t81 = r9_t
   && r9_b81 = r9_b /\ r9_t81 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b81 * -1089) [Q] /\
       eqmod lr_t (r9_t81 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b81 * -1089) [Q] /\
       eqmod lr_t (r9_t81 * -1089) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b37@int16, r4_t37@int16:
      r4_b37 = r4_b /\ r4_t37 = r4_t
   && r4_b37 = r4_b /\ r4_t37 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401764; Value = 0xdc518394; PC = 0x400b88 *)
mov [r10, r11] [L0x401764, L0x401768];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b37 *  -464) [Q] /\
       eqmod lr_t (r4_t37 *  -464) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b37 *  -464) [Q] /\
       eqmod lr_t (r4_t37 *  -464) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b59@int16, r5_t59@int16:
      r5_b59 = r5_b /\ r5_t59 = r5_t
   && r5_b59 = r5_b /\ r5_t59 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b59 *  -464) [Q] /\
       eqmod lr_t (r5_t59 *  -464) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b59 *  -464) [Q] /\
       eqmod lr_t (r5_t59 *  -464) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b60@int16, r8_t60@int16:
      r8_b60 = r8_b /\ r8_t60 = r8_t
   && r8_b60 = r8_b /\ r8_t60 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b60 *    33) [Q] /\
       eqmod lr_t (r8_t60 *    33) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b60 *    33) [Q] /\
       eqmod lr_t (r8_t60 *    33) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b82@int16, r9_t82@int16:
      r9_b82 = r9_b /\ r9_t82 = r9_t
   && r9_b82 = r9_b /\ r9_t82 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b82 *    33) [Q] /\
       eqmod lr_t (r9_t82 *    33) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b82 *    33) [Q] /\
       eqmod lr_t (r9_t82 *    33) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b37@int16, r3_t37@int16:
      r3_b37 = r3_b /\ r3_t37 = r3_t
   && r3_b37 = r3_b /\ r3_t37 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x40176c; Value = 0x483585bb; PC = 0x400bfc *)
mov [r10, r11] [L0x40176c, L0x401770];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b37 *   939) [Q] /\
       eqmod lr_t (r3_t37 *   939) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b37 *   939) [Q] /\
       eqmod lr_t (r3_t37 *   939) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b60@int16, r5_t60@int16:
      r5_b60 = r5_b /\ r5_t60 = r5_t
   && r5_b60 = r5_b /\ r5_t60 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b60 * -1021) [Q] /\
       eqmod lr_t (r5_t60 * -1021) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b60 * -1021) [Q] /\
       eqmod lr_t (r5_t60 * -1021) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b60@int16, r7_t60@int16:
      r7_b60 = r7_b /\ r7_t60 = r7_t
   && r7_b60 = r7_b /\ r7_t60 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401774; Value = 0xbb67bcf2; PC = 0x400c38 *)
mov [r10, r11] [L0x401774, L0x401778];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b60 *  -892) [Q] /\
       eqmod lr_t (r7_t60 *  -892) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b60 *  -892) [Q] /\
       eqmod lr_t (r7_t60 *  -892) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b83@int16, r9_t83@int16:
      r9_b83 = r9_b /\ r9_t83 = r9_t
   && r9_b83 = r9_b /\ r9_t83 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b83 *  -941) [Q] /\
       eqmod lr_t (r9_t83 *  -941) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b83 *  -941) [Q] /\
       eqmod lr_t (r9_t83 *  -941) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff294; PC = 0x400c78 *)
mov [L0xbefff294, L0xbefff296] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff298; PC = 0x400c7c *)
mov [L0xbefff298, L0xbefff29a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff29c; PC = 0x400c80 *)
mov [L0xbefff29c, L0xbefff29e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff2a0; PC = 0x400c84 *)
mov [L0xbefff2a0, L0xbefff2a2] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff288; PC = 0x400c88 *)
mov [L0xbefff288, L0xbefff28a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff28c; PC = 0x400c8c *)
mov [L0xbefff28c, L0xbefff28e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff290; PC = 0x400c90 *)
mov [L0xbefff290, L0xbefff292] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff284; PC = 0x400c94 *)
mov [L0xbefff284, L0xbefff286] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff284,L0xbefff286] /\
                     [L0xbefff284,L0xbefff286]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff288,L0xbefff28a] /\
                     [L0xbefff288,L0xbefff28a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff28c,L0xbefff28e] /\
                     [L0xbefff28c,L0xbefff28e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff290,L0xbefff292] /\
                     [L0xbefff290,L0xbefff292]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff294,L0xbefff296] /\
                     [L0xbefff294,L0xbefff296]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff298,L0xbefff29a] /\
                     [L0xbefff298,L0xbefff29a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff29c,L0xbefff29e] /\
                     [L0xbefff29c,L0xbefff29e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2a0,L0xbefff2a2] /\
                     [L0xbefff2a0,L0xbefff2a2]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff284,L0xbefff286] /\
                     [L0xbefff284,L0xbefff286]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff288,L0xbefff28a] /\
                     [L0xbefff288,L0xbefff28a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff28c,L0xbefff28e] /\
                     [L0xbefff28c,L0xbefff28e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff290,L0xbefff292] /\
                     [L0xbefff290,L0xbefff292]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff294,L0xbefff296] /\
                     [L0xbefff294,L0xbefff296]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff298,L0xbefff29a] /\
                     [L0xbefff298,L0xbefff29a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff29c,L0xbefff29e] /\
                     [L0xbefff29c,L0xbefff29e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2a0,L0xbefff2a2] /\
                     [L0xbefff2a0,L0xbefff2a2]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff284,L0xbefff286] /\
                           [L0xbefff284,L0xbefff286]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff288,L0xbefff28a] /\
                           [L0xbefff288,L0xbefff28a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff28c,L0xbefff28e] /\
                           [L0xbefff28c,L0xbefff28e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff290,L0xbefff292] /\
                           [L0xbefff290,L0xbefff292]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff294,L0xbefff296] /\
                           [L0xbefff294,L0xbefff296]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff298,L0xbefff29a] /\
                           [L0xbefff298,L0xbefff29a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff29c,L0xbefff29e] /\
                           [L0xbefff29c,L0xbefff29e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a0,L0xbefff2a2] /\
                           [L0xbefff2a0,L0xbefff2a2]<s[8@16*Q2,8@16*Q2];


(* CUT 31 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff284+L0xbefff286*X) [Q,X**2 - 17** 13] /\
    eqmod (F**2) (L0xbefff288+L0xbefff28a*X) [Q,X**2 - 17**141] /\
    eqmod (F**2) (L0xbefff28c+L0xbefff28e*X) [Q,X**2 - 17** 77] /\
    eqmod (F**2) (L0xbefff290+L0xbefff292*X) [Q,X**2 - 17**205] /\
    eqmod (F**2) (L0xbefff294+L0xbefff296*X) [Q,X**2 - 17** 45] /\
    eqmod (F**2) (L0xbefff298+L0xbefff29a*X) [Q,X**2 - 17**173] /\
    eqmod (F**2) (L0xbefff29c+L0xbefff29e*X) [Q,X**2 - 17**109] /\
    eqmod (F**2) (L0xbefff2a0+L0xbefff2a2*X) [Q,X**2 - 17**237] /\
    [8*NQ2,8*NQ2]<[L0xbefff284,L0xbefff286] /\
                  [L0xbefff284,L0xbefff286]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff288,L0xbefff28a] /\
                  [L0xbefff288,L0xbefff28a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff28c,L0xbefff28e] /\
                  [L0xbefff28c,L0xbefff28e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff290,L0xbefff292] /\
                  [L0xbefff290,L0xbefff292]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff294,L0xbefff296] /\
                  [L0xbefff294,L0xbefff296]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff298,L0xbefff29a] /\
                  [L0xbefff298,L0xbefff29a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff29c,L0xbefff29e] /\
                  [L0xbefff29c,L0xbefff29e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2a0,L0xbefff2a2] /\
                  [L0xbefff2a0,L0xbefff2a2]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff284,L0xbefff286] /\
                         [L0xbefff284,L0xbefff286]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff288,L0xbefff28a] /\
                         [L0xbefff288,L0xbefff28a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff28c,L0xbefff28e] /\
                         [L0xbefff28c,L0xbefff28e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff290,L0xbefff292] /\
                         [L0xbefff290,L0xbefff292]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff294,L0xbefff296] /\
                         [L0xbefff294,L0xbefff296]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff298,L0xbefff29a] /\
                         [L0xbefff298,L0xbefff29a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff29c,L0xbefff29e] /\
                         [L0xbefff29c,L0xbefff29e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a0,L0xbefff2a2] /\
                         [L0xbefff2a0,L0xbefff2a2]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff2a4; Value = 0xbee09312; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff2a4, L0xbefff2a6];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff2a8; Value = 0xb579b159; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff2a8, L0xbefff2aa];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff2ac; Value = 0xf94afc9d; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff2ac, L0xbefff2ae];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff2b0; Value = 0xfe70f686; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff2b0, L0xbefff2b2];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff2b4; Value = 0xbfc60896; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff2b4, L0xbefff2b6];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff2b8; Value = 0xbc0ff143; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff2b8, L0xbefff2ba];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff2bc; Value = 0x030a07a0; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff2bc, L0xbefff2be];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff2c0; Value = 0xbb73ed07; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff2c0, L0xbefff2c2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b38@int16, r6_t38@int16:
      r6_b38 = r6_b /\ r6_t38 = r6_t
   && r6_b38 = r6_b /\ r6_t38 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x40177c; Value = 0x6681f601; PC = 0x400b14 *)
mov r10 L0x40177c;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b38 *  1333) [Q] /\
       eqmod lr_t (r6_t38 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b38 *  1333) [Q] /\
       eqmod lr_t (r6_t38 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b61@int16, r7_t61@int16:
      r7_b61 = r7_b /\ r7_t61 = r7_t
   && r7_b61 = r7_b /\ r7_t61 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b61 *  1333) [Q] /\
       eqmod lr_t (r7_t61 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b61 *  1333) [Q] /\
       eqmod lr_t (r7_t61 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b61@int16, r8_t61@int16:
      r8_b61 = r8_b /\ r8_t61 = r8_t
   && r8_b61 = r8_b /\ r8_t61 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b61 *  1333) [Q] /\
       eqmod lr_t (r8_t61 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b61 *  1333) [Q] /\
       eqmod lr_t (r8_t61 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b84@int16, r9_t84@int16:
      r9_b84 = r9_b /\ r9_t84 = r9_t
   && r9_b84 = r9_b /\ r9_t84 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b84 *  1333) [Q] /\
       eqmod lr_t (r9_t84 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b84 *  1333) [Q] /\
       eqmod lr_t (r9_t84 *  1333) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b38@int16, r4_t38@int16:
      r4_b38 = r4_b /\ r4_t38 = r4_t
   && r4_b38 = r4_b /\ r4_t38 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401780; Value = 0x658209b1; PC = 0x400b88 *)
mov [r10, r11] [L0x401780, L0x401784];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b38 *  1320) [Q] /\
       eqmod lr_t (r4_t38 *  1320) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b38 *  1320) [Q] /\
       eqmod lr_t (r4_t38 *  1320) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b61@int16, r5_t61@int16:
      r5_b61 = r5_b /\ r5_t61 = r5_t
   && r5_b61 = r5_b /\ r5_t61 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b61 *  1320) [Q] /\
       eqmod lr_t (r5_t61 *  1320) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b61 *  1320) [Q] /\
       eqmod lr_t (r5_t61 *  1320) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b62@int16, r8_t62@int16:
      r8_b62 = r8_b /\ r8_t62 = r8_t
   && r8_b62 = r8_b /\ r8_t62 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b62 * -1414) [Q] /\
       eqmod lr_t (r8_t62 * -1414) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b62 * -1414) [Q] /\
       eqmod lr_t (r8_t62 * -1414) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b85@int16, r9_t85@int16:
      r9_b85 = r9_b /\ r9_t85 = r9_t
   && r9_b85 = r9_b /\ r9_t85 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b85 * -1414) [Q] /\
       eqmod lr_t (r9_t85 * -1414) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b85 * -1414) [Q] /\
       eqmod lr_t (r9_t85 * -1414) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b38@int16, r3_t38@int16:
      r3_b38 = r3_b /\ r3_t38 = r3_t
   && r3_b38 = r3_b /\ r3_t38 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401788; Value = 0x385e2025; PC = 0x400bfc *)
mov [r10, r11] [L0x401788, L0x40178c];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b38 *   733) [Q] /\
       eqmod lr_t (r3_t38 *   733) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b38 *   733) [Q] /\
       eqmod lr_t (r3_t38 *   733) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b62@int16, r5_t62@int16:
      r5_b62 = r5_b /\ r5_t62 = r5_t
   && r5_b62 = r5_b /\ r5_t62 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b62 *  -992) [Q] /\
       eqmod lr_t (r5_t62 *  -992) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b62 *  -992) [Q] /\
       eqmod lr_t (r5_t62 *  -992) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b62@int16, r7_t62@int16:
      r7_b62 = r7_b /\ r7_t62 = r7_t
   && r7_b62 = r7_b /\ r7_t62 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401790; Value = 0x149bf401; PC = 0x400c38 *)
mov [r10, r11] [L0x401790, L0x401794];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b62 *   268) [Q] /\
       eqmod lr_t (r7_t62 *   268) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b62 *   268) [Q] /\
       eqmod lr_t (r7_t62 *   268) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b86@int16, r9_t86@int16:
      r9_b86 = r9_b /\ r9_t86 = r9_t
   && r9_b86 = r9_b /\ r9_t86 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b86 *   641) [Q] /\
       eqmod lr_t (r9_t86 *   641) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b86 *   641) [Q] /\
       eqmod lr_t (r9_t86 *   641) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff2b4; PC = 0x400c78 *)
mov [L0xbefff2b4, L0xbefff2b6] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff2b8; PC = 0x400c7c *)
mov [L0xbefff2b8, L0xbefff2ba] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff2bc; PC = 0x400c80 *)
mov [L0xbefff2bc, L0xbefff2be] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff2c0; PC = 0x400c84 *)
mov [L0xbefff2c0, L0xbefff2c2] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff2a8; PC = 0x400c88 *)
mov [L0xbefff2a8, L0xbefff2aa] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff2ac; PC = 0x400c8c *)
mov [L0xbefff2ac, L0xbefff2ae] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff2b0; PC = 0x400c90 *)
mov [L0xbefff2b0, L0xbefff2b2] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff2a4; PC = 0x400c94 *)
mov [L0xbefff2a4, L0xbefff2a6] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff2a4,L0xbefff2a6] /\
                     [L0xbefff2a4,L0xbefff2a6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2a8,L0xbefff2aa] /\
                     [L0xbefff2a8,L0xbefff2aa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2ac,L0xbefff2ae] /\
                     [L0xbefff2ac,L0xbefff2ae]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2b0,L0xbefff2b2] /\
                     [L0xbefff2b0,L0xbefff2b2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2b4,L0xbefff2b6] /\
                     [L0xbefff2b4,L0xbefff2b6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2b8,L0xbefff2ba] /\
                     [L0xbefff2b8,L0xbefff2ba]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2bc,L0xbefff2be] /\
                     [L0xbefff2bc,L0xbefff2be]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2c0,L0xbefff2c2] /\
                     [L0xbefff2c0,L0xbefff2c2]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff2a4,L0xbefff2a6] /\
                     [L0xbefff2a4,L0xbefff2a6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2a8,L0xbefff2aa] /\
                     [L0xbefff2a8,L0xbefff2aa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2ac,L0xbefff2ae] /\
                     [L0xbefff2ac,L0xbefff2ae]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2b0,L0xbefff2b2] /\
                     [L0xbefff2b0,L0xbefff2b2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2b4,L0xbefff2b6] /\
                     [L0xbefff2b4,L0xbefff2b6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2b8,L0xbefff2ba] /\
                     [L0xbefff2b8,L0xbefff2ba]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2bc,L0xbefff2be] /\
                     [L0xbefff2bc,L0xbefff2be]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2c0,L0xbefff2c2] /\
                     [L0xbefff2c0,L0xbefff2c2]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a4,L0xbefff2a6] /\
                           [L0xbefff2a4,L0xbefff2a6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a8,L0xbefff2aa] /\
                           [L0xbefff2a8,L0xbefff2aa]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2ac,L0xbefff2ae] /\
                           [L0xbefff2ac,L0xbefff2ae]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b0,L0xbefff2b2] /\
                           [L0xbefff2b0,L0xbefff2b2]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b4,L0xbefff2b6] /\
                           [L0xbefff2b4,L0xbefff2b6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b8,L0xbefff2ba] /\
                           [L0xbefff2b8,L0xbefff2ba]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2bc,L0xbefff2be] /\
                           [L0xbefff2bc,L0xbefff2be]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c0,L0xbefff2c2] /\
                           [L0xbefff2c0,L0xbefff2c2]<s[8@16*Q2,8@16*Q2];


(* CUT 32 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff2a4+L0xbefff2a6*X) [Q,X**2 - 17** 29] /\
    eqmod (F**2) (L0xbefff2a8+L0xbefff2aa*X) [Q,X**2 - 17**157] /\
    eqmod (F**2) (L0xbefff2ac+L0xbefff2ae*X) [Q,X**2 - 17** 93] /\
    eqmod (F**2) (L0xbefff2b0+L0xbefff2b2*X) [Q,X**2 - 17**221] /\
    eqmod (F**2) (L0xbefff2b4+L0xbefff2b6*X) [Q,X**2 - 17** 61] /\
    eqmod (F**2) (L0xbefff2b8+L0xbefff2ba*X) [Q,X**2 - 17**189] /\
    eqmod (F**2) (L0xbefff2bc+L0xbefff2be*X) [Q,X**2 - 17**125] /\
    eqmod (F**2) (L0xbefff2c0+L0xbefff2c2*X) [Q,X**2 - 17**253] /\
    [8*NQ2,8*NQ2]<[L0xbefff2a4,L0xbefff2a6] /\
                  [L0xbefff2a4,L0xbefff2a6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2a8,L0xbefff2aa] /\
                  [L0xbefff2a8,L0xbefff2aa]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2ac,L0xbefff2ae] /\
                  [L0xbefff2ac,L0xbefff2ae]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2b0,L0xbefff2b2] /\
                  [L0xbefff2b0,L0xbefff2b2]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2b4,L0xbefff2b6] /\
                  [L0xbefff2b4,L0xbefff2b6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2b8,L0xbefff2ba] /\
                  [L0xbefff2b8,L0xbefff2ba]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2bc,L0xbefff2be] /\
                  [L0xbefff2bc,L0xbefff2be]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2c0,L0xbefff2c2] /\
                  [L0xbefff2c0,L0xbefff2c2]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a4,L0xbefff2a6] /\
                         [L0xbefff2a4,L0xbefff2a6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a8,L0xbefff2aa] /\
                         [L0xbefff2a8,L0xbefff2aa]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2ac,L0xbefff2ae] /\
                         [L0xbefff2ac,L0xbefff2ae]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b0,L0xbefff2b2] /\
                         [L0xbefff2b0,L0xbefff2b2]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b4,L0xbefff2b6] /\
                         [L0xbefff2b4,L0xbefff2b6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b8,L0xbefff2ba] /\
                         [L0xbefff2b8,L0xbefff2ba]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2bc,L0xbefff2be] /\
                         [L0xbefff2bc,L0xbefff2be]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c0,L0xbefff2c2] /\
                         [L0xbefff2c0,L0xbefff2c2]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff2c4; Value = 0xb72ba011; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff2c4, L0xbefff2c6];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff2c8; Value = 0xb921b3bb; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff2c8, L0xbefff2ca];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff2cc; Value = 0xfd92f7ff; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff2cc, L0xbefff2ce];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff2d0; Value = 0xf861fd66; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff2d0, L0xbefff2d2];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff2d4; Value = 0xadfbfb74; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff2d4, L0xbefff2d6];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff2d8; Value = 0xa80ae720; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff2d8, L0xbefff2da];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff2dc; Value = 0x01ae074d; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff2dc, L0xbefff2de];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff2e0; Value = 0xb0ff0270; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff2e0, L0xbefff2e2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b39@int16, r6_t39@int16:
      r6_b39 = r6_b /\ r6_t39 = r6_t
   && r6_b39 = r6_b /\ r6_t39 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x401798; Value = 0x6da8cba2; PC = 0x400b14 *)
mov r10 L0x401798;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b39 *  1426) [Q] /\
       eqmod lr_t (r6_t39 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b39 *  1426) [Q] /\
       eqmod lr_t (r6_t39 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b63@int16, r7_t63@int16:
      r7_b63 = r7_b /\ r7_t63 = r7_t
   && r7_b63 = r7_b /\ r7_t63 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b63 *  1426) [Q] /\
       eqmod lr_t (r7_t63 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b63 *  1426) [Q] /\
       eqmod lr_t (r7_t63 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b63@int16, r8_t63@int16:
      r8_b63 = r8_b /\ r8_t63 = r8_t
   && r8_b63 = r8_b /\ r8_t63 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b63 *  1426) [Q] /\
       eqmod lr_t (r8_t63 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b63 *  1426) [Q] /\
       eqmod lr_t (r8_t63 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b87@int16, r9_t87@int16:
      r9_b87 = r9_b /\ r9_t87 = r9_t
   && r9_b87 = r9_b /\ r9_t87 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b87 *  1426) [Q] /\
       eqmod lr_t (r9_t87 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b87 *  1426) [Q] /\
       eqmod lr_t (r9_t87 *  1426) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b39@int16, r4_t39@int16:
      r4_b39 = r4_b /\ r4_t39 = r4_t
   && r4_b39 = r4_b /\ r4_t39 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x40179c; Value = 0xb254be68; PC = 0x400b88 *)
mov [r10, r11] [L0x40179c, L0x4017a0];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b39 * -1010) [Q] /\
       eqmod lr_t (r4_t39 * -1010) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b39 * -1010) [Q] /\
       eqmod lr_t (r4_t39 * -1010) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b63@int16, r5_t63@int16:
      r5_b63 = r5_b /\ r5_t63 = r5_t
   && r5_b63 = r5_b /\ r5_t63 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b63 * -1010) [Q] /\
       eqmod lr_t (r5_t63 * -1010) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b63 * -1010) [Q] /\
       eqmod lr_t (r5_t63 * -1010) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b64@int16, r8_t64@int16:
      r8_b64 = r8_b /\ r8_t64 = r8_t
   && r8_b64 = r8_b /\ r8_t64 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b64 *  1435) [Q] /\
       eqmod lr_t (r8_t64 *  1435) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b64 *  1435) [Q] /\
       eqmod lr_t (r8_t64 *  1435) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b88@int16, r9_t88@int16:
      r9_b88 = r9_b /\ r9_t88 = r9_t
   && r9_b88 = r9_b /\ r9_t88 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b88 *  1435) [Q] /\
       eqmod lr_t (r9_t88 *  1435) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b88 *  1435) [Q] /\
       eqmod lr_t (r9_t88 *  1435) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];

ghost r3_b39@int16, r3_t39@int16:
      r3_b39 = r3_b /\ r3_t39 = r3_t
   && r3_b39 = r3_b /\ r3_t39 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017a4; Value = 0x79cf3ed4; PC = 0x400bfc *)
mov [r10, r11] [L0x4017a4, L0x4017a8];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b39 *  1584) [Q] /\
       eqmod lr_t (r3_t39 *  1584) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b39 *  1584) [Q] /\
       eqmod lr_t (r3_t39 *  1584) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b64@int16, r5_t64@int16:
      r5_b64 = r5_b /\ r5_t64 = r5_t
   && r5_b64 = r5_b /\ r5_t64 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b64 * -1031) [Q] /\
       eqmod lr_t (r5_t64 * -1031) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b64 * -1031) [Q] /\
       eqmod lr_t (r5_t64 * -1031) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r7_b64@int16, r7_t64@int16:
      r7_b64 = r7_b /\ r7_t64 = r7_t
   && r7_b64 = r7_b /\ r7_t64 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017ac; Value = 0x9ca52e5f; PC = 0x400c38 *)
mov [r10, r11] [L0x4017ac, L0x4017b0];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b64 * -1292) [Q] /\
       eqmod lr_t (r7_t64 * -1292) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b64 * -1292) [Q] /\
       eqmod lr_t (r7_t64 * -1292) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];

ghost r9_b89@int16, r9_t89@int16:
      r9_b89 = r9_b /\ r9_t89 = r9_t
   && r9_b89 = r9_b /\ r9_t89 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b89 *  -109) [Q] /\
       eqmod lr_t (r9_t89 *  -109) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b89 *  -109) [Q] /\
       eqmod lr_t (r9_t89 *  -109) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff2d4; PC = 0x400c78 *)
mov [L0xbefff2d4, L0xbefff2d6] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff2d8; PC = 0x400c7c *)
mov [L0xbefff2d8, L0xbefff2da] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff2dc; PC = 0x400c80 *)
mov [L0xbefff2dc, L0xbefff2de] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff2e0; PC = 0x400c84 *)
mov [L0xbefff2e0, L0xbefff2e2] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff2c8; PC = 0x400c88 *)
mov [L0xbefff2c8, L0xbefff2ca] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff2cc; PC = 0x400c8c *)
mov [L0xbefff2cc, L0xbefff2ce] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff2d0; PC = 0x400c90 *)
mov [L0xbefff2d0, L0xbefff2d2] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff2c4; PC = 0x400c94 *)
mov [L0xbefff2c4, L0xbefff2c6] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;

assert [8*NQ2,8*NQ2]<[L0xbefff2c4,L0xbefff2c6] /\
                     [L0xbefff2c4,L0xbefff2c6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2c8,L0xbefff2ca] /\
                     [L0xbefff2c8,L0xbefff2ca]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2cc,L0xbefff2ce] /\
                     [L0xbefff2cc,L0xbefff2ce]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2d0,L0xbefff2d2] /\
                     [L0xbefff2d0,L0xbefff2d2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2d4,L0xbefff2d6] /\
                     [L0xbefff2d4,L0xbefff2d6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2d8,L0xbefff2da] /\
                     [L0xbefff2d8,L0xbefff2da]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2dc,L0xbefff2de] /\
                     [L0xbefff2dc,L0xbefff2de]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2e0,L0xbefff2e2] /\
                     [L0xbefff2e0,L0xbefff2e2]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff2c4,L0xbefff2c6] /\
                     [L0xbefff2c4,L0xbefff2c6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2c8,L0xbefff2ca] /\
                     [L0xbefff2c8,L0xbefff2ca]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2cc,L0xbefff2ce] /\
                     [L0xbefff2cc,L0xbefff2ce]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2d0,L0xbefff2d2] /\
                     [L0xbefff2d0,L0xbefff2d2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2d4,L0xbefff2d6] /\
                     [L0xbefff2d4,L0xbefff2d6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2d8,L0xbefff2da] /\
                     [L0xbefff2d8,L0xbefff2da]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2dc,L0xbefff2de] /\
                     [L0xbefff2dc,L0xbefff2de]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2e0,L0xbefff2e2] /\
                     [L0xbefff2e0,L0xbefff2e2]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c4,L0xbefff2c6] /\
                           [L0xbefff2c4,L0xbefff2c6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c8,L0xbefff2ca] /\
                           [L0xbefff2c8,L0xbefff2ca]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2cc,L0xbefff2ce] /\
                           [L0xbefff2cc,L0xbefff2ce]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d0,L0xbefff2d2] /\
                           [L0xbefff2d0,L0xbefff2d2]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d4,L0xbefff2d6] /\
                           [L0xbefff2d4,L0xbefff2d6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d8,L0xbefff2da] /\
                           [L0xbefff2d8,L0xbefff2da]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2dc,L0xbefff2de] /\
                           [L0xbefff2dc,L0xbefff2de]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e0,L0xbefff2e2] /\
                           [L0xbefff2e0,L0xbefff2e2]<s[8@16*Q2,8@16*Q2];


(* CUT 33 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff2c4+L0xbefff2c6*X) [Q,X**2 - 17**  3] /\
    eqmod (F**2) (L0xbefff2c8+L0xbefff2ca*X) [Q,X**2 - 17**131] /\
    eqmod (F**2) (L0xbefff2cc+L0xbefff2ce*X) [Q,X**2 - 17** 67] /\
    eqmod (F**2) (L0xbefff2d0+L0xbefff2d2*X) [Q,X**2 - 17**195] /\
    eqmod (F**2) (L0xbefff2d4+L0xbefff2d6*X) [Q,X**2 - 17** 35] /\
    eqmod (F**2) (L0xbefff2d8+L0xbefff2da*X) [Q,X**2 - 17**163] /\
    eqmod (F**2) (L0xbefff2dc+L0xbefff2de*X) [Q,X**2 - 17** 99] /\
    eqmod (F**2) (L0xbefff2e0+L0xbefff2e2*X) [Q,X**2 - 17**227] /\
    [8*NQ2,8*NQ2]<[L0xbefff2c4,L0xbefff2c6] /\
                  [L0xbefff2c4,L0xbefff2c6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2c8,L0xbefff2ca] /\
                  [L0xbefff2c8,L0xbefff2ca]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2cc,L0xbefff2ce] /\
                  [L0xbefff2cc,L0xbefff2ce]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2d0,L0xbefff2d2] /\
                  [L0xbefff2d0,L0xbefff2d2]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2d4,L0xbefff2d6] /\
                  [L0xbefff2d4,L0xbefff2d6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2d8,L0xbefff2da] /\
                  [L0xbefff2d8,L0xbefff2da]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2dc,L0xbefff2de] /\
                  [L0xbefff2dc,L0xbefff2de]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2e0,L0xbefff2e2] /\
                  [L0xbefff2e0,L0xbefff2e2]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c4,L0xbefff2c6] /\
                         [L0xbefff2c4,L0xbefff2c6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c8,L0xbefff2ca] /\
                         [L0xbefff2c8,L0xbefff2ca]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2cc,L0xbefff2ce] /\
                         [L0xbefff2cc,L0xbefff2ce]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d0,L0xbefff2d2] /\
                         [L0xbefff2d0,L0xbefff2d2]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d4,L0xbefff2d6] /\
                         [L0xbefff2d4,L0xbefff2d6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d8,L0xbefff2da] /\
                         [L0xbefff2d8,L0xbefff2da]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2dc,L0xbefff2de] /\
                         [L0xbefff2dc,L0xbefff2de]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e0,L0xbefff2e2] /\
                         [L0xbefff2e0,L0xbefff2e2]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff2e4; Value = 0xb96d9485; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff2e4, L0xbefff2e6];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff2e8; Value = 0xbb3fb0cd; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff2e8, L0xbefff2ea];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff2ec; Value = 0xf79cfab7; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff2ec, L0xbefff2ee];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff2f0; Value = 0x047903c4; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff2f0, L0xbefff2f2];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff2f4; Value = 0xa96bf424; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff2f4, L0xbefff2f6];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff2f8; Value = 0xb26ee5a4; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff2f8, L0xbefff2fa];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff2fc; Value = 0xfa600483; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff2fc, L0xbefff2fe];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff300; Value = 0xb281f5f2; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff300, L0xbefff302];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;

ghost r6_b40@int16, r6_t40@int16:
      r6_b40 = r6_b /\ r6_t40 = r6_t
   && r6_b40 = r6_b /\ r6_t40 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x4017b4; Value = 0xa1074e36; PC = 0x400b14 *)
mov r10 L0x4017b4;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b40 * -1235) [Q] /\
       eqmod lr_t (r6_t40 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b40 * -1235) [Q] /\
       eqmod lr_t (r6_t40 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r7_b65@int16, r7_t65@int16:
      r7_b65 = r7_b /\ r7_t65 = r7_t
   && r7_b65 = r7_b /\ r7_t65 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b65 * -1235) [Q] /\
       eqmod lr_t (r7_t65 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b65 * -1235) [Q] /\
       eqmod lr_t (r7_t65 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];

ghost r8_b65@int16, r8_t65@int16:
      r8_b65 = r8_b /\ r8_t65 = r8_t
   && r8_b65 = r8_b /\ r8_t65 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b65 * -1235) [Q] /\
       eqmod lr_t (r8_t65 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b65 * -1235) [Q] /\
       eqmod lr_t (r8_t65 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];

ghost r9_b90@int16, r9_t90@int16:
      r9_b90 = r9_b /\ r9_t90 = r9_t
   && r9_b90 = r9_b /\ r9_t90 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b90 * -1235) [Q] /\
       eqmod lr_t (r9_t90 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b90 * -1235) [Q] /\
       eqmod lr_t (r9_t90 * -1235) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];

ghost r4_b40@int16, r4_t40@int16:
      r4_b40 = r4_b /\ r4_t40 = r4_t
   && r4_b40 = r4_b /\ r4_t40 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017b8; Value = 0x3e0eeb29; PC = 0x400b88 *)
mov [r10, r11] [L0x4017b8, L0x4017bc];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b40 *   807) [Q] /\
       eqmod lr_t (r4_t40 *   807) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b40 *   807) [Q] /\
       eqmod lr_t (r4_t40 *   807) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];

ghost r5_b65@int16, r5_t65@int16:
      r5_b65 = r5_b /\ r5_t65 = r5_t
   && r5_b65 = r5_b /\ r5_t65 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b65 *   807) [Q] /\
       eqmod lr_t (r5_t65 *   807) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b65 *   807) [Q] /\
       eqmod lr_t (r5_t65 *   807) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b66@int16, r8_t66@int16:
      r8_b66 = r8_b /\ r8_t66 = r8_t
   && r8_b66 = r8_b /\ r8_t66 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b66 *   452) [Q] /\
       eqmod lr_t (r8_t66 *   452) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b66 *   452) [Q] /\
       eqmod lr_t (r8_t66 *   452) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b91@int16, r9_t91@int16:
      r9_b91 = r9_b /\ r9_t91 = r9_t
   && r9_b91 = r9_b /\ r9_t91 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b91 *   452) [Q] /\
       eqmod lr_t (r9_t91 *   452) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b91 *   452) [Q] /\
       eqmod lr_t (r9_t91 *   452) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];


ghost r3_b40@int16, r3_t40@int16:
      r3_b40 = r3_b /\ r3_t40 = r3_t
   && r3_b40 = r3_b /\ r3_t40 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017c0; Value = 0x1cd665aa; PC = 0x400bfc *)
mov [r10, r11] [L0x4017c0, L0x4017c4];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b40 *   375) [Q] /\
       eqmod lr_t (r3_t40 *   375) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b40 *   375) [Q] /\
       eqmod lr_t (r3_t40 *   375) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b66@int16, r5_t66@int16:
      r5_b66 = r5_b /\ r5_t66 = r5_t
   && r5_b66 = r5_b /\ r5_t66 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b66 *  -780) [Q] /\
       eqmod lr_t (r5_t66 *  -780) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b66 *  -780) [Q] /\
       eqmod lr_t (r5_t66 *  -780) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b66@int16, r7_t66@int16:
      r7_b66 = r7_b /\ r7_t66 = r7_t
   && r7_b66 = r7_b /\ r7_t66 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017c8; Value = 0xa0b88f58; PC = 0x400c38 *)
mov [r10, r11] [L0x4017c8, L0x4017cc];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b66 * -1239) [Q] /\
       eqmod lr_t (r7_t66 * -1239) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b66 * -1239) [Q] /\
       eqmod lr_t (r7_t66 * -1239) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b92@int16, r9_t92@int16:
      r9_b92 = r9_b /\ r9_t92 = r9_t
   && r9_b92 = r9_b /\ r9_t92 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b92 *  1645) [Q] /\
       eqmod lr_t (r9_t92 *  1645) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b92 *  1645) [Q] /\
       eqmod lr_t (r9_t92 *  1645) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff2f4; PC = 0x400c78 *)
mov [L0xbefff2f4, L0xbefff2f6] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff2f8; PC = 0x400c7c *)
mov [L0xbefff2f8, L0xbefff2fa] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff2fc; PC = 0x400c80 *)
mov [L0xbefff2fc, L0xbefff2fe] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff300; PC = 0x400c84 *)
mov [L0xbefff300, L0xbefff302] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff2e8; PC = 0x400c88 *)
mov [L0xbefff2e8, L0xbefff2ea] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff2ec; PC = 0x400c8c *)
mov [L0xbefff2ec, L0xbefff2ee] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff2f0; PC = 0x400c90 *)
mov [L0xbefff2f0, L0xbefff2f2] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff2e4; PC = 0x400c94 *)
mov [L0xbefff2e4, L0xbefff2e6] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;


assert [8*NQ2,8*NQ2]<[L0xbefff2e4,L0xbefff2e6] /\
                     [L0xbefff2e4,L0xbefff2e6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2e8,L0xbefff2ea] /\
                     [L0xbefff2e8,L0xbefff2ea]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2ec,L0xbefff2ee] /\
                     [L0xbefff2ec,L0xbefff2ee]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2f0,L0xbefff2f2] /\
                     [L0xbefff2f0,L0xbefff2f2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2f4,L0xbefff2f6] /\
                     [L0xbefff2f4,L0xbefff2f6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2f8,L0xbefff2fa] /\
                     [L0xbefff2f8,L0xbefff2fa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2fc,L0xbefff2fe] /\
                     [L0xbefff2fc,L0xbefff2fe]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff300,L0xbefff302] /\
                     [L0xbefff300,L0xbefff302]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff2e4,L0xbefff2e6] /\
                     [L0xbefff2e4,L0xbefff2e6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2e8,L0xbefff2ea] /\
                     [L0xbefff2e8,L0xbefff2ea]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2ec,L0xbefff2ee] /\
                     [L0xbefff2ec,L0xbefff2ee]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2f0,L0xbefff2f2] /\
                     [L0xbefff2f0,L0xbefff2f2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2f4,L0xbefff2f6] /\
                     [L0xbefff2f4,L0xbefff2f6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2f8,L0xbefff2fa] /\
                     [L0xbefff2f8,L0xbefff2fa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff2fc,L0xbefff2fe] /\
                     [L0xbefff2fc,L0xbefff2fe]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff300,L0xbefff302] /\
                     [L0xbefff300,L0xbefff302]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e4,L0xbefff2e6] /\
                           [L0xbefff2e4,L0xbefff2e6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e8,L0xbefff2ea] /\
                           [L0xbefff2e8,L0xbefff2ea]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2ec,L0xbefff2ee] /\
                           [L0xbefff2ec,L0xbefff2ee]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f0,L0xbefff2f2] /\
                           [L0xbefff2f0,L0xbefff2f2]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f4,L0xbefff2f6] /\
                           [L0xbefff2f4,L0xbefff2f6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f8,L0xbefff2fa] /\
                           [L0xbefff2f8,L0xbefff2fa]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff2fc,L0xbefff2fe] /\
                           [L0xbefff2fc,L0xbefff2fe]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff300,L0xbefff302] /\
                           [L0xbefff300,L0xbefff302]<s[8@16*Q2,8@16*Q2];


(* CUT 34 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff2e4+L0xbefff2e6*X) [Q,X**2 - 17** 19] /\
    eqmod (F**2) (L0xbefff2e8+L0xbefff2ea*X) [Q,X**2 - 17**147] /\
    eqmod (F**2) (L0xbefff2ec+L0xbefff2ee*X) [Q,X**2 - 17** 83] /\
    eqmod (F**2) (L0xbefff2f0+L0xbefff2f2*X) [Q,X**2 - 17**211] /\
    eqmod (F**2) (L0xbefff2f4+L0xbefff2f6*X) [Q,X**2 - 17** 51] /\
    eqmod (F**2) (L0xbefff2f8+L0xbefff2fa*X) [Q,X**2 - 17**179] /\
    eqmod (F**2) (L0xbefff2fc+L0xbefff2fe*X) [Q,X**2 - 17**115] /\
    eqmod (F**2) (L0xbefff300+L0xbefff302*X) [Q,X**2 - 17**243] /\
    [8*NQ2,8*NQ2]<[L0xbefff2e4,L0xbefff2e6] /\
                  [L0xbefff2e4,L0xbefff2e6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2e8,L0xbefff2ea] /\
                  [L0xbefff2e8,L0xbefff2ea]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2ec,L0xbefff2ee] /\
                  [L0xbefff2ec,L0xbefff2ee]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2f0,L0xbefff2f2] /\
                  [L0xbefff2f0,L0xbefff2f2]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2f4,L0xbefff2f6] /\
                  [L0xbefff2f4,L0xbefff2f6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2f8,L0xbefff2fa] /\
                  [L0xbefff2f8,L0xbefff2fa]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff2fc,L0xbefff2fe] /\
                  [L0xbefff2fc,L0xbefff2fe]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff300,L0xbefff302] /\
                  [L0xbefff300,L0xbefff302]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e4,L0xbefff2e6] /\
                         [L0xbefff2e4,L0xbefff2e6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e8,L0xbefff2ea] /\
                         [L0xbefff2e8,L0xbefff2ea]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2ec,L0xbefff2ee] /\
                         [L0xbefff2ec,L0xbefff2ee]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f0,L0xbefff2f2] /\
                         [L0xbefff2f0,L0xbefff2f2]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f4,L0xbefff2f6] /\
                         [L0xbefff2f4,L0xbefff2f6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f8,L0xbefff2fa] /\
                         [L0xbefff2f8,L0xbefff2fa]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff2fc,L0xbefff2fe] /\
                         [L0xbefff2fc,L0xbefff2fe]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff300,L0xbefff302] /\
                         [L0xbefff300,L0xbefff302]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff304; Value = 0xb9a58ea4; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff304, L0xbefff306];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff308; Value = 0xae27a8d7; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff308, L0xbefff30a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff30c; Value = 0xf8c103cb; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff30c, L0xbefff30e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff310; Value = 0xf4810789; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff310, L0xbefff312];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff314; Value = 0xa642017b; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff314, L0xbefff316];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff318; Value = 0xbb72eca7; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff318, L0xbefff31a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff31c; Value = 0xf6940234; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff31c, L0xbefff31e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff320; Value = 0xab29f765; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff320, L0xbefff322];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;


ghost r6_b41@int16, r6_t41@int16:
      r6_b41 = r6_b /\ r6_t41 = r6_t
   && r6_b41 = r6_b /\ r6_t41 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x4017d0; Value = 0x2924384b; PC = 0x400b14 *)
mov r10 L0x4017d0;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b41 *   535) [Q] /\
       eqmod lr_t (r6_t41 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b41 *   535) [Q] /\
       eqmod lr_t (r6_t41 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r7_b67@int16, r7_t67@int16:
      r7_b67 = r7_b /\ r7_t67 = r7_t
   && r7_b67 = r7_b /\ r7_t67 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b67 *   535) [Q] /\
       eqmod lr_t (r7_t67 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b67 *   535) [Q] /\
       eqmod lr_t (r7_t67 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b67@int16, r8_t67@int16:
      r8_b67 = r8_b /\ r8_t67 = r8_t
   && r8_b67 = r8_b /\ r8_t67 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b67 *   535) [Q] /\
       eqmod lr_t (r8_t67 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b67 *   535) [Q] /\
       eqmod lr_t (r8_t67 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r9_b93@int16, r9_t93@int16:
      r9_b93 = r9_b /\ r9_t93 = r9_t
   && r9_b93 = r9_b /\ r9_t93 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b93 *   535) [Q] /\
       eqmod lr_t (r9_t93 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b93 *   535) [Q] /\
       eqmod lr_t (r9_t93 *   535) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b41@int16, r4_t41@int16:
      r4_b41 = r4_b /\ r4_t41 = r4_t
   && r4_b41 = r4_b /\ r4_t41 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017d4; Value = 0x6e95083b; PC = 0x400b88 *)
mov [r10, r11] [L0x4017d4, L0x4017d8];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b41 *  1438) [Q] /\
       eqmod lr_t (r4_t41 *  1438) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b41 *  1438) [Q] /\
       eqmod lr_t (r4_t41 *  1438) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b67@int16, r5_t67@int16:
      r5_b67 = r5_b /\ r5_t67 = r5_t
   && r5_b67 = r5_b /\ r5_t67 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b67 *  1438) [Q] /\
       eqmod lr_t (r5_t67 *  1438) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b67 *  1438) [Q] /\
       eqmod lr_t (r5_t67 *  1438) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b68@int16, r8_t68@int16:
      r8_b68 = r8_b /\ r8_t68 = r8_t
   && r8_b68 = r8_b /\ r8_t68 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b68 *  -461) [Q] /\
       eqmod lr_t (r8_t68 *  -461) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b68 *  -461) [Q] /\
       eqmod lr_t (r8_t68 *  -461) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b94@int16, r9_t94@int16:
      r9_b94 = r9_b /\ r9_t94 = r9_t
   && r9_b94 = r9_b /\ r9_t94 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b94 *  -461) [Q] /\
       eqmod lr_t (r9_t94 *  -461) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b94 *  -461) [Q] /\
       eqmod lr_t (r9_t94 *  -461) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];


ghost r3_b41@int16, r3_t41@int16:
      r3_b41 = r3_b /\ r3_t41 = r3_t
   && r3_b41 = r3_b /\ r3_t41 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017dc; Value = 0x51bea292; PC = 0x400bfc *)
mov [r10, r11] [L0x4017dc, L0x4017e0];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b41 *  1063) [Q] /\
       eqmod lr_t (r3_t41 *  1063) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b41 *  1063) [Q] /\
       eqmod lr_t (r3_t41 *  1063) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b68@int16, r5_t68@int16:
      r5_b68 = r5_b /\ r5_t68 = r5_t
   && r5_b68 = r5_b /\ r5_t68 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b68 *   319) [Q] /\
       eqmod lr_t (r5_t68 *   319) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b68 *   319) [Q] /\
       eqmod lr_t (r5_t68 *   319) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b68@int16, r7_t68@int16:
      r7_b68 = r7_b /\ r7_t68 = r7_t
   && r7_b68 = r7_b /\ r7_t68 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017e4; Value = 0xd53e5dab; PC = 0x400c38 *)
mov [r10, r11] [L0x4017e4, L0x4017e8];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b68 *  -556) [Q] /\
       eqmod lr_t (r7_t68 *  -556) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b68 *  -556) [Q] /\
       eqmod lr_t (r7_t68 *  -556) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b95@int16, r9_t95@int16:
      r9_b95 = r9_b /\ r9_t95 = r9_t
   && r9_b95 = r9_b /\ r9_t95 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b95 *   757) [Q] /\
       eqmod lr_t (r9_t95 *   757) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b95 *   757) [Q] /\
       eqmod lr_t (r9_t95 *   757) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff314; PC = 0x400c78 *)
mov [L0xbefff314, L0xbefff316] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff318; PC = 0x400c7c *)
mov [L0xbefff318, L0xbefff31a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff31c; PC = 0x400c80 *)
mov [L0xbefff31c, L0xbefff31e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff320; PC = 0x400c84 *)
mov [L0xbefff320, L0xbefff322] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff308; PC = 0x400c88 *)
mov [L0xbefff308, L0xbefff30a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff30c; PC = 0x400c8c *)
mov [L0xbefff30c, L0xbefff30e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff310; PC = 0x400c90 *)
mov [L0xbefff310, L0xbefff312] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff304; PC = 0x400c94 *)
mov [L0xbefff304, L0xbefff306] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;


assert [8*NQ2,8*NQ2]<[L0xbefff304,L0xbefff306] /\
                     [L0xbefff304,L0xbefff306]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff308,L0xbefff30a] /\
                     [L0xbefff308,L0xbefff30a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff30c,L0xbefff30e] /\
                     [L0xbefff30c,L0xbefff30e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff310,L0xbefff312] /\
                     [L0xbefff310,L0xbefff312]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff314,L0xbefff316] /\
                     [L0xbefff314,L0xbefff316]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff318,L0xbefff31a] /\
                     [L0xbefff318,L0xbefff31a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff31c,L0xbefff31e] /\
                     [L0xbefff31c,L0xbefff31e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff320,L0xbefff322] /\
                     [L0xbefff320,L0xbefff322]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff304,L0xbefff306] /\
                     [L0xbefff304,L0xbefff306]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff308,L0xbefff30a] /\
                     [L0xbefff308,L0xbefff30a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff30c,L0xbefff30e] /\
                     [L0xbefff30c,L0xbefff30e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff310,L0xbefff312] /\
                     [L0xbefff310,L0xbefff312]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff314,L0xbefff316] /\
                     [L0xbefff314,L0xbefff316]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff318,L0xbefff31a] /\
                     [L0xbefff318,L0xbefff31a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff31c,L0xbefff31e] /\
                     [L0xbefff31c,L0xbefff31e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff320,L0xbefff322] /\
                     [L0xbefff320,L0xbefff322]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff304,L0xbefff306] /\
                           [L0xbefff304,L0xbefff306]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff308,L0xbefff30a] /\
                           [L0xbefff308,L0xbefff30a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff30c,L0xbefff30e] /\
                           [L0xbefff30c,L0xbefff30e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff310,L0xbefff312] /\
                           [L0xbefff310,L0xbefff312]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff314,L0xbefff316] /\
                           [L0xbefff314,L0xbefff316]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff318,L0xbefff31a] /\
                           [L0xbefff318,L0xbefff31a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff31c,L0xbefff31e] /\
                           [L0xbefff31c,L0xbefff31e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff320,L0xbefff322] /\
                           [L0xbefff320,L0xbefff322]<s[8@16*Q2,8@16*Q2];


(* CUT 35 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff304+L0xbefff306*X) [Q,X**2 - 17** 11] /\
    eqmod (F**2) (L0xbefff308+L0xbefff30a*X) [Q,X**2 - 17**139] /\
    eqmod (F**2) (L0xbefff30c+L0xbefff30e*X) [Q,X**2 - 17** 75] /\
    eqmod (F**2) (L0xbefff310+L0xbefff312*X) [Q,X**2 - 17**203] /\
    eqmod (F**2) (L0xbefff314+L0xbefff316*X) [Q,X**2 - 17** 43] /\
    eqmod (F**2) (L0xbefff318+L0xbefff31a*X) [Q,X**2 - 17**171] /\
    eqmod (F**2) (L0xbefff31c+L0xbefff31e*X) [Q,X**2 - 17**107] /\
    eqmod (F**2) (L0xbefff320+L0xbefff322*X) [Q,X**2 - 17**235] /\
    [8*NQ2,8*NQ2]<[L0xbefff304,L0xbefff306] /\
                  [L0xbefff304,L0xbefff306]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff308,L0xbefff30a] /\
                  [L0xbefff308,L0xbefff30a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff30c,L0xbefff30e] /\
                  [L0xbefff30c,L0xbefff30e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff310,L0xbefff312] /\
                  [L0xbefff310,L0xbefff312]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff314,L0xbefff316] /\
                  [L0xbefff314,L0xbefff316]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff318,L0xbefff31a] /\
                  [L0xbefff318,L0xbefff31a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff31c,L0xbefff31e] /\
                  [L0xbefff31c,L0xbefff31e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff320,L0xbefff322] /\
                  [L0xbefff320,L0xbefff322]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff304,L0xbefff306] /\
                         [L0xbefff304,L0xbefff306]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff308,L0xbefff30a] /\
                         [L0xbefff308,L0xbefff30a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff30c,L0xbefff30e] /\
                         [L0xbefff30c,L0xbefff30e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff310,L0xbefff312] /\
                         [L0xbefff310,L0xbefff312]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff314,L0xbefff316] /\
                         [L0xbefff314,L0xbefff316]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff318,L0xbefff31a] /\
                         [L0xbefff318,L0xbefff31a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff31c,L0xbefff31e] /\
                         [L0xbefff31c,L0xbefff31e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff320,L0xbefff322] /\
                         [L0xbefff320,L0xbefff322]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff324; Value = 0xb1738ce6; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff324, L0xbefff326];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff328; Value = 0xb975b2a1; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff328, L0xbefff32a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff32c; Value = 0xfc6d054b; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff32c, L0xbefff32e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff330; Value = 0xf9010b01; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff330, L0xbefff332];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff334; Value = 0xb2c4fe81; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff334, L0xbefff336];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff338; Value = 0xb16ae619; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff338, L0xbefff33a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff33c; Value = 0xf8b6fbf4; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff33c, L0xbefff33e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff340; Value = 0xa307eba9; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff340, L0xbefff342];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;


ghost r6_b42@int16, r6_t42@int16:
      r6_b42 = r6_b /\ r6_t42 = r6_t
   && r6_b42 = r6_b /\ r6_t42 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x4017ec; Value = 0xdda02ec2; PC = 0x400b14 *)
mov r10 L0x4017ec;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b42 *  -447) [Q] /\
       eqmod lr_t (r6_t42 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b42 *  -447) [Q] /\
       eqmod lr_t (r6_t42 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r7_b69@int16, r7_t69@int16:
      r7_b69 = r7_b /\ r7_t69 = r7_t
   && r7_b69 = r7_b /\ r7_t69 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b69 *  -447) [Q] /\
       eqmod lr_t (r7_t69 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b69 *  -447) [Q] /\
       eqmod lr_t (r7_t69 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b69@int16, r8_t69@int16:
      r8_b69 = r8_b /\ r8_t69 = r8_t
   && r8_b69 = r8_b /\ r8_t69 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b69 *  -447) [Q] /\
       eqmod lr_t (r8_t69 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b69 *  -447) [Q] /\
       eqmod lr_t (r8_t69 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r9_b96@int16, r9_t96@int16:
      r9_b96 = r9_b /\ r9_t96 = r9_t
   && r9_b96 = r9_b /\ r9_t96 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b96 *  -447) [Q] /\
       eqmod lr_t (r9_t96 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b96 *  -447) [Q] /\
       eqmod lr_t (r9_t96 *  -447) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b42@int16, r4_t42@int16:
      r4_b42 = r4_b /\ r4_t42 = r4_t
   && r4_b42 = r4_b /\ r4_t42 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017f0; Value = 0x75f6ed02; PC = 0x400b88 *)
mov [r10, r11] [L0x4017f0, L0x4017f4];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b42 *  1534) [Q] /\
       eqmod lr_t (r4_t42 *  1534) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b42 *  1534) [Q] /\
       eqmod lr_t (r4_t42 *  1534) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b69@int16, r5_t69@int16:
      r5_b69 = r5_b /\ r5_t69 = r5_t
   && r5_b69 = r5_b /\ r5_t69 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b69 *  1534) [Q] /\
       eqmod lr_t (r5_t69 *  1534) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b69 *  1534) [Q] /\
       eqmod lr_t (r5_t69 *  1534) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b70@int16, r8_t70@int16:
      r8_b70 = r8_b /\ r8_t70 = r8_t
   && r8_b70 = r8_b /\ r8_t70 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b70 *  -927) [Q] /\
       eqmod lr_t (r8_t70 *  -927) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b70 *  -927) [Q] /\
       eqmod lr_t (r8_t70 *  -927) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b97@int16, r9_t97@int16:
      r9_b97 = r9_b /\ r9_t97 = r9_t
   && r9_b97 = r9_b /\ r9_t97 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b97 *  -927) [Q] /\
       eqmod lr_t (r9_t97 *  -927) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b97 *  -927) [Q] /\
       eqmod lr_t (r9_t97 *  -927) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];


ghost r3_b42@int16, r3_t42@int16:
      r3_b42 = r3_b /\ r3_t42 = r3_t
   && r3_b42 = r3_b /\ r3_t42 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x4017f8; Value = 0xa169bccb; PC = 0x400bfc *)
mov [r10, r11] [L0x4017f8, L0x4017fc];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b42 * -1230) [Q] /\
       eqmod lr_t (r3_t42 * -1230) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b42 * -1230) [Q] /\
       eqmod lr_t (r3_t42 * -1230) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b70@int16, r5_t70@int16:
      r5_b70 = r5_b /\ r5_t70 = r5_t
   && r5_b70 = r5_b /\ r5_t70 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b70 *   561) [Q] /\
       eqmod lr_t (r5_t70 *   561) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b70 *   561) [Q] /\
       eqmod lr_t (r5_t70 *   561) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b70@int16, r7_t70@int16:
      r7_b70 = r7_b /\ r7_t70 = r7_t
   && r7_b70 = r7_b /\ r7_t70 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401800; Value = 0xbda2a4b9; PC = 0x400c38 *)
mov [r10, r11] [L0x401800, L0x401804];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b70 *  -863) [Q] /\
       eqmod lr_t (r7_t70 *  -863) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b70 *  -863) [Q] /\
       eqmod lr_t (r7_t70 *  -863) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b98@int16, r9_t98@int16:
      r9_b98 = r9_b /\ r9_t98 = r9_t
   && r9_b98 = r9_b /\ r9_t98 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b98 *  -735) [Q] /\
       eqmod lr_t (r9_t98 *  -735) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b98 *  -735) [Q] /\
       eqmod lr_t (r9_t98 *  -735) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff334; PC = 0x400c78 *)
mov [L0xbefff334, L0xbefff336] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff338; PC = 0x400c7c *)
mov [L0xbefff338, L0xbefff33a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff33c; PC = 0x400c80 *)
mov [L0xbefff33c, L0xbefff33e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff340; PC = 0x400c84 *)
mov [L0xbefff340, L0xbefff342] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff328; PC = 0x400c88 *)
mov [L0xbefff328, L0xbefff32a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff32c; PC = 0x400c8c *)
mov [L0xbefff32c, L0xbefff32e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff330; PC = 0x400c90 *)
mov [L0xbefff330, L0xbefff332] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff324; PC = 0x400c94 *)
mov [L0xbefff324, L0xbefff326] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;


assert [8*NQ2,8*NQ2]<[L0xbefff324,L0xbefff326] /\
                     [L0xbefff324,L0xbefff326]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff328,L0xbefff32a] /\
                     [L0xbefff328,L0xbefff32a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff32c,L0xbefff32e] /\
                     [L0xbefff32c,L0xbefff32e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff330,L0xbefff332] /\
                     [L0xbefff330,L0xbefff332]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff334,L0xbefff336] /\
                     [L0xbefff334,L0xbefff336]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff338,L0xbefff33a] /\
                     [L0xbefff338,L0xbefff33a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff33c,L0xbefff33e] /\
                     [L0xbefff33c,L0xbefff33e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff340,L0xbefff342] /\
                     [L0xbefff340,L0xbefff342]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff324,L0xbefff326] /\
                     [L0xbefff324,L0xbefff326]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff328,L0xbefff32a] /\
                     [L0xbefff328,L0xbefff32a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff32c,L0xbefff32e] /\
                     [L0xbefff32c,L0xbefff32e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff330,L0xbefff332] /\
                     [L0xbefff330,L0xbefff332]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff334,L0xbefff336] /\
                     [L0xbefff334,L0xbefff336]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff338,L0xbefff33a] /\
                     [L0xbefff338,L0xbefff33a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff33c,L0xbefff33e] /\
                     [L0xbefff33c,L0xbefff33e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff340,L0xbefff342] /\
                     [L0xbefff340,L0xbefff342]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff324,L0xbefff326] /\
                           [L0xbefff324,L0xbefff326]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff328,L0xbefff32a] /\
                           [L0xbefff328,L0xbefff32a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff32c,L0xbefff32e] /\
                           [L0xbefff32c,L0xbefff32e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff330,L0xbefff332] /\
                           [L0xbefff330,L0xbefff332]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff334,L0xbefff336] /\
                           [L0xbefff334,L0xbefff336]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff338,L0xbefff33a] /\
                           [L0xbefff338,L0xbefff33a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff33c,L0xbefff33e] /\
                           [L0xbefff33c,L0xbefff33e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff340,L0xbefff342] /\
                           [L0xbefff340,L0xbefff342]<s[8@16*Q2,8@16*Q2];


(* CUT 36 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff324+L0xbefff326*X) [Q,X**2 - 17** 27] /\
    eqmod (F**2) (L0xbefff328+L0xbefff32a*X) [Q,X**2 - 17**155] /\
    eqmod (F**2) (L0xbefff32c+L0xbefff32e*X) [Q,X**2 - 17** 91] /\
    eqmod (F**2) (L0xbefff330+L0xbefff332*X) [Q,X**2 - 17**219] /\
    eqmod (F**2) (L0xbefff334+L0xbefff336*X) [Q,X**2 - 17** 59] /\
    eqmod (F**2) (L0xbefff338+L0xbefff33a*X) [Q,X**2 - 17**187] /\
    eqmod (F**2) (L0xbefff33c+L0xbefff33e*X) [Q,X**2 - 17**123] /\
    eqmod (F**2) (L0xbefff340+L0xbefff342*X) [Q,X**2 - 17**251] /\
    [8*NQ2,8*NQ2]<[L0xbefff324,L0xbefff326] /\
                  [L0xbefff324,L0xbefff326]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff328,L0xbefff32a] /\
                  [L0xbefff328,L0xbefff32a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff32c,L0xbefff32e] /\
                  [L0xbefff32c,L0xbefff32e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff330,L0xbefff332] /\
                  [L0xbefff330,L0xbefff332]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff334,L0xbefff336] /\
                  [L0xbefff334,L0xbefff336]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff338,L0xbefff33a] /\
                  [L0xbefff338,L0xbefff33a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff33c,L0xbefff33e] /\
                  [L0xbefff33c,L0xbefff33e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff340,L0xbefff342] /\
                  [L0xbefff340,L0xbefff342]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff324,L0xbefff326] /\
                         [L0xbefff324,L0xbefff326]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff328,L0xbefff32a] /\
                         [L0xbefff328,L0xbefff32a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff32c,L0xbefff32e] /\
                         [L0xbefff32c,L0xbefff32e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff330,L0xbefff332] /\
                         [L0xbefff330,L0xbefff332]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff334,L0xbefff336] /\
                         [L0xbefff334,L0xbefff336]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff338,L0xbefff33a] /\
                         [L0xbefff338,L0xbefff33a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff33c,L0xbefff33e] /\
                         [L0xbefff33c,L0xbefff33e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff340,L0xbefff342] /\
                         [L0xbefff340,L0xbefff342]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff344; Value = 0xae6d8d80; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff344, L0xbefff346];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff348; Value = 0xbaa3b0cd; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff348, L0xbefff34a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff34c; Value = 0x09580338; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff34c, L0xbefff34e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff350; Value = 0x076dfd64; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff350, L0xbefff352];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff354; Value = 0xb52cfc4f; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff354, L0xbefff356];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff358; Value = 0xb015dcb0; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff358, L0xbefff35a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff35c; Value = 0xffa70786; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff35c, L0xbefff35e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff360; Value = 0xb78e023c; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff360, L0xbefff362];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;


ghost r6_b43@int16, r6_t43@int16:
      r6_b43 = r6_b /\ r6_t43 = r6_t
   && r6_b43 = r6_b /\ r6_t43 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x401808; Value = 0xb805896c; PC = 0x400b14 *)
mov r10 L0x401808;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b43 *  -936) [Q] /\
       eqmod lr_t (r6_t43 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b43 *  -936) [Q] /\
       eqmod lr_t (r6_t43 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r7_b71@int16, r7_t71@int16:
      r7_b71 = r7_b /\ r7_t71 = r7_t
   && r7_b71 = r7_b /\ r7_t71 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b71 *  -936) [Q] /\
       eqmod lr_t (r7_t71 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b71 *  -936) [Q] /\
       eqmod lr_t (r7_t71 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b71@int16, r8_t71@int16:
      r8_b71 = r8_b /\ r8_t71 = r8_t
   && r8_b71 = r8_b /\ r8_t71 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b71 *  -936) [Q] /\
       eqmod lr_t (r8_t71 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b71 *  -936) [Q] /\
       eqmod lr_t (r8_t71 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r9_b99@int16, r9_t99@int16:
      r9_b99 = r9_b /\ r9_t99 = r9_t
   && r9_b99 = r9_b /\ r9_t99 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b99 *  -936) [Q] /\
       eqmod lr_t (r9_t99 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b99 *  -936) [Q] /\
       eqmod lr_t (r9_t99 *  -936) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b43@int16, r4_t43@int16:
      r4_b43 = r4_b /\ r4_t43 = r4_t
   && r4_b43 = r4_b /\ r4_t43 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x40180c; Value = 0xcb8de165; PC = 0x400b88 *)
mov [r10, r11] [L0x40180c, L0x401810];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b43 *  -682) [Q] /\
       eqmod lr_t (r4_t43 *  -682) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b43 *  -682) [Q] /\
       eqmod lr_t (r4_t43 *  -682) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b71@int16, r5_t71@int16:
      r5_b71 = r5_b /\ r5_t71 = r5_t
   && r5_b71 = r5_b /\ r5_t71 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b71 *  -682) [Q] /\
       eqmod lr_t (r5_t71 *  -682) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b71 *  -682) [Q] /\
       eqmod lr_t (r5_t71 *  -682) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b72@int16, r8_t72@int16:
      r8_b72 = r8_b /\ r8_t72 = r8_t
   && r8_b72 = r8_b /\ r8_t72 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b72 *  -712) [Q] /\
       eqmod lr_t (r8_t72 *  -712) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b72 *  -712) [Q] /\
       eqmod lr_t (r8_t72 *  -712) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b100@int16, r9_t100@int16:
      r9_b100 = r9_b /\ r9_t100 = r9_t
   && r9_b100 = r9_b /\ r9_t100 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b100 *  -712) [Q] /\
       eqmod lr_t (r9_t100 *  -712) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b100 *  -712) [Q] /\
       eqmod lr_t (r9_t100 *  -712) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];


ghost r3_b43@int16, r3_t43@int16:
      r3_b43 = r3_b /\ r3_t43 = r3_t
   && r3_b43 = r3_b /\ r3_t43 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401814; Value = 0xd7a0a4e0; PC = 0x400bfc *)
mov [r10, r11] [L0x401814, L0x401818];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b43 *  -525) [Q] /\
       eqmod lr_t (r3_t43 *  -525) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b43 *  -525) [Q] /\
       eqmod lr_t (r3_t43 *  -525) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b72@int16, r5_t72@int16:
      r5_b72 = r5_b /\ r5_t72 = r5_t
   && r5_b72 = r5_b /\ r5_t72 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b72 *  1092) [Q] /\
       eqmod lr_t (r5_t72 *  1092) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b72 *  1092) [Q] /\
       eqmod lr_t (r5_t72 *  1092) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b72@int16, r7_t72@int16:
      r7_b72 = r7_b /\ r7_t72 = r7_t
   && r7_b72 = r7_b /\ r7_t72 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x40181c; Value = 0x1efd9db9; PC = 0x400c38 *)
mov [r10, r11] [L0x40181c, L0x401820];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b72 *   403) [Q] /\
       eqmod lr_t (r7_t72 *   403) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b72 *   403) [Q] /\
       eqmod lr_t (r7_t72 *   403) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b101@int16, r9_t101@int16:
      r9_b101 = r9_b /\ r9_t101 = r9_t
   && r9_b101 = r9_b /\ r9_t101 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b101 *  1026) [Q] /\
       eqmod lr_t (r9_t101 *  1026) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b101 *  1026) [Q] /\
       eqmod lr_t (r9_t101 *  1026) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff354; PC = 0x400c78 *)
mov [L0xbefff354, L0xbefff356] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff358; PC = 0x400c7c *)
mov [L0xbefff358, L0xbefff35a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff35c; PC = 0x400c80 *)
mov [L0xbefff35c, L0xbefff35e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff360; PC = 0x400c84 *)
mov [L0xbefff360, L0xbefff362] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff348; PC = 0x400c88 *)
mov [L0xbefff348, L0xbefff34a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff34c; PC = 0x400c8c *)
mov [L0xbefff34c, L0xbefff34e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff350; PC = 0x400c90 *)
mov [L0xbefff350, L0xbefff352] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff344; PC = 0x400c94 *)
mov [L0xbefff344, L0xbefff346] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;


assert [8*NQ2,8*NQ2]<[L0xbefff344,L0xbefff346] /\
                     [L0xbefff344,L0xbefff346]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff348,L0xbefff34a] /\
                     [L0xbefff348,L0xbefff34a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff34c,L0xbefff34e] /\
                     [L0xbefff34c,L0xbefff34e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff350,L0xbefff352] /\
                     [L0xbefff350,L0xbefff352]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff354,L0xbefff356] /\
                     [L0xbefff354,L0xbefff356]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff358,L0xbefff35a] /\
                     [L0xbefff358,L0xbefff35a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff35c,L0xbefff35e] /\
                     [L0xbefff35c,L0xbefff35e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff360,L0xbefff362] /\
                     [L0xbefff360,L0xbefff362]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff344,L0xbefff346] /\
                     [L0xbefff344,L0xbefff346]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff348,L0xbefff34a] /\
                     [L0xbefff348,L0xbefff34a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff34c,L0xbefff34e] /\
                     [L0xbefff34c,L0xbefff34e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff350,L0xbefff352] /\
                     [L0xbefff350,L0xbefff352]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff354,L0xbefff356] /\
                     [L0xbefff354,L0xbefff356]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff358,L0xbefff35a] /\
                     [L0xbefff358,L0xbefff35a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff35c,L0xbefff35e] /\
                     [L0xbefff35c,L0xbefff35e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff360,L0xbefff362] /\
                     [L0xbefff360,L0xbefff362]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff344,L0xbefff346] /\
                           [L0xbefff344,L0xbefff346]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff348,L0xbefff34a] /\
                           [L0xbefff348,L0xbefff34a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff34c,L0xbefff34e] /\
                           [L0xbefff34c,L0xbefff34e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff350,L0xbefff352] /\
                           [L0xbefff350,L0xbefff352]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff354,L0xbefff356] /\
                           [L0xbefff354,L0xbefff356]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff358,L0xbefff35a] /\
                           [L0xbefff358,L0xbefff35a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff35c,L0xbefff35e] /\
                           [L0xbefff35c,L0xbefff35e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff360,L0xbefff362] /\
                           [L0xbefff360,L0xbefff362]<s[8@16*Q2,8@16*Q2];


(* CUT 37 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff344+L0xbefff346*X) [Q,X**2 - 17**  7] /\
    eqmod (F**2) (L0xbefff348+L0xbefff34a*X) [Q,X**2 - 17**135] /\
    eqmod (F**2) (L0xbefff34c+L0xbefff34e*X) [Q,X**2 - 17** 71] /\
    eqmod (F**2) (L0xbefff350+L0xbefff352*X) [Q,X**2 - 17**199] /\
    eqmod (F**2) (L0xbefff354+L0xbefff356*X) [Q,X**2 - 17** 39] /\
    eqmod (F**2) (L0xbefff358+L0xbefff35a*X) [Q,X**2 - 17**167] /\
    eqmod (F**2) (L0xbefff35c+L0xbefff35e*X) [Q,X**2 - 17**103] /\
    eqmod (F**2) (L0xbefff360+L0xbefff362*X) [Q,X**2 - 17**231] /\
    [8*NQ2,8*NQ2]<[L0xbefff344,L0xbefff346] /\
                  [L0xbefff344,L0xbefff346]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff348,L0xbefff34a] /\
                  [L0xbefff348,L0xbefff34a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff34c,L0xbefff34e] /\
                  [L0xbefff34c,L0xbefff34e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff350,L0xbefff352] /\
                  [L0xbefff350,L0xbefff352]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff354,L0xbefff356] /\
                  [L0xbefff354,L0xbefff356]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff358,L0xbefff35a] /\
                  [L0xbefff358,L0xbefff35a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff35c,L0xbefff35e] /\
                  [L0xbefff35c,L0xbefff35e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff360,L0xbefff362] /\
                  [L0xbefff360,L0xbefff362]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff344,L0xbefff346] /\
                         [L0xbefff344,L0xbefff346]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff348,L0xbefff34a] /\
                         [L0xbefff348,L0xbefff34a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff34c,L0xbefff34e] /\
                         [L0xbefff34c,L0xbefff34e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff350,L0xbefff352] /\
                         [L0xbefff350,L0xbefff352]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff354,L0xbefff356] /\
                         [L0xbefff354,L0xbefff356]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff358,L0xbefff35a] /\
                         [L0xbefff358,L0xbefff35a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff35c,L0xbefff35e] /\
                         [L0xbefff35c,L0xbefff35e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff360,L0xbefff362] /\
                         [L0xbefff360,L0xbefff362]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff364; Value = 0xbabd8f14; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff364, L0xbefff366];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff368; Value = 0xbbedb561; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff368, L0xbefff36a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff36c; Value = 0x017a05b6; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff36c, L0xbefff36e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff370; Value = 0x02b5fc26; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff370, L0xbefff372];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff374; Value = 0xba52072f; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff374, L0xbefff376];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff378; Value = 0xb2a3e7e6; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff378, L0xbefff37a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff37c; Value = 0xfe97070a; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff37c, L0xbefff37e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff380; Value = 0xb178021a; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff380, L0xbefff382];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;


ghost r6_b44@int16, r6_t44@int16:
      r6_b44 = r6_b /\ r6_t44 = r6_t
   && r6_b44 = r6_b /\ r6_t44 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x401824; Value = 0xdd651f9c; PC = 0x400b14 *)
mov r10 L0x401824;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b44 *  -450) [Q] /\
       eqmod lr_t (r6_t44 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b44 *  -450) [Q] /\
       eqmod lr_t (r6_t44 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r7_b73@int16, r7_t73@int16:
      r7_b73 = r7_b /\ r7_t73 = r7_t
   && r7_b73 = r7_b /\ r7_t73 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b73 *  -450) [Q] /\
       eqmod lr_t (r7_t73 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b73 *  -450) [Q] /\
       eqmod lr_t (r7_t73 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b73@int16, r8_t73@int16:
      r8_b73 = r8_b /\ r8_t73 = r8_t
   && r8_b73 = r8_b /\ r8_t73 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b73 *  -450) [Q] /\
       eqmod lr_t (r8_t73 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b73 *  -450) [Q] /\
       eqmod lr_t (r8_t73 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r9_b102@int16, r9_t102@int16:
      r9_b102 = r9_b /\ r9_t102 = r9_t
   && r9_b102 = r9_b /\ r9_t102 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b102 *  -450) [Q] /\
       eqmod lr_t (r9_t102 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b102 *  -450) [Q] /\
       eqmod lr_t (r9_t102 *  -450) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b44@int16, r4_t44@int16:
      r4_b44 = r4_b /\ r4_t44 = r4_t
   && r4_b44 = r4_b /\ r4_t44 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401828; Value = 0x71e38c09; PC = 0x400b88 *)
mov [r10, r11] [L0x401828, L0x40182c];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b44 *  1481) [Q] /\
       eqmod lr_t (r4_t44 *  1481) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b44 *  1481) [Q] /\
       eqmod lr_t (r4_t44 *  1481) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b73@int16, r5_t73@int16:
      r5_b73 = r5_b /\ r5_t73 = r5_t
   && r5_b73 = r5_b /\ r5_t73 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b73 *  1481) [Q] /\
       eqmod lr_t (r5_t73 *  1481) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b73 *  1481) [Q] /\
       eqmod lr_t (r5_t73 *  1481) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b74@int16, r8_t74@int16:
      r8_b74 = r8_b /\ r8_t74 = r8_t
   && r8_b74 = r8_b /\ r8_t74 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b74 *   648) [Q] /\
       eqmod lr_t (r8_t74 *   648) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b74 *   648) [Q] /\
       eqmod lr_t (r8_t74 *   648) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b103@int16, r9_t103@int16:
      r9_b103 = r9_b /\ r9_t103 = r9_t
   && r9_b103 = r9_b /\ r9_t103 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b103 *   648) [Q] /\
       eqmod lr_t (r9_t103 *   648) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b103 *   648) [Q] /\
       eqmod lr_t (r9_t103 *   648) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];


ghost r3_b44@int16, r3_t44@int16:
      r3_b44 = r3_b /\ r3_t44 = r3_t
   && r3_b44 = r3_b /\ r3_t44 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401830; Value = 0x57e58be2; PC = 0x400bfc *)
mov [r10, r11] [L0x401830, L0x401834];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b44 *  1143) [Q] /\
       eqmod lr_t (r3_t44 *  1143) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b44 *  1143) [Q] /\
       eqmod lr_t (r3_t44 *  1143) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b74@int16, r5_t74@int16:
      r5_b74 = r5_b /\ r5_t74 = r5_t
   && r5_b74 = r5_b /\ r5_t74 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b74 * -1179) [Q] /\
       eqmod lr_t (r5_t74 * -1179) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b74 * -1179) [Q] /\
       eqmod lr_t (r5_t74 * -1179) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b74@int16, r7_t74@int16:
      r7_b74 = r7_b /\ r7_t74 = r7_t
   && r7_b74 = r7_b /\ r7_t74 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401838; Value = 0xd565bd19; PC = 0x400c38 *)
mov [r10, r11] [L0x401838, L0x40183c];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b74 *  -554) [Q] /\
       eqmod lr_t (r7_t74 *  -554) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b74 *  -554) [Q] /\
       eqmod lr_t (r7_t74 *  -554) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b104@int16, r9_t104@int16:
      r9_b104 = r9_b /\ r9_t104 = r9_t
   && r9_b104 = r9_b /\ r9_t104 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b104 *   886) [Q] /\
       eqmod lr_t (r9_t104 *   886) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b104 *   886) [Q] /\
       eqmod lr_t (r9_t104 *   886) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff374; PC = 0x400c78 *)
mov [L0xbefff374, L0xbefff376] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff378; PC = 0x400c7c *)
mov [L0xbefff378, L0xbefff37a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff37c; PC = 0x400c80 *)
mov [L0xbefff37c, L0xbefff37e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff380; PC = 0x400c84 *)
mov [L0xbefff380, L0xbefff382] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff368; PC = 0x400c88 *)
mov [L0xbefff368, L0xbefff36a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff36c; PC = 0x400c8c *)
mov [L0xbefff36c, L0xbefff36e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff370; PC = 0x400c90 *)
mov [L0xbefff370, L0xbefff372] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff364; PC = 0x400c94 *)
mov [L0xbefff364, L0xbefff366] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;


assert [8*NQ2,8*NQ2]<[L0xbefff364,L0xbefff366] /\
                     [L0xbefff364,L0xbefff366]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff368,L0xbefff36a] /\
                     [L0xbefff368,L0xbefff36a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff36c,L0xbefff36e] /\
                     [L0xbefff36c,L0xbefff36e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff370,L0xbefff372] /\
                     [L0xbefff370,L0xbefff372]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff374,L0xbefff376] /\
                     [L0xbefff374,L0xbefff376]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff378,L0xbefff37a] /\
                     [L0xbefff378,L0xbefff37a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff37c,L0xbefff37e] /\
                     [L0xbefff37c,L0xbefff37e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff380,L0xbefff382] /\
                     [L0xbefff380,L0xbefff382]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff364,L0xbefff366] /\
                     [L0xbefff364,L0xbefff366]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff368,L0xbefff36a] /\
                     [L0xbefff368,L0xbefff36a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff36c,L0xbefff36e] /\
                     [L0xbefff36c,L0xbefff36e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff370,L0xbefff372] /\
                     [L0xbefff370,L0xbefff372]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff374,L0xbefff376] /\
                     [L0xbefff374,L0xbefff376]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff378,L0xbefff37a] /\
                     [L0xbefff378,L0xbefff37a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff37c,L0xbefff37e] /\
                     [L0xbefff37c,L0xbefff37e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff380,L0xbefff382] /\
                     [L0xbefff380,L0xbefff382]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff364,L0xbefff366] /\
                           [L0xbefff364,L0xbefff366]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff368,L0xbefff36a] /\
                           [L0xbefff368,L0xbefff36a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff36c,L0xbefff36e] /\
                           [L0xbefff36c,L0xbefff36e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff370,L0xbefff372] /\
                           [L0xbefff370,L0xbefff372]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff374,L0xbefff376] /\
                           [L0xbefff374,L0xbefff376]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff378,L0xbefff37a] /\
                           [L0xbefff378,L0xbefff37a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff37c,L0xbefff37e] /\
                           [L0xbefff37c,L0xbefff37e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff380,L0xbefff382] /\
                           [L0xbefff380,L0xbefff382]<s[8@16*Q2,8@16*Q2];


(* CUT 38 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff364+L0xbefff366*X) [Q,X**2 - 17** 23] /\
    eqmod (F**2) (L0xbefff368+L0xbefff36a*X) [Q,X**2 - 17**151] /\
    eqmod (F**2) (L0xbefff36c+L0xbefff36e*X) [Q,X**2 - 17** 87] /\
    eqmod (F**2) (L0xbefff370+L0xbefff372*X) [Q,X**2 - 17**215] /\
    eqmod (F**2) (L0xbefff374+L0xbefff376*X) [Q,X**2 - 17** 55] /\
    eqmod (F**2) (L0xbefff378+L0xbefff37a*X) [Q,X**2 - 17**183] /\
    eqmod (F**2) (L0xbefff37c+L0xbefff37e*X) [Q,X**2 - 17**119] /\
    eqmod (F**2) (L0xbefff380+L0xbefff382*X) [Q,X**2 - 17**247] /\
    [8*NQ2,8*NQ2]<[L0xbefff364,L0xbefff366] /\
                  [L0xbefff364,L0xbefff366]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff368,L0xbefff36a] /\
                  [L0xbefff368,L0xbefff36a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff36c,L0xbefff36e] /\
                  [L0xbefff36c,L0xbefff36e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff370,L0xbefff372] /\
                  [L0xbefff370,L0xbefff372]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff374,L0xbefff376] /\
                  [L0xbefff374,L0xbefff376]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff378,L0xbefff37a] /\
                  [L0xbefff378,L0xbefff37a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff37c,L0xbefff37e] /\
                  [L0xbefff37c,L0xbefff37e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff380,L0xbefff382] /\
                  [L0xbefff380,L0xbefff382]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff364,L0xbefff366] /\
                         [L0xbefff364,L0xbefff366]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff368,L0xbefff36a] /\
                         [L0xbefff368,L0xbefff36a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff36c,L0xbefff36e] /\
                         [L0xbefff36c,L0xbefff36e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff370,L0xbefff372] /\
                         [L0xbefff370,L0xbefff372]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff374,L0xbefff376] /\
                         [L0xbefff374,L0xbefff376]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff378,L0xbefff37a] /\
                         [L0xbefff378,L0xbefff37a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff37c,L0xbefff37e] /\
                         [L0xbefff37c,L0xbefff37e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff380,L0xbefff382] /\
                         [L0xbefff380,L0xbefff382]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff384; Value = 0xb4529a2a; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff384, L0xbefff386];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff388; Value = 0xac6fa9d6; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff388, L0xbefff38a];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff38c; Value = 0x004bf90d; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff38c, L0xbefff38e];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff390; Value = 0x0c2bfacb; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff390, L0xbefff392];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff394; Value = 0xbd640654; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff394, L0xbefff396];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff398; Value = 0xb158ecb5; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff398, L0xbefff39a];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff39c; Value = 0xf0bef766; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff39c, L0xbefff39e];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff3a0; Value = 0xb395fe50; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff3a0, L0xbefff3a2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;


ghost r6_b45@int16, r6_t45@int16:
      r6_b45 = r6_b /\ r6_t45 = r6_t
   && r6_b45 = r6_b /\ r6_t45 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x401840; Value = 0x97ccf03d; PC = 0x400b14 *)
mov r10 L0x401840;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b45 * -1355) [Q] /\
       eqmod lr_t (r6_t45 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b45 * -1355) [Q] /\
       eqmod lr_t (r6_t45 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r7_b75@int16, r7_t75@int16:
      r7_b75 = r7_b /\ r7_t75 = r7_t
   && r7_b75 = r7_b /\ r7_t75 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b75 * -1355) [Q] /\
       eqmod lr_t (r7_t75 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b75 * -1355) [Q] /\
       eqmod lr_t (r7_t75 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b75@int16, r8_t75@int16:
      r8_b75 = r8_b /\ r8_t75 = r8_t
   && r8_b75 = r8_b /\ r8_t75 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b75 * -1355) [Q] /\
       eqmod lr_t (r8_t75 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b75 * -1355) [Q] /\
       eqmod lr_t (r8_t75 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r9_b105@int16, r9_t105@int16:
      r9_b105 = r9_b /\ r9_t105 = r9_t
   && r9_b105 = r9_b /\ r9_t105 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b105 * -1355) [Q] /\
       eqmod lr_t (r9_t105 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b105 * -1355) [Q] /\
       eqmod lr_t (r9_t105 * -1355) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b45@int16, r4_t45@int16:
      r4_b45 = r4_b /\ r4_t45 = r4_t
   && r4_b45 = r4_b /\ r4_t45 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401844; Value = 0xbe402274; PC = 0x400b88 *)
mov [r10, r11] [L0x401844, L0x401848];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b45 *  -855) [Q] /\
       eqmod lr_t (r4_t45 *  -855) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b45 *  -855) [Q] /\
       eqmod lr_t (r4_t45 *  -855) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b75@int16, r5_t75@int16:
      r5_b75 = r5_b /\ r5_t75 = r5_t
   && r5_b75 = r5_b /\ r5_t75 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b75 *  -855) [Q] /\
       eqmod lr_t (r5_t75 *  -855) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b75 *  -855) [Q] /\
       eqmod lr_t (r5_t75 *  -855) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b76@int16, r8_t76@int16:
      r8_b76 = r8_b /\ r8_t76 = r8_t
   && r8_b76 = r8_b /\ r8_t76 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b76 *  -219) [Q] /\
       eqmod lr_t (r8_t76 *  -219) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b76 *  -219) [Q] /\
       eqmod lr_t (r8_t76 *  -219) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b106@int16, r9_t106@int16:
      r9_b106 = r9_b /\ r9_t106 = r9_t
   && r9_b106 = r9_b /\ r9_t106 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b106 *  -219) [Q] /\
       eqmod lr_t (r9_t106 *  -219) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b106 *  -219) [Q] /\
       eqmod lr_t (r9_t106 *  -219) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];


ghost r3_b45@int16, r3_t45@int16:
      r3_b45 = r3_b /\ r3_t45 = r3_t
   && r3_b45 = r3_b /\ r3_t45 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x40184c; Value = 0x846bf7b2; PC = 0x400bfc *)
mov [r10, r11] [L0x40184c, L0x401850];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b45 * -1607) [Q] /\
       eqmod lr_t (r3_t45 * -1607) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b45 * -1607) [Q] /\
       eqmod lr_t (r3_t45 * -1607) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b76@int16, r5_t76@int16:
      r5_b76 = r5_b /\ r5_t76 = r5_t
   && r5_b76 = r5_b /\ r5_t76 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b76 *  1212) [Q] /\
       eqmod lr_t (r5_t76 *  1212) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b76 *  1212) [Q] /\
       eqmod lr_t (r5_t76 *  1212) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b76@int16, r7_t76@int16:
      r7_b76 = r7_b /\ r7_t76 = r7_t
   && r7_b76 = r7_b /\ r7_t76 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401854; Value = 0x901c4c98; PC = 0x400c38 *)
mov [r10, r11] [L0x401854, L0x401858];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b76 * -1455) [Q] /\
       eqmod lr_t (r7_t76 * -1455) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b76 * -1455) [Q] /\
       eqmod lr_t (r7_t76 * -1455) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b107@int16, r9_t107@int16:
      r9_b107 = r9_b /\ r9_t107 = r9_t
   && r9_b107 = r9_b /\ r9_t107 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b107 *  1029) [Q] /\
       eqmod lr_t (r9_t107 *  1029) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b107 *  1029) [Q] /\
       eqmod lr_t (r9_t107 *  1029) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff394; PC = 0x400c78 *)
mov [L0xbefff394, L0xbefff396] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff398; PC = 0x400c7c *)
mov [L0xbefff398, L0xbefff39a] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff39c; PC = 0x400c80 *)
mov [L0xbefff39c, L0xbefff39e] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff3a0; PC = 0x400c84 *)
mov [L0xbefff3a0, L0xbefff3a2] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff388; PC = 0x400c88 *)
mov [L0xbefff388, L0xbefff38a] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff38c; PC = 0x400c8c *)
mov [L0xbefff38c, L0xbefff38e] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff390; PC = 0x400c90 *)
mov [L0xbefff390, L0xbefff392] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff384; PC = 0x400c94 *)
mov [L0xbefff384, L0xbefff386] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;


assert [8*NQ2,8*NQ2]<[L0xbefff384,L0xbefff386] /\
                     [L0xbefff384,L0xbefff386]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff388,L0xbefff38a] /\
                     [L0xbefff388,L0xbefff38a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff38c,L0xbefff38e] /\
                     [L0xbefff38c,L0xbefff38e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff390,L0xbefff392] /\
                     [L0xbefff390,L0xbefff392]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff394,L0xbefff396] /\
                     [L0xbefff394,L0xbefff396]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff398,L0xbefff39a] /\
                     [L0xbefff398,L0xbefff39a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff39c,L0xbefff39e] /\
                     [L0xbefff39c,L0xbefff39e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3a0,L0xbefff3a2] /\
                     [L0xbefff3a0,L0xbefff3a2]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff384,L0xbefff386] /\
                     [L0xbefff384,L0xbefff386]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff388,L0xbefff38a] /\
                     [L0xbefff388,L0xbefff38a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff38c,L0xbefff38e] /\
                     [L0xbefff38c,L0xbefff38e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff390,L0xbefff392] /\
                     [L0xbefff390,L0xbefff392]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff394,L0xbefff396] /\
                     [L0xbefff394,L0xbefff396]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff398,L0xbefff39a] /\
                     [L0xbefff398,L0xbefff39a]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff39c,L0xbefff39e] /\
                     [L0xbefff39c,L0xbefff39e]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3a0,L0xbefff3a2] /\
                     [L0xbefff3a0,L0xbefff3a2]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff384,L0xbefff386] /\
                           [L0xbefff384,L0xbefff386]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff388,L0xbefff38a] /\
                           [L0xbefff388,L0xbefff38a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff38c,L0xbefff38e] /\
                           [L0xbefff38c,L0xbefff38e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff390,L0xbefff392] /\
                           [L0xbefff390,L0xbefff392]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff394,L0xbefff396] /\
                           [L0xbefff394,L0xbefff396]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff398,L0xbefff39a] /\
                           [L0xbefff398,L0xbefff39a]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff39c,L0xbefff39e] /\
                           [L0xbefff39c,L0xbefff39e]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a0,L0xbefff3a2] /\
                           [L0xbefff3a0,L0xbefff3a2]<s[8@16*Q2,8@16*Q2];


(* CUT 39 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff384+L0xbefff386*X) [Q,X**2 - 17** 15] /\
    eqmod (F**2) (L0xbefff388+L0xbefff38a*X) [Q,X**2 - 17**143] /\
    eqmod (F**2) (L0xbefff38c+L0xbefff38e*X) [Q,X**2 - 17** 79] /\
    eqmod (F**2) (L0xbefff390+L0xbefff392*X) [Q,X**2 - 17**207] /\
    eqmod (F**2) (L0xbefff394+L0xbefff396*X) [Q,X**2 - 17** 47] /\
    eqmod (F**2) (L0xbefff398+L0xbefff39a*X) [Q,X**2 - 17**175] /\
    eqmod (F**2) (L0xbefff39c+L0xbefff39e*X) [Q,X**2 - 17**111] /\
    eqmod (F**2) (L0xbefff3a0+L0xbefff3a2*X) [Q,X**2 - 17**239] /\
    [8*NQ2,8*NQ2]<[L0xbefff384,L0xbefff386] /\
                  [L0xbefff384,L0xbefff386]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff388,L0xbefff38a] /\
                  [L0xbefff388,L0xbefff38a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff38c,L0xbefff38e] /\
                  [L0xbefff38c,L0xbefff38e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff390,L0xbefff392] /\
                  [L0xbefff390,L0xbefff392]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff394,L0xbefff396] /\
                  [L0xbefff394,L0xbefff396]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff398,L0xbefff39a] /\
                  [L0xbefff398,L0xbefff39a]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff39c,L0xbefff39e] /\
                  [L0xbefff39c,L0xbefff39e]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3a0,L0xbefff3a2] /\
                  [L0xbefff3a0,L0xbefff3a2]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff384,L0xbefff386] /\
                         [L0xbefff384,L0xbefff386]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff388,L0xbefff38a] /\
                         [L0xbefff388,L0xbefff38a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff38c,L0xbefff38e] /\
                         [L0xbefff38c,L0xbefff38e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff390,L0xbefff392] /\
                         [L0xbefff390,L0xbefff392]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff394,L0xbefff396] /\
                         [L0xbefff394,L0xbefff396]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff398,L0xbefff39a] /\
                         [L0xbefff398,L0xbefff39a]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff39c,L0xbefff39e] /\
                         [L0xbefff39c,L0xbefff39e]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a0,L0xbefff3a2] /\
                         [L0xbefff3a0,L0xbefff3a2]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];

(* vmov	s23, r0                                    #! PC = 0x400aec *)
mov s23 r0;
(* ldr.w	r2, [r0]                                  #! EA = L0xbefff3a4; Value = 0xbe349962; PC = 0x400af0 *)
mov [r2_b, r2_t] [L0xbefff3a4, L0xbefff3a6];
(* ldr.w	r3, [r0, #4]                              #! EA = L0xbefff3a8; Value = 0xb8fdaffc; PC = 0x400af4 *)
mov [r3_b, r3_t] [L0xbefff3a8, L0xbefff3aa];
(* ldr.w	r4, [r0, #8]                              #! EA = L0xbefff3ac; Value = 0x0a8702a1; PC = 0x400af8 *)
mov [r4_b, r4_t] [L0xbefff3ac, L0xbefff3ae];
(* ldr.w	r5, [r0, #12]                             #! EA = L0xbefff3b0; Value = 0xff57f7f7; PC = 0x400afc *)
mov [r5_b, r5_t] [L0xbefff3b0, L0xbefff3b2];
(* ldr.w	r6, [r0, #16]                             #! EA = L0xbefff3b4; Value = 0xb152064a; PC = 0x400b00 *)
mov [r6_b, r6_t] [L0xbefff3b4, L0xbefff3b6];
(* ldr.w	r7, [r0, #20]                             #! EA = L0xbefff3b8; Value = 0xb344e629; PC = 0x400b04 *)
mov [r7_b, r7_t] [L0xbefff3b8, L0xbefff3ba];
(* ldr.w	r8, [r0, #24]                             #! EA = L0xbefff3bc; Value = 0xfc5c0402; PC = 0x400b08 *)
mov [r8_b, r8_t] [L0xbefff3bc, L0xbefff3be];
(* ldr.w	r9, [r0, #28]                             #! EA = L0xbefff3c0; Value = 0xc05dfdd2; PC = 0x400b0c *)
mov [r9_b, r9_t] [L0xbefff3c0, L0xbefff3c2];
(* movw	r0, #26632	; 0x6808                        #! PC = 0x400b10 *)
mov r0_b 26632@int16; mov r0_t 0@int16; mov r0 26632@int32;


ghost r6_b46@int16, r6_t46@int16:
      r6_b46 = r6_b /\ r6_t46 = r6_t
   && r6_b46 = r6_b /\ r6_t46 = r6_t;

(* ldr.w	r10, [r1], #4                             #! EA = L0x40185c; Value = 0x3f228731; PC = 0x400b14 *)
mov r10 L0x40185c;
(* smulwb	lr, r10, r6                              #! PC = 0x400b18 *)
vpc r6_bW@int32 r6_b; mulj tmp r10 r6_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r6, r10, r6                              #! PC = 0x400b1c *)
vpc r6_tW@int32 r6_t; mulj tmp r10 r6_tW; spl r6_w dc tmp 16;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b; vpc r6_t@int16 r6_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b20 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r6, r6, r12, r0                          #! PC = 0x400b24 *)
mulj prod r6_b r12_t; add r6_w prod r0;
spl r6_t r6_b r6_w 16; cast r6_b@int16 r6_b;
(* pkhtb	lr, r6, lr, asr #16                       #! PC = 0x400b28 *)
mov tmp_b lr_t; mov tmp_t r6_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r6_b46 *   821) [Q] /\
       eqmod lr_t (r6_t46 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r6_b46 *   821) [Q] /\
       eqmod lr_t (r6_t46 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r6, r2, lr                               #! PC = 0x400b2c *)
sub [r6_b, r6_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400b30 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r7_b77@int16, r7_t77@int16:
      r7_b77 = r7_b /\ r7_t77 = r7_t
   && r7_b77 = r7_b /\ r7_t77 = r7_t;

(* smulwb	lr, r10, r7                              #! PC = 0x400b34 *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400b38 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b3c *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400b40 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400b44 *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b77 *   821) [Q] /\
       eqmod lr_t (r7_t77 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b77 *   821) [Q] /\
       eqmod lr_t (r7_t77 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r3, lr                               #! PC = 0x400b48 *)
sub [r7_b, r7_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400b4c *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b77@int16, r8_t77@int16:
      r8_b77 = r8_b /\ r8_t77 = r8_t
   && r8_b77 = r8_b /\ r8_t77 = r8_t;

(* smulwb	lr, r10, r8                              #! PC = 0x400b50 *)
vpc r8_bW@int32 r8_b; mulj tmp r10 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r10, r8                              #! PC = 0x400b54 *)
vpc r8_tW@int32 r8_t; mulj tmp r10 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b58 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400b5c *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400b60 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b77 *   821) [Q] /\
       eqmod lr_t (r8_t77 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b77 *   821) [Q] /\
       eqmod lr_t (r8_t77 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r4, lr                               #! PC = 0x400b64 *)
sub [r8_b, r8_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400b68 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r9_b108@int16, r9_t108@int16:
      r9_b108 = r9_b /\ r9_t108 = r9_t
   && r9_b108 = r9_b /\ r9_t108 = r9_t;

(* smulwb	lr, r10, r9                              #! PC = 0x400b6c *)
vpc r9_bW@int32 r9_b; mulj tmp r10 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r10, r9                              #! PC = 0x400b70 *)
vpc r9_tW@int32 r9_t; mulj tmp r10 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b74 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400b78 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400b7c *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b108 *   821) [Q] /\
       eqmod lr_t (r9_t108 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b108 *   821) [Q] /\
       eqmod lr_t (r9_t108 *   821) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r5, lr                               #! PC = 0x400b80 *)
sub [r9_b, r9_t] [r5_b, r5_t] [lr_b, lr_t];
(* uadd16	r5, r5, lr                               #! PC = 0x400b84 *)
add [r5_b, r5_t] [r5_b, r5_t] [lr_b, lr_t];


ghost r4_b46@int16, r4_t46@int16:
      r4_b46 = r4_b /\ r4_t46 = r4_t
   && r4_b46 = r4_b /\ r4_t46 = r4_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401860; Value = 0x5e5b3410; PC = 0x400b88 *)
mov [r10, r11] [L0x401860, L0x401864];
(* smulwb	lr, r10, r4                              #! PC = 0x400b8c *)
vpc r4_bW@int32 r4_b; mulj tmp r10 r4_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r4, r10, r4                              #! PC = 0x400b90 *)
vpc r4_tW@int32 r4_t; mulj tmp r10 r4_tW; spl r4_w dc tmp 16;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b; vpc r4_t@int16 r4_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400b94 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r4, r4, r12, r0                          #! PC = 0x400b98 *)
mulj prod r4_b r12_t; add r4_w prod r0;
spl r4_t r4_b r4_w 16; cast r4_b@int16 r4_b;
(* pkhtb	lr, r4, lr, asr #16                       #! PC = 0x400b9c *)
mov tmp_b lr_t; mov tmp_t r4_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r4_b46 *  1227) [Q] /\
       eqmod lr_t (r4_t46 *  1227) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r4_b46 *  1227) [Q] /\
       eqmod lr_t (r4_t46 *  1227) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r4, r2, lr                               #! PC = 0x400ba0 *)
sub [r4_b, r4_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400ba4 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b77@int16, r5_t77@int16:
      r5_b77 = r5_b /\ r5_t77 = r5_t
   && r5_b77 = r5_b /\ r5_t77 = r5_t;

(* smulwb	lr, r10, r5                              #! PC = 0x400ba8 *)
vpc r5_bW@int32 r5_b; mulj tmp r10 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r10, r5                              #! PC = 0x400bac *)
vpc r5_tW@int32 r5_t; mulj tmp r10 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bb0 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400bb4 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400bb8 *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b77 *  1227) [Q] /\
       eqmod lr_t (r5_t77 *  1227) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b77 *  1227) [Q] /\
       eqmod lr_t (r5_t77 *  1227) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r3, lr                               #! PC = 0x400bbc *)
sub [r5_b, r5_t] [r3_b, r3_t] [lr_b, lr_t];
(* uadd16	r3, r3, lr                               #! PC = 0x400bc0 *)
add [r3_b, r3_t] [r3_b, r3_t] [lr_b, lr_t];


ghost r8_b78@int16, r8_t78@int16:
      r8_b78 = r8_b /\ r8_t78 = r8_t
   && r8_b78 = r8_b /\ r8_t78 = r8_t;

(* smulwb	lr, r11, r8                              #! PC = 0x400bc4 *)
vpc r8_bW@int32 r8_b; mulj tmp r11 r8_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r8, r11, r8                              #! PC = 0x400bc8 *)
vpc r8_tW@int32 r8_t; mulj tmp r11 r8_tW; spl r8_w dc tmp 16;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b; vpc r8_t@int16 r8_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400bcc *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r8, r8, r12, r0                          #! PC = 0x400bd0 *)
mulj prod r8_b r12_t; add r8_w prod r0;
spl r8_t r8_b r8_w 16; cast r8_b@int16 r8_b;
(* pkhtb	lr, r8, lr, asr #16                       #! PC = 0x400bd4 *)
mov tmp_b lr_t; mov tmp_t r8_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r8_b78 *   910) [Q] /\
       eqmod lr_t (r8_t78 *   910) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r8_b78 *   910) [Q] /\
       eqmod lr_t (r8_t78 *   910) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r8, r6, lr                               #! PC = 0x400bd8 *)
sub [r8_b, r8_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400bdc *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b109@int16, r9_t109@int16:
      r9_b109 = r9_b /\ r9_t109 = r9_t
   && r9_b109 = r9_b /\ r9_t109 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400be0 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400be4 *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400be8 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400bec *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400bf0 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b109 *   910) [Q] /\
       eqmod lr_t (r9_t109 *   910) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b109 *   910) [Q] /\
       eqmod lr_t (r9_t109 *   910) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r7, lr                               #! PC = 0x400bf4 *)
sub [r9_b, r9_t] [r7_b, r7_t] [lr_b, lr_t];
(* uadd16	r7, r7, lr                               #! PC = 0x400bf8 *)
add [r7_b, r7_t] [r7_b, r7_t] [lr_b, lr_t];


ghost r3_b46@int16, r3_t46@int16:
      r3_b46 = r3_b /\ r3_t46 = r3_t
   && r3_b46 = r3_b /\ r3_t46 = r3_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401868; Value = 0xa24249ac; PC = 0x400bfc *)
mov [r10, r11] [L0x401868, L0x40186c];
(* smulwb	lr, r10, r3                              #! PC = 0x400c00 *)
vpc r3_bW@int32 r3_b; mulj tmp r10 r3_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r3, r10, r3                              #! PC = 0x400c04 *)
vpc r3_tW@int32 r3_t; mulj tmp r10 r3_tW; spl r3_w dc tmp 16;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b; vpc r3_t@int16 r3_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c08 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r3, r3, r12, r0                          #! PC = 0x400c0c *)
mulj prod r3_b r12_t; add r3_w prod r0;
spl r3_t r3_b r3_w 16; cast r3_b@int16 r3_b;
(* pkhtb	lr, r3, lr, asr #16                       #! PC = 0x400c10 *)
mov tmp_b lr_t; mov tmp_t r3_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r3_b46 * -1219) [Q] /\
       eqmod lr_t (r3_t46 * -1219) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r3_b46 * -1219) [Q] /\
       eqmod lr_t (r3_t46 * -1219) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r3, r2, lr                               #! PC = 0x400c14 *)
sub [r3_b, r3_t] [r2_b, r2_t] [lr_b, lr_t];
(* uadd16	r2, r2, lr                               #! PC = 0x400c18 *)
add [r2_b, r2_t] [r2_b, r2_t] [lr_b, lr_t];


ghost r5_b78@int16, r5_t78@int16:
      r5_b78 = r5_b /\ r5_t78 = r5_t
   && r5_b78 = r5_b /\ r5_t78 = r5_t;

(* smulwb	lr, r11, r5                              #! PC = 0x400c1c *)
vpc r5_bW@int32 r5_b; mulj tmp r11 r5_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r5, r11, r5                              #! PC = 0x400c20 *)
vpc r5_tW@int32 r5_t; mulj tmp r11 r5_tW; spl r5_w dc tmp 16;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b; vpc r5_t@int16 r5_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c24 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r5, r5, r12, r0                          #! PC = 0x400c28 *)
mulj prod r5_b r12_t; add r5_w prod r0;
spl r5_t r5_b r5_w 16; cast r5_b@int16 r5_b;
(* pkhtb	lr, r5, lr, asr #16                       #! PC = 0x400c2c *)
mov tmp_b lr_t; mov tmp_t r5_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r5_b78 *  -394) [Q] /\
       eqmod lr_t (r5_t78 *  -394) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r5_b78 *  -394) [Q] /\
       eqmod lr_t (r5_t78 *  -394) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r5, r4, lr                               #! PC = 0x400c30 *)
sub [r5_b, r5_t] [r4_b, r4_t] [lr_b, lr_t];
(* uadd16	r4, r4, lr                               #! PC = 0x400c34 *)
add [r4_b, r4_t] [r4_b, r4_t] [lr_b, lr_t];


ghost r7_b78@int16, r7_t78@int16:
      r7_b78 = r7_b /\ r7_t78 = r7_t
   && r7_b78 = r7_b /\ r7_t78 = r7_t;

(* ldrd	r10, r11, [r1], #8                         #! EA = L0x401870; Value = 0x440e750b; PC = 0x400c38 *)
mov [r10, r11] [L0x401870, L0x401874];
(* smulwb	lr, r10, r7                              #! PC = 0x400c3c *)
vpc r7_bW@int32 r7_b; mulj tmp r10 r7_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r7, r10, r7                              #! PC = 0x400c40 *)
vpc r7_tW@int32 r7_t; mulj tmp r10 r7_tW; spl r7_w dc tmp 16;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b; vpc r7_t@int16 r7_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c44 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r7, r7, r12, r0                          #! PC = 0x400c48 *)
mulj prod r7_b r12_t; add r7_w prod r0;
spl r7_t r7_b r7_w 16; cast r7_b@int16 r7_b;
(* pkhtb	lr, r7, lr, asr #16                       #! PC = 0x400c4c *)
mov tmp_b lr_t; mov tmp_t r7_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r7_b78 *   885) [Q] /\
       eqmod lr_t (r7_t78 *   885) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r7_b78 *   885) [Q] /\
       eqmod lr_t (r7_t78 *   885) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r7, r6, lr                               #! PC = 0x400c50 *)
sub [r7_b, r7_t] [r6_b, r6_t] [lr_b, lr_t];
(* uadd16	r6, r6, lr                               #! PC = 0x400c54 *)
add [r6_b, r6_t] [r6_b, r6_t] [lr_b, lr_t];


ghost r9_b110@int16, r9_t110@int16:
      r9_b110 = r9_b /\ r9_t110 = r9_t
   && r9_b110 = r9_b /\ r9_t110 = r9_t;

(* smulwb	lr, r11, r9                              #! PC = 0x400c58 *)
vpc r9_bW@int32 r9_b; mulj tmp r11 r9_bW; spl lr_w dc tmp 16;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b; vpc lr_t@int16 lr_t;
(* smulwt	r9, r11, r9                              #! PC = 0x400c5c *)
vpc r9_tW@int32 r9_t; mulj tmp r11 r9_tW; spl r9_w dc tmp 16;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b; vpc r9_t@int16 r9_t;
(* smlabt	lr, lr, r12, r0                          #! PC = 0x400c60 *)
mulj prod lr_b r12_t; add lr_w prod r0;
spl lr_t lr_b lr_w 16; cast lr_b@int16 lr_b;
(* smlabt	r9, r9, r12, r0                          #! PC = 0x400c64 *)
mulj prod r9_b r12_t; add r9_w prod r0;
spl r9_t r9_b r9_w 16; cast r9_b@int16 r9_b;
(* pkhtb	lr, r9, lr, asr #16                       #! PC = 0x400c68 *)
mov tmp_b lr_t; mov tmp_t r9_t;
mov lr_b tmp_b; mov lr_t tmp_t;

assert eqmod lr_b (r9_b110 * -1175) [Q] /\
       eqmod lr_t (r9_t110 * -1175) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
       prove with [algebra solver isl] && true;
assume eqmod lr_b (r9_b110 * -1175) [Q] /\
       eqmod lr_t (r9_t110 * -1175) [Q] /\
       [NQ2, NQ2]<[lr_b, lr_t] /\ [lr_b, lr_t]<[Q2, Q2]
    && [NQ2, NQ2]<s[lr_b, lr_t] /\ [lr_b, lr_t]<s[Q2, Q2];

(* usub16	r9, r8, lr                               #! PC = 0x400c6c *)
sub [r9_b, r9_t] [r8_b, r8_t] [lr_b, lr_t];
(* uadd16	r8, r8, lr                               #! PC = 0x400c70 *)
add [r8_b, r8_t] [r8_b, r8_t] [lr_b, lr_t];
(* vmov	r0, s23                                    #! PC = 0x400c74 *)
mov r0 s23;
(* str.w	r6, [r0, #16]                             #! EA = L0xbefff3b4; PC = 0x400c78 *)
mov [L0xbefff3b4, L0xbefff3b6] [r6_b, r6_t];
(* str.w	r7, [r0, #20]                             #! EA = L0xbefff3b8; PC = 0x400c7c *)
mov [L0xbefff3b8, L0xbefff3ba] [r7_b, r7_t];
(* str.w	r8, [r0, #24]                             #! EA = L0xbefff3bc; PC = 0x400c80 *)
mov [L0xbefff3bc, L0xbefff3be] [r8_b, r8_t];
(* str.w	r9, [r0, #28]                             #! EA = L0xbefff3c0; PC = 0x400c84 *)
mov [L0xbefff3c0, L0xbefff3c2] [r9_b, r9_t];
(* str.w	r3, [r0, #4]                              #! EA = L0xbefff3a8; PC = 0x400c88 *)
mov [L0xbefff3a8, L0xbefff3aa] [r3_b, r3_t];
(* str.w	r4, [r0, #8]                              #! EA = L0xbefff3ac; PC = 0x400c8c *)
mov [L0xbefff3ac, L0xbefff3ae] [r4_b, r4_t];
(* str.w	r5, [r0, #12]                             #! EA = L0xbefff3b0; PC = 0x400c90 *)
mov [L0xbefff3b0, L0xbefff3b2] [r5_b, r5_t];
(* str.w	r2, [r0], #32                             #! EA = L0xbefff3a4; PC = 0x400c94 *)
mov [L0xbefff3a4, L0xbefff3a6] [r2_b, r2_t];
(* vmov	lr, s13                                    #! PC = 0x400c98 *)
mov lr s13;
(* cmp.w	r0, lr                                    #! PC = 0x400c9c *)
(* cmp.w r0, lr *)
nop;
(* #bne.w	0x400aec <ntt_fast+1244>                 #! PC = 0x400ca0 *)
#bne.w	0x400aec <ntt_fast+1244>                 #! 0x400ca0 = 0x400ca0;


assert [8*NQ2,8*NQ2]<[L0xbefff3a4,L0xbefff3a6] /\
                     [L0xbefff3a4,L0xbefff3a6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3a8,L0xbefff3aa] /\
                     [L0xbefff3a8,L0xbefff3aa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3ac,L0xbefff3ae] /\
                     [L0xbefff3ac,L0xbefff3ae]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3b0,L0xbefff3b2] /\
                     [L0xbefff3b0,L0xbefff3b2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3b4,L0xbefff3b6] /\
                     [L0xbefff3b4,L0xbefff3b6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3b8,L0xbefff3ba] /\
                     [L0xbefff3b8,L0xbefff3ba]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3bc,L0xbefff3be] /\
                     [L0xbefff3bc,L0xbefff3be]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3c0,L0xbefff3c2] /\
                     [L0xbefff3c0,L0xbefff3c2]<[8*Q2,8*Q2]
       prove with [all cuts, algebra solver isl]
    && true;

assume [8*NQ2,8*NQ2]<[L0xbefff3a4,L0xbefff3a6] /\
                     [L0xbefff3a4,L0xbefff3a6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3a8,L0xbefff3aa] /\
                     [L0xbefff3a8,L0xbefff3aa]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3ac,L0xbefff3ae] /\
                     [L0xbefff3ac,L0xbefff3ae]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3b0,L0xbefff3b2] /\
                     [L0xbefff3b0,L0xbefff3b2]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3b4,L0xbefff3b6] /\
                     [L0xbefff3b4,L0xbefff3b6]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3b8,L0xbefff3ba] /\
                     [L0xbefff3b8,L0xbefff3ba]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3bc,L0xbefff3be] /\
                     [L0xbefff3bc,L0xbefff3be]<[8*Q2,8*Q2] /\
       [8*NQ2,8*NQ2]<[L0xbefff3c0,L0xbefff3c2] /\
                     [L0xbefff3c0,L0xbefff3c2]<[8*Q2,8*Q2]
   && [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a4,L0xbefff3a6] /\
                           [L0xbefff3a4,L0xbefff3a6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a8,L0xbefff3aa] /\
                           [L0xbefff3a8,L0xbefff3aa]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3ac,L0xbefff3ae] /\
                           [L0xbefff3ac,L0xbefff3ae]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b0,L0xbefff3b2] /\
                           [L0xbefff3b0,L0xbefff3b2]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b4,L0xbefff3b6] /\
                           [L0xbefff3b4,L0xbefff3b6]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b8,L0xbefff3ba] /\
                           [L0xbefff3b8,L0xbefff3ba]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3bc,L0xbefff3be] /\
                           [L0xbefff3bc,L0xbefff3be]<s[8@16*Q2,8@16*Q2] /\
      [8@16*NQ2,8@16*NQ2]<s[L0xbefff3c0,L0xbefff3c2] /\
                           [L0xbefff3c0,L0xbefff3c2]<s[8@16*Q2,8@16*Q2];


(* CUT 40 *)

cut Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
    eqmod (F**2) (L0xbefff3a4+L0xbefff3a6*X) [Q,X**2 - 17** 31] /\
    eqmod (F**2) (L0xbefff3a8+L0xbefff3aa*X) [Q,X**2 - 17**159] /\
    eqmod (F**2) (L0xbefff3ac+L0xbefff3ae*X) [Q,X**2 - 17** 95] /\
    eqmod (F**2) (L0xbefff3b0+L0xbefff3b2*X) [Q,X**2 - 17**223] /\
    eqmod (F**2) (L0xbefff3b4+L0xbefff3b6*X) [Q,X**2 - 17** 63] /\
    eqmod (F**2) (L0xbefff3b8+L0xbefff3ba*X) [Q,X**2 - 17**191] /\
    eqmod (F**2) (L0xbefff3bc+L0xbefff3be*X) [Q,X**2 - 17**127] /\
    eqmod (F**2) (L0xbefff3c0+L0xbefff3c2*X) [Q,X**2 - 17**255] /\
    [8*NQ2,8*NQ2]<[L0xbefff3a4,L0xbefff3a6] /\
                  [L0xbefff3a4,L0xbefff3a6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3a8,L0xbefff3aa] /\
                  [L0xbefff3a8,L0xbefff3aa]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3ac,L0xbefff3ae] /\
                  [L0xbefff3ac,L0xbefff3ae]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3b0,L0xbefff3b2] /\
                  [L0xbefff3b0,L0xbefff3b2]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3b4,L0xbefff3b6] /\
                  [L0xbefff3b4,L0xbefff3b6]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3b8,L0xbefff3ba] /\
                  [L0xbefff3b8,L0xbefff3ba]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3bc,L0xbefff3be] /\
                  [L0xbefff3bc,L0xbefff3be]<[8*Q2,8*Q2] /\
    [8*NQ2,8*NQ2]<[L0xbefff3c0,L0xbefff3c2] /\
                  [L0xbefff3c0,L0xbefff3c2]<[8*Q2,8*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24], all ghosts]
 && Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a4,L0xbefff3a6] /\
                         [L0xbefff3a4,L0xbefff3a6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a8,L0xbefff3aa] /\
                         [L0xbefff3a8,L0xbefff3aa]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3ac,L0xbefff3ae] /\
                         [L0xbefff3ac,L0xbefff3ae]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b0,L0xbefff3b2] /\
                         [L0xbefff3b0,L0xbefff3b2]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b4,L0xbefff3b6] /\
                         [L0xbefff3b4,L0xbefff3b6]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b8,L0xbefff3ba] /\
                         [L0xbefff3b8,L0xbefff3ba]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3bc,L0xbefff3be] /\
                         [L0xbefff3bc,L0xbefff3be]<s[8@16*Q2,8@16*Q2] /\
    [8@16*NQ2,8@16*NQ2]<s[L0xbefff3c0,L0xbefff3c2] /\
                         [L0xbefff3c0,L0xbefff3c2]<s[8@16*Q2,8@16*Q2]
    prove with [cuts [3, 6, 9, 12, 15, 18, 21, 24]];


{
   Q = 3329 /\ NQ = -3329 /\ Q2 = 1665 /\ NQ2 = -1665 /\
   eqmod (F**2) (L0xbefff1c4+L0xbefff1c6*X) [Q,X**2 - 17**  1] /\
   eqmod (F**2) (L0xbefff1c8+L0xbefff1ca*X) [Q,X**2 - 17**129] /\
   eqmod (F**2) (L0xbefff1cc+L0xbefff1ce*X) [Q,X**2 - 17** 65] /\
   eqmod (F**2) (L0xbefff1d0+L0xbefff1d2*X) [Q,X**2 - 17**193] /\
   eqmod (F**2) (L0xbefff1d4+L0xbefff1d6*X) [Q,X**2 - 17** 33] /\
   eqmod (F**2) (L0xbefff1d8+L0xbefff1da*X) [Q,X**2 - 17**161] /\
   eqmod (F**2) (L0xbefff1dc+L0xbefff1de*X) [Q,X**2 - 17** 97] /\
   eqmod (F**2) (L0xbefff1e0+L0xbefff1e2*X) [Q,X**2 - 17**225] /\
   eqmod (F**2) (L0xbefff1e4+L0xbefff1e6*X) [Q,X**2 - 17** 17] /\
   eqmod (F**2) (L0xbefff1e8+L0xbefff1ea*X) [Q,X**2 - 17**145] /\
   eqmod (F**2) (L0xbefff1ec+L0xbefff1ee*X) [Q,X**2 - 17** 81] /\
   eqmod (F**2) (L0xbefff1f0+L0xbefff1f2*X) [Q,X**2 - 17**209] /\
   eqmod (F**2) (L0xbefff1f4+L0xbefff1f6*X) [Q,X**2 - 17** 49] /\
   eqmod (F**2) (L0xbefff1f8+L0xbefff1fa*X) [Q,X**2 - 17**177] /\
   eqmod (F**2) (L0xbefff1fc+L0xbefff1fe*X) [Q,X**2 - 17**113] /\
   eqmod (F**2) (L0xbefff200+L0xbefff202*X) [Q,X**2 - 17**241] /\
   eqmod (F**2) (L0xbefff204+L0xbefff206*X) [Q,X**2 - 17**  9] /\
   eqmod (F**2) (L0xbefff208+L0xbefff20a*X) [Q,X**2 - 17**137] /\
   eqmod (F**2) (L0xbefff20c+L0xbefff20e*X) [Q,X**2 - 17** 73] /\
   eqmod (F**2) (L0xbefff210+L0xbefff212*X) [Q,X**2 - 17**201] /\
   eqmod (F**2) (L0xbefff214+L0xbefff216*X) [Q,X**2 - 17** 41] /\
   eqmod (F**2) (L0xbefff218+L0xbefff21a*X) [Q,X**2 - 17**169] /\
   eqmod (F**2) (L0xbefff21c+L0xbefff21e*X) [Q,X**2 - 17**105] /\
   eqmod (F**2) (L0xbefff220+L0xbefff222*X) [Q,X**2 - 17**233] /\
   eqmod (F**2) (L0xbefff224+L0xbefff226*X) [Q,X**2 - 17** 25] /\
   eqmod (F**2) (L0xbefff228+L0xbefff22a*X) [Q,X**2 - 17**153] /\
   eqmod (F**2) (L0xbefff22c+L0xbefff22e*X) [Q,X**2 - 17** 89] /\
   eqmod (F**2) (L0xbefff230+L0xbefff232*X) [Q,X**2 - 17**217] /\
   eqmod (F**2) (L0xbefff234+L0xbefff236*X) [Q,X**2 - 17** 57] /\
   eqmod (F**2) (L0xbefff238+L0xbefff23a*X) [Q,X**2 - 17**185] /\
   eqmod (F**2) (L0xbefff23c+L0xbefff23e*X) [Q,X**2 - 17**121] /\
   eqmod (F**2) (L0xbefff240+L0xbefff242*X) [Q,X**2 - 17**249] /\
   eqmod (F**2) (L0xbefff244+L0xbefff246*X) [Q,X**2 - 17**  5] /\
   eqmod (F**2) (L0xbefff248+L0xbefff24a*X) [Q,X**2 - 17**133] /\
   eqmod (F**2) (L0xbefff24c+L0xbefff24e*X) [Q,X**2 - 17** 69] /\
   eqmod (F**2) (L0xbefff250+L0xbefff252*X) [Q,X**2 - 17**197] /\
   eqmod (F**2) (L0xbefff254+L0xbefff256*X) [Q,X**2 - 17** 37] /\
   eqmod (F**2) (L0xbefff258+L0xbefff25a*X) [Q,X**2 - 17**165] /\
   eqmod (F**2) (L0xbefff25c+L0xbefff25e*X) [Q,X**2 - 17**101] /\
   eqmod (F**2) (L0xbefff260+L0xbefff262*X) [Q,X**2 - 17**229] /\
   eqmod (F**2) (L0xbefff264+L0xbefff266*X) [Q,X**2 - 17** 21] /\
   eqmod (F**2) (L0xbefff268+L0xbefff26a*X) [Q,X**2 - 17**149] /\
   eqmod (F**2) (L0xbefff26c+L0xbefff26e*X) [Q,X**2 - 17** 85] /\
   eqmod (F**2) (L0xbefff270+L0xbefff272*X) [Q,X**2 - 17**213] /\
   eqmod (F**2) (L0xbefff274+L0xbefff276*X) [Q,X**2 - 17** 53] /\
   eqmod (F**2) (L0xbefff278+L0xbefff27a*X) [Q,X**2 - 17**181] /\
   eqmod (F**2) (L0xbefff27c+L0xbefff27e*X) [Q,X**2 - 17**117] /\
   eqmod (F**2) (L0xbefff280+L0xbefff282*X) [Q,X**2 - 17**245] /\
   eqmod (F**2) (L0xbefff284+L0xbefff286*X) [Q,X**2 - 17** 13] /\
   eqmod (F**2) (L0xbefff288+L0xbefff28a*X) [Q,X**2 - 17**141] /\
   eqmod (F**2) (L0xbefff28c+L0xbefff28e*X) [Q,X**2 - 17** 77] /\
   eqmod (F**2) (L0xbefff290+L0xbefff292*X) [Q,X**2 - 17**205] /\
   eqmod (F**2) (L0xbefff294+L0xbefff296*X) [Q,X**2 - 17** 45] /\
   eqmod (F**2) (L0xbefff298+L0xbefff29a*X) [Q,X**2 - 17**173] /\
   eqmod (F**2) (L0xbefff29c+L0xbefff29e*X) [Q,X**2 - 17**109] /\
   eqmod (F**2) (L0xbefff2a0+L0xbefff2a2*X) [Q,X**2 - 17**237] /\
   eqmod (F**2) (L0xbefff2a4+L0xbefff2a6*X) [Q,X**2 - 17** 29] /\
   eqmod (F**2) (L0xbefff2a8+L0xbefff2aa*X) [Q,X**2 - 17**157] /\
   eqmod (F**2) (L0xbefff2ac+L0xbefff2ae*X) [Q,X**2 - 17** 93] /\
   eqmod (F**2) (L0xbefff2b0+L0xbefff2b2*X) [Q,X**2 - 17**221] /\
   eqmod (F**2) (L0xbefff2b4+L0xbefff2b6*X) [Q,X**2 - 17** 61] /\
   eqmod (F**2) (L0xbefff2b8+L0xbefff2ba*X) [Q,X**2 - 17**189] /\
   eqmod (F**2) (L0xbefff2bc+L0xbefff2be*X) [Q,X**2 - 17**125] /\
   eqmod (F**2) (L0xbefff2c0+L0xbefff2c2*X) [Q,X**2 - 17**253] /\
   eqmod (F**2) (L0xbefff2c4+L0xbefff2c6*X) [Q,X**2 - 17**  3] /\
   eqmod (F**2) (L0xbefff2c8+L0xbefff2ca*X) [Q,X**2 - 17**131] /\
   eqmod (F**2) (L0xbefff2cc+L0xbefff2ce*X) [Q,X**2 - 17** 67] /\
   eqmod (F**2) (L0xbefff2d0+L0xbefff2d2*X) [Q,X**2 - 17**195] /\
   eqmod (F**2) (L0xbefff2d4+L0xbefff2d6*X) [Q,X**2 - 17** 35] /\
   eqmod (F**2) (L0xbefff2d8+L0xbefff2da*X) [Q,X**2 - 17**163] /\
   eqmod (F**2) (L0xbefff2dc+L0xbefff2de*X) [Q,X**2 - 17** 99] /\
   eqmod (F**2) (L0xbefff2e0+L0xbefff2e2*X) [Q,X**2 - 17**227] /\
   eqmod (F**2) (L0xbefff2e4+L0xbefff2e6*X) [Q,X**2 - 17** 19] /\
   eqmod (F**2) (L0xbefff2e8+L0xbefff2ea*X) [Q,X**2 - 17**147] /\
   eqmod (F**2) (L0xbefff2ec+L0xbefff2ee*X) [Q,X**2 - 17** 83] /\
   eqmod (F**2) (L0xbefff2f0+L0xbefff2f2*X) [Q,X**2 - 17**211] /\
   eqmod (F**2) (L0xbefff2f4+L0xbefff2f6*X) [Q,X**2 - 17** 51] /\
   eqmod (F**2) (L0xbefff2f8+L0xbefff2fa*X) [Q,X**2 - 17**179] /\
   eqmod (F**2) (L0xbefff2fc+L0xbefff2fe*X) [Q,X**2 - 17**115] /\
   eqmod (F**2) (L0xbefff300+L0xbefff302*X) [Q,X**2 - 17**243] /\
   eqmod (F**2) (L0xbefff304+L0xbefff306*X) [Q,X**2 - 17** 11] /\
   eqmod (F**2) (L0xbefff308+L0xbefff30a*X) [Q,X**2 - 17**139] /\
   eqmod (F**2) (L0xbefff30c+L0xbefff30e*X) [Q,X**2 - 17** 75] /\
   eqmod (F**2) (L0xbefff310+L0xbefff312*X) [Q,X**2 - 17**203] /\
   eqmod (F**2) (L0xbefff314+L0xbefff316*X) [Q,X**2 - 17** 43] /\
   eqmod (F**2) (L0xbefff318+L0xbefff31a*X) [Q,X**2 - 17**171] /\
   eqmod (F**2) (L0xbefff31c+L0xbefff31e*X) [Q,X**2 - 17**107] /\
   eqmod (F**2) (L0xbefff320+L0xbefff322*X) [Q,X**2 - 17**235] /\
   eqmod (F**2) (L0xbefff324+L0xbefff326*X) [Q,X**2 - 17** 27] /\
   eqmod (F**2) (L0xbefff328+L0xbefff32a*X) [Q,X**2 - 17**155] /\
   eqmod (F**2) (L0xbefff32c+L0xbefff32e*X) [Q,X**2 - 17** 91] /\
   eqmod (F**2) (L0xbefff330+L0xbefff332*X) [Q,X**2 - 17**219] /\
   eqmod (F**2) (L0xbefff334+L0xbefff336*X) [Q,X**2 - 17** 59] /\
   eqmod (F**2) (L0xbefff338+L0xbefff33a*X) [Q,X**2 - 17**187] /\
   eqmod (F**2) (L0xbefff33c+L0xbefff33e*X) [Q,X**2 - 17**123] /\
   eqmod (F**2) (L0xbefff340+L0xbefff342*X) [Q,X**2 - 17**251] /\
   eqmod (F**2) (L0xbefff344+L0xbefff346*X) [Q,X**2 - 17**  7] /\
   eqmod (F**2) (L0xbefff348+L0xbefff34a*X) [Q,X**2 - 17**135] /\
   eqmod (F**2) (L0xbefff34c+L0xbefff34e*X) [Q,X**2 - 17** 71] /\
   eqmod (F**2) (L0xbefff350+L0xbefff352*X) [Q,X**2 - 17**199] /\
   eqmod (F**2) (L0xbefff354+L0xbefff356*X) [Q,X**2 - 17** 39] /\
   eqmod (F**2) (L0xbefff358+L0xbefff35a*X) [Q,X**2 - 17**167] /\
   eqmod (F**2) (L0xbefff35c+L0xbefff35e*X) [Q,X**2 - 17**103] /\
   eqmod (F**2) (L0xbefff360+L0xbefff362*X) [Q,X**2 - 17**231] /\
   eqmod (F**2) (L0xbefff364+L0xbefff366*X) [Q,X**2 - 17** 23] /\
   eqmod (F**2) (L0xbefff368+L0xbefff36a*X) [Q,X**2 - 17**151] /\
   eqmod (F**2) (L0xbefff36c+L0xbefff36e*X) [Q,X**2 - 17** 87] /\
   eqmod (F**2) (L0xbefff370+L0xbefff372*X) [Q,X**2 - 17**215] /\
   eqmod (F**2) (L0xbefff374+L0xbefff376*X) [Q,X**2 - 17** 55] /\
   eqmod (F**2) (L0xbefff378+L0xbefff37a*X) [Q,X**2 - 17**183] /\
   eqmod (F**2) (L0xbefff37c+L0xbefff37e*X) [Q,X**2 - 17**119] /\
   eqmod (F**2) (L0xbefff380+L0xbefff382*X) [Q,X**2 - 17**247] /\
   eqmod (F**2) (L0xbefff384+L0xbefff386*X) [Q,X**2 - 17** 15] /\
   eqmod (F**2) (L0xbefff388+L0xbefff38a*X) [Q,X**2 - 17**143] /\
   eqmod (F**2) (L0xbefff38c+L0xbefff38e*X) [Q,X**2 - 17** 79] /\
   eqmod (F**2) (L0xbefff390+L0xbefff392*X) [Q,X**2 - 17**207] /\
   eqmod (F**2) (L0xbefff394+L0xbefff396*X) [Q,X**2 - 17** 47] /\
   eqmod (F**2) (L0xbefff398+L0xbefff39a*X) [Q,X**2 - 17**175] /\
   eqmod (F**2) (L0xbefff39c+L0xbefff39e*X) [Q,X**2 - 17**111] /\
   eqmod (F**2) (L0xbefff3a0+L0xbefff3a2*X) [Q,X**2 - 17**239] /\
   eqmod (F**2) (L0xbefff3a4+L0xbefff3a6*X) [Q,X**2 - 17** 31] /\
   eqmod (F**2) (L0xbefff3a8+L0xbefff3aa*X) [Q,X**2 - 17**159] /\
   eqmod (F**2) (L0xbefff3ac+L0xbefff3ae*X) [Q,X**2 - 17** 95] /\
   eqmod (F**2) (L0xbefff3b0+L0xbefff3b2*X) [Q,X**2 - 17**223] /\
   eqmod (F**2) (L0xbefff3b4+L0xbefff3b6*X) [Q,X**2 - 17** 63] /\
   eqmod (F**2) (L0xbefff3b8+L0xbefff3ba*X) [Q,X**2 - 17**191] /\
   eqmod (F**2) (L0xbefff3bc+L0xbefff3be*X) [Q,X**2 - 17**127] /\
   eqmod (F**2) (L0xbefff3c0+L0xbefff3c2*X) [Q,X**2 - 17**255] /\
   [8*NQ2,8*NQ2]<[L0xbefff1c4,L0xbefff1c6] /\
                 [L0xbefff1c4,L0xbefff1c6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1c8,L0xbefff1ca] /\
                 [L0xbefff1c8,L0xbefff1ca]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1cc,L0xbefff1ce] /\
                 [L0xbefff1cc,L0xbefff1ce]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1d0,L0xbefff1d2] /\
                 [L0xbefff1d0,L0xbefff1d2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1d4,L0xbefff1d6] /\
                 [L0xbefff1d4,L0xbefff1d6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1d8,L0xbefff1da] /\
                 [L0xbefff1d8,L0xbefff1da]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1dc,L0xbefff1de] /\
                 [L0xbefff1dc,L0xbefff1de]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1e0,L0xbefff1e2] /\
                 [L0xbefff1e0,L0xbefff1e2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1e4,L0xbefff1e6] /\
                 [L0xbefff1e4,L0xbefff1e6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1e8,L0xbefff1ea] /\
                 [L0xbefff1e8,L0xbefff1ea]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1ec,L0xbefff1ee] /\
                 [L0xbefff1ec,L0xbefff1ee]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1f0,L0xbefff1f2] /\
                 [L0xbefff1f0,L0xbefff1f2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1f4,L0xbefff1f6] /\
                 [L0xbefff1f4,L0xbefff1f6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1f8,L0xbefff1fa] /\
                 [L0xbefff1f8,L0xbefff1fa]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff1fc,L0xbefff1fe] /\
                 [L0xbefff1fc,L0xbefff1fe]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff200,L0xbefff202] /\
                 [L0xbefff200,L0xbefff202]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff204,L0xbefff206] /\
                 [L0xbefff204,L0xbefff206]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff208,L0xbefff20a] /\
                 [L0xbefff208,L0xbefff20a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff20c,L0xbefff20e] /\
                 [L0xbefff20c,L0xbefff20e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff210,L0xbefff212] /\
                 [L0xbefff210,L0xbefff212]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff214,L0xbefff216] /\
                 [L0xbefff214,L0xbefff216]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff218,L0xbefff21a] /\
                 [L0xbefff218,L0xbefff21a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff21c,L0xbefff21e] /\
                 [L0xbefff21c,L0xbefff21e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff220,L0xbefff222] /\
                 [L0xbefff220,L0xbefff222]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff224,L0xbefff226] /\
                 [L0xbefff224,L0xbefff226]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff228,L0xbefff22a] /\
                 [L0xbefff228,L0xbefff22a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff22c,L0xbefff22e] /\
                 [L0xbefff22c,L0xbefff22e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff230,L0xbefff232] /\
                 [L0xbefff230,L0xbefff232]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff234,L0xbefff236] /\
                 [L0xbefff234,L0xbefff236]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff238,L0xbefff23a] /\
                 [L0xbefff238,L0xbefff23a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff23c,L0xbefff23e] /\
                 [L0xbefff23c,L0xbefff23e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff240,L0xbefff242] /\
                 [L0xbefff240,L0xbefff242]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff244,L0xbefff246] /\
                 [L0xbefff244,L0xbefff246]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff248,L0xbefff24a] /\
                 [L0xbefff248,L0xbefff24a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff24c,L0xbefff24e] /\
                 [L0xbefff24c,L0xbefff24e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff250,L0xbefff252] /\
                 [L0xbefff250,L0xbefff252]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff254,L0xbefff256] /\
                 [L0xbefff254,L0xbefff256]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff258,L0xbefff25a] /\
                 [L0xbefff258,L0xbefff25a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff25c,L0xbefff25e] /\
                 [L0xbefff25c,L0xbefff25e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff260,L0xbefff262] /\
                 [L0xbefff260,L0xbefff262]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff264,L0xbefff266] /\
                 [L0xbefff264,L0xbefff266]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff268,L0xbefff26a] /\
                 [L0xbefff268,L0xbefff26a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff26c,L0xbefff26e] /\
                 [L0xbefff26c,L0xbefff26e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff270,L0xbefff272] /\
                 [L0xbefff270,L0xbefff272]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff274,L0xbefff276] /\
                 [L0xbefff274,L0xbefff276]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff278,L0xbefff27a] /\
                 [L0xbefff278,L0xbefff27a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff27c,L0xbefff27e] /\
                 [L0xbefff27c,L0xbefff27e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff280,L0xbefff282] /\
                 [L0xbefff280,L0xbefff282]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff284,L0xbefff286] /\
                 [L0xbefff284,L0xbefff286]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff288,L0xbefff28a] /\
                 [L0xbefff288,L0xbefff28a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff28c,L0xbefff28e] /\
                 [L0xbefff28c,L0xbefff28e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff290,L0xbefff292] /\
                 [L0xbefff290,L0xbefff292]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff294,L0xbefff296] /\
                 [L0xbefff294,L0xbefff296]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff298,L0xbefff29a] /\
                 [L0xbefff298,L0xbefff29a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff29c,L0xbefff29e] /\
                 [L0xbefff29c,L0xbefff29e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2a0,L0xbefff2a2] /\
                 [L0xbefff2a0,L0xbefff2a2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2a4,L0xbefff2a6] /\
                 [L0xbefff2a4,L0xbefff2a6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2a8,L0xbefff2aa] /\
                 [L0xbefff2a8,L0xbefff2aa]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2ac,L0xbefff2ae] /\
                 [L0xbefff2ac,L0xbefff2ae]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2b0,L0xbefff2b2] /\
                 [L0xbefff2b0,L0xbefff2b2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2b4,L0xbefff2b6] /\
                 [L0xbefff2b4,L0xbefff2b6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2b8,L0xbefff2ba] /\
                 [L0xbefff2b8,L0xbefff2ba]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2bc,L0xbefff2be] /\
                 [L0xbefff2bc,L0xbefff2be]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2c0,L0xbefff2c2] /\
                 [L0xbefff2c0,L0xbefff2c2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2c4,L0xbefff2c6] /\
                 [L0xbefff2c4,L0xbefff2c6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2c8,L0xbefff2ca] /\
                 [L0xbefff2c8,L0xbefff2ca]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2cc,L0xbefff2ce] /\
                 [L0xbefff2cc,L0xbefff2ce]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2d0,L0xbefff2d2] /\
                 [L0xbefff2d0,L0xbefff2d2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2d4,L0xbefff2d6] /\
                 [L0xbefff2d4,L0xbefff2d6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2d8,L0xbefff2da] /\
                 [L0xbefff2d8,L0xbefff2da]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2dc,L0xbefff2de] /\
                 [L0xbefff2dc,L0xbefff2de]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2e0,L0xbefff2e2] /\
                 [L0xbefff2e0,L0xbefff2e2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2e4,L0xbefff2e6] /\
                 [L0xbefff2e4,L0xbefff2e6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2e8,L0xbefff2ea] /\
                 [L0xbefff2e8,L0xbefff2ea]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2ec,L0xbefff2ee] /\
                 [L0xbefff2ec,L0xbefff2ee]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2f0,L0xbefff2f2] /\
                 [L0xbefff2f0,L0xbefff2f2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2f4,L0xbefff2f6] /\
                 [L0xbefff2f4,L0xbefff2f6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2f8,L0xbefff2fa] /\
                 [L0xbefff2f8,L0xbefff2fa]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff2fc,L0xbefff2fe] /\
                 [L0xbefff2fc,L0xbefff2fe]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff300,L0xbefff302] /\
                 [L0xbefff300,L0xbefff302]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff304,L0xbefff306] /\
                 [L0xbefff304,L0xbefff306]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff308,L0xbefff30a] /\
                 [L0xbefff308,L0xbefff30a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff30c,L0xbefff30e] /\
                 [L0xbefff30c,L0xbefff30e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff310,L0xbefff312] /\
                 [L0xbefff310,L0xbefff312]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff314,L0xbefff316] /\
                 [L0xbefff314,L0xbefff316]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff318,L0xbefff31a] /\
                 [L0xbefff318,L0xbefff31a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff31c,L0xbefff31e] /\
                 [L0xbefff31c,L0xbefff31e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff320,L0xbefff322] /\
                 [L0xbefff320,L0xbefff322]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff324,L0xbefff326] /\
                 [L0xbefff324,L0xbefff326]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff328,L0xbefff32a] /\
                 [L0xbefff328,L0xbefff32a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff32c,L0xbefff32e] /\
                 [L0xbefff32c,L0xbefff32e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff330,L0xbefff332] /\
                 [L0xbefff330,L0xbefff332]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff334,L0xbefff336] /\
                 [L0xbefff334,L0xbefff336]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff338,L0xbefff33a] /\
                 [L0xbefff338,L0xbefff33a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff33c,L0xbefff33e] /\
                 [L0xbefff33c,L0xbefff33e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff340,L0xbefff342] /\
                 [L0xbefff340,L0xbefff342]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff344,L0xbefff346] /\
                 [L0xbefff344,L0xbefff346]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff348,L0xbefff34a] /\
                 [L0xbefff348,L0xbefff34a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff34c,L0xbefff34e] /\
                 [L0xbefff34c,L0xbefff34e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff350,L0xbefff352] /\
                 [L0xbefff350,L0xbefff352]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff354,L0xbefff356] /\
                 [L0xbefff354,L0xbefff356]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff358,L0xbefff35a] /\
                 [L0xbefff358,L0xbefff35a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff35c,L0xbefff35e] /\
                 [L0xbefff35c,L0xbefff35e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff360,L0xbefff362] /\
                 [L0xbefff360,L0xbefff362]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff364,L0xbefff366] /\
                 [L0xbefff364,L0xbefff366]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff368,L0xbefff36a] /\
                 [L0xbefff368,L0xbefff36a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff36c,L0xbefff36e] /\
                 [L0xbefff36c,L0xbefff36e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff370,L0xbefff372] /\
                 [L0xbefff370,L0xbefff372]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff374,L0xbefff376] /\
                 [L0xbefff374,L0xbefff376]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff378,L0xbefff37a] /\
                 [L0xbefff378,L0xbefff37a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff37c,L0xbefff37e] /\
                 [L0xbefff37c,L0xbefff37e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff380,L0xbefff382] /\
                 [L0xbefff380,L0xbefff382]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff384,L0xbefff386] /\
                 [L0xbefff384,L0xbefff386]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff388,L0xbefff38a] /\
                 [L0xbefff388,L0xbefff38a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff38c,L0xbefff38e] /\
                 [L0xbefff38c,L0xbefff38e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff390,L0xbefff392] /\
                 [L0xbefff390,L0xbefff392]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff394,L0xbefff396] /\
                 [L0xbefff394,L0xbefff396]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff398,L0xbefff39a] /\
                 [L0xbefff398,L0xbefff39a]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff39c,L0xbefff39e] /\
                 [L0xbefff39c,L0xbefff39e]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3a0,L0xbefff3a2] /\
                 [L0xbefff3a0,L0xbefff3a2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3a4,L0xbefff3a6] /\
                 [L0xbefff3a4,L0xbefff3a6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3a8,L0xbefff3aa] /\
                 [L0xbefff3a8,L0xbefff3aa]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3ac,L0xbefff3ae] /\
                 [L0xbefff3ac,L0xbefff3ae]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3b0,L0xbefff3b2] /\
                 [L0xbefff3b0,L0xbefff3b2]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3b4,L0xbefff3b6] /\
                 [L0xbefff3b4,L0xbefff3b6]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3b8,L0xbefff3ba] /\
                 [L0xbefff3b8,L0xbefff3ba]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3bc,L0xbefff3be] /\
                 [L0xbefff3bc,L0xbefff3be]<[8*Q2,8*Q2] /\
   [8*NQ2,8*NQ2]<[L0xbefff3c0,L0xbefff3c2] /\
                 [L0xbefff3c0,L0xbefff3c2]<[8*Q2,8*Q2]
   prove with [cuts [25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40]]
&& Q = 3329@16 /\ NQ = (-3329)@16 /\ Q2 = 1665@16 /\ NQ2 = (-1665)@16 /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1c4,L0xbefff1c6] /\
                        [L0xbefff1c4,L0xbefff1c6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1c8,L0xbefff1ca] /\
                        [L0xbefff1c8,L0xbefff1ca]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1cc,L0xbefff1ce] /\
                        [L0xbefff1cc,L0xbefff1ce]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d0,L0xbefff1d2] /\
                        [L0xbefff1d0,L0xbefff1d2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d4,L0xbefff1d6] /\
                        [L0xbefff1d4,L0xbefff1d6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1d8,L0xbefff1da] /\
                        [L0xbefff1d8,L0xbefff1da]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1dc,L0xbefff1de] /\
                        [L0xbefff1dc,L0xbefff1de]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e0,L0xbefff1e2] /\
                        [L0xbefff1e0,L0xbefff1e2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e4,L0xbefff1e6] /\
                        [L0xbefff1e4,L0xbefff1e6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1e8,L0xbefff1ea] /\
                        [L0xbefff1e8,L0xbefff1ea]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1ec,L0xbefff1ee] /\
                        [L0xbefff1ec,L0xbefff1ee]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f0,L0xbefff1f2] /\
                        [L0xbefff1f0,L0xbefff1f2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f4,L0xbefff1f6] /\
                        [L0xbefff1f4,L0xbefff1f6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1f8,L0xbefff1fa] /\
                        [L0xbefff1f8,L0xbefff1fa]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff1fc,L0xbefff1fe] /\
                        [L0xbefff1fc,L0xbefff1fe]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff200,L0xbefff202] /\
                        [L0xbefff200,L0xbefff202]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff204,L0xbefff206] /\
                        [L0xbefff204,L0xbefff206]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff208,L0xbefff20a] /\
                        [L0xbefff208,L0xbefff20a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff20c,L0xbefff20e] /\
                        [L0xbefff20c,L0xbefff20e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff210,L0xbefff212] /\
                        [L0xbefff210,L0xbefff212]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff214,L0xbefff216] /\
                        [L0xbefff214,L0xbefff216]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff218,L0xbefff21a] /\
                        [L0xbefff218,L0xbefff21a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff21c,L0xbefff21e] /\
                        [L0xbefff21c,L0xbefff21e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff220,L0xbefff222] /\
                        [L0xbefff220,L0xbefff222]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff224,L0xbefff226] /\
                        [L0xbefff224,L0xbefff226]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff228,L0xbefff22a] /\
                        [L0xbefff228,L0xbefff22a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff22c,L0xbefff22e] /\
                        [L0xbefff22c,L0xbefff22e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff230,L0xbefff232] /\
                        [L0xbefff230,L0xbefff232]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff234,L0xbefff236] /\
                        [L0xbefff234,L0xbefff236]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff238,L0xbefff23a] /\
                        [L0xbefff238,L0xbefff23a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff23c,L0xbefff23e] /\
                        [L0xbefff23c,L0xbefff23e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff240,L0xbefff242] /\
                        [L0xbefff240,L0xbefff242]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff244,L0xbefff246] /\
                        [L0xbefff244,L0xbefff246]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff248,L0xbefff24a] /\
                        [L0xbefff248,L0xbefff24a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff24c,L0xbefff24e] /\
                        [L0xbefff24c,L0xbefff24e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff250,L0xbefff252] /\
                        [L0xbefff250,L0xbefff252]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff254,L0xbefff256] /\
                        [L0xbefff254,L0xbefff256]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff258,L0xbefff25a] /\
                        [L0xbefff258,L0xbefff25a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff25c,L0xbefff25e] /\
                        [L0xbefff25c,L0xbefff25e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff260,L0xbefff262] /\
                        [L0xbefff260,L0xbefff262]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff264,L0xbefff266] /\
                        [L0xbefff264,L0xbefff266]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff268,L0xbefff26a] /\
                        [L0xbefff268,L0xbefff26a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff26c,L0xbefff26e] /\
                        [L0xbefff26c,L0xbefff26e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff270,L0xbefff272] /\
                        [L0xbefff270,L0xbefff272]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff274,L0xbefff276] /\
                        [L0xbefff274,L0xbefff276]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff278,L0xbefff27a] /\
                        [L0xbefff278,L0xbefff27a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff27c,L0xbefff27e] /\
                        [L0xbefff27c,L0xbefff27e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff280,L0xbefff282] /\
                        [L0xbefff280,L0xbefff282]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff284,L0xbefff286] /\
                        [L0xbefff284,L0xbefff286]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff288,L0xbefff28a] /\
                        [L0xbefff288,L0xbefff28a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff28c,L0xbefff28e] /\
                        [L0xbefff28c,L0xbefff28e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff290,L0xbefff292] /\
                        [L0xbefff290,L0xbefff292]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff294,L0xbefff296] /\
                        [L0xbefff294,L0xbefff296]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff298,L0xbefff29a] /\
                        [L0xbefff298,L0xbefff29a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff29c,L0xbefff29e] /\
                        [L0xbefff29c,L0xbefff29e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a0,L0xbefff2a2] /\
                        [L0xbefff2a0,L0xbefff2a2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a4,L0xbefff2a6] /\
                        [L0xbefff2a4,L0xbefff2a6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2a8,L0xbefff2aa] /\
                        [L0xbefff2a8,L0xbefff2aa]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2ac,L0xbefff2ae] /\
                        [L0xbefff2ac,L0xbefff2ae]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b0,L0xbefff2b2] /\
                        [L0xbefff2b0,L0xbefff2b2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b4,L0xbefff2b6] /\
                        [L0xbefff2b4,L0xbefff2b6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2b8,L0xbefff2ba] /\
                        [L0xbefff2b8,L0xbefff2ba]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2bc,L0xbefff2be] /\
                        [L0xbefff2bc,L0xbefff2be]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c0,L0xbefff2c2] /\
                        [L0xbefff2c0,L0xbefff2c2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c4,L0xbefff2c6] /\
                        [L0xbefff2c4,L0xbefff2c6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2c8,L0xbefff2ca] /\
                        [L0xbefff2c8,L0xbefff2ca]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2cc,L0xbefff2ce] /\
                        [L0xbefff2cc,L0xbefff2ce]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d0,L0xbefff2d2] /\
                        [L0xbefff2d0,L0xbefff2d2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d4,L0xbefff2d6] /\
                        [L0xbefff2d4,L0xbefff2d6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2d8,L0xbefff2da] /\
                        [L0xbefff2d8,L0xbefff2da]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2dc,L0xbefff2de] /\
                        [L0xbefff2dc,L0xbefff2de]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e0,L0xbefff2e2] /\
                        [L0xbefff2e0,L0xbefff2e2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e4,L0xbefff2e6] /\
                        [L0xbefff2e4,L0xbefff2e6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2e8,L0xbefff2ea] /\
                        [L0xbefff2e8,L0xbefff2ea]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2ec,L0xbefff2ee] /\
                        [L0xbefff2ec,L0xbefff2ee]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f0,L0xbefff2f2] /\
                        [L0xbefff2f0,L0xbefff2f2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f4,L0xbefff2f6] /\
                        [L0xbefff2f4,L0xbefff2f6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2f8,L0xbefff2fa] /\
                        [L0xbefff2f8,L0xbefff2fa]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff2fc,L0xbefff2fe] /\
                        [L0xbefff2fc,L0xbefff2fe]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff300,L0xbefff302] /\
                        [L0xbefff300,L0xbefff302]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff304,L0xbefff306] /\
                        [L0xbefff304,L0xbefff306]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff308,L0xbefff30a] /\
                        [L0xbefff308,L0xbefff30a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff30c,L0xbefff30e] /\
                        [L0xbefff30c,L0xbefff30e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff310,L0xbefff312] /\
                        [L0xbefff310,L0xbefff312]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff314,L0xbefff316] /\
                        [L0xbefff314,L0xbefff316]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff318,L0xbefff31a] /\
                        [L0xbefff318,L0xbefff31a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff31c,L0xbefff31e] /\
                        [L0xbefff31c,L0xbefff31e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff320,L0xbefff322] /\
                        [L0xbefff320,L0xbefff322]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff324,L0xbefff326] /\
                        [L0xbefff324,L0xbefff326]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff328,L0xbefff32a] /\
                        [L0xbefff328,L0xbefff32a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff32c,L0xbefff32e] /\
                        [L0xbefff32c,L0xbefff32e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff330,L0xbefff332] /\
                        [L0xbefff330,L0xbefff332]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff334,L0xbefff336] /\
                        [L0xbefff334,L0xbefff336]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff338,L0xbefff33a] /\
                        [L0xbefff338,L0xbefff33a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff33c,L0xbefff33e] /\
                        [L0xbefff33c,L0xbefff33e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff340,L0xbefff342] /\
                        [L0xbefff340,L0xbefff342]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff344,L0xbefff346] /\
                        [L0xbefff344,L0xbefff346]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff348,L0xbefff34a] /\
                        [L0xbefff348,L0xbefff34a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff34c,L0xbefff34e] /\
                        [L0xbefff34c,L0xbefff34e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff350,L0xbefff352] /\
                        [L0xbefff350,L0xbefff352]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff354,L0xbefff356] /\
                        [L0xbefff354,L0xbefff356]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff358,L0xbefff35a] /\
                        [L0xbefff358,L0xbefff35a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff35c,L0xbefff35e] /\
                        [L0xbefff35c,L0xbefff35e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff360,L0xbefff362] /\
                        [L0xbefff360,L0xbefff362]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff364,L0xbefff366] /\
                        [L0xbefff364,L0xbefff366]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff368,L0xbefff36a] /\
                        [L0xbefff368,L0xbefff36a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff36c,L0xbefff36e] /\
                        [L0xbefff36c,L0xbefff36e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff370,L0xbefff372] /\
                        [L0xbefff370,L0xbefff372]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff374,L0xbefff376] /\
                        [L0xbefff374,L0xbefff376]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff378,L0xbefff37a] /\
                        [L0xbefff378,L0xbefff37a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff37c,L0xbefff37e] /\
                        [L0xbefff37c,L0xbefff37e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff380,L0xbefff382] /\
                        [L0xbefff380,L0xbefff382]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff384,L0xbefff386] /\
                        [L0xbefff384,L0xbefff386]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff388,L0xbefff38a] /\
                        [L0xbefff388,L0xbefff38a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff38c,L0xbefff38e] /\
                        [L0xbefff38c,L0xbefff38e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff390,L0xbefff392] /\
                        [L0xbefff390,L0xbefff392]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff394,L0xbefff396] /\
                        [L0xbefff394,L0xbefff396]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff398,L0xbefff39a] /\
                        [L0xbefff398,L0xbefff39a]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff39c,L0xbefff39e] /\
                        [L0xbefff39c,L0xbefff39e]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a0,L0xbefff3a2] /\
                        [L0xbefff3a0,L0xbefff3a2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a4,L0xbefff3a6] /\
                        [L0xbefff3a4,L0xbefff3a6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3a8,L0xbefff3aa] /\
                        [L0xbefff3a8,L0xbefff3aa]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3ac,L0xbefff3ae] /\
                        [L0xbefff3ac,L0xbefff3ae]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b0,L0xbefff3b2] /\
                        [L0xbefff3b0,L0xbefff3b2]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b4,L0xbefff3b6] /\
                        [L0xbefff3b4,L0xbefff3b6]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3b8,L0xbefff3ba] /\
                        [L0xbefff3b8,L0xbefff3ba]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3bc,L0xbefff3be] /\
                        [L0xbefff3bc,L0xbefff3be]<s[8@16*Q2,8@16*Q2] /\
   [8@16*NQ2,8@16*NQ2]<s[L0xbefff3c0,L0xbefff3c2] /\
                        [L0xbefff3c0,L0xbefff3c2]<s[8@16*Q2,8@16*Q2]
   prove with [cuts [25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40]]
}

